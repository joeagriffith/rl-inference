09:50:57

=== Loading experiment [device: cuda] ===

{'action_noise': None,
 'action_repeat': 4,
 'batch_size': 50,
 'coverage': False,
 'ensemble_size': 10,
 'env_name': 'DeepMindCatch',
 'epsilon': 1e-08,
 'expl_scale': 0.1,
 'expl_strategy': 'information',
 'grad_clip_norm': 1000,
 'hidden_size': 200,
 'learning_rate': 0.001,
 'logdir': 'cup_catch_OG',
 'max_episode_len': 1000,
 'n_candidates': 500,
 'n_episodes': 50,
 'n_seed_episodes': 5,
 'n_train_epochs': 100,
 'optimisation_iters': 5,
 'plan_horizon': 12,
 'record_every': None,
 'reward_scale': 1.0,
 'seed': 4,
 'strategy': 'information',
 'top_candidates': 50,
 'use_exploration': True,
 'use_mean': False,
 'use_reward': True}

Collected seeds: [5 episodes | 1250 frames]

=== Episode 1 ===
Training on [1250/5000] data points
> Train epoch 20 [ensemble -20.42 | reward 0.07]
> Train epoch 40 [ensemble -28.24 | reward 0.04]
> Train epoch 60 [ensemble -32.03 | reward 0.03]
> Train epoch 80 [ensemble -34.44 | reward 0.02]
> Train epoch 100 [ensemble -36.17 | reward 0.02]
Ensemble loss -36.17 / Reward Loss 0.02

=== Collecting data [1] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 89.00]
Rewards 89.00 / Steps 250.00
Reward stats:
 {'max': '50.10', 'mean': '10.94', 'min': '-0.75', 'std': '8.57'}
Information gain stats:
 {'max': '2.32', 'mean': '1.16', 'min': '0.42', 'std': '0.17'}
Episode time 23.39
Saved _metrics_

=== Episode 2 ===
Training on [1500/6000] data points
> Train epoch 20 [ensemble -18.30 | reward 0.12]
> Train epoch 40 [ensemble -26.37 | reward 0.06]
> Train epoch 60 [ensemble -30.19 | reward 0.04]
> Train epoch 80 [ensemble -32.63 | reward 0.03]
> Train epoch 100 [ensemble -34.39 | reward 0.02]
Ensemble loss -34.39 / Reward Loss 0.02

=== Collecting data [2] ===
> Step 25 [reward 17.00]
> Step 50 [reward 117.00]
> Step 75 [reward 217.00]
> Step 100 [reward 317.00]
> Step 125 [reward 417.00]
> Step 150 [reward 517.00]
> Step 175 [reward 617.00]
> Step 200 [reward 717.00]
> Step 225 [reward 817.00]
> Step 250 [reward 917.00]
Rewards 917.00 / Steps 250.00
Reward stats:
 {'max': '40.10', 'mean': '8.32', 'min': '-1.15', 'std': '6.23'}
Information gain stats:
 {'max': '1.58', 'mean': '0.99', 'min': '0.52', 'std': '0.13'}
Episode time 24.40
Saved _metrics_

=== Episode 3 ===
Training on [1750/7000] data points
> Train epoch 20 [ensemble -19.44 | reward 0.24]
> Train epoch 40 [ensemble -27.10 | reward 0.13]
> Train epoch 60 [ensemble -30.74 | reward 0.08]
> Train epoch 80 [ensemble -33.06 | reward 0.06]
> Train epoch 100 [ensemble -34.73 | reward 0.05]
Ensemble loss -34.73 / Reward Loss 0.05

=== Collecting data [3] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '73.21', 'mean': '11.17', 'min': '-3.16', 'std': '11.42'}
Information gain stats:
 {'max': '1.53', 'mean': '0.92', 'min': '0.52', 'std': '0.13'}
Episode time 25.61
Saved _metrics_

=== Episode 4 ===
Training on [2000/8000] data points
> Train epoch 20 [ensemble -20.24 | reward 0.30]
> Train epoch 40 [ensemble -27.59 | reward 0.16]
> Train epoch 60 [ensemble -31.16 | reward 0.11]
> Train epoch 80 [ensemble -33.43 | reward 0.08]
> Train epoch 100 [ensemble -35.05 | reward 0.06]
Ensemble loss -35.05 / Reward Loss 0.06

=== Collecting data [4] ===
> Step 25 [reward 50.00]
> Step 50 [reward 150.00]
> Step 75 [reward 250.00]
> Step 100 [reward 350.00]
> Step 125 [reward 450.00]
> Step 150 [reward 550.00]
> Step 175 [reward 650.00]
> Step 200 [reward 750.00]
> Step 225 [reward 850.00]
> Step 250 [reward 950.00]
Rewards 950.00 / Steps 250.00
Reward stats:
 {'max': '27.99', 'mean': '7.36', 'min': '-3.22', 'std': '4.56'}
Information gain stats:
 {'max': '1.59', 'mean': '0.99', 'min': '0.47', 'std': '0.14'}
Episode time 26.74
Saved _metrics_

=== Episode 5 ===
Training on [2250/9000] data points
> Train epoch 20 [ensemble -21.36 | reward 0.31]
> Train epoch 40 [ensemble -28.46 | reward 0.16]
> Train epoch 60 [ensemble -31.95 | reward 0.11]
> Train epoch 80 [ensemble -34.14 | reward 0.08]
> Train epoch 100 [ensemble -35.72 | reward 0.07]
Ensemble loss -35.72 / Reward Loss 0.07

=== Collecting data [5] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '32.24', 'mean': '6.30', 'min': '-5.03', 'std': '5.51'}
Information gain stats:
 {'max': '1.61', 'mean': '0.97', 'min': '0.42', 'std': '0.14'}
Episode time 27.86
Saved _metrics_

=== Episode 6 ===
Training on [2500/10000] data points
> Train epoch 20 [ensemble -22.11 | reward 0.27]
> Train epoch 40 [ensemble -28.70 | reward 0.14]
> Train epoch 60 [ensemble -31.98 | reward 0.09]
> Train epoch 80 [ensemble -34.06 | reward 0.07]
> Train epoch 100 [ensemble -35.56 | reward 0.06]
Ensemble loss -35.56 / Reward Loss 0.06

=== Collecting data [6] ===
> Step 25 [reward 89.00]
> Step 50 [reward 189.00]
> Step 75 [reward 289.00]
> Step 100 [reward 389.00]
> Step 125 [reward 489.00]
> Step 150 [reward 589.00]
> Step 175 [reward 689.00]
> Step 200 [reward 789.00]
> Step 225 [reward 889.00]
> Step 250 [reward 989.00]
Rewards 989.00 / Steps 250.00
Reward stats:
 {'max': '29.64', 'mean': '7.64', 'min': '-1.80', 'std': '4.67'}
Information gain stats:
 {'max': '1.57', 'mean': '0.93', 'min': '0.49', 'std': '0.14'}
Episode time 28.87
Saved _metrics_

=== Episode 7 ===
Training on [2750/11000] data points
> Train epoch 20 [ensemble -23.30 | reward 0.27]
> Train epoch 40 [ensemble -29.62 | reward 0.14]
> Train epoch 60 [ensemble -32.78 | reward 0.09]
> Train epoch 80 [ensemble -34.80 | reward 0.07]
> Train epoch 100 [ensemble -36.25 | reward 0.06]
Ensemble loss -36.25 / Reward Loss 0.06

=== Collecting data [7] ===
> Step 25 [reward 0.00]
> Step 50 [reward 85.00]
> Step 75 [reward 185.00]
> Step 100 [reward 285.00]
> Step 125 [reward 385.00]
> Step 150 [reward 485.00]
> Step 175 [reward 585.00]
> Step 200 [reward 685.00]
> Step 225 [reward 785.00]
> Step 250 [reward 885.00]
Rewards 885.00 / Steps 250.00
Reward stats:
 {'max': '29.92', 'mean': '6.87', 'min': '-1.64', 'std': '3.93'}
Information gain stats:
 {'max': '1.66', 'mean': '0.99', 'min': '0.52', 'std': '0.14'}
Episode time 30.12
Saved _metrics_

=== Episode 8 ===
Training on [3000/12000] data points
> Train epoch 20 [ensemble -24.07 | reward 0.29]
> Train epoch 40 [ensemble -30.20 | reward 0.16]
> Train epoch 60 [ensemble -33.24 | reward 0.11]
> Train epoch 80 [ensemble -35.18 | reward 0.08]
> Train epoch 100 [ensemble -36.58 | reward 0.06]
Ensemble loss -36.58 / Reward Loss 0.06

=== Collecting data [8] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 26.00]
> Step 175 [reward 126.00]
> Step 200 [reward 226.00]
> Step 225 [reward 326.00]
> Step 250 [reward 426.00]
Rewards 426.00 / Steps 250.00
Reward stats:
 {'max': '25.03', 'mean': '3.93', 'min': '-7.16', 'std': '4.17'}
Information gain stats:
 {'max': '1.60', 'mean': '0.99', 'min': '0.50', 'std': '0.13'}
Episode time 31.16
Saved _metrics_

=== Episode 9 ===
Training on [3250/13000] data points
> Train epoch 20 [ensemble -24.42 | reward 0.25]
> Train epoch 40 [ensemble -30.40 | reward 0.13]
> Train epoch 60 [ensemble -33.33 | reward 0.09]
> Train epoch 80 [ensemble -35.20 | reward 0.07]
> Train epoch 100 [ensemble -36.57 | reward 0.05]
Ensemble loss -36.57 / Reward Loss 0.05

=== Collecting data [9] ===
> Step 25 [reward 52.00]
> Step 50 [reward 152.00]
> Step 75 [reward 252.00]
> Step 100 [reward 352.00]
> Step 125 [reward 452.00]
> Step 150 [reward 552.00]
> Step 175 [reward 652.00]
> Step 200 [reward 752.00]
> Step 225 [reward 852.00]
> Step 250 [reward 952.00]
Rewards 952.00 / Steps 250.00
Reward stats:
 {'max': '25.82', 'mean': '4.02', 'min': '-2.60', 'std': '3.48'}
Information gain stats:
 {'max': '1.54', 'mean': '0.96', 'min': '0.54', 'std': '0.13'}
Episode time 32.28
Saved _metrics_

=== Episode 10 ===
Training on [3500/14000] data points
> Train epoch 20 [ensemble -25.22 | reward 0.24]
> Train epoch 40 [ensemble -30.91 | reward 0.13]
> Train epoch 60 [ensemble -33.74 | reward 0.09]
> Train epoch 80 [ensemble -35.56 | reward 0.07]
> Train epoch 100 [ensemble -36.88 | reward 0.05]
Ensemble loss -36.88 / Reward Loss 0.05

=== Collecting data [10] ===
> Step 25 [reward 0.00]
> Step 50 [reward 58.00]
> Step 75 [reward 158.00]
> Step 100 [reward 258.00]
> Step 125 [reward 358.00]
> Step 150 [reward 458.00]
> Step 175 [reward 558.00]
> Step 200 [reward 658.00]
> Step 225 [reward 758.00]
> Step 250 [reward 858.00]
Rewards 858.00 / Steps 250.00
Reward stats:
 {'max': '28.04', 'mean': '6.09', 'min': '-3.11', 'std': '4.47'}
Information gain stats:
 {'max': '1.63', 'mean': '0.97', 'min': '0.53', 'std': '0.15'}
Episode time 33.28
Saved _metrics_

=== Episode 11 ===
Training on [3750/15000] data points
> Train epoch 20 [ensemble -25.80 | reward 0.24]
> Train epoch 40 [ensemble -31.34 | reward 0.13]
> Train epoch 60 [ensemble -34.11 | reward 0.09]
> Train epoch 80 [ensemble -35.88 | reward 0.07]
> Train epoch 100 [ensemble -37.17 | reward 0.05]
Ensemble loss -37.17 / Reward Loss 0.05

=== Collecting data [11] ===
> Step 25 [reward 72.00]
> Step 50 [reward 172.00]
> Step 75 [reward 272.00]
> Step 100 [reward 372.00]
> Step 125 [reward 472.00]
> Step 150 [reward 572.00]
> Step 175 [reward 672.00]
> Step 200 [reward 772.00]
> Step 225 [reward 872.00]
> Step 250 [reward 972.00]
Rewards 972.00 / Steps 250.00
Reward stats:
 {'max': '31.91', 'mean': '5.98', 'min': '-2.33', 'std': '4.79'}
Information gain stats:
 {'max': '1.53', 'mean': '0.98', 'min': '0.50', 'std': '0.14'}
Episode time 34.92
Saved _metrics_

=== Episode 12 ===
Training on [4000/16000] data points
> Train epoch 20 [ensemble -26.76 | reward 0.26]
> Train epoch 40 [ensemble -31.93 | reward 0.14]
> Train epoch 60 [ensemble -34.57 | reward 0.09]
> Train epoch 80 [ensemble -36.28 | reward 0.07]
> Train epoch 100 [ensemble -37.53 | reward 0.06]
Ensemble loss -37.53 / Reward Loss 0.06

=== Collecting data [12] ===
> Step 25 [reward 46.00]
> Step 50 [reward 146.00]
> Step 75 [reward 246.00]
> Step 100 [reward 346.00]
> Step 125 [reward 446.00]
> Step 150 [reward 546.00]
> Step 175 [reward 646.00]
> Step 200 [reward 746.00]
> Step 225 [reward 846.00]
> Step 250 [reward 946.00]
Rewards 946.00 / Steps 250.00
Reward stats:
 {'max': '36.34', 'mean': '7.76', 'min': '-4.63', 'std': '5.86'}
Information gain stats:
 {'max': '1.59', 'mean': '0.96', 'min': '0.41', 'std': '0.15'}
Episode time 35.63
Saved _metrics_

=== Episode 13 ===
Training on [4250/17000] data points
> Train epoch 20 [ensemble -27.50 | reward 0.24]
> Train epoch 40 [ensemble -32.51 | reward 0.13]
> Train epoch 60 [ensemble -35.06 | reward 0.09]
> Train epoch 80 [ensemble -36.70 | reward 0.06]
> Train epoch 100 [ensemble -37.91 | reward 0.05]
Ensemble loss -37.91 / Reward Loss 0.05

=== Collecting data [13] ===
> Step 25 [reward 89.00]
> Step 50 [reward 189.00]
> Step 75 [reward 289.00]
> Step 100 [reward 389.00]
> Step 125 [reward 489.00]
> Step 150 [reward 589.00]
> Step 175 [reward 689.00]
> Step 200 [reward 789.00]
> Step 225 [reward 889.00]
> Step 250 [reward 989.00]
Rewards 989.00 / Steps 250.00
Reward stats:
 {'max': '30.14', 'mean': '7.68', 'min': '-4.51', 'std': '5.57'}
Information gain stats:
 {'max': '1.59', 'mean': '0.97', 'min': '0.53', 'std': '0.14'}
Episode time 37.23
Saved _metrics_

=== Episode 14 ===
Training on [4500/18000] data points
> Train epoch 20 [ensemble -28.45 | reward 0.23]
> Train epoch 40 [ensemble -33.24 | reward 0.12]
> Train epoch 60 [ensemble -35.68 | reward 0.08]
> Train epoch 80 [ensemble -37.25 | reward 0.06]
> Train epoch 100 [ensemble -38.40 | reward 0.05]
Ensemble loss -38.40 / Reward Loss 0.05

=== Collecting data [14] ===
> Step 25 [reward 96.00]
> Step 50 [reward 196.00]
> Step 75 [reward 296.00]
> Step 100 [reward 396.00]
> Step 125 [reward 496.00]
> Step 150 [reward 596.00]
> Step 175 [reward 696.00]
> Step 200 [reward 796.00]
> Step 225 [reward 896.00]
> Step 250 [reward 996.00]
Rewards 996.00 / Steps 250.00
Reward stats:
 {'max': '29.87', 'mean': '6.39', 'min': '-1.61', 'std': '4.73'}
Information gain stats:
 {'max': '1.62', 'mean': '0.99', 'min': '0.50', 'std': '0.13'}
Episode time 37.54
Saved _metrics_

=== Episode 15 ===
Training on [4750/19000] data points
> Train epoch 20 [ensemble -29.18 | reward 0.23]
> Train epoch 40 [ensemble -33.81 | reward 0.12]
> Train epoch 60 [ensemble -36.15 | reward 0.08]
> Train epoch 80 [ensemble -37.67 | reward 0.06]
> Train epoch 100 [ensemble -38.79 | reward 0.05]
Ensemble loss -38.79 / Reward Loss 0.05

=== Collecting data [15] ===
> Step 25 [reward 41.00]
> Step 50 [reward 141.00]
> Step 75 [reward 241.00]
> Step 100 [reward 341.00]
> Step 125 [reward 441.00]
> Step 150 [reward 541.00]
> Step 175 [reward 641.00]
> Step 200 [reward 741.00]
> Step 225 [reward 841.00]
> Step 250 [reward 941.00]
Rewards 941.00 / Steps 250.00
Reward stats:
 {'max': '36.88', 'mean': '7.61', 'min': '-4.24', 'std': '5.81'}
Information gain stats:
 {'max': '1.65', 'mean': '0.98', 'min': '0.51', 'std': '0.15'}
Episode time 38.26
Saved _metrics_

=== Episode 16 ===
Training on [5000/20000] data points
> Train epoch 20 [ensemble -29.71 | reward 0.21]
> Train epoch 40 [ensemble -34.19 | reward 0.11]
> Train epoch 60 [ensemble -36.48 | reward 0.07]
> Train epoch 80 [ensemble -37.97 | reward 0.06]
> Train epoch 100 [ensemble -39.07 | reward 0.04]
Ensemble loss -39.07 / Reward Loss 0.04

=== Collecting data [16] ===
> Step 25 [reward 56.00]
> Step 50 [reward 156.00]
> Step 75 [reward 256.00]
> Step 100 [reward 356.00]
> Step 125 [reward 456.00]
> Step 150 [reward 556.00]
> Step 175 [reward 656.00]
> Step 200 [reward 756.00]
> Step 225 [reward 856.00]
> Step 250 [reward 956.00]
Rewards 956.00 / Steps 250.00
Reward stats:
 {'max': '35.04', 'mean': '8.49', 'min': '-6.99', 'std': '5.98'}
Information gain stats:
 {'max': '1.72', 'mean': '1.00', 'min': '0.54', 'std': '0.15'}
Episode time 39.34
Saved _metrics_

=== Episode 17 ===
Training on [5250/21000] data points
> Train epoch 20 [ensemble -30.41 | reward 0.20]
> Train epoch 40 [ensemble -34.70 | reward 0.10]
> Train epoch 60 [ensemble -36.89 | reward 0.07]
> Train epoch 80 [ensemble -38.32 | reward 0.05]
> Train epoch 100 [ensemble -39.37 | reward 0.04]
Ensemble loss -39.37 / Reward Loss 0.04

=== Collecting data [17] ===
> Step 25 [reward 0.00]
> Step 50 [reward 70.00]
> Step 75 [reward 170.00]
> Step 100 [reward 270.00]
> Step 125 [reward 370.00]
> Step 150 [reward 470.00]
> Step 175 [reward 570.00]
> Step 200 [reward 670.00]
> Step 225 [reward 770.00]
> Step 250 [reward 870.00]
Rewards 870.00 / Steps 250.00
Reward stats:
 {'max': '32.71', 'mean': '7.72', 'min': '-2.51', 'std': '5.58'}
Information gain stats:
 {'max': '1.71', 'mean': '1.02', 'min': '0.53', 'std': '0.16'}
Episode time 40.47
Saved _metrics_

=== Episode 18 ===
Training on [5500/22000] data points
> Train epoch 20 [ensemble -31.16 | reward 0.22]
> Train epoch 40 [ensemble -35.27 | reward 0.12]
> Train epoch 60 [ensemble -37.34 | reward 0.08]
> Train epoch 80 [ensemble -38.69 | reward 0.06]
> Train epoch 100 [ensemble -39.69 | reward 0.05]
Ensemble loss -39.69 / Reward Loss 0.05

=== Collecting data [18] ===
> Step 25 [reward 22.00]
> Step 50 [reward 96.00]
> Step 75 [reward 196.00]
> Step 100 [reward 296.00]
> Step 125 [reward 396.00]
> Step 150 [reward 496.00]
> Step 175 [reward 596.00]
> Step 200 [reward 696.00]
> Step 225 [reward 796.00]
> Step 250 [reward 896.00]
Rewards 896.00 / Steps 250.00
Reward stats:
 {'max': '31.18', 'mean': '7.04', 'min': '-4.75', 'std': '4.89'}
Information gain stats:
 {'max': '1.64', 'mean': '1.03', 'min': '0.50', 'std': '0.15'}
Episode time 41.71
Saved _metrics_

=== Episode 19 ===
Training on [5750/23000] data points
> Train epoch 20 [ensemble -31.46 | reward 0.20]
> Train epoch 40 [ensemble -35.47 | reward 0.10]
> Train epoch 60 [ensemble -37.50 | reward 0.07]
> Train epoch 80 [ensemble -38.83 | reward 0.05]
> Train epoch 100 [ensemble -39.82 | reward 0.04]
Ensemble loss -39.82 / Reward Loss 0.04

=== Collecting data [19] ===
> Step 25 [reward 18.00]
> Step 50 [reward 118.00]
> Step 75 [reward 218.00]
> Step 100 [reward 318.00]
> Step 125 [reward 418.00]
> Step 150 [reward 518.00]
> Step 175 [reward 618.00]
> Step 200 [reward 718.00]
> Step 225 [reward 818.00]
> Step 250 [reward 918.00]
Rewards 918.00 / Steps 250.00
Reward stats:
 {'max': '26.89', 'mean': '6.00', 'min': '-1.87', 'std': '4.57'}
Information gain stats:
 {'max': '1.64', 'mean': '1.04', 'min': '0.53', 'std': '0.14'}
Episode time 42.73
Saved _metrics_

=== Episode 20 ===
Training on [6000/24000] data points
> Train epoch 20 [ensemble -31.84 | reward 0.18]
> Train epoch 40 [ensemble -35.74 | reward 0.10]
> Train epoch 60 [ensemble -37.74 | reward 0.06]
> Train epoch 80 [ensemble -39.05 | reward 0.05]
> Train epoch 100 [ensemble -40.03 | reward 0.04]
Ensemble loss -40.03 / Reward Loss 0.04

=== Collecting data [20] ===
> Step 25 [reward 5.00]
> Step 50 [reward 100.00]
> Step 75 [reward 185.00]
> Step 100 [reward 282.00]
> Step 125 [reward 359.00]
> Step 150 [reward 438.00]
> Step 175 [reward 516.00]
> Step 200 [reward 605.00]
> Step 225 [reward 694.00]
> Step 250 [reward 780.00]
Rewards 780.00 / Steps 250.00
Reward stats:
 {'max': '27.05', 'mean': '7.33', 'min': '-3.73', 'std': '4.34'}
Information gain stats:
 {'max': '1.70', 'mean': '1.14', 'min': '0.63', 'std': '0.12'}
Episode time 43.84
Saved _metrics_

=== Episode 21 ===
Training on [6250/25000] data points
> Train epoch 20 [ensemble -31.63 | reward 0.20]
> Train epoch 40 [ensemble -35.58 | reward 0.11]
> Train epoch 60 [ensemble -37.57 | reward 0.07]
> Train epoch 80 [ensemble -38.89 | reward 0.05]
> Train epoch 100 [ensemble -39.87 | reward 0.04]
Ensemble loss -39.87 / Reward Loss 0.04

=== Collecting data [21] ===
> Step 25 [reward 0.00]
> Step 50 [reward 7.00]
> Step 75 [reward 107.00]
> Step 100 [reward 207.00]
> Step 125 [reward 307.00]
> Step 150 [reward 407.00]
> Step 175 [reward 507.00]
> Step 200 [reward 607.00]
> Step 225 [reward 707.00]
> Step 250 [reward 807.00]
Rewards 807.00 / Steps 250.00
Reward stats:
 {'max': '46.01', 'mean': '11.55', 'min': '-3.65', 'std': '8.76'}
Information gain stats:
 {'max': '1.71', 'mean': '0.96', 'min': '0.36', 'std': '0.22'}
Episode time 44.76
Saved _metrics_

=== Episode 22 ===
Training on [6500/26000] data points
> Train epoch 20 [ensemble -31.88 | reward 0.18]
> Train epoch 40 [ensemble -35.75 | reward 0.10]
> Train epoch 60 [ensemble -37.68 | reward 0.06]
> Train epoch 80 [ensemble -38.96 | reward 0.05]
> Train epoch 100 [ensemble -39.91 | reward 0.04]
Ensemble loss -39.91 / Reward Loss 0.04

=== Collecting data [22] ===
> Step 25 [reward 7.00]
> Step 50 [reward 107.00]
> Step 75 [reward 207.00]
> Step 100 [reward 307.00]
> Step 125 [reward 407.00]
> Step 150 [reward 507.00]
> Step 175 [reward 607.00]
> Step 200 [reward 707.00]
> Step 225 [reward 807.00]
> Step 250 [reward 907.00]
Rewards 907.00 / Steps 250.00
Reward stats:
 {'max': '49.24', 'mean': '13.19', 'min': '-1.79', 'std': '8.55'}
Information gain stats:
 {'max': '1.65', 'mean': '0.97', 'min': '0.36', 'std': '0.21'}
Episode time 45.10
Saved _metrics_

=== Episode 23 ===
Training on [6750/27000] data points
> Train epoch 20 [ensemble -31.89 | reward 0.20]
> Train epoch 40 [ensemble -35.91 | reward 0.11]
> Train epoch 60 [ensemble -37.88 | reward 0.07]
> Train epoch 80 [ensemble -39.16 | reward 0.05]
> Train epoch 100 [ensemble -40.11 | reward 0.04]
Ensemble loss -40.11 / Reward Loss 0.04

=== Collecting data [23] ===
> Step 25 [reward 89.00]
> Step 50 [reward 189.00]
> Step 75 [reward 289.00]
> Step 100 [reward 389.00]
> Step 125 [reward 489.00]
> Step 150 [reward 589.00]
> Step 175 [reward 689.00]
> Step 200 [reward 789.00]
> Step 225 [reward 889.00]
> Step 250 [reward 989.00]
Rewards 989.00 / Steps 250.00
Reward stats:
 {'max': '48.33', 'mean': '14.87', 'min': '-2.26', 'std': '9.28'}
Information gain stats:
 {'max': '1.66', 'mean': '0.91', 'min': '0.32', 'std': '0.22'}
Episode time 46.41
Saved _metrics_

=== Episode 24 ===
Training on [7000/28000] data points
> Train epoch 20 [ensemble -32.32 | reward 0.19]
> Train epoch 40 [ensemble -36.29 | reward 0.10]
> Train epoch 60 [ensemble -38.18 | reward 0.07]
> Train epoch 80 [ensemble -39.41 | reward 0.05]
> Train epoch 100 [ensemble -40.33 | reward 0.04]
Ensemble loss -40.33 / Reward Loss 0.04

=== Collecting data [24] ===
> Step 25 [reward 18.00]
> Step 50 [reward 118.00]
> Step 75 [reward 218.00]
> Step 100 [reward 318.00]
> Step 125 [reward 418.00]
> Step 150 [reward 518.00]
> Step 175 [reward 618.00]
> Step 200 [reward 718.00]
> Step 225 [reward 818.00]
> Step 250 [reward 918.00]
Rewards 918.00 / Steps 250.00
Reward stats:
 {'max': '49.64', 'mean': '15.77', 'min': '-1.56', 'std': '10.60'}
Information gain stats:
 {'max': '1.79', 'mean': '0.92', 'min': '0.30', 'std': '0.23'}
Episode time 47.05
Saved _metrics_

=== Episode 25 ===
Training on [7250/29000] data points
> Train epoch 20 [ensemble -32.70 | reward 0.20]
> Train epoch 40 [ensemble -36.57 | reward 0.10]
> Train epoch 60 [ensemble -38.42 | reward 0.07]
> Train epoch 80 [ensemble -39.62 | reward 0.05]
> Train epoch 100 [ensemble -40.51 | reward 0.04]
Ensemble loss -40.51 / Reward Loss 0.04

=== Collecting data [25] ===
> Step 25 [reward 84.00]
> Step 50 [reward 184.00]
> Step 75 [reward 284.00]
> Step 100 [reward 384.00]
> Step 125 [reward 484.00]
> Step 150 [reward 584.00]
> Step 175 [reward 684.00]
> Step 200 [reward 784.00]
> Step 225 [reward 884.00]
> Step 250 [reward 984.00]
Rewards 984.00 / Steps 250.00
Reward stats:
 {'max': '52.41', 'mean': '17.97', 'min': '-0.79', 'std': '10.49'}
Information gain stats:
 {'max': '1.76', 'mean': '0.92', 'min': '0.33', 'std': '0.23'}
Episode time 48.02
Saved _metrics_

=== Episode 26 ===
Training on [7500/30000] data points
> Train epoch 20 [ensemble -33.13 | reward 0.19]
> Train epoch 40 [ensemble -36.89 | reward 0.10]
> Train epoch 60 [ensemble -38.68 | reward 0.07]
> Train epoch 80 [ensemble -39.84 | reward 0.05]
> Train epoch 100 [ensemble -40.70 | reward 0.04]
Ensemble loss -40.70 / Reward Loss 0.04

=== Collecting data [26] ===
> Step 25 [reward 95.00]
> Step 50 [reward 195.00]
> Step 75 [reward 295.00]
> Step 100 [reward 395.00]
> Step 125 [reward 495.00]
> Step 150 [reward 595.00]
> Step 175 [reward 695.00]
> Step 200 [reward 795.00]
> Step 225 [reward 895.00]
> Step 250 [reward 995.00]
Rewards 995.00 / Steps 250.00
Reward stats:
 {'max': '57.23', 'mean': '16.72', 'min': '-1.26', 'std': '11.51'}
Information gain stats:
 {'max': '1.69', 'mean': '0.94', 'min': '0.36', 'std': '0.22'}
Episode time 48.98
Saved _metrics_

=== Episode 27 ===
Training on [7750/31000] data points
> Train epoch 20 [ensemble -33.35 | reward 0.19]
> Train epoch 40 [ensemble -37.06 | reward 0.10]
> Train epoch 60 [ensemble -38.82 | reward 0.07]
> Train epoch 80 [ensemble -39.97 | reward 0.05]
> Train epoch 100 [ensemble -40.83 | reward 0.04]
Ensemble loss -40.83 / Reward Loss 0.04

=== Collecting data [27] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 20.00]
> Step 200 [reward 120.00]
> Step 225 [reward 220.00]
> Step 250 [reward 320.00]
Rewards 320.00 / Steps 250.00
Reward stats:
 {'max': '47.46', 'mean': '8.77', 'min': '-6.18', 'std': '9.67'}
Information gain stats:
 {'max': '1.73', 'mean': '1.09', 'min': '0.30', 'std': '0.21'}
Episode time 50.45
Saved _metrics_

=== Episode 28 ===
Training on [8000/32000] data points
> Train epoch 20 [ensemble -33.36 | reward 0.19]
> Train epoch 40 [ensemble -36.99 | reward 0.10]
> Train epoch 60 [ensemble -38.75 | reward 0.07]
> Train epoch 80 [ensemble -39.91 | reward 0.05]
> Train epoch 100 [ensemble -40.77 | reward 0.04]
Ensemble loss -40.77 / Reward Loss 0.04

=== Collecting data [28] ===
> Step 25 [reward 89.00]
> Step 50 [reward 189.00]
> Step 75 [reward 289.00]
> Step 100 [reward 389.00]
> Step 125 [reward 489.00]
> Step 150 [reward 589.00]
> Step 175 [reward 689.00]
> Step 200 [reward 789.00]
> Step 225 [reward 889.00]
> Step 250 [reward 989.00]
Rewards 989.00 / Steps 250.00
Reward stats:
 {'max': '46.91', 'mean': '14.32', 'min': '-1.10', 'std': '8.84'}
Information gain stats:
 {'max': '1.67', 'mean': '0.94', 'min': '0.32', 'std': '0.22'}
Episode time 51.22
Saved _metrics_

=== Episode 29 ===
Training on [8250/33000] data points
> Train epoch 20 [ensemble -33.70 | reward 0.19]
> Train epoch 40 [ensemble -37.25 | reward 0.10]
> Train epoch 60 [ensemble -38.95 | reward 0.07]
> Train epoch 80 [ensemble -40.06 | reward 0.05]
> Train epoch 100 [ensemble -40.89 | reward 0.04]
Ensemble loss -40.89 / Reward Loss 0.04

=== Collecting data [29] ===
> Step 25 [reward 52.00]
> Step 50 [reward 152.00]
> Step 75 [reward 252.00]
> Step 100 [reward 352.00]
> Step 125 [reward 452.00]
> Step 150 [reward 552.00]
> Step 175 [reward 652.00]
> Step 200 [reward 752.00]
> Step 225 [reward 852.00]
> Step 250 [reward 952.00]
Rewards 952.00 / Steps 250.00
Reward stats:
 {'max': '44.93', 'mean': '13.90', 'min': '-3.03', 'std': '8.57'}
Information gain stats:
 {'max': '1.70', 'mean': '0.93', 'min': '0.29', 'std': '0.23'}
Episode time 52.29
Saved _metrics_

=== Episode 30 ===
Training on [8500/34000] data points
> Train epoch 20 [ensemble -33.98 | reward 0.18]
> Train epoch 40 [ensemble -37.48 | reward 0.09]
> Train epoch 60 [ensemble -39.16 | reward 0.06]
> Train epoch 80 [ensemble -40.25 | reward 0.05]
> Train epoch 100 [ensemble -41.07 | reward 0.04]
Ensemble loss -41.07 / Reward Loss 0.04

=== Collecting data [30] ===
> Step 25 [reward 89.00]
> Step 50 [reward 189.00]
> Step 75 [reward 289.00]
> Step 100 [reward 389.00]
> Step 125 [reward 489.00]
> Step 150 [reward 589.00]
> Step 175 [reward 689.00]
> Step 200 [reward 789.00]
> Step 225 [reward 889.00]
> Step 250 [reward 989.00]
Rewards 989.00 / Steps 250.00
Reward stats:
 {'max': '49.47', 'mean': '14.69', 'min': '-1.89', 'std': '9.71'}
Information gain stats:
 {'max': '1.74', 'mean': '0.95', 'min': '0.29', 'std': '0.25'}
Episode time 53.39
Saved _metrics_

=== Episode 31 ===
Training on [8750/35000] data points
> Train epoch 20 [ensemble -34.25 | reward 0.18]
> Train epoch 40 [ensemble -37.70 | reward 0.10]
> Train epoch 60 [ensemble -39.35 | reward 0.07]
> Train epoch 80 [ensemble -40.43 | reward 0.05]
> Train epoch 100 [ensemble -41.23 | reward 0.04]
Ensemble loss -41.23 / Reward Loss 0.04

=== Collecting data [31] ===
> Step 25 [reward 90.00]
> Step 50 [reward 190.00]
> Step 75 [reward 290.00]
> Step 100 [reward 390.00]
> Step 125 [reward 490.00]
> Step 150 [reward 590.00]
> Step 175 [reward 690.00]
> Step 200 [reward 790.00]
> Step 225 [reward 890.00]
> Step 250 [reward 990.00]
Rewards 990.00 / Steps 250.00
Reward stats:
 {'max': '44.75', 'mean': '14.95', 'min': '-0.46', 'std': '8.83'}
Information gain stats:
 {'max': '1.76', 'mean': '0.96', 'min': '0.32', 'std': '0.24'}
Episode time 54.67
Saved _metrics_

=== Episode 32 ===
Training on [9000/36000] data points
> Train epoch 20 [ensemble -34.65 | reward 0.17]
> Train epoch 40 [ensemble -37.99 | reward 0.09]
> Train epoch 60 [ensemble -39.59 | reward 0.06]
> Train epoch 80 [ensemble -40.65 | reward 0.05]
> Train epoch 100 [ensemble -41.43 | reward 0.04]
Ensemble loss -41.43 / Reward Loss 0.04

=== Collecting data [32] ===
> Step 25 [reward 89.00]
> Step 50 [reward 189.00]
> Step 75 [reward 289.00]
> Step 100 [reward 389.00]
> Step 125 [reward 489.00]
> Step 150 [reward 589.00]
> Step 175 [reward 689.00]
> Step 200 [reward 789.00]
> Step 225 [reward 889.00]
> Step 250 [reward 989.00]
Rewards 989.00 / Steps 250.00
Reward stats:
 {'max': '47.78', 'mean': '16.86', 'min': '-0.74', 'std': '9.30'}
Information gain stats:
 {'max': '1.68', 'mean': '0.97', 'min': '0.35', 'std': '0.23'}
Episode time 55.57
Saved _metrics_

=== Episode 33 ===
Training on [9250/37000] data points
> Train epoch 20 [ensemble -34.90 | reward 0.17]
> Train epoch 40 [ensemble -38.20 | reward 0.09]
> Train epoch 60 [ensemble -39.77 | reward 0.06]
> Train epoch 80 [ensemble -40.80 | reward 0.05]
> Train epoch 100 [ensemble -41.56 | reward 0.04]
Ensemble loss -41.56 / Reward Loss 0.04

=== Collecting data [33] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 74.00]
> Step 125 [reward 174.00]
> Step 150 [reward 274.00]
> Step 175 [reward 374.00]
> Step 200 [reward 474.00]
> Step 225 [reward 574.00]
> Step 250 [reward 674.00]
Rewards 674.00 / Steps 250.00
Reward stats:
 {'max': '45.59', 'mean': '11.10', 'min': '-5.39', 'std': '9.29'}
Information gain stats:
 {'max': '1.77', 'mean': '1.02', 'min': '0.32', 'std': '0.23'}
Episode time 56.98
Saved _metrics_

=== Episode 34 ===
Training on [9500/38000] data points
> Train epoch 20 [ensemble -35.06 | reward 0.16]
> Train epoch 40 [ensemble -38.27 | reward 0.09]
> Train epoch 60 [ensemble -39.81 | reward 0.06]
> Train epoch 80 [ensemble -40.81 | reward 0.05]
> Train epoch 100 [ensemble -41.56 | reward 0.04]
Ensemble loss -41.56 / Reward Loss 0.04

=== Collecting data [34] ===
> Step 25 [reward 90.00]
> Step 50 [reward 190.00]
> Step 75 [reward 290.00]
> Step 100 [reward 390.00]
> Step 125 [reward 490.00]
> Step 150 [reward 590.00]
> Step 175 [reward 690.00]
> Step 200 [reward 790.00]
> Step 225 [reward 890.00]
> Step 250 [reward 990.00]
Rewards 990.00 / Steps 250.00
Reward stats:
 {'max': '48.07', 'mean': '15.91', 'min': '-1.03', 'std': '9.52'}
Information gain stats:
 {'max': '1.68', 'mean': '0.95', 'min': '0.32', 'std': '0.23'}
Episode time 57.80
Saved _metrics_

=== Episode 35 ===
Training on [9750/39000] data points
> Train epoch 20 [ensemble -35.15 | reward 0.16]
> Train epoch 40 [ensemble -38.36 | reward 0.08]
> Train epoch 60 [ensemble -39.88 | reward 0.06]
> Train epoch 80 [ensemble -40.88 | reward 0.04]
> Train epoch 100 [ensemble -41.62 | reward 0.03]
Ensemble loss -41.62 / Reward Loss 0.03

=== Collecting data [35] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 71.00]
> Step 100 [reward 171.00]
> Step 125 [reward 271.00]
> Step 150 [reward 371.00]
> Step 175 [reward 471.00]
> Step 200 [reward 571.00]
> Step 225 [reward 671.00]
> Step 250 [reward 771.00]
Rewards 771.00 / Steps 250.00
Reward stats:
 {'max': '45.76', 'mean': '12.51', 'min': '-5.70', 'std': '9.72'}
Information gain stats:
 {'max': '1.66', 'mean': '1.01', 'min': '0.34', 'std': '0.22'}
Episode time 58.74
Saved _metrics_

=== Episode 36 ===
Training on [10000/40000] data points
> Train epoch 20 [ensemble -35.26 | reward 0.16]
> Train epoch 40 [ensemble -38.46 | reward 0.08]
> Train epoch 60 [ensemble -39.97 | reward 0.06]
> Train epoch 80 [ensemble -40.97 | reward 0.04]
> Train epoch 100 [ensemble -41.70 | reward 0.04]
Ensemble loss -41.70 / Reward Loss 0.04

=== Collecting data [36] ===
> Step 25 [reward 18.00]
> Step 50 [reward 118.00]
> Step 75 [reward 218.00]
> Step 100 [reward 318.00]
> Step 125 [reward 418.00]
> Step 150 [reward 518.00]
> Step 175 [reward 618.00]
> Step 200 [reward 718.00]
> Step 225 [reward 818.00]
> Step 250 [reward 918.00]
Rewards 918.00 / Steps 250.00
Reward stats:
 {'max': '47.37', 'mean': '16.57', 'min': '-1.59', 'std': '9.62'}
Information gain stats:
 {'max': '1.69', 'mean': '0.98', 'min': '0.31', 'std': '0.23'}
Episode time 60.16
Saved _metrics_

=== Episode 37 ===
Training on [10250/41000] data points
> Train epoch 20 [ensemble -35.48 | reward 0.15]
> Train epoch 40 [ensemble -38.63 | reward 0.08]
> Train epoch 60 [ensemble -40.14 | reward 0.06]
> Train epoch 80 [ensemble -41.12 | reward 0.04]
> Train epoch 100 [ensemble -41.85 | reward 0.03]
Ensemble loss -41.85 / Reward Loss 0.03

=== Collecting data [37] ===
> Step 25 [reward 92.00]
> Step 50 [reward 192.00]
> Step 75 [reward 292.00]
> Step 100 [reward 392.00]
> Step 125 [reward 492.00]
> Step 150 [reward 592.00]
> Step 175 [reward 692.00]
> Step 200 [reward 792.00]
> Step 225 [reward 892.00]
> Step 250 [reward 992.00]
Rewards 992.00 / Steps 250.00
Reward stats:
 {'max': '47.30', 'mean': '14.69', 'min': '-2.42', 'std': '8.61'}
Information gain stats:
 {'max': '1.74', 'mean': '0.99', 'min': '0.33', 'std': '0.23'}
Episode time 60.99
Saved _metrics_

=== Episode 38 ===
Training on [10500/42000] data points
> Train epoch 20 [ensemble -35.78 | reward 0.15]
> Train epoch 40 [ensemble -38.83 | reward 0.08]
> Train epoch 60 [ensemble -40.29 | reward 0.05]
> Train epoch 80 [ensemble -41.24 | reward 0.04]
> Train epoch 100 [ensemble -41.95 | reward 0.03]
Ensemble loss -41.95 / Reward Loss 0.03

=== Collecting data [38] ===
> Step 25 [reward 18.00]
> Step 50 [reward 118.00]
> Step 75 [reward 218.00]
> Step 100 [reward 318.00]
> Step 125 [reward 418.00]
> Step 150 [reward 518.00]
> Step 175 [reward 618.00]
> Step 200 [reward 718.00]
> Step 225 [reward 818.00]
> Step 250 [reward 918.00]
Rewards 918.00 / Steps 250.00
Reward stats:
 {'max': '45.91', 'mean': '14.45', 'min': '-4.61', 'std': '9.10'}
Information gain stats:
 {'max': '1.73', 'mean': '0.96', 'min': '0.31', 'std': '0.23'}
Episode time 62.01
Saved _metrics_

=== Episode 39 ===
Training on [10750/43000] data points
> Train epoch 20 [ensemble -35.87 | reward 0.15]
> Train epoch 40 [ensemble -38.91 | reward 0.08]
> Train epoch 60 [ensemble -40.36 | reward 0.05]
> Train epoch 80 [ensemble -41.31 | reward 0.04]
> Train epoch 100 [ensemble -42.01 | reward 0.03]
Ensemble loss -42.01 / Reward Loss 0.03

=== Collecting data [39] ===
> Step 25 [reward 88.00]
> Step 50 [reward 188.00]
> Step 75 [reward 288.00]
> Step 100 [reward 388.00]
> Step 125 [reward 488.00]
> Step 150 [reward 588.00]
> Step 175 [reward 688.00]
> Step 200 [reward 788.00]
> Step 225 [reward 888.00]
> Step 250 [reward 988.00]
Rewards 988.00 / Steps 250.00
Reward stats:
 {'max': '47.23', 'mean': '15.48', 'min': '-2.04', 'std': '8.36'}
Information gain stats:
 {'max': '1.76', 'mean': '1.00', 'min': '0.34', 'std': '0.22'}
Episode time 62.96
Saved _metrics_

=== Episode 40 ===
Training on [11000/44000] data points
> Train epoch 20 [ensemble -36.06 | reward 0.14]
> Train epoch 40 [ensemble -39.08 | reward 0.08]
> Train epoch 60 [ensemble -40.51 | reward 0.05]
> Train epoch 80 [ensemble -41.45 | reward 0.04]
> Train epoch 100 [ensemble -42.15 | reward 0.03]
Ensemble loss -42.15 / Reward Loss 0.03

=== Collecting data [40] ===
> Step 25 [reward 91.00]
> Step 50 [reward 191.00]
> Step 75 [reward 291.00]
> Step 100 [reward 391.00]
> Step 125 [reward 491.00]
> Step 150 [reward 591.00]
> Step 175 [reward 691.00]
> Step 200 [reward 791.00]
> Step 225 [reward 891.00]
> Step 250 [reward 991.00]
Rewards 991.00 / Steps 250.00
Reward stats:
 {'max': '46.31', 'mean': '16.98', 'min': '-1.15', 'std': '9.29'}
Information gain stats:
 {'max': '1.74', 'mean': '0.97', 'min': '0.30', 'std': '0.24'}
Episode time 63.93
Saved _metrics_

=== Episode 41 ===
Training on [11250/45000] data points
> Train epoch 20 [ensemble -36.34 | reward 0.14]
> Train epoch 40 [ensemble -39.26 | reward 0.07]
> Train epoch 60 [ensemble -40.65 | reward 0.05]
> Train epoch 80 [ensemble -41.56 | reward 0.04]
> Train epoch 100 [ensemble -42.24 | reward 0.03]
Ensemble loss -42.24 / Reward Loss 0.03

=== Collecting data [41] ===
> Step 25 [reward 58.00]
> Step 50 [reward 158.00]
> Step 75 [reward 258.00]
> Step 100 [reward 358.00]
> Step 125 [reward 458.00]
> Step 150 [reward 558.00]
> Step 175 [reward 658.00]
> Step 200 [reward 758.00]
> Step 225 [reward 858.00]
> Step 250 [reward 958.00]
Rewards 958.00 / Steps 250.00
Reward stats:
 {'max': '44.89', 'mean': '16.46', 'min': '-1.32', 'std': '8.75'}
Information gain stats:
 {'max': '1.65', 'mean': '0.97', 'min': '0.29', 'std': '0.22'}
Episode time 65.34
Saved _metrics_

=== Episode 42 ===
Training on [11500/46000] data points
> Train epoch 20 [ensemble -36.45 | reward 0.15]
> Train epoch 40 [ensemble -39.39 | reward 0.08]
> Train epoch 60 [ensemble -40.79 | reward 0.06]
> Train epoch 80 [ensemble -41.71 | reward 0.04]
> Train epoch 100 [ensemble -42.38 | reward 0.03]
Ensemble loss -42.38 / Reward Loss 0.03

=== Collecting data [42] ===
> Step 25 [reward 0.00]
> Step 50 [reward 58.00]
> Step 75 [reward 158.00]
> Step 100 [reward 258.00]
> Step 125 [reward 358.00]
> Step 150 [reward 458.00]
> Step 175 [reward 558.00]
> Step 200 [reward 658.00]
> Step 225 [reward 758.00]
> Step 250 [reward 858.00]
Rewards 858.00 / Steps 250.00
Reward stats:
 {'max': '46.39', 'mean': '14.55', 'min': '-5.21', 'std': '9.41'}
Information gain stats:
 {'max': '1.74', 'mean': '1.02', 'min': '0.34', 'std': '0.23'}
Episode time 68.14
Saved _metrics_

=== Episode 43 ===
Training on [11750/47000] data points
> Train epoch 20 [ensemble -36.69 | reward 0.14]
> Train epoch 40 [ensemble -39.49 | reward 0.07]
> Train epoch 60 [ensemble -40.84 | reward 0.05]
> Train epoch 80 [ensemble -41.73 | reward 0.04]
> Train epoch 100 [ensemble -42.39 | reward 0.03]
Ensemble loss -42.39 / Reward Loss 0.03

=== Collecting data [43] ===
> Step 25 [reward 89.00]
> Step 50 [reward 189.00]
> Step 75 [reward 289.00]
> Step 100 [reward 389.00]
> Step 125 [reward 489.00]
> Step 150 [reward 589.00]
> Step 175 [reward 689.00]
> Step 200 [reward 789.00]
> Step 225 [reward 889.00]
> Step 250 [reward 989.00]
Rewards 989.00 / Steps 250.00
Reward stats:
 {'max': '46.29', 'mean': '14.67', 'min': '-3.26', 'std': '8.48'}
Information gain stats:
 {'max': '1.82', 'mean': '1.01', 'min': '0.31', 'std': '0.23'}
Episode time 70.17
Saved _metrics_

=== Episode 44 ===
Training on [12000/48000] data points
> Train epoch 20 [ensemble -36.71 | reward 0.14]
> Train epoch 40 [ensemble -39.55 | reward 0.07]
> Train epoch 60 [ensemble -40.91 | reward 0.05]
> Train epoch 80 [ensemble -41.80 | reward 0.04]
> Train epoch 100 [ensemble -42.46 | reward 0.03]
Ensemble loss -42.46 / Reward Loss 0.03

=== Collecting data [44] ===
> Step 25 [reward 89.00]
> Step 50 [reward 189.00]
> Step 75 [reward 289.00]
> Step 100 [reward 389.00]
> Step 125 [reward 489.00]
> Step 150 [reward 589.00]
> Step 175 [reward 689.00]
> Step 200 [reward 789.00]
> Step 225 [reward 889.00]
> Step 250 [reward 989.00]
Rewards 989.00 / Steps 250.00
Reward stats:
 {'max': '45.76', 'mean': '18.06', 'min': '-1.68', 'std': '8.47'}
Information gain stats:
 {'max': '1.78', 'mean': '1.02', 'min': '0.34', 'std': '0.22'}
Episode time 70.17
Saved _metrics_

=== Episode 45 ===
Training on [12250/49000] data points
> Train epoch 20 [ensemble -36.92 | reward 0.13]
> Train epoch 40 [ensemble -39.71 | reward 0.07]
> Train epoch 60 [ensemble -41.05 | reward 0.05]
> Train epoch 80 [ensemble -41.92 | reward 0.04]
> Train epoch 100 [ensemble -42.56 | reward 0.03]
Ensemble loss -42.56 / Reward Loss 0.03

=== Collecting data [45] ===
> Step 25 [reward 90.00]
> Step 50 [reward 190.00]
> Step 75 [reward 290.00]
> Step 100 [reward 390.00]
> Step 125 [reward 490.00]
> Step 150 [reward 590.00]
> Step 175 [reward 690.00]
> Step 200 [reward 790.00]
> Step 225 [reward 890.00]
> Step 250 [reward 990.00]
Rewards 990.00 / Steps 250.00
Reward stats:
 {'max': '47.10', 'mean': '15.31', 'min': '-1.50', 'std': '8.83'}
Information gain stats:
 {'max': '1.79', 'mean': '1.00', 'min': '0.32', 'std': '0.23'}
Episode time 71.26
Saved _metrics_

=== Episode 46 ===
Training on [12500/50000] data points
> Train epoch 20 [ensemble -36.99 | reward 0.13]
> Train epoch 40 [ensemble -39.79 | reward 0.07]
> Train epoch 60 [ensemble -41.13 | reward 0.05]
> Train epoch 80 [ensemble -42.00 | reward 0.04]
> Train epoch 100 [ensemble -42.64 | reward 0.03]
Ensemble loss -42.64 / Reward Loss 0.03

=== Collecting data [46] ===
> Step 25 [reward 91.00]
> Step 50 [reward 191.00]
> Step 75 [reward 291.00]
> Step 100 [reward 391.00]
> Step 125 [reward 491.00]
> Step 150 [reward 591.00]
> Step 175 [reward 691.00]
> Step 200 [reward 791.00]
> Step 225 [reward 891.00]
> Step 250 [reward 991.00]
Rewards 991.00 / Steps 250.00
Reward stats:
 {'max': '47.49', 'mean': '16.58', 'min': '-0.40', 'std': '8.85'}
Information gain stats:
 {'max': '1.73', 'mean': '1.01', 'min': '0.31', 'std': '0.23'}
Episode time 72.43
Saved _metrics_

=== Episode 47 ===
Training on [12750/51000] data points
> Train epoch 20 [ensemble -37.29 | reward 0.13]
> Train epoch 40 [ensemble -39.99 | reward 0.07]
> Train epoch 60 [ensemble -41.30 | reward 0.05]
> Train epoch 80 [ensemble -42.15 | reward 0.04]
> Train epoch 100 [ensemble -42.77 | reward 0.03]
Ensemble loss -42.77 / Reward Loss 0.03

=== Collecting data [47] ===
> Step 25 [reward 90.00]
> Step 50 [reward 190.00]
> Step 75 [reward 290.00]
> Step 100 [reward 390.00]
> Step 125 [reward 490.00]
> Step 150 [reward 590.00]
> Step 175 [reward 690.00]
> Step 200 [reward 790.00]
> Step 225 [reward 890.00]
> Step 250 [reward 990.00]
Rewards 990.00 / Steps 250.00
Reward stats:
 {'max': '47.36', 'mean': '16.96', 'min': '-2.35', 'std': '8.81'}
Information gain stats:
 {'max': '1.79', 'mean': '1.02', 'min': '0.34', 'std': '0.24'}
Episode time 73.45
Saved _metrics_

=== Episode 48 ===
Training on [13000/52000] data points
> Train epoch 20 [ensemble -37.45 | reward 0.12]
> Train epoch 40 [ensemble -40.12 | reward 0.06]
> Train epoch 60 [ensemble -41.40 | reward 0.04]
> Train epoch 80 [ensemble -42.24 | reward 0.03]
> Train epoch 100 [ensemble -42.85 | reward 0.03]
Ensemble loss -42.85 / Reward Loss 0.03

=== Collecting data [48] ===
> Step 25 [reward 64.00]
> Step 50 [reward 164.00]
> Step 75 [reward 264.00]
> Step 100 [reward 364.00]
> Step 125 [reward 464.00]
> Step 150 [reward 564.00]
> Step 175 [reward 664.00]
> Step 200 [reward 764.00]
> Step 225 [reward 864.00]
> Step 250 [reward 964.00]
Rewards 964.00 / Steps 250.00
Reward stats:
 {'max': '46.71', 'mean': '15.39', 'min': '-1.78', 'std': '8.22'}
Information gain stats:
 {'max': '1.71', 'mean': '1.03', 'min': '0.36', 'std': '0.21'}
Episode time 74.47
Saved _metrics_

=== Episode 49 ===
Training on [13250/53000] data points
> Train epoch 20 [ensemble -37.49 | reward 0.12]
> Train epoch 40 [ensemble -40.16 | reward 0.06]
> Train epoch 60 [ensemble -41.43 | reward 0.04]
> Train epoch 80 [ensemble -42.27 | reward 0.03]
> Train epoch 100 [ensemble -42.89 | reward 0.03]
Ensemble loss -42.89 / Reward Loss 0.03

=== Collecting data [49] ===
> Step 25 [reward 72.00]
> Step 50 [reward 172.00]
> Step 75 [reward 272.00]
> Step 100 [reward 372.00]
> Step 125 [reward 472.00]
> Step 150 [reward 572.00]
> Step 175 [reward 672.00]
> Step 200 [reward 772.00]
> Step 225 [reward 872.00]
> Step 250 [reward 972.00]
Rewards 972.00 / Steps 250.00
Reward stats:
 {'max': '46.30', 'mean': '15.17', 'min': '-0.82', 'std': '8.43'}
Information gain stats:
 {'max': '1.77', 'mean': '1.04', 'min': '0.31', 'std': '0.23'}
Episode time 75.73
Saved _metrics_