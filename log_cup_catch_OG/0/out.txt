11:13:40

=== Loading experiment [device: cuda] ===

{'action_noise': None,
 'action_repeat': 4,
 'batch_size': 50,
 'coverage': False,
 'ensemble_size': 10,
 'env_name': 'DeepMindCatch',
 'epsilon': 1e-08,
 'expl_scale': 0.1,
 'expl_strategy': 'information',
 'grad_clip_norm': 1000,
 'hidden_size': 200,
 'learning_rate': 0.001,
 'logdir': 'cup_catch_OG',
 'max_episode_len': 1000,
 'n_candidates': 500,
 'n_episodes': 50,
 'n_seed_episodes': 5,
 'n_train_epochs': 100,
 'optimisation_iters': 5,
 'plan_horizon': 12,
 'record_every': None,
 'reward_scale': 1.0,
 'seed': 0,
 'strategy': 'information',
 'top_candidates': 50,
 'use_exploration': True,
 'use_mean': False,
 'use_reward': True}

Collected seeds: [5 episodes | 1250 frames]

=== Episode 1 ===
Training on [1250/5000] data points
> Train epoch 20 [ensemble -20.36 | reward 0.12]
> Train epoch 40 [ensemble -28.24 | reward 0.06]
> Train epoch 60 [ensemble -32.04 | reward 0.04]
> Train epoch 80 [ensemble -34.42 | reward 0.03]
> Train epoch 100 [ensemble -36.12 | reward 0.03]
Ensemble loss -36.12 / Reward Loss 0.03

=== Collecting data [1] ===
> Step 25 [reward 0.00]
> Step 50 [reward 80.00]
> Step 75 [reward 180.00]
> Step 100 [reward 278.00]
> Step 125 [reward 378.00]
> Step 150 [reward 478.00]
> Step 175 [reward 562.00]
> Step 200 [reward 662.00]
> Step 225 [reward 762.00]
> Step 250 [reward 787.00]
Rewards 787.00 / Steps 250.00
Reward stats:
 {'max': '25.68', 'mean': '2.67', 'min': '-1.89', 'std': '2.95'}
Information gain stats:
 {'max': '2.28', 'mean': '1.14', 'min': '0.55', 'std': '0.13'}
Episode time 24.59
Saved _metrics_

=== Episode 2 ===
Training on [1500/6000] data points
> Train epoch 20 [ensemble -18.17 | reward 0.34]
> Train epoch 40 [ensemble -26.03 | reward 0.19]
> Train epoch 60 [ensemble -30.12 | reward 0.13]
> Train epoch 80 [ensemble -32.75 | reward 0.09]
> Train epoch 100 [ensemble -34.61 | reward 0.08]
Ensemble loss -34.61 / Reward Loss 0.08

=== Collecting data [2] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '44.67', 'mean': '5.70', 'min': '-2.90', 'std': '6.37'}
Information gain stats:
 {'max': '2.05', 'mean': '0.96', 'min': '0.37', 'std': '0.17'}
Episode time 24.24
Saved _metrics_

=== Episode 3 ===
Training on [1750/7000] data points
> Train epoch 20 [ensemble -17.81 | reward 0.30]
> Train epoch 40 [ensemble -25.56 | reward 0.16]
> Train epoch 60 [ensemble -29.60 | reward 0.11]
> Train epoch 80 [ensemble -32.17 | reward 0.08]
> Train epoch 100 [ensemble -33.99 | reward 0.06]
Ensemble loss -33.99 / Reward Loss 0.06

=== Collecting data [3] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 3.00]
> Step 100 [reward 73.00]
> Step 125 [reward 173.00]
> Step 150 [reward 273.00]
> Step 175 [reward 373.00]
> Step 200 [reward 473.00]
> Step 225 [reward 573.00]
> Step 250 [reward 673.00]
Rewards 673.00 / Steps 250.00
Reward stats:
 {'max': '40.21', 'mean': '8.80', 'min': '-0.63', 'std': '6.71'}
Information gain stats:
 {'max': '1.86', 'mean': '0.94', 'min': '0.36', 'std': '0.23'}
Episode time 25.86
Saved _metrics_

=== Episode 4 ===
Training on [2000/8000] data points
> Train epoch 20 [ensemble -19.31 | reward 0.37]
> Train epoch 40 [ensemble -26.73 | reward 0.20]
> Train epoch 60 [ensemble -30.46 | reward 0.13]
> Train epoch 80 [ensemble -32.82 | reward 0.10]
> Train epoch 100 [ensemble -34.52 | reward 0.08]
Ensemble loss -34.52 / Reward Loss 0.08

=== Collecting data [4] ===
> Step 25 [reward 2.00]
> Step 50 [reward 91.00]
> Step 75 [reward 191.00]
> Step 100 [reward 291.00]
> Step 125 [reward 391.00]
> Step 150 [reward 491.00]
> Step 175 [reward 591.00]
> Step 200 [reward 691.00]
> Step 225 [reward 791.00]
> Step 250 [reward 891.00]
Rewards 891.00 / Steps 250.00
Reward stats:
 {'max': '35.52', 'mean': '11.39', 'min': '-2.60', 'std': '7.18'}
Information gain stats:
 {'max': '1.61', 'mean': '0.86', 'min': '0.35', 'std': '0.21'}
Episode time 27.26
Saved _metrics_

=== Episode 5 ===
Training on [2250/9000] data points
> Train epoch 20 [ensemble -21.21 | reward 0.36]
> Train epoch 40 [ensemble -28.15 | reward 0.19]
> Train epoch 60 [ensemble -31.57 | reward 0.13]
> Train epoch 80 [ensemble -33.75 | reward 0.10]
> Train epoch 100 [ensemble -35.33 | reward 0.08]
Ensemble loss -35.33 / Reward Loss 0.08

=== Collecting data [5] ===
> Step 25 [reward 79.00]
> Step 50 [reward 179.00]
> Step 75 [reward 279.00]
> Step 100 [reward 379.00]
> Step 125 [reward 479.00]
> Step 150 [reward 579.00]
> Step 175 [reward 679.00]
> Step 200 [reward 779.00]
> Step 225 [reward 879.00]
> Step 250 [reward 979.00]
Rewards 979.00 / Steps 250.00
Reward stats:
 {'max': '41.15', 'mean': '13.71', 'min': '-1.39', 'std': '8.16'}
Information gain stats:
 {'max': '1.59', 'mean': '0.80', 'min': '0.30', 'std': '0.21'}
Episode time 27.80
Saved _metrics_

=== Episode 6 ===
Training on [2500/10000] data points
> Train epoch 20 [ensemble -23.01 | reward 0.36]
> Train epoch 40 [ensemble -29.46 | reward 0.19]
> Train epoch 60 [ensemble -32.61 | reward 0.13]
> Train epoch 80 [ensemble -34.62 | reward 0.10]
> Train epoch 100 [ensemble -36.08 | reward 0.08]
Ensemble loss -36.08 / Reward Loss 0.08

=== Collecting data [6] ===
> Step 25 [reward 83.00]
> Step 50 [reward 183.00]
> Step 75 [reward 283.00]
> Step 100 [reward 383.00]
> Step 125 [reward 483.00]
> Step 150 [reward 583.00]
> Step 175 [reward 683.00]
> Step 200 [reward 783.00]
> Step 225 [reward 883.00]
> Step 250 [reward 983.00]
Rewards 983.00 / Steps 250.00
Reward stats:
 {'max': '42.51', 'mean': '14.93', 'min': '-1.50', 'std': '9.10'}
Information gain stats:
 {'max': '1.57', 'mean': '0.80', 'min': '0.32', 'std': '0.23'}
Episode time 28.03
Saved _metrics_

=== Episode 7 ===
Training on [2750/11000] data points
> Train epoch 20 [ensemble -24.58 | reward 0.32]
> Train epoch 40 [ensemble -30.68 | reward 0.17]
> Train epoch 60 [ensemble -33.63 | reward 0.11]
> Train epoch 80 [ensemble -35.54 | reward 0.08]
> Train epoch 100 [ensemble -36.92 | reward 0.07]
Ensemble loss -36.92 / Reward Loss 0.07

=== Collecting data [7] ===
> Step 25 [reward 61.00]
> Step 50 [reward 161.00]
> Step 75 [reward 261.00]
> Step 100 [reward 361.00]
> Step 125 [reward 461.00]
> Step 150 [reward 561.00]
> Step 175 [reward 661.00]
> Step 200 [reward 761.00]
> Step 225 [reward 861.00]
> Step 250 [reward 961.00]
Rewards 961.00 / Steps 250.00
Reward stats:
 {'max': '42.72', 'mean': '14.75', 'min': '-0.56', 'std': '8.77'}
Information gain stats:
 {'max': '1.70', 'mean': '0.82', 'min': '0.30', 'std': '0.23'}
Episode time 29.14
Saved _metrics_

=== Episode 8 ===
Training on [3000/12000] data points
> Train epoch 20 [ensemble -25.67 | reward 0.32]
> Train epoch 40 [ensemble -31.49 | reward 0.17]
> Train epoch 60 [ensemble -34.33 | reward 0.11]
> Train epoch 80 [ensemble -36.17 | reward 0.08]
> Train epoch 100 [ensemble -37.49 | reward 0.07]
Ensemble loss -37.49 / Reward Loss 0.07

=== Collecting data [8] ===
> Step 25 [reward 4.00]
> Step 50 [reward 58.00]
> Step 75 [reward 158.00]
> Step 100 [reward 258.00]
> Step 125 [reward 358.00]
> Step 150 [reward 458.00]
> Step 175 [reward 558.00]
> Step 200 [reward 658.00]
> Step 225 [reward 758.00]
> Step 250 [reward 858.00]
Rewards 858.00 / Steps 250.00
Reward stats:
 {'max': '44.25', 'mean': '14.03', 'min': '-3.94', 'std': '9.48'}
Information gain stats:
 {'max': '1.68', 'mean': '0.85', 'min': '0.31', 'std': '0.23'}
Episode time 30.26
Saved _metrics_

=== Episode 9 ===
Training on [3250/13000] data points
> Train epoch 20 [ensemble -26.38 | reward 0.32]
> Train epoch 40 [ensemble -31.97 | reward 0.17]
> Train epoch 60 [ensemble -34.71 | reward 0.12]
> Train epoch 80 [ensemble -36.48 | reward 0.09]
> Train epoch 100 [ensemble -37.77 | reward 0.07]
Ensemble loss -37.77 / Reward Loss 0.07

=== Collecting data [9] ===
> Step 25 [reward 84.00]
> Step 50 [reward 184.00]
> Step 75 [reward 284.00]
> Step 100 [reward 384.00]
> Step 125 [reward 484.00]
> Step 150 [reward 584.00]
> Step 175 [reward 684.00]
> Step 200 [reward 784.00]
> Step 225 [reward 884.00]
> Step 250 [reward 984.00]
Rewards 984.00 / Steps 250.00
Reward stats:
 {'max': '42.26', 'mean': '15.80', 'min': '-1.39', 'std': '8.86'}
Information gain stats:
 {'max': '1.66', 'mean': '0.85', 'min': '0.31', 'std': '0.24'}
Episode time 31.45
Saved _metrics_

=== Episode 10 ===
Training on [3500/14000] data points
> Train epoch 20 [ensemble -27.13 | reward 0.28]
> Train epoch 40 [ensemble -32.55 | reward 0.15]
> Train epoch 60 [ensemble -35.22 | reward 0.10]
> Train epoch 80 [ensemble -36.94 | reward 0.08]
> Train epoch 100 [ensemble -38.19 | reward 0.06]
Ensemble loss -38.19 / Reward Loss 0.06

=== Collecting data [10] ===
> Step 25 [reward 0.00]
> Step 50 [reward 7.00]
> Step 75 [reward 107.00]
> Step 100 [reward 207.00]
> Step 125 [reward 307.00]
> Step 150 [reward 407.00]
> Step 175 [reward 507.00]
> Step 200 [reward 607.00]
> Step 225 [reward 707.00]
> Step 250 [reward 807.00]
Rewards 807.00 / Steps 250.00
Reward stats:
 {'max': '43.82', 'mean': '13.63', 'min': '-5.43', 'std': '9.64'}
Information gain stats:
 {'max': '1.69', 'mean': '0.90', 'min': '0.32', 'std': '0.25'}
Episode time 32.39
Saved _metrics_

=== Episode 11 ===
Training on [3750/15000] data points
> Train epoch 20 [ensemble -27.70 | reward 0.28]
> Train epoch 40 [ensemble -32.98 | reward 0.15]
> Train epoch 60 [ensemble -35.56 | reward 0.10]
> Train epoch 80 [ensemble -37.21 | reward 0.07]
> Train epoch 100 [ensemble -38.42 | reward 0.06]
Ensemble loss -38.42 / Reward Loss 0.06

=== Collecting data [11] ===
> Step 25 [reward 35.00]
> Step 50 [reward 135.00]
> Step 75 [reward 235.00]
> Step 100 [reward 335.00]
> Step 125 [reward 435.00]
> Step 150 [reward 535.00]
> Step 175 [reward 635.00]
> Step 200 [reward 735.00]
> Step 225 [reward 835.00]
> Step 250 [reward 935.00]
Rewards 935.00 / Steps 250.00
Reward stats:
 {'max': '43.22', 'mean': '14.19', 'min': '-2.55', 'std': '9.31'}
Information gain stats:
 {'max': '1.68', 'mean': '0.89', 'min': '0.31', 'std': '0.24'}
Episode time 33.46
Saved _metrics_

=== Episode 12 ===
Training on [4000/16000] data points
> Train epoch 20 [ensemble -28.56 | reward 0.27]
> Train epoch 40 [ensemble -33.54 | reward 0.14]
> Train epoch 60 [ensemble -36.01 | reward 0.09]
> Train epoch 80 [ensemble -37.60 | reward 0.07]
> Train epoch 100 [ensemble -38.76 | reward 0.06]
Ensemble loss -38.76 / Reward Loss 0.06

=== Collecting data [12] ===
> Step 25 [reward 50.00]
> Step 50 [reward 150.00]
> Step 75 [reward 250.00]
> Step 100 [reward 350.00]
> Step 125 [reward 450.00]
> Step 150 [reward 550.00]
> Step 175 [reward 650.00]
> Step 200 [reward 750.00]
> Step 225 [reward 850.00]
> Step 250 [reward 950.00]
Rewards 950.00 / Steps 250.00
Reward stats:
 {'max': '40.77', 'mean': '13.19', 'min': '-1.70', 'std': '7.89'}
Information gain stats:
 {'max': '1.74', 'mean': '0.96', 'min': '0.39', 'std': '0.20'}
Episode time 34.60
Saved _metrics_

=== Episode 13 ===
Training on [4250/17000] data points
> Train epoch 20 [ensemble -29.09 | reward 0.27]
> Train epoch 40 [ensemble -33.98 | reward 0.14]
> Train epoch 60 [ensemble -36.40 | reward 0.09]
> Train epoch 80 [ensemble -37.96 | reward 0.07]
> Train epoch 100 [ensemble -39.10 | reward 0.06]
Ensemble loss -39.10 / Reward Loss 0.06

=== Collecting data [13] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '16.99', 'mean': '3.65', 'min': '-1.35', 'std': '2.74'}
Information gain stats:
 {'max': '1.94', 'mean': '1.33', 'min': '0.65', 'std': '0.13'}
Episode time 35.73
Saved _metrics_

=== Episode 14 ===
Training on [4500/18000] data points
> Train epoch 20 [ensemble -29.98 | reward 0.24]
> Train epoch 40 [ensemble -34.67 | reward 0.12]
> Train epoch 60 [ensemble -37.01 | reward 0.08]
> Train epoch 80 [ensemble -38.53 | reward 0.06]
> Train epoch 100 [ensemble -39.64 | reward 0.05]
Ensemble loss -39.64 / Reward Loss 0.05

=== Collecting data [14] ===
> Step 25 [reward 0.00]
> Step 50 [reward 94.00]
> Step 75 [reward 194.00]
> Step 100 [reward 294.00]
> Step 125 [reward 394.00]
> Step 150 [reward 494.00]
> Step 175 [reward 594.00]
> Step 200 [reward 694.00]
> Step 225 [reward 794.00]
> Step 250 [reward 894.00]
Rewards 894.00 / Steps 250.00
Reward stats:
 {'max': '44.69', 'mean': '15.91', 'min': '-0.87', 'std': '10.02'}
Information gain stats:
 {'max': '1.63', 'mean': '0.87', 'min': '0.31', 'std': '0.21'}
Episode time 36.75
Saved _metrics_

=== Episode 15 ===
Training on [4750/19000] data points
> Train epoch 20 [ensemble -30.59 | reward 0.24]
> Train epoch 40 [ensemble -35.07 | reward 0.13]
> Train epoch 60 [ensemble -37.31 | reward 0.08]
> Train epoch 80 [ensemble -38.77 | reward 0.06]
> Train epoch 100 [ensemble -39.83 | reward 0.05]
Ensemble loss -39.83 / Reward Loss 0.05

=== Collecting data [15] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 39.00]
> Step 175 [reward 139.00]
> Step 200 [reward 239.00]
> Step 225 [reward 339.00]
> Step 250 [reward 439.00]
Rewards 439.00 / Steps 250.00
Reward stats:
 {'max': '44.34', 'mean': '7.97', 'min': '-0.54', 'std': '8.42'}
Information gain stats:
 {'max': '1.58', 'mean': '0.95', 'min': '0.30', 'std': '0.18'}
Episode time 37.79
Saved _metrics_

=== Episode 16 ===
Training on [5000/20000] data points
> Train epoch 20 [ensemble -30.72 | reward 0.25]
> Train epoch 40 [ensemble -35.12 | reward 0.13]
> Train epoch 60 [ensemble -37.32 | reward 0.09]
> Train epoch 80 [ensemble -38.75 | reward 0.07]
> Train epoch 100 [ensemble -39.79 | reward 0.05]
Ensemble loss -39.79 / Reward Loss 0.05

=== Collecting data [16] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '37.63', 'mean': '4.26', 'min': '-0.89', 'std': '5.34'}
Information gain stats:
 {'max': '1.54', 'mean': '0.95', 'min': '0.39', 'std': '0.13'}
Episode time 38.79
Saved _metrics_

=== Episode 17 ===
Training on [5250/21000] data points
> Train epoch 20 [ensemble -30.79 | reward 0.24]
> Train epoch 40 [ensemble -35.05 | reward 0.13]
> Train epoch 60 [ensemble -37.17 | reward 0.09]
> Train epoch 80 [ensemble -38.58 | reward 0.07]
> Train epoch 100 [ensemble -39.64 | reward 0.05]
Ensemble loss -39.64 / Reward Loss 0.05

=== Collecting data [17] ===
> Step 25 [reward 59.00]
> Step 50 [reward 159.00]
> Step 75 [reward 259.00]
> Step 100 [reward 359.00]
> Step 125 [reward 459.00]
> Step 150 [reward 559.00]
> Step 175 [reward 659.00]
> Step 200 [reward 759.00]
> Step 225 [reward 859.00]
> Step 250 [reward 959.00]
Rewards 959.00 / Steps 250.00
Reward stats:
 {'max': '30.01', 'mean': '10.00', 'min': '-1.05', 'std': '5.50'}
Information gain stats:
 {'max': '1.55', 'mean': '0.99', 'min': '0.49', 'std': '0.14'}
Episode time 40.08
Saved _metrics_

=== Episode 18 ===
Training on [5500/22000] data points
> Train epoch 20 [ensemble -31.23 | reward 0.24]
> Train epoch 40 [ensemble -35.35 | reward 0.13]
> Train epoch 60 [ensemble -37.43 | reward 0.09]
> Train epoch 80 [ensemble -38.81 | reward 0.07]
> Train epoch 100 [ensemble -39.85 | reward 0.05]
Ensemble loss -39.85 / Reward Loss 0.05

=== Collecting data [18] ===
> Step 25 [reward 10.00]
> Step 50 [reward 110.00]
> Step 75 [reward 210.00]
> Step 100 [reward 310.00]
> Step 125 [reward 410.00]
> Step 150 [reward 510.00]
> Step 175 [reward 610.00]
> Step 200 [reward 710.00]
> Step 225 [reward 810.00]
> Step 250 [reward 910.00]
Rewards 910.00 / Steps 250.00
Reward stats:
 {'max': '35.73', 'mean': '10.77', 'min': '-0.67', 'std': '6.93'}
Information gain stats:
 {'max': '1.71', 'mean': '0.96', 'min': '0.39', 'std': '0.18'}
Episode time 41.03
Saved _metrics_

=== Episode 19 ===
Training on [5750/23000] data points
> Train epoch 20 [ensemble -31.52 | reward 0.25]
> Train epoch 40 [ensemble -35.45 | reward 0.14]
> Train epoch 60 [ensemble -37.46 | reward 0.09]
> Train epoch 80 [ensemble -38.81 | reward 0.07]
> Train epoch 100 [ensemble -39.82 | reward 0.06]
Ensemble loss -39.82 / Reward Loss 0.06

=== Collecting data [19] ===
> Step 25 [reward 19.00]
> Step 50 [reward 119.00]
> Step 75 [reward 219.00]
> Step 100 [reward 319.00]
> Step 125 [reward 419.00]
> Step 150 [reward 519.00]
> Step 175 [reward 619.00]
> Step 200 [reward 719.00]
> Step 225 [reward 819.00]
> Step 250 [reward 919.00]
Rewards 919.00 / Steps 250.00
Reward stats:
 {'max': '40.17', 'mean': '10.71', 'min': '-0.74', 'std': '6.92'}
Information gain stats:
 {'max': '1.58', 'mean': '0.95', 'min': '0.33', 'std': '0.18'}
Episode time 42.13
Saved _metrics_

=== Episode 20 ===
Training on [6000/24000] data points
> Train epoch 20 [ensemble -31.96 | reward 0.25]
> Train epoch 40 [ensemble -35.84 | reward 0.14]
> Train epoch 60 [ensemble -37.81 | reward 0.09]
> Train epoch 80 [ensemble -39.12 | reward 0.07]
> Train epoch 100 [ensemble -40.11 | reward 0.06]
Ensemble loss -40.11 / Reward Loss 0.06

=== Collecting data [20] ===
> Step 25 [reward 57.00]
> Step 50 [reward 157.00]
> Step 75 [reward 257.00]
> Step 100 [reward 357.00]
> Step 125 [reward 457.00]
> Step 150 [reward 557.00]
> Step 175 [reward 657.00]
> Step 200 [reward 757.00]
> Step 225 [reward 857.00]
> Step 250 [reward 957.00]
Rewards 957.00 / Steps 250.00
Reward stats:
 {'max': '39.61', 'mean': '12.14', 'min': '-0.55', 'std': '6.85'}
Information gain stats:
 {'max': '1.66', 'mean': '0.94', 'min': '0.39', 'std': '0.17'}
Episode time 43.15
Saved _metrics_

=== Episode 21 ===
Training on [6250/25000] data points
> Train epoch 20 [ensemble -32.22 | reward 0.25]
> Train epoch 40 [ensemble -36.03 | reward 0.14]
> Train epoch 60 [ensemble -37.96 | reward 0.09]
> Train epoch 80 [ensemble -39.24 | reward 0.07]
> Train epoch 100 [ensemble -40.20 | reward 0.06]
Ensemble loss -40.20 / Reward Loss 0.06

=== Collecting data [21] ===
> Step 25 [reward 58.00]
> Step 50 [reward 158.00]
> Step 75 [reward 258.00]
> Step 100 [reward 358.00]
> Step 125 [reward 458.00]
> Step 150 [reward 558.00]
> Step 175 [reward 658.00]
> Step 200 [reward 758.00]
> Step 225 [reward 858.00]
> Step 250 [reward 958.00]
Rewards 958.00 / Steps 250.00
Reward stats:
 {'max': '38.42', 'mean': '11.50', 'min': '-3.05', 'std': '6.78'}
Information gain stats:
 {'max': '1.62', 'mean': '0.94', 'min': '0.37', 'std': '0.19'}
Episode time 44.33
Saved _metrics_

=== Episode 22 ===
Training on [6500/26000] data points
> Train epoch 20 [ensemble -32.60 | reward 0.23]
> Train epoch 40 [ensemble -36.31 | reward 0.13]
> Train epoch 60 [ensemble -38.19 | reward 0.09]
> Train epoch 80 [ensemble -39.45 | reward 0.07]
> Train epoch 100 [ensemble -40.38 | reward 0.05]
Ensemble loss -40.38 / Reward Loss 0.05

=== Collecting data [22] ===
> Step 25 [reward 31.00]
> Step 50 [reward 131.00]
> Step 75 [reward 231.00]
> Step 100 [reward 331.00]
> Step 125 [reward 431.00]
> Step 150 [reward 531.00]
> Step 175 [reward 631.00]
> Step 200 [reward 731.00]
> Step 225 [reward 831.00]
> Step 250 [reward 931.00]
Rewards 931.00 / Steps 250.00
Reward stats:
 {'max': '39.83', 'mean': '11.37', 'min': '-0.77', 'std': '6.92'}
Information gain stats:
 {'max': '1.59', 'mean': '0.96', 'min': '0.35', 'std': '0.18'}
Episode time 45.43
Saved _metrics_

=== Episode 23 ===
Training on [6750/27000] data points
> Train epoch 20 [ensemble -32.88 | reward 0.22]
> Train epoch 40 [ensemble -36.54 | reward 0.11]
> Train epoch 60 [ensemble -38.40 | reward 0.08]
> Train epoch 80 [ensemble -39.64 | reward 0.06]
> Train epoch 100 [ensemble -40.56 | reward 0.05]
Ensemble loss -40.56 / Reward Loss 0.05

=== Collecting data [23] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 71.00]
> Step 100 [reward 171.00]
> Step 125 [reward 271.00]
> Step 150 [reward 371.00]
> Step 175 [reward 471.00]
> Step 200 [reward 571.00]
> Step 225 [reward 671.00]
> Step 250 [reward 771.00]
Rewards 771.00 / Steps 250.00
Reward stats:
 {'max': '43.38', 'mean': '11.50', 'min': '-0.79', 'std': '8.30'}
Information gain stats:
 {'max': '2.18', 'mean': '0.97', 'min': '0.33', 'std': '0.21'}
Episode time 46.71
Saved _metrics_

=== Episode 24 ===
Training on [7000/28000] data points
> Train epoch 20 [ensemble -33.02 | reward 0.24]
> Train epoch 40 [ensemble -36.65 | reward 0.13]
> Train epoch 60 [ensemble -38.48 | reward 0.09]
> Train epoch 80 [ensemble -39.70 | reward 0.06]
> Train epoch 100 [ensemble -40.61 | reward 0.05]
Ensemble loss -40.61 / Reward Loss 0.05

=== Collecting data [24] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 78.00]
> Step 100 [reward 178.00]
> Step 125 [reward 278.00]
> Step 150 [reward 378.00]
> Step 175 [reward 478.00]
> Step 200 [reward 578.00]
> Step 225 [reward 678.00]
> Step 250 [reward 778.00]
Rewards 778.00 / Steps 250.00
Reward stats:
 {'max': '41.18', 'mean': '11.40', 'min': '-1.50', 'std': '8.28'}
Information gain stats:
 {'max': '1.63', 'mean': '0.95', 'min': '0.35', 'std': '0.21'}
Episode time 48.55
Saved _metrics_

=== Episode 25 ===
Training on [7250/29000] data points
> Train epoch 20 [ensemble -33.28 | reward 0.21]
> Train epoch 40 [ensemble -36.82 | reward 0.11]
> Train epoch 60 [ensemble -38.62 | reward 0.08]
> Train epoch 80 [ensemble -39.82 | reward 0.06]
> Train epoch 100 [ensemble -40.71 | reward 0.05]
Ensemble loss -40.71 / Reward Loss 0.05

=== Collecting data [25] ===
> Step 25 [reward 0.00]
> Step 50 [reward 43.00]
> Step 75 [reward 143.00]
> Step 100 [reward 243.00]
> Step 125 [reward 343.00]
> Step 150 [reward 443.00]
> Step 175 [reward 543.00]
> Step 200 [reward 643.00]
> Step 225 [reward 743.00]
> Step 250 [reward 843.00]
Rewards 843.00 / Steps 250.00
Reward stats:
 {'max': '38.50', 'mean': '11.08', 'min': '-1.30', 'std': '7.64'}
Information gain stats:
 {'max': '1.61', 'mean': '0.99', 'min': '0.39', 'std': '0.18'}
Episode time 48.61
Saved _metrics_

=== Episode 26 ===
Training on [7500/30000] data points
> Train epoch 20 [ensemble -33.45 | reward 0.23]
> Train epoch 40 [ensemble -36.96 | reward 0.12]
> Train epoch 60 [ensemble -38.73 | reward 0.08]
> Train epoch 80 [ensemble -39.91 | reward 0.06]
> Train epoch 100 [ensemble -40.79 | reward 0.05]
Ensemble loss -40.79 / Reward Loss 0.05

=== Collecting data [26] ===
> Step 25 [reward 84.00]
> Step 50 [reward 184.00]
> Step 75 [reward 284.00]
> Step 100 [reward 384.00]
> Step 125 [reward 484.00]
> Step 150 [reward 584.00]
> Step 175 [reward 684.00]
> Step 200 [reward 784.00]
> Step 225 [reward 884.00]
> Step 250 [reward 984.00]
Rewards 984.00 / Steps 250.00
Reward stats:
 {'max': '42.03', 'mean': '12.97', 'min': '-0.89', 'std': '7.44'}
Information gain stats:
 {'max': '1.66', 'mean': '0.96', 'min': '0.33', 'std': '0.21'}
Episode time 49.60
Saved _metrics_

=== Episode 27 ===
Training on [7750/31000] data points
> Train epoch 20 [ensemble -33.75 | reward 0.21]
> Train epoch 40 [ensemble -37.19 | reward 0.11]
> Train epoch 60 [ensemble -38.92 | reward 0.08]
> Train epoch 80 [ensemble -40.08 | reward 0.06]
> Train epoch 100 [ensemble -40.93 | reward 0.05]
Ensemble loss -40.93 / Reward Loss 0.05

=== Collecting data [27] ===
> Step 25 [reward 0.00]
> Step 50 [reward 100.00]
> Step 75 [reward 200.00]
> Step 100 [reward 300.00]
> Step 125 [reward 400.00]
> Step 150 [reward 500.00]
> Step 175 [reward 600.00]
> Step 200 [reward 700.00]
> Step 225 [reward 800.00]
> Step 250 [reward 900.00]
Rewards 900.00 / Steps 250.00
Reward stats:
 {'max': '42.71', 'mean': '12.07', 'min': '-1.22', 'std': '8.07'}
Information gain stats:
 {'max': '1.72', 'mean': '0.97', 'min': '0.36', 'std': '0.20'}
Episode time 50.74
Saved _metrics_

=== Episode 28 ===
Training on [8000/32000] data points
> Train epoch 20 [ensemble -34.08 | reward 0.20]
> Train epoch 40 [ensemble -37.42 | reward 0.11]
> Train epoch 60 [ensemble -39.10 | reward 0.07]
> Train epoch 80 [ensemble -40.22 | reward 0.05]
> Train epoch 100 [ensemble -41.06 | reward 0.04]
Ensemble loss -41.06 / Reward Loss 0.04

=== Collecting data [28] ===
> Step 25 [reward 94.00]
> Step 50 [reward 194.00]
> Step 75 [reward 294.00]
> Step 100 [reward 394.00]
> Step 125 [reward 494.00]
> Step 150 [reward 594.00]
> Step 175 [reward 694.00]
> Step 200 [reward 794.00]
> Step 225 [reward 894.00]
> Step 250 [reward 994.00]
Rewards 994.00 / Steps 250.00
Reward stats:
 {'max': '42.53', 'mean': '12.97', 'min': '-0.40', 'std': '7.51'}
Information gain stats:
 {'max': '1.64', 'mean': '0.98', 'min': '0.36', 'std': '0.21'}
Episode time 51.93
Saved _metrics_

=== Episode 29 ===
Training on [8250/33000] data points
> Train epoch 20 [ensemble -34.35 | reward 0.19]
> Train epoch 40 [ensemble -37.64 | reward 0.10]
> Train epoch 60 [ensemble -39.30 | reward 0.07]
> Train epoch 80 [ensemble -40.41 | reward 0.05]
> Train epoch 100 [ensemble -41.23 | reward 0.04]
Ensemble loss -41.23 / Reward Loss 0.04

=== Collecting data [29] ===
> Step 25 [reward 88.00]
> Step 50 [reward 188.00]
> Step 75 [reward 288.00]
> Step 100 [reward 388.00]
> Step 125 [reward 488.00]
> Step 150 [reward 588.00]
> Step 175 [reward 688.00]
> Step 200 [reward 788.00]
> Step 225 [reward 888.00]
> Step 250 [reward 988.00]
Rewards 988.00 / Steps 250.00
Reward stats:
 {'max': '43.07', 'mean': '14.58', 'min': '-0.14', 'std': '8.09'}
Information gain stats:
 {'max': '1.67', 'mean': '0.96', 'min': '0.33', 'std': '0.21'}
Episode time 52.56
Saved _metrics_

=== Episode 30 ===
Training on [8500/34000] data points
> Train epoch 20 [ensemble -34.65 | reward 0.17]
> Train epoch 40 [ensemble -37.87 | reward 0.09]
> Train epoch 60 [ensemble -39.50 | reward 0.06]
> Train epoch 80 [ensemble -40.58 | reward 0.05]
> Train epoch 100 [ensemble -41.39 | reward 0.04]
Ensemble loss -41.39 / Reward Loss 0.04

=== Collecting data [30] ===
> Step 25 [reward 32.00]
> Step 50 [reward 132.00]
> Step 75 [reward 232.00]
> Step 100 [reward 332.00]
> Step 125 [reward 432.00]
> Step 150 [reward 532.00]
> Step 175 [reward 632.00]
> Step 200 [reward 732.00]
> Step 225 [reward 832.00]
> Step 250 [reward 932.00]
Rewards 932.00 / Steps 250.00
Reward stats:
 {'max': '43.87', 'mean': '12.95', 'min': '-0.49', 'std': '8.24'}
Information gain stats:
 {'max': '1.69', 'mean': '0.99', 'min': '0.32', 'std': '0.21'}
Episode time 53.66
Saved _metrics_

=== Episode 31 ===
Training on [8750/35000] data points
> Train epoch 20 [ensemble -34.86 | reward 0.18]
> Train epoch 40 [ensemble -38.03 | reward 0.10]
> Train epoch 60 [ensemble -39.62 | reward 0.07]
> Train epoch 80 [ensemble -40.69 | reward 0.05]
> Train epoch 100 [ensemble -41.47 | reward 0.04]
Ensemble loss -41.47 / Reward Loss 0.04

=== Collecting data [31] ===
> Step 25 [reward 44.00]
> Step 50 [reward 144.00]
> Step 75 [reward 244.00]
> Step 100 [reward 344.00]
> Step 125 [reward 444.00]
> Step 150 [reward 544.00]
> Step 175 [reward 644.00]
> Step 200 [reward 744.00]
> Step 225 [reward 844.00]
> Step 250 [reward 944.00]
Rewards 944.00 / Steps 250.00
Reward stats:
 {'max': '44.11', 'mean': '12.66', 'min': '-0.46', 'std': '8.07'}
Information gain stats:
 {'max': '1.72', 'mean': '0.98', 'min': '0.36', 'std': '0.20'}
Episode time 54.73
Saved _metrics_

=== Episode 32 ===
Training on [9000/36000] data points
> Train epoch 20 [ensemble -35.04 | reward 0.17]
> Train epoch 40 [ensemble -38.15 | reward 0.09]
> Train epoch 60 [ensemble -39.72 | reward 0.06]
> Train epoch 80 [ensemble -40.77 | reward 0.05]
> Train epoch 100 [ensemble -41.55 | reward 0.04]
Ensemble loss -41.55 / Reward Loss 0.04

=== Collecting data [32] ===
> Step 25 [reward 23.00]
> Step 50 [reward 123.00]
> Step 75 [reward 223.00]
> Step 100 [reward 323.00]
> Step 125 [reward 423.00]
> Step 150 [reward 523.00]
> Step 175 [reward 623.00]
> Step 200 [reward 723.00]
> Step 225 [reward 823.00]
> Step 250 [reward 923.00]
Rewards 923.00 / Steps 250.00
Reward stats:
 {'max': '39.12', 'mean': '12.07', 'min': '-2.03', 'std': '7.34'}
Information gain stats:
 {'max': '1.66', 'mean': '0.99', 'min': '0.37', 'std': '0.20'}
Episode time 55.80
Saved _metrics_

=== Episode 33 ===
Training on [9250/37000] data points
> Train epoch 20 [ensemble -35.16 | reward 0.17]
> Train epoch 40 [ensemble -38.27 | reward 0.09]
> Train epoch 60 [ensemble -39.83 | reward 0.06]
> Train epoch 80 [ensemble -40.87 | reward 0.05]
> Train epoch 100 [ensemble -41.64 | reward 0.04]
Ensemble loss -41.64 / Reward Loss 0.04

=== Collecting data [33] ===
> Step 25 [reward 0.00]
> Step 50 [reward 85.00]
> Step 75 [reward 185.00]
> Step 100 [reward 285.00]
> Step 125 [reward 385.00]
> Step 150 [reward 485.00]
> Step 175 [reward 585.00]
> Step 200 [reward 685.00]
> Step 225 [reward 785.00]
> Step 250 [reward 885.00]
Rewards 885.00 / Steps 250.00
Reward stats:
 {'max': '42.85', 'mean': '12.36', 'min': '-1.07', 'std': '7.97'}
Information gain stats:
 {'max': '1.72', 'mean': '1.01', 'min': '0.36', 'std': '0.21'}
Episode time 56.71
Saved _metrics_

=== Episode 34 ===
Training on [9500/38000] data points
> Train epoch 20 [ensemble -35.47 | reward 0.17]
> Train epoch 40 [ensemble -38.45 | reward 0.09]
> Train epoch 60 [ensemble -39.97 | reward 0.06]
> Train epoch 80 [ensemble -40.99 | reward 0.05]
> Train epoch 100 [ensemble -41.75 | reward 0.04]
Ensemble loss -41.75 / Reward Loss 0.04

=== Collecting data [34] ===
> Step 25 [reward 90.00]
> Step 50 [reward 190.00]
> Step 75 [reward 290.00]
> Step 100 [reward 390.00]
> Step 125 [reward 490.00]
> Step 150 [reward 590.00]
> Step 175 [reward 690.00]
> Step 200 [reward 790.00]
> Step 225 [reward 890.00]
> Step 250 [reward 990.00]
Rewards 990.00 / Steps 250.00
Reward stats:
 {'max': '43.02', 'mean': '12.98', 'min': '-0.77', 'std': '7.54'}
Information gain stats:
 {'max': '1.69', 'mean': '0.99', 'min': '0.37', 'std': '0.21'}
Episode time 57.84
Saved _metrics_

=== Episode 35 ===
Training on [9750/39000] data points
> Train epoch 20 [ensemble -35.75 | reward 0.15]
> Train epoch 40 [ensemble -38.66 | reward 0.08]
> Train epoch 60 [ensemble -40.14 | reward 0.05]
> Train epoch 80 [ensemble -41.12 | reward 0.04]
> Train epoch 100 [ensemble -41.86 | reward 0.03]
Ensemble loss -41.86 / Reward Loss 0.03

=== Collecting data [35] ===
> Step 25 [reward 16.00]
> Step 50 [reward 116.00]
> Step 75 [reward 216.00]
> Step 100 [reward 316.00]
> Step 125 [reward 416.00]
> Step 150 [reward 516.00]
> Step 175 [reward 616.00]
> Step 200 [reward 716.00]
> Step 225 [reward 816.00]
> Step 250 [reward 916.00]
Rewards 916.00 / Steps 250.00
Reward stats:
 {'max': '41.95', 'mean': '12.39', 'min': '-0.43', 'std': '8.13'}
Information gain stats:
 {'max': '1.72', 'mean': '0.99', 'min': '0.35', 'std': '0.21'}
Episode time 60.67
Saved _metrics_

=== Episode 36 ===
Training on [10000/40000] data points
> Train epoch 20 [ensemble -35.87 | reward 0.16]
> Train epoch 40 [ensemble -38.76 | reward 0.08]
> Train epoch 60 [ensemble -40.23 | reward 0.06]
> Train epoch 80 [ensemble -41.22 | reward 0.04]
> Train epoch 100 [ensemble -41.94 | reward 0.03]
Ensemble loss -41.94 / Reward Loss 0.03

=== Collecting data [36] ===
> Step 25 [reward 87.00]
> Step 50 [reward 187.00]
> Step 75 [reward 287.00]
> Step 100 [reward 387.00]
> Step 125 [reward 487.00]
> Step 150 [reward 587.00]
> Step 175 [reward 687.00]
> Step 200 [reward 787.00]
> Step 225 [reward 887.00]
> Step 250 [reward 987.00]
Rewards 987.00 / Steps 250.00
Reward stats:
 {'max': '43.07', 'mean': '14.41', 'min': '-0.45', 'std': '8.12'}
Information gain stats:
 {'max': '1.74', 'mean': '0.99', 'min': '0.35', 'std': '0.22'}
Episode time 60.56
Saved _metrics_

=== Episode 37 ===
Training on [10250/41000] data points
> Train epoch 20 [ensemble -36.17 | reward 0.15]
> Train epoch 40 [ensemble -38.99 | reward 0.08]
> Train epoch 60 [ensemble -40.43 | reward 0.05]
> Train epoch 80 [ensemble -41.39 | reward 0.04]
> Train epoch 100 [ensemble -42.10 | reward 0.03]
Ensemble loss -42.10 / Reward Loss 0.03

=== Collecting data [37] ===
> Step 25 [reward 90.00]
> Step 50 [reward 190.00]
> Step 75 [reward 290.00]
> Step 100 [reward 390.00]
> Step 125 [reward 490.00]
> Step 150 [reward 590.00]
> Step 175 [reward 690.00]
> Step 200 [reward 790.00]
> Step 225 [reward 890.00]
> Step 250 [reward 990.00]
Rewards 990.00 / Steps 250.00
Reward stats:
 {'max': '46.25', 'mean': '15.20', 'min': '-0.10', 'std': '8.61'}
Information gain stats:
 {'max': '1.72', 'mean': '1.01', 'min': '0.35', 'std': '0.23'}
Episode time 61.65
Saved _metrics_

=== Episode 38 ===
Training on [10500/42000] data points
> Train epoch 20 [ensemble -36.43 | reward 0.15]
> Train epoch 40 [ensemble -39.20 | reward 0.08]
> Train epoch 60 [ensemble -40.60 | reward 0.05]
> Train epoch 80 [ensemble -41.53 | reward 0.04]
> Train epoch 100 [ensemble -42.22 | reward 0.03]
Ensemble loss -42.22 / Reward Loss 0.03

=== Collecting data [38] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 64.00]
> Step 100 [reward 164.00]
> Step 125 [reward 264.00]
> Step 150 [reward 364.00]
> Step 175 [reward 464.00]
> Step 200 [reward 564.00]
> Step 225 [reward 664.00]
> Step 250 [reward 764.00]
Rewards 764.00 / Steps 250.00
Reward stats:
 {'max': '47.25', 'mean': '11.81', 'min': '-1.07', 'std': '9.49'}
Information gain stats:
 {'max': '1.79', 'mean': '1.02', 'min': '0.34', 'std': '0.22'}
Episode time 62.88
Saved _metrics_

=== Episode 39 ===
Training on [10750/43000] data points
> Train epoch 20 [ensemble -36.42 | reward 0.14]
> Train epoch 40 [ensemble -39.20 | reward 0.07]
> Train epoch 60 [ensemble -40.60 | reward 0.05]
> Train epoch 80 [ensemble -41.54 | reward 0.04]
> Train epoch 100 [ensemble -42.24 | reward 0.03]
Ensemble loss -42.24 / Reward Loss 0.03

=== Collecting data [39] ===
> Step 25 [reward 49.00]
> Step 50 [reward 149.00]
> Step 75 [reward 249.00]
> Step 100 [reward 349.00]
> Step 125 [reward 449.00]
> Step 150 [reward 549.00]
> Step 175 [reward 649.00]
> Step 200 [reward 749.00]
> Step 225 [reward 849.00]
> Step 250 [reward 949.00]
Rewards 949.00 / Steps 250.00
Reward stats:
 {'max': '45.14', 'mean': '14.22', 'min': '-1.10', 'std': '8.80'}
Information gain stats:
 {'max': '1.76', 'mean': '0.99', 'min': '0.31', 'std': '0.22'}
Episode time 63.90
Saved _metrics_

=== Episode 40 ===
Training on [11000/44000] data points
> Train epoch 20 [ensemble -36.56 | reward 0.14]
> Train epoch 40 [ensemble -39.31 | reward 0.07]
> Train epoch 60 [ensemble -40.71 | reward 0.05]
> Train epoch 80 [ensemble -41.63 | reward 0.04]
> Train epoch 100 [ensemble -42.32 | reward 0.03]
Ensemble loss -42.32 / Reward Loss 0.03

=== Collecting data [40] ===
> Step 25 [reward 0.00]
> Step 50 [reward 32.00]
> Step 75 [reward 132.00]
> Step 100 [reward 232.00]
> Step 125 [reward 332.00]
> Step 150 [reward 432.00]
> Step 175 [reward 532.00]
> Step 200 [reward 632.00]
> Step 225 [reward 732.00]
> Step 250 [reward 832.00]
Rewards 832.00 / Steps 250.00
Reward stats:
 {'max': '44.63', 'mean': '12.49', 'min': '-0.82', 'std': '8.80'}
Information gain stats:
 {'max': '1.78', 'mean': '1.02', 'min': '0.33', 'std': '0.22'}
Episode time 65.27
Saved _metrics_

=== Episode 41 ===
Training on [11250/45000] data points
> Train epoch 20 [ensemble -36.64 | reward 0.15]
> Train epoch 40 [ensemble -39.37 | reward 0.08]
> Train epoch 60 [ensemble -40.76 | reward 0.05]
> Train epoch 80 [ensemble -41.68 | reward 0.04]
> Train epoch 100 [ensemble -42.36 | reward 0.03]
Ensemble loss -42.36 / Reward Loss 0.03

=== Collecting data [41] ===
> Step 25 [reward 48.00]
> Step 50 [reward 148.00]
> Step 75 [reward 248.00]
> Step 100 [reward 348.00]
> Step 125 [reward 448.00]
> Step 150 [reward 548.00]
> Step 175 [reward 648.00]
> Step 200 [reward 748.00]
> Step 225 [reward 848.00]
> Step 250 [reward 948.00]
Rewards 948.00 / Steps 250.00
Reward stats:
 {'max': '45.59', 'mean': '13.57', 'min': '-1.62', 'std': '8.47'}
Information gain stats:
 {'max': '1.72', 'mean': '1.02', 'min': '0.32', 'std': '0.23'}
Episode time 66.20
Saved _metrics_

=== Episode 42 ===
Training on [11500/46000] data points
> Train epoch 20 [ensemble -36.86 | reward 0.13]
> Train epoch 40 [ensemble -39.52 | reward 0.07]
> Train epoch 60 [ensemble -40.87 | reward 0.05]
> Train epoch 80 [ensemble -41.77 | reward 0.03]
> Train epoch 100 [ensemble -42.44 | reward 0.03]
Ensemble loss -42.44 / Reward Loss 0.03

=== Collecting data [42] ===
> Step 25 [reward 0.00]
> Step 50 [reward 92.00]
> Step 75 [reward 192.00]
> Step 100 [reward 292.00]
> Step 125 [reward 392.00]
> Step 150 [reward 492.00]
> Step 175 [reward 592.00]
> Step 200 [reward 692.00]
> Step 225 [reward 792.00]
> Step 250 [reward 892.00]
Rewards 892.00 / Steps 250.00
Reward stats:
 {'max': '46.60', 'mean': '12.90', 'min': '-0.38', 'std': '8.78'}
Information gain stats:
 {'max': '1.70', 'mean': '1.04', 'min': '0.34', 'std': '0.22'}
Episode time 67.18
Saved _metrics_

=== Episode 43 ===
Training on [11750/47000] data points
> Train epoch 20 [ensemble -36.98 | reward 0.13]
> Train epoch 40 [ensemble -39.61 | reward 0.07]
> Train epoch 60 [ensemble -40.95 | reward 0.04]
> Train epoch 80 [ensemble -41.84 | reward 0.03]
> Train epoch 100 [ensemble -42.50 | reward 0.03]
Ensemble loss -42.50 / Reward Loss 0.03

=== Collecting data [43] ===
> Step 25 [reward 89.00]
> Step 50 [reward 189.00]
> Step 75 [reward 289.00]
> Step 100 [reward 389.00]
> Step 125 [reward 489.00]
> Step 150 [reward 589.00]
> Step 175 [reward 689.00]
> Step 200 [reward 789.00]
> Step 225 [reward 889.00]
> Step 250 [reward 989.00]
Rewards 989.00 / Steps 250.00
Reward stats:
 {'max': '45.83', 'mean': '14.23', 'min': '-0.41', 'std': '8.77'}
Information gain stats:
 {'max': '1.74', 'mean': '1.01', 'min': '0.32', 'std': '0.23'}
Episode time 68.10
Saved _metrics_

=== Episode 44 ===
Training on [12000/48000] data points
> Train epoch 20 [ensemble -37.14 | reward 0.14]
> Train epoch 40 [ensemble -39.75 | reward 0.07]
> Train epoch 60 [ensemble -41.08 | reward 0.05]
> Train epoch 80 [ensemble -41.96 | reward 0.04]
> Train epoch 100 [ensemble -42.60 | reward 0.03]
Ensemble loss -42.60 / Reward Loss 0.03

=== Collecting data [44] ===
> Step 25 [reward 64.00]
> Step 50 [reward 164.00]
> Step 75 [reward 264.00]
> Step 100 [reward 364.00]
> Step 125 [reward 464.00]
> Step 150 [reward 564.00]
> Step 175 [reward 664.00]
> Step 200 [reward 764.00]
> Step 225 [reward 864.00]
> Step 250 [reward 964.00]
Rewards 964.00 / Steps 250.00
Reward stats:
 {'max': '45.16', 'mean': '13.28', 'min': '-0.35', 'std': '8.13'}
Information gain stats:
 {'max': '1.76', 'mean': '1.03', 'min': '0.36', 'std': '0.22'}
Episode time 69.33
Saved _metrics_

=== Episode 45 ===
Training on [12250/49000] data points
> Train epoch 20 [ensemble -37.29 | reward 0.13]
> Train epoch 40 [ensemble -39.85 | reward 0.07]
> Train epoch 60 [ensemble -41.15 | reward 0.05]
> Train epoch 80 [ensemble -42.02 | reward 0.03]
> Train epoch 100 [ensemble -42.66 | reward 0.03]
Ensemble loss -42.66 / Reward Loss 0.03

=== Collecting data [45] ===
> Step 25 [reward 58.00]
> Step 50 [reward 158.00]
> Step 75 [reward 258.00]
> Step 100 [reward 358.00]
> Step 125 [reward 458.00]
> Step 150 [reward 558.00]
> Step 175 [reward 658.00]
> Step 200 [reward 758.00]
> Step 225 [reward 858.00]
> Step 250 [reward 958.00]
Rewards 958.00 / Steps 250.00
Reward stats:
 {'max': '48.17', 'mean': '15.38', 'min': '-0.39', 'std': '9.21'}
Information gain stats:
 {'max': '1.68', 'mean': '1.01', 'min': '0.33', 'std': '0.22'}
Episode time 70.25
Saved _metrics_

=== Episode 46 ===
Training on [12500/50000] data points
> Train epoch 20 [ensemble -37.46 | reward 0.13]
> Train epoch 40 [ensemble -40.00 | reward 0.07]
> Train epoch 60 [ensemble -41.29 | reward 0.05]
> Train epoch 80 [ensemble -42.15 | reward 0.03]
> Train epoch 100 [ensemble -42.79 | reward 0.03]
Ensemble loss -42.79 / Reward Loss 0.03

=== Collecting data [46] ===
> Step 25 [reward 0.00]
> Step 50 [reward 32.00]
> Step 75 [reward 132.00]
> Step 100 [reward 232.00]
> Step 125 [reward 332.00]
> Step 150 [reward 432.00]
> Step 175 [reward 532.00]
> Step 200 [reward 632.00]
> Step 225 [reward 732.00]
> Step 250 [reward 832.00]
Rewards 832.00 / Steps 250.00
Reward stats:
 {'max': '46.32', 'mean': '13.34', 'min': '-0.73', 'std': '9.29'}
Information gain stats:
 {'max': '1.79', 'mean': '1.02', 'min': '0.32', 'std': '0.21'}
Episode time 71.43
Saved _metrics_

=== Episode 47 ===
Training on [12750/51000] data points
> Train epoch 20 [ensemble -37.62 | reward 0.12]
> Train epoch 40 [ensemble -40.12 | reward 0.06]
> Train epoch 60 [ensemble -41.39 | reward 0.04]
> Train epoch 80 [ensemble -42.23 | reward 0.03]
> Train epoch 100 [ensemble -42.84 | reward 0.03]
Ensemble loss -42.84 / Reward Loss 0.03

=== Collecting data [47] ===
> Step 25 [reward 52.00]
> Step 50 [reward 152.00]
> Step 75 [reward 252.00]
> Step 100 [reward 352.00]
> Step 125 [reward 452.00]
> Step 150 [reward 552.00]
> Step 175 [reward 652.00]
> Step 200 [reward 752.00]
> Step 225 [reward 852.00]
> Step 250 [reward 952.00]
Rewards 952.00 / Steps 250.00
Reward stats:
 {'max': '46.43', 'mean': '14.31', 'min': '-1.07', 'std': '8.55'}
Information gain stats:
 {'max': '1.72', 'mean': '1.03', 'min': '0.36', 'std': '0.22'}
Episode time 72.36
Saved _metrics_

=== Episode 48 ===
Training on [13000/52000] data points
> Train epoch 20 [ensemble -37.76 | reward 0.13]
> Train epoch 40 [ensemble -40.22 | reward 0.07]
> Train epoch 60 [ensemble -41.47 | reward 0.04]
> Train epoch 80 [ensemble -42.29 | reward 0.03]
> Train epoch 100 [ensemble -42.90 | reward 0.03]
Ensemble loss -42.90 / Reward Loss 0.03

=== Collecting data [48] ===
> Step 25 [reward 94.00]
> Step 50 [reward 194.00]
> Step 75 [reward 294.00]
> Step 100 [reward 394.00]
> Step 125 [reward 494.00]
> Step 150 [reward 594.00]
> Step 175 [reward 694.00]
> Step 200 [reward 794.00]
> Step 225 [reward 894.00]
> Step 250 [reward 994.00]
Rewards 994.00 / Steps 250.00
Reward stats:
 {'max': '45.82', 'mean': '14.37', 'min': '-0.57', 'std': '8.34'}
Information gain stats:
 {'max': '1.72', 'mean': '1.02', 'min': '0.33', 'std': '0.21'}
Episode time 73.54
Saved _metrics_

=== Episode 49 ===
Training on [13250/53000] data points
> Train epoch 20 [ensemble -37.87 | reward 0.12]
> Train epoch 40 [ensemble -40.32 | reward 0.06]
> Train epoch 60 [ensemble -41.55 | reward 0.04]
> Train epoch 80 [ensemble -42.37 | reward 0.03]
> Train epoch 100 [ensemble -42.98 | reward 0.02]
Ensemble loss -42.98 / Reward Loss 0.02

=== Collecting data [49] ===
> Step 25 [reward 88.00]
> Step 50 [reward 188.00]
> Step 75 [reward 288.00]
> Step 100 [reward 388.00]
> Step 125 [reward 488.00]
> Step 150 [reward 588.00]
> Step 175 [reward 688.00]
> Step 200 [reward 788.00]
> Step 225 [reward 888.00]
> Step 250 [reward 988.00]
Rewards 988.00 / Steps 250.00
Reward stats:
 {'max': '46.93', 'mean': '15.36', 'min': '-0.58', 'std': '8.69'}
Information gain stats:
 {'max': '1.72', 'mean': '1.02', 'min': '0.34', 'std': '0.23'}
Episode time 74.36
Saved _metrics_