09:10:41

=== Loading experiment [device: cuda] ===

{'action_noise': None,
 'action_repeat': 4,
 'batch_size': 50,
 'coverage': False,
 'ensemble_size': 10,
 'env_name': 'DeepMindCatch',
 'epsilon': 1e-08,
 'expl_scale': 0.1,
 'expl_strategy': 'information',
 'grad_clip_norm': 1000,
 'hidden_size': 200,
 'learning_rate': 0.001,
 'logdir': 'cup_catch_OG',
 'max_episode_len': 1000,
 'n_candidates': 500,
 'n_episodes': 50,
 'n_seed_episodes': 5,
 'n_train_epochs': 100,
 'optimisation_iters': 5,
 'plan_horizon': 12,
 'record_every': None,
 'reward_scale': 1.0,
 'seed': 3,
 'strategy': 'information',
 'top_candidates': 50,
 'use_exploration': True,
 'use_mean': False,
 'use_reward': True}

Collected seeds: [5 episodes | 1250 frames]

=== Episode 1 ===
Training on [1250/5000] data points
> Train epoch 20 [ensemble -21.02 | reward 0.01]
> Train epoch 40 [ensemble -28.98 | reward 0.00]
> Train epoch 60 [ensemble -32.89 | reward 0.00]
> Train epoch 80 [ensemble -35.36 | reward 0.00]
> Train epoch 100 [ensemble -37.12 | reward 0.00]
Ensemble loss -37.12 / Reward Loss 0.00

=== Collecting data [1] ===
> Step 25 [reward 14.00]
> Step 50 [reward 112.00]
> Step 75 [reward 212.00]
> Step 100 [reward 311.00]
> Step 125 [reward 408.00]
> Step 150 [reward 508.00]
> Step 175 [reward 607.00]
> Step 200 [reward 694.00]
> Step 225 [reward 793.00]
> Step 250 [reward 884.00]
Rewards 884.00 / Steps 250.00
Reward stats:
 {'max': '15.05', 'mean': '2.17', 'min': '-0.29', 'std': '2.18'}
Information gain stats:
 {'max': '2.18', 'mean': '1.08', 'min': '0.43', 'std': '0.21'}
Episode time 22.53
Saved _metrics_

=== Episode 2 ===
Training on [1500/6000] data points
> Train epoch 20 [ensemble -19.02 | reward 0.21]
> Train epoch 40 [ensemble -26.34 | reward 0.11]
> Train epoch 60 [ensemble -30.03 | reward 0.08]
> Train epoch 80 [ensemble -32.45 | reward 0.06]
> Train epoch 100 [ensemble -34.25 | reward 0.05]
Ensemble loss -34.25 / Reward Loss 0.05

=== Collecting data [2] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 65.00]
> Step 150 [reward 159.00]
> Step 175 [reward 247.00]
> Step 200 [reward 330.00]
> Step 225 [reward 415.00]
> Step 250 [reward 497.00]
Rewards 497.00 / Steps 250.00
Reward stats:
 {'max': '54.89', 'mean': '13.45', 'min': '-2.49', 'std': '9.84'}
Information gain stats:
 {'max': '1.62', 'mean': '0.94', 'min': '0.46', 'std': '0.14'}
Episode time 23.52
Saved _metrics_

=== Episode 3 ===
Training on [1750/7000] data points
> Train epoch 20 [ensemble -19.52 | reward 0.26]
> Train epoch 40 [ensemble -26.64 | reward 0.14]
> Train epoch 60 [ensemble -30.26 | reward 0.10]
> Train epoch 80 [ensemble -32.63 | reward 0.08]
> Train epoch 100 [ensemble -34.38 | reward 0.07]
Ensemble loss -34.38 / Reward Loss 0.07

=== Collecting data [3] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 95.00]
> Step 175 [reward 195.00]
> Step 200 [reward 295.00]
> Step 225 [reward 395.00]
> Step 250 [reward 495.00]
Rewards 495.00 / Steps 250.00
Reward stats:
 {'max': '43.17', 'mean': '9.97', 'min': '-1.07', 'std': '9.95'}
Information gain stats:
 {'max': '1.53', 'mean': '0.81', 'min': '0.31', 'std': '0.20'}
Episode time 24.61
Saved _metrics_

=== Episode 4 ===
Training on [2000/8000] data points
> Train epoch 20 [ensemble -19.76 | reward 0.27]
> Train epoch 40 [ensemble -26.84 | reward 0.15]
> Train epoch 60 [ensemble -30.43 | reward 0.11]
> Train epoch 80 [ensemble -32.80 | reward 0.09]
> Train epoch 100 [ensemble -34.55 | reward 0.07]
Ensemble loss -34.55 / Reward Loss 0.07

=== Collecting data [4] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 13.00]
> Step 125 [reward 110.00]
> Step 150 [reward 210.00]
> Step 175 [reward 309.00]
> Step 200 [reward 409.00]
> Step 225 [reward 508.00]
> Step 250 [reward 608.00]
Rewards 608.00 / Steps 250.00
Reward stats:
 {'max': '43.76', 'mean': '11.11', 'min': '-2.46', 'std': '9.97'}
Information gain stats:
 {'max': '1.61', 'mean': '0.82', 'min': '0.28', 'std': '0.24'}
Episode time 25.63
Saved _metrics_

=== Episode 5 ===
Training on [2250/9000] data points
> Train epoch 20 [ensemble -20.44 | reward 0.30]
> Train epoch 40 [ensemble -27.17 | reward 0.17]
> Train epoch 60 [ensemble -30.62 | reward 0.13]
> Train epoch 80 [ensemble -32.92 | reward 0.10]
> Train epoch 100 [ensemble -34.62 | reward 0.08]
Ensemble loss -34.62 / Reward Loss 0.08

=== Collecting data [5] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '42.27', 'mean': '4.78', 'min': '-2.06', 'std': '6.61'}
Information gain stats:
 {'max': '1.61', 'mean': '0.92', 'min': '0.31', 'std': '0.18'}
Episode time 26.72
Saved _metrics_

=== Episode 6 ===
Training on [2500/10000] data points
> Train epoch 20 [ensemble -21.06 | reward 0.30]
> Train epoch 40 [ensemble -27.35 | reward 0.17]
> Train epoch 60 [ensemble -30.64 | reward 0.12]
> Train epoch 80 [ensemble -32.87 | reward 0.10]
> Train epoch 100 [ensemble -34.53 | reward 0.08]
Ensemble loss -34.53 / Reward Loss 0.08

=== Collecting data [6] ===
> Step 25 [reward 75.00]
> Step 50 [reward 175.00]
> Step 75 [reward 275.00]
> Step 100 [reward 375.00]
> Step 125 [reward 475.00]
> Step 150 [reward 575.00]
> Step 175 [reward 675.00]
> Step 200 [reward 775.00]
> Step 225 [reward 875.00]
> Step 250 [reward 975.00]
Rewards 975.00 / Steps 250.00
Reward stats:
 {'max': '28.68', 'mean': '7.35', 'min': '-1.61', 'std': '4.26'}
Information gain stats:
 {'max': '1.53', 'mean': '0.90', 'min': '0.48', 'std': '0.12'}
Episode time 27.74
Saved _metrics_

=== Episode 7 ===
Training on [2750/11000] data points
> Train epoch 20 [ensemble -22.14 | reward 0.32]
> Train epoch 40 [ensemble -28.19 | reward 0.18]
> Train epoch 60 [ensemble -31.34 | reward 0.13]
> Train epoch 80 [ensemble -33.47 | reward 0.10]
> Train epoch 100 [ensemble -35.06 | reward 0.08]
Ensemble loss -35.06 / Reward Loss 0.08

=== Collecting data [7] ===
> Step 25 [reward 56.00]
> Step 50 [reward 156.00]
> Step 75 [reward 256.00]
> Step 100 [reward 356.00]
> Step 125 [reward 456.00]
> Step 150 [reward 556.00]
> Step 175 [reward 656.00]
> Step 200 [reward 756.00]
> Step 225 [reward 856.00]
> Step 250 [reward 956.00]
Rewards 956.00 / Steps 250.00
Reward stats:
 {'max': '37.76', 'mean': '9.12', 'min': '-0.55', 'std': '6.10'}
Information gain stats:
 {'max': '1.57', 'mean': '0.86', 'min': '0.37', 'std': '0.16'}
Episode time 28.93
Saved _metrics_

=== Episode 8 ===
Training on [3000/12000] data points
> Train epoch 20 [ensemble -23.35 | reward 0.28]
> Train epoch 40 [ensemble -29.14 | reward 0.16]
> Train epoch 60 [ensemble -32.18 | reward 0.12]
> Train epoch 80 [ensemble -34.21 | reward 0.09]
> Train epoch 100 [ensemble -35.74 | reward 0.07]
Ensemble loss -35.74 / Reward Loss 0.07

=== Collecting data [8] ===
> Step 25 [reward 95.00]
> Step 50 [reward 195.00]
> Step 75 [reward 295.00]
> Step 100 [reward 395.00]
> Step 125 [reward 495.00]
> Step 150 [reward 595.00]
> Step 175 [reward 695.00]
> Step 200 [reward 795.00]
> Step 225 [reward 895.00]
> Step 250 [reward 995.00]
Rewards 995.00 / Steps 250.00
Reward stats:
 {'max': '37.18', 'mean': '8.39', 'min': '-2.11', 'std': '6.11'}
Information gain stats:
 {'max': '1.54', 'mean': '0.86', 'min': '0.34', 'std': '0.16'}
Episode time 29.87
Saved _metrics_

=== Episode 9 ===
Training on [3250/13000] data points
> Train epoch 20 [ensemble -24.18 | reward 0.29]
> Train epoch 40 [ensemble -29.83 | reward 0.16]
> Train epoch 60 [ensemble -32.75 | reward 0.12]
> Train epoch 80 [ensemble -34.73 | reward 0.09]
> Train epoch 100 [ensemble -36.20 | reward 0.07]
Ensemble loss -36.20 / Reward Loss 0.07

=== Collecting data [9] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '15.19', 'mean': '2.06', 'min': '-2.63', 'std': '1.56'}
Information gain stats:
 {'max': '1.77', 'mean': '1.20', 'min': '0.57', 'std': '0.12'}
Episode time 30.89
Saved _metrics_

=== Episode 10 ===
Training on [3500/14000] data points
> Train epoch 20 [ensemble -25.46 | reward 0.27]
> Train epoch 40 [ensemble -30.82 | reward 0.16]
> Train epoch 60 [ensemble -33.58 | reward 0.11]
> Train epoch 80 [ensemble -35.44 | reward 0.09]
> Train epoch 100 [ensemble -36.84 | reward 0.07]
Ensemble loss -36.84 / Reward Loss 0.07

=== Collecting data [10] ===
> Step 25 [reward 0.00]
> Step 50 [reward 97.00]
> Step 75 [reward 197.00]
> Step 100 [reward 297.00]
> Step 125 [reward 397.00]
> Step 150 [reward 497.00]
> Step 175 [reward 597.00]
> Step 200 [reward 697.00]
> Step 225 [reward 797.00]
> Step 250 [reward 897.00]
Rewards 897.00 / Steps 250.00
Reward stats:
 {'max': '36.61', 'mean': '8.23', 'min': '-2.15', 'std': '6.18'}
Information gain stats:
 {'max': '1.54', 'mean': '0.86', 'min': '0.34', 'std': '0.16'}
Episode time 31.95
Saved _metrics_

=== Episode 11 ===
Training on [3750/15000] data points
> Train epoch 20 [ensemble -25.85 | reward 0.25]
> Train epoch 40 [ensemble -31.18 | reward 0.14]
> Train epoch 60 [ensemble -33.91 | reward 0.10]
> Train epoch 80 [ensemble -35.74 | reward 0.08]
> Train epoch 100 [ensemble -37.12 | reward 0.06]
Ensemble loss -37.12 / Reward Loss 0.06

=== Collecting data [11] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 82.00]
> Step 125 [reward 182.00]
> Step 150 [reward 282.00]
> Step 175 [reward 382.00]
> Step 200 [reward 482.00]
> Step 225 [reward 582.00]
> Step 250 [reward 682.00]
Rewards 682.00 / Steps 250.00
Reward stats:
 {'max': '36.18', 'mean': '6.05', 'min': '-1.99', 'std': '5.83'}
Information gain stats:
 {'max': '1.77', 'mean': '0.89', 'min': '0.35', 'std': '0.17'}
Episode time 33.17
Saved _metrics_

=== Episode 12 ===
Training on [4000/16000] data points
> Train epoch 20 [ensemble -26.29 | reward 0.26]
> Train epoch 40 [ensemble -31.50 | reward 0.15]
> Train epoch 60 [ensemble -34.18 | reward 0.10]
> Train epoch 80 [ensemble -35.98 | reward 0.08]
> Train epoch 100 [ensemble -37.31 | reward 0.07]
Ensemble loss -37.31 / Reward Loss 0.07

=== Collecting data [12] ===
> Step 25 [reward 48.00]
> Step 50 [reward 148.00]
> Step 75 [reward 248.00]
> Step 100 [reward 348.00]
> Step 125 [reward 448.00]
> Step 150 [reward 548.00]
> Step 175 [reward 648.00]
> Step 200 [reward 748.00]
> Step 225 [reward 848.00]
> Step 250 [reward 948.00]
Rewards 948.00 / Steps 250.00
Reward stats:
 {'max': '38.95', 'mean': '9.08', 'min': '-1.96', 'std': '7.00'}
Information gain stats:
 {'max': '1.55', 'mean': '0.84', 'min': '0.33', 'std': '0.17'}
Episode time 34.19
Saved _metrics_

=== Episode 13 ===
Training on [4250/17000] data points
> Train epoch 20 [ensemble -26.58 | reward 0.25]
> Train epoch 40 [ensemble -31.81 | reward 0.15]
> Train epoch 60 [ensemble -34.45 | reward 0.11]
> Train epoch 80 [ensemble -36.21 | reward 0.08]
> Train epoch 100 [ensemble -37.52 | reward 0.07]
Ensemble loss -37.52 / Reward Loss 0.07

=== Collecting data [13] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 97.00]
> Step 125 [reward 197.00]
> Step 150 [reward 297.00]
> Step 175 [reward 397.00]
> Step 200 [reward 497.00]
> Step 225 [reward 597.00]
> Step 250 [reward 697.00]
Rewards 697.00 / Steps 250.00
Reward stats:
 {'max': '42.63', 'mean': '8.01', 'min': '-1.73', 'std': '7.75'}
Information gain stats:
 {'max': '1.50', 'mean': '0.86', 'min': '0.27', 'std': '0.18'}
Episode time 35.21
Saved _metrics_

=== Episode 14 ===
Training on [4500/18000] data points
> Train epoch 20 [ensemble -26.74 | reward 0.25]
> Train epoch 40 [ensemble -32.01 | reward 0.14]
> Train epoch 60 [ensemble -34.69 | reward 0.10]
> Train epoch 80 [ensemble -36.47 | reward 0.08]
> Train epoch 100 [ensemble -37.80 | reward 0.06]
Ensemble loss -37.80 / Reward Loss 0.06

=== Collecting data [14] ===
> Step 25 [reward 96.00]
> Step 50 [reward 196.00]
> Step 75 [reward 296.00]
> Step 100 [reward 396.00]
> Step 125 [reward 496.00]
> Step 150 [reward 596.00]
> Step 175 [reward 696.00]
> Step 200 [reward 796.00]
> Step 225 [reward 896.00]
> Step 250 [reward 996.00]
Rewards 996.00 / Steps 250.00
Reward stats:
 {'max': '41.02', 'mean': '10.17', 'min': '-1.02', 'std': '7.29'}
Information gain stats:
 {'max': '1.58', 'mean': '0.86', 'min': '0.32', 'std': '0.17'}
Episode time 36.40
Saved _metrics_

=== Episode 15 ===
Training on [4750/19000] data points
> Train epoch 20 [ensemble -27.61 | reward 0.25]
> Train epoch 40 [ensemble -32.62 | reward 0.14]
> Train epoch 60 [ensemble -35.16 | reward 0.10]
> Train epoch 80 [ensemble -36.86 | reward 0.08]
> Train epoch 100 [ensemble -38.13 | reward 0.06]
Ensemble loss -38.13 / Reward Loss 0.06

=== Collecting data [15] ===
> Step 25 [reward 30.00]
> Step 50 [reward 130.00]
> Step 75 [reward 230.00]
> Step 100 [reward 330.00]
> Step 125 [reward 430.00]
> Step 150 [reward 530.00]
> Step 175 [reward 630.00]
> Step 200 [reward 730.00]
> Step 225 [reward 830.00]
> Step 250 [reward 930.00]
Rewards 930.00 / Steps 250.00
Reward stats:
 {'max': '41.27', 'mean': '10.35', 'min': '-0.99', 'std': '7.59'}
Information gain stats:
 {'max': '1.57', 'mean': '0.87', 'min': '0.32', 'std': '0.18'}
Episode time 37.40
Saved _metrics_

=== Episode 16 ===
Training on [5000/20000] data points
> Train epoch 20 [ensemble -27.97 | reward 0.22]
> Train epoch 40 [ensemble -32.90 | reward 0.13]
> Train epoch 60 [ensemble -35.40 | reward 0.09]
> Train epoch 80 [ensemble -37.07 | reward 0.07]
> Train epoch 100 [ensemble -38.32 | reward 0.06]
Ensemble loss -38.32 / Reward Loss 0.06

=== Collecting data [16] ===
> Step 25 [reward 12.00]
> Step 50 [reward 112.00]
> Step 75 [reward 212.00]
> Step 100 [reward 312.00]
> Step 125 [reward 412.00]
> Step 150 [reward 512.00]
> Step 175 [reward 612.00]
> Step 200 [reward 712.00]
> Step 225 [reward 812.00]
> Step 250 [reward 912.00]
Rewards 912.00 / Steps 250.00
Reward stats:
 {'max': '42.28', 'mean': '10.78', 'min': '-1.96', 'std': '8.04'}
Information gain stats:
 {'max': '1.71', 'mean': '0.88', 'min': '0.32', 'std': '0.20'}
Episode time 38.32
Saved _metrics_

=== Episode 17 ===
Training on [5250/21000] data points
> Train epoch 20 [ensemble -28.38 | reward 0.23]
> Train epoch 40 [ensemble -33.21 | reward 0.14]
> Train epoch 60 [ensemble -35.67 | reward 0.10]
> Train epoch 80 [ensemble -37.31 | reward 0.08]
> Train epoch 100 [ensemble -38.53 | reward 0.06]
Ensemble loss -38.53 / Reward Loss 0.06

=== Collecting data [17] ===
> Step 25 [reward 64.00]
> Step 50 [reward 164.00]
> Step 75 [reward 264.00]
> Step 100 [reward 364.00]
> Step 125 [reward 464.00]
> Step 150 [reward 564.00]
> Step 175 [reward 664.00]
> Step 200 [reward 764.00]
> Step 225 [reward 864.00]
> Step 250 [reward 964.00]
Rewards 964.00 / Steps 250.00
Reward stats:
 {'max': '42.54', 'mean': '11.43', 'min': '-1.01', 'std': '8.15'}
Information gain stats:
 {'max': '1.64', 'mean': '0.86', 'min': '0.31', 'std': '0.19'}
Episode time 39.58
Saved _metrics_

=== Episode 18 ===
Training on [5500/22000] data points
> Train epoch 20 [ensemble -28.78 | reward 0.22]
> Train epoch 40 [ensemble -33.53 | reward 0.13]
> Train epoch 60 [ensemble -35.98 | reward 0.09]
> Train epoch 80 [ensemble -37.61 | reward 0.07]
> Train epoch 100 [ensemble -38.81 | reward 0.06]
Ensemble loss -38.81 / Reward Loss 0.06

=== Collecting data [18] ===
> Step 25 [reward 86.00]
> Step 50 [reward 186.00]
> Step 75 [reward 286.00]
> Step 100 [reward 386.00]
> Step 125 [reward 486.00]
> Step 150 [reward 586.00]
> Step 175 [reward 686.00]
> Step 200 [reward 786.00]
> Step 225 [reward 886.00]
> Step 250 [reward 986.00]
Rewards 986.00 / Steps 250.00
Reward stats:
 {'max': '42.92', 'mean': '11.80', 'min': '-1.25', 'std': '8.44'}
Information gain stats:
 {'max': '1.57', 'mean': '0.84', 'min': '0.31', 'std': '0.20'}
Episode time 40.49
Saved _metrics_

=== Episode 19 ===
Training on [5750/23000] data points
> Train epoch 20 [ensemble -29.16 | reward 0.21]
> Train epoch 40 [ensemble -33.82 | reward 0.12]
> Train epoch 60 [ensemble -36.24 | reward 0.09]
> Train epoch 80 [ensemble -37.84 | reward 0.07]
> Train epoch 100 [ensemble -39.03 | reward 0.05]
Ensemble loss -39.03 / Reward Loss 0.05

=== Collecting data [19] ===
> Step 25 [reward 17.00]
> Step 50 [reward 117.00]
> Step 75 [reward 217.00]
> Step 100 [reward 317.00]
> Step 125 [reward 417.00]
> Step 150 [reward 517.00]
> Step 175 [reward 617.00]
> Step 200 [reward 717.00]
> Step 225 [reward 817.00]
> Step 250 [reward 917.00]
Rewards 917.00 / Steps 250.00
Reward stats:
 {'max': '44.30', 'mean': '12.43', 'min': '-2.17', 'std': '9.41'}
Information gain stats:
 {'max': '1.63', 'mean': '0.88', 'min': '0.30', 'std': '0.20'}
Episode time 41.72
Saved _metrics_

=== Episode 20 ===
Training on [6000/24000] data points
> Train epoch 20 [ensemble -29.65 | reward 0.22]
> Train epoch 40 [ensemble -34.21 | reward 0.13]
> Train epoch 60 [ensemble -36.57 | reward 0.09]
> Train epoch 80 [ensemble -38.14 | reward 0.07]
> Train epoch 100 [ensemble -39.30 | reward 0.06]
Ensemble loss -39.30 / Reward Loss 0.06

=== Collecting data [20] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 69.00]
> Step 100 [reward 169.00]
> Step 125 [reward 269.00]
> Step 150 [reward 369.00]
> Step 175 [reward 469.00]
> Step 200 [reward 569.00]
> Step 225 [reward 669.00]
> Step 250 [reward 769.00]
Rewards 769.00 / Steps 250.00
Reward stats:
 {'max': '43.09', 'mean': '10.23', 'min': '-3.65', 'std': '8.66'}
Information gain stats:
 {'max': '1.65', 'mean': '0.91', 'min': '0.31', 'std': '0.20'}
Episode time 42.71
Saved _metrics_

=== Episode 21 ===
Training on [6250/25000] data points
> Train epoch 20 [ensemble -30.27 | reward 0.21]
> Train epoch 40 [ensemble -34.67 | reward 0.12]
> Train epoch 60 [ensemble -36.93 | reward 0.08]
> Train epoch 80 [ensemble -38.43 | reward 0.06]
> Train epoch 100 [ensemble -39.53 | reward 0.05]
Ensemble loss -39.53 / Reward Loss 0.05

=== Collecting data [21] ===
> Step 25 [reward 0.00]
> Step 50 [reward 17.00]
> Step 75 [reward 117.00]
> Step 100 [reward 217.00]
> Step 125 [reward 317.00]
> Step 150 [reward 417.00]
> Step 175 [reward 517.00]
> Step 200 [reward 617.00]
> Step 225 [reward 717.00]
> Step 250 [reward 817.00]
Rewards 817.00 / Steps 250.00
Reward stats:
 {'max': '42.28', 'mean': '10.73', 'min': '-2.17', 'std': '8.47'}
Information gain stats:
 {'max': '1.64', 'mean': '0.92', 'min': '0.35', 'std': '0.19'}
Episode time 43.81
Saved _metrics_

=== Episode 22 ===
Training on [6500/26000] data points
> Train epoch 20 [ensemble -30.38 | reward 0.19]
> Train epoch 40 [ensemble -34.75 | reward 0.11]
> Train epoch 60 [ensemble -37.03 | reward 0.07]
> Train epoch 80 [ensemble -38.54 | reward 0.06]
> Train epoch 100 [ensemble -39.65 | reward 0.05]
Ensemble loss -39.65 / Reward Loss 0.05

=== Collecting data [22] ===
> Step 25 [reward 52.00]
> Step 50 [reward 152.00]
> Step 75 [reward 252.00]
> Step 100 [reward 352.00]
> Step 125 [reward 452.00]
> Step 150 [reward 552.00]
> Step 175 [reward 652.00]
> Step 200 [reward 752.00]
> Step 225 [reward 852.00]
> Step 250 [reward 952.00]
Rewards 952.00 / Steps 250.00
Reward stats:
 {'max': '42.69', 'mean': '11.44', 'min': '-1.23', 'std': '8.08'}
Information gain stats:
 {'max': '1.65', 'mean': '0.90', 'min': '0.36', 'std': '0.18'}
Episode time 44.74
Saved _metrics_

=== Episode 23 ===
Training on [6750/27000] data points
> Train epoch 20 [ensemble -31.00 | reward 0.22]
> Train epoch 40 [ensemble -35.22 | reward 0.13]
> Train epoch 60 [ensemble -37.41 | reward 0.09]
> Train epoch 80 [ensemble -38.86 | reward 0.07]
> Train epoch 100 [ensemble -39.93 | reward 0.06]
Ensemble loss -39.93 / Reward Loss 0.06

=== Collecting data [23] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 17.00]
> Step 175 [reward 117.00]
> Step 200 [reward 217.00]
> Step 225 [reward 317.00]
> Step 250 [reward 417.00]
Rewards 417.00 / Steps 250.00
Reward stats:
 {'max': '38.29', 'mean': '5.99', 'min': '-4.00', 'std': '6.61'}
Information gain stats:
 {'max': '1.67', 'mean': '1.02', 'min': '0.35', 'std': '0.18'}
Episode time 45.71
Saved _metrics_

=== Episode 24 ===
Training on [7000/28000] data points
> Train epoch 20 [ensemble -31.06 | reward 0.21]
> Train epoch 40 [ensemble -35.23 | reward 0.11]
> Train epoch 60 [ensemble -37.40 | reward 0.08]
> Train epoch 80 [ensemble -38.85 | reward 0.06]
> Train epoch 100 [ensemble -39.92 | reward 0.05]
Ensemble loss -39.92 / Reward Loss 0.05

=== Collecting data [24] ===
> Step 25 [reward 42.00]
> Step 50 [reward 142.00]
> Step 75 [reward 242.00]
> Step 100 [reward 342.00]
> Step 125 [reward 442.00]
> Step 150 [reward 542.00]
> Step 175 [reward 642.00]
> Step 200 [reward 742.00]
> Step 225 [reward 842.00]
> Step 250 [reward 942.00]
Rewards 942.00 / Steps 250.00
Reward stats:
 {'max': '41.42', 'mean': '10.68', 'min': '-1.31', 'std': '8.11'}
Information gain stats:
 {'max': '1.69', 'mean': '0.91', 'min': '0.35', 'std': '0.20'}
Episode time 46.81
Saved _metrics_

=== Episode 25 ===
Training on [7250/29000] data points
> Train epoch 20 [ensemble -31.64 | reward 0.21]
> Train epoch 40 [ensemble -35.72 | reward 0.12]
> Train epoch 60 [ensemble -37.82 | reward 0.08]
> Train epoch 80 [ensemble -39.20 | reward 0.06]
> Train epoch 100 [ensemble -40.22 | reward 0.05]
Ensemble loss -40.22 / Reward Loss 0.05

=== Collecting data [25] ===
> Step 25 [reward 5.00]
> Step 50 [reward 105.00]
> Step 75 [reward 205.00]
> Step 100 [reward 305.00]
> Step 125 [reward 405.00]
> Step 150 [reward 505.00]
> Step 175 [reward 605.00]
> Step 200 [reward 705.00]
> Step 225 [reward 805.00]
> Step 250 [reward 905.00]
Rewards 905.00 / Steps 250.00
Reward stats:
 {'max': '45.03', 'mean': '11.24', 'min': '-2.89', 'std': '8.78'}
Information gain stats:
 {'max': '1.81', 'mean': '0.92', 'min': '0.35', 'std': '0.19'}
Episode time 49.06
Saved _metrics_

=== Episode 26 ===
Training on [7500/30000] data points
> Train epoch 20 [ensemble -31.80 | reward 0.19]
> Train epoch 40 [ensemble -35.79 | reward 0.11]
> Train epoch 60 [ensemble -37.87 | reward 0.08]
> Train epoch 80 [ensemble -39.25 | reward 0.06]
> Train epoch 100 [ensemble -40.28 | reward 0.05]
Ensemble loss -40.28 / Reward Loss 0.05

=== Collecting data [26] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 42.00]
> Step 100 [reward 142.00]
> Step 125 [reward 242.00]
> Step 150 [reward 342.00]
> Step 175 [reward 442.00]
> Step 200 [reward 542.00]
> Step 225 [reward 642.00]
> Step 250 [reward 742.00]
Rewards 742.00 / Steps 250.00
Reward stats:
 {'max': '43.94', 'mean': '9.44', 'min': '-2.93', 'std': '8.84'}
Information gain stats:
 {'max': '1.71', 'mean': '0.96', 'min': '0.35', 'std': '0.20'}
Episode time 51.40
Saved _metrics_

=== Episode 27 ===
Training on [7750/31000] data points
> Train epoch 20 [ensemble -32.23 | reward 0.20]
> Train epoch 40 [ensemble -36.11 | reward 0.11]
> Train epoch 60 [ensemble -38.14 | reward 0.08]
> Train epoch 80 [ensemble -39.49 | reward 0.06]
> Train epoch 100 [ensemble -40.49 | reward 0.05]
Ensemble loss -40.49 / Reward Loss 0.05

=== Collecting data [27] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 2.00]
> Step 100 [reward 102.00]
> Step 125 [reward 202.00]
> Step 150 [reward 302.00]
> Step 175 [reward 402.00]
> Step 200 [reward 502.00]
> Step 225 [reward 602.00]
> Step 250 [reward 702.00]
Rewards 702.00 / Steps 250.00
Reward stats:
 {'max': '37.48', 'mean': '7.80', 'min': '-2.34', 'std': '7.00'}
Information gain stats:
 {'max': '1.74', 'mean': '1.02', 'min': '0.40', 'std': '0.17'}
Episode time 51.62
Saved _metrics_

=== Episode 28 ===
Training on [8000/32000] data points
> Train epoch 20 [ensemble -32.30 | reward 0.18]
> Train epoch 40 [ensemble -36.20 | reward 0.10]
> Train epoch 60 [ensemble -38.22 | reward 0.07]
> Train epoch 80 [ensemble -39.57 | reward 0.05]
> Train epoch 100 [ensemble -40.56 | reward 0.04]
Ensemble loss -40.56 / Reward Loss 0.04

=== Collecting data [28] ===
> Step 25 [reward 43.00]
> Step 50 [reward 143.00]
> Step 75 [reward 243.00]
> Step 100 [reward 343.00]
> Step 125 [reward 443.00]
> Step 150 [reward 543.00]
> Step 175 [reward 643.00]
> Step 200 [reward 743.00]
> Step 225 [reward 843.00]
> Step 250 [reward 943.00]
Rewards 943.00 / Steps 250.00
Reward stats:
 {'max': '42.33', 'mean': '10.59', 'min': '-2.00', 'std': '7.93'}
Information gain stats:
 {'max': '1.68', 'mean': '0.95', 'min': '0.38', 'std': '0.19'}
Episode time 52.54
Saved _metrics_

=== Episode 29 ===
Training on [8250/33000] data points
> Train epoch 20 [ensemble -32.82 | reward 0.19]
> Train epoch 40 [ensemble -36.55 | reward 0.11]
> Train epoch 60 [ensemble -38.50 | reward 0.08]
> Train epoch 80 [ensemble -39.79 | reward 0.06]
> Train epoch 100 [ensemble -40.74 | reward 0.05]
Ensemble loss -40.74 / Reward Loss 0.05

=== Collecting data [29] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 22.00]
> Step 100 [reward 122.00]
> Step 125 [reward 222.00]
> Step 150 [reward 322.00]
> Step 175 [reward 422.00]
> Step 200 [reward 522.00]
> Step 225 [reward 622.00]
> Step 250 [reward 722.00]
Rewards 722.00 / Steps 250.00
Reward stats:
 {'max': '43.18', 'mean': '8.78', 'min': '-5.59', 'std': '7.96'}
Information gain stats:
 {'max': '1.71', 'mean': '0.99', 'min': '0.38', 'std': '0.19'}
Episode time 53.57
Saved _metrics_

=== Episode 30 ===
Training on [8500/34000] data points
> Train epoch 20 [ensemble -32.94 | reward 0.17]
> Train epoch 40 [ensemble -36.65 | reward 0.10]
> Train epoch 60 [ensemble -38.59 | reward 0.07]
> Train epoch 80 [ensemble -39.88 | reward 0.05]
> Train epoch 100 [ensemble -40.82 | reward 0.04]
Ensemble loss -40.82 / Reward Loss 0.04

=== Collecting data [30] ===
> Step 25 [reward 87.00]
> Step 50 [reward 187.00]
> Step 75 [reward 287.00]
> Step 100 [reward 387.00]
> Step 125 [reward 487.00]
> Step 150 [reward 587.00]
> Step 175 [reward 687.00]
> Step 200 [reward 787.00]
> Step 225 [reward 887.00]
> Step 250 [reward 987.00]
Rewards 987.00 / Steps 250.00
Reward stats:
 {'max': '41.94', 'mean': '11.55', 'min': '-0.84', 'std': '8.02'}
Information gain stats:
 {'max': '1.63', 'mean': '0.94', 'min': '0.32', 'std': '0.18'}
Episode time 54.99
Saved _metrics_

=== Episode 31 ===
Training on [8750/35000] data points
> Train epoch 20 [ensemble -33.29 | reward 0.18]
> Train epoch 40 [ensemble -36.89 | reward 0.10]
> Train epoch 60 [ensemble -38.78 | reward 0.07]
> Train epoch 80 [ensemble -40.03 | reward 0.05]
> Train epoch 100 [ensemble -40.95 | reward 0.04]
Ensemble loss -40.95 / Reward Loss 0.04

=== Collecting data [31] ===
> Step 25 [reward 95.00]
> Step 50 [reward 195.00]
> Step 75 [reward 295.00]
> Step 100 [reward 395.00]
> Step 125 [reward 495.00]
> Step 150 [reward 595.00]
> Step 175 [reward 695.00]
> Step 200 [reward 795.00]
> Step 225 [reward 895.00]
> Step 250 [reward 995.00]
Rewards 995.00 / Steps 250.00
Reward stats:
 {'max': '43.27', 'mean': '12.24', 'min': '-0.81', 'std': '8.21'}
Information gain stats:
 {'max': '1.67', 'mean': '0.93', 'min': '0.34', 'std': '0.19'}
Episode time 57.97
Saved _metrics_

=== Episode 32 ===
Training on [9000/36000] data points
> Train epoch 20 [ensemble -33.66 | reward 0.17]
> Train epoch 40 [ensemble -37.14 | reward 0.09]
> Train epoch 60 [ensemble -38.97 | reward 0.07]
> Train epoch 80 [ensemble -40.19 | reward 0.05]
> Train epoch 100 [ensemble -41.09 | reward 0.04]
Ensemble loss -41.09 / Reward Loss 0.04

=== Collecting data [32] ===
> Step 25 [reward 15.00]
> Step 50 [reward 115.00]
> Step 75 [reward 215.00]
> Step 100 [reward 315.00]
> Step 125 [reward 415.00]
> Step 150 [reward 515.00]
> Step 175 [reward 615.00]
> Step 200 [reward 715.00]
> Step 225 [reward 815.00]
> Step 250 [reward 915.00]
Rewards 915.00 / Steps 250.00
Reward stats:
 {'max': '45.50', 'mean': '11.06', 'min': '-2.95', 'std': '8.42'}
Information gain stats:
 {'max': '1.68', 'mean': '0.97', 'min': '0.34', 'std': '0.19'}
Episode time 57.25
Saved _metrics_

=== Episode 33 ===
Training on [9250/37000] data points
> Train epoch 20 [ensemble -33.90 | reward 0.18]
> Train epoch 40 [ensemble -37.35 | reward 0.10]
> Train epoch 60 [ensemble -39.16 | reward 0.07]
> Train epoch 80 [ensemble -40.37 | reward 0.05]
> Train epoch 100 [ensemble -41.25 | reward 0.04]
Ensemble loss -41.25 / Reward Loss 0.04

=== Collecting data [33] ===
> Step 25 [reward 0.00]
> Step 50 [reward 67.00]
> Step 75 [reward 167.00]
> Step 100 [reward 267.00]
> Step 125 [reward 367.00]
> Step 150 [reward 467.00]
> Step 175 [reward 567.00]
> Step 200 [reward 667.00]
> Step 225 [reward 767.00]
> Step 250 [reward 867.00]
Rewards 867.00 / Steps 250.00
Reward stats:
 {'max': '45.29', 'mean': '10.90', 'min': '-3.39', 'std': '8.90'}
Information gain stats:
 {'max': '1.72', 'mean': '0.97', 'min': '0.33', 'std': '0.20'}
Episode time 58.52
Saved _metrics_

=== Episode 34 ===
Training on [9500/38000] data points
> Train epoch 20 [ensemble -34.17 | reward 0.17]
> Train epoch 40 [ensemble -37.56 | reward 0.10]
> Train epoch 60 [ensemble -39.33 | reward 0.07]
> Train epoch 80 [ensemble -40.51 | reward 0.05]
> Train epoch 100 [ensemble -41.38 | reward 0.04]
Ensemble loss -41.38 / Reward Loss 0.04

=== Collecting data [34] ===
> Step 25 [reward 91.00]
> Step 50 [reward 191.00]
> Step 75 [reward 291.00]
> Step 100 [reward 391.00]
> Step 125 [reward 491.00]
> Step 150 [reward 591.00]
> Step 175 [reward 691.00]
> Step 200 [reward 791.00]
> Step 225 [reward 891.00]
> Step 250 [reward 991.00]
Rewards 991.00 / Steps 250.00
Reward stats:
 {'max': '41.82', 'mean': '12.12', 'min': '-2.56', 'std': '7.98'}
Information gain stats:
 {'max': '1.62', 'mean': '0.93', 'min': '0.34', 'std': '0.19'}
Episode time 60.69
Saved _metrics_

=== Episode 35 ===
Training on [9750/39000] data points
> Train epoch 20 [ensemble -34.47 | reward 0.16]
> Train epoch 40 [ensemble -37.77 | reward 0.09]
> Train epoch 60 [ensemble -39.50 | reward 0.06]
> Train epoch 80 [ensemble -40.65 | reward 0.05]
> Train epoch 100 [ensemble -41.49 | reward 0.04]
Ensemble loss -41.49 / Reward Loss 0.04

=== Collecting data [35] ===
> Step 25 [reward 0.00]
> Step 50 [reward 19.00]
> Step 75 [reward 119.00]
> Step 100 [reward 219.00]
> Step 125 [reward 319.00]
> Step 150 [reward 419.00]
> Step 175 [reward 519.00]
> Step 200 [reward 619.00]
> Step 225 [reward 719.00]
> Step 250 [reward 819.00]
Rewards 819.00 / Steps 250.00
Reward stats:
 {'max': '45.36', 'mean': '10.91', 'min': '-2.30', 'std': '8.80'}
Information gain stats:
 {'max': '1.65', 'mean': '0.97', 'min': '0.35', 'std': '0.18'}
Episode time 61.19
Saved _metrics_

=== Episode 36 ===
Training on [10000/40000] data points
> Train epoch 20 [ensemble -34.65 | reward 0.15]
> Train epoch 40 [ensemble -37.92 | reward 0.08]
> Train epoch 60 [ensemble -39.62 | reward 0.06]
> Train epoch 80 [ensemble -40.76 | reward 0.04]
> Train epoch 100 [ensemble -41.59 | reward 0.04]
Ensemble loss -41.59 / Reward Loss 0.04

=== Collecting data [36] ===
> Step 25 [reward 15.00]
> Step 50 [reward 115.00]
> Step 75 [reward 215.00]
> Step 100 [reward 315.00]
> Step 125 [reward 415.00]
> Step 150 [reward 515.00]
> Step 175 [reward 615.00]
> Step 200 [reward 715.00]
> Step 225 [reward 815.00]
> Step 250 [reward 915.00]
Rewards 915.00 / Steps 250.00
Reward stats:
 {'max': '46.48', 'mean': '11.81', 'min': '-1.73', 'std': '8.65'}
Information gain stats:
 {'max': '1.70', 'mean': '0.96', 'min': '0.35', 'std': '0.20'}
Episode time 62.22
Saved _metrics_

=== Episode 37 ===
Training on [10250/41000] data points
> Train epoch 20 [ensemble -35.02 | reward 0.15]
> Train epoch 40 [ensemble -38.19 | reward 0.08]
> Train epoch 60 [ensemble -39.84 | reward 0.06]
> Train epoch 80 [ensemble -40.93 | reward 0.04]
> Train epoch 100 [ensemble -41.73 | reward 0.03]
Ensemble loss -41.73 / Reward Loss 0.03

=== Collecting data [37] ===
> Step 25 [reward 46.00]
> Step 50 [reward 146.00]
> Step 75 [reward 246.00]
> Step 100 [reward 346.00]
> Step 125 [reward 446.00]
> Step 150 [reward 546.00]
> Step 175 [reward 646.00]
> Step 200 [reward 746.00]
> Step 225 [reward 846.00]
> Step 250 [reward 946.00]
Rewards 946.00 / Steps 250.00
Reward stats:
 {'max': '42.83', 'mean': '11.25', 'min': '-2.56', 'std': '8.27'}
Information gain stats:
 {'max': '1.65', 'mean': '0.95', 'min': '0.34', 'std': '0.19'}
Episode time 63.55
Saved _metrics_

=== Episode 38 ===
Training on [10500/42000] data points
> Train epoch 20 [ensemble -35.15 | reward 0.14]
> Train epoch 40 [ensemble -38.27 | reward 0.08]
> Train epoch 60 [ensemble -39.91 | reward 0.05]
> Train epoch 80 [ensemble -41.00 | reward 0.04]
> Train epoch 100 [ensemble -41.80 | reward 0.03]
Ensemble loss -41.80 / Reward Loss 0.03

=== Collecting data [38] ===
> Step 25 [reward 100.00]
> Step 50 [reward 200.00]
> Step 75 [reward 300.00]
> Step 100 [reward 400.00]
> Step 125 [reward 500.00]
> Step 150 [reward 600.00]
> Step 175 [reward 700.00]
> Step 200 [reward 800.00]
> Step 225 [reward 900.00]
> Step 250 [reward 1000.00]
Rewards 1000.00 / Steps 250.00
Reward stats:
 {'max': '44.97', 'mean': '11.67', 'min': '-1.56', 'std': '8.21'}
Information gain stats:
 {'max': '1.66', 'mean': '0.95', 'min': '0.34', 'std': '0.19'}
Episode time 64.43
Saved _metrics_

=== Episode 39 ===
Training on [10750/43000] data points
> Train epoch 20 [ensemble -35.37 | reward 0.14]
> Train epoch 40 [ensemble -38.48 | reward 0.07]
> Train epoch 60 [ensemble -40.11 | reward 0.05]
> Train epoch 80 [ensemble -41.18 | reward 0.04]
> Train epoch 100 [ensemble -41.97 | reward 0.03]
Ensemble loss -41.97 / Reward Loss 0.03

=== Collecting data [39] ===
> Step 25 [reward 54.00]
> Step 50 [reward 154.00]
> Step 75 [reward 254.00]
> Step 100 [reward 354.00]
> Step 125 [reward 454.00]
> Step 150 [reward 554.00]
> Step 175 [reward 654.00]
> Step 200 [reward 754.00]
> Step 225 [reward 854.00]
> Step 250 [reward 954.00]
Rewards 954.00 / Steps 250.00
Reward stats:
 {'max': '43.86', 'mean': '12.57', 'min': '-2.47', 'std': '8.47'}
Information gain stats:
 {'max': '1.68', 'mean': '0.96', 'min': '0.34', 'std': '0.19'}
Episode time 65.71
Saved _metrics_

=== Episode 40 ===
Training on [11000/44000] data points
> Train epoch 20 [ensemble -35.66 | reward 0.14]
> Train epoch 40 [ensemble -38.69 | reward 0.08]
> Train epoch 60 [ensemble -40.26 | reward 0.05]
> Train epoch 80 [ensemble -41.30 | reward 0.04]
> Train epoch 100 [ensemble -42.06 | reward 0.03]
Ensemble loss -42.06 / Reward Loss 0.03

=== Collecting data [40] ===
> Step 25 [reward 88.00]
> Step 50 [reward 188.00]
> Step 75 [reward 288.00]
> Step 100 [reward 388.00]
> Step 125 [reward 488.00]
> Step 150 [reward 588.00]
> Step 175 [reward 688.00]
> Step 200 [reward 788.00]
> Step 225 [reward 888.00]
> Step 250 [reward 988.00]
Rewards 988.00 / Steps 250.00
Reward stats:
 {'max': '45.71', 'mean': '13.32', 'min': '-1.45', 'std': '9.02'}
Information gain stats:
 {'max': '1.67', 'mean': '0.94', 'min': '0.34', 'std': '0.21'}
Episode time 66.61
Saved _metrics_

=== Episode 41 ===
Training on [11250/45000] data points
> Train epoch 20 [ensemble -36.03 | reward 0.15]
> Train epoch 40 [ensemble -38.93 | reward 0.08]
> Train epoch 60 [ensemble -40.45 | reward 0.06]
> Train epoch 80 [ensemble -41.46 | reward 0.05]
> Train epoch 100 [ensemble -42.21 | reward 0.04]
Ensemble loss -42.21 / Reward Loss 0.04

=== Collecting data [41] ===
> Step 25 [reward 63.00]
> Step 50 [reward 163.00]
> Step 75 [reward 263.00]
> Step 100 [reward 363.00]
> Step 125 [reward 463.00]
> Step 150 [reward 563.00]
> Step 175 [reward 663.00]
> Step 200 [reward 763.00]
> Step 225 [reward 863.00]
> Step 250 [reward 963.00]
Rewards 963.00 / Steps 250.00
Reward stats:
 {'max': '46.64', 'mean': '11.97', 'min': '-1.64', 'std': '8.54'}
Information gain stats:
 {'max': '1.66', 'mean': '0.95', 'min': '0.32', 'std': '0.21'}
Episode time 67.97
Saved _metrics_

=== Episode 42 ===
Training on [11500/46000] data points
> Train epoch 20 [ensemble -36.14 | reward 0.13]
> Train epoch 40 [ensemble -39.02 | reward 0.07]
> Train epoch 60 [ensemble -40.53 | reward 0.05]
> Train epoch 80 [ensemble -41.53 | reward 0.04]
> Train epoch 100 [ensemble -42.27 | reward 0.03]
Ensemble loss -42.27 / Reward Loss 0.03

=== Collecting data [42] ===
> Step 25 [reward 18.00]
> Step 50 [reward 118.00]
> Step 75 [reward 218.00]
> Step 100 [reward 318.00]
> Step 125 [reward 418.00]
> Step 150 [reward 518.00]
> Step 175 [reward 618.00]
> Step 200 [reward 718.00]
> Step 225 [reward 818.00]
> Step 250 [reward 918.00]
Rewards 918.00 / Steps 250.00
Reward stats:
 {'max': '47.24', 'mean': '11.74', 'min': '-2.64', 'std': '9.30'}
Information gain stats:
 {'max': '1.70', 'mean': '0.97', 'min': '0.32', 'std': '0.22'}
Episode time 69.05
Saved _metrics_

=== Episode 43 ===
Training on [11750/47000] data points
> Train epoch 20 [ensemble -36.33 | reward 0.14]
> Train epoch 40 [ensemble -39.19 | reward 0.08]
> Train epoch 60 [ensemble -40.69 | reward 0.05]
> Train epoch 80 [ensemble -41.68 | reward 0.04]
> Train epoch 100 [ensemble -42.40 | reward 0.03]
Ensemble loss -42.40 / Reward Loss 0.03

=== Collecting data [43] ===
> Step 25 [reward 91.00]
> Step 50 [reward 191.00]
> Step 75 [reward 291.00]
> Step 100 [reward 391.00]
> Step 125 [reward 491.00]
> Step 150 [reward 591.00]
> Step 175 [reward 691.00]
> Step 200 [reward 791.00]
> Step 225 [reward 891.00]
> Step 250 [reward 991.00]
Rewards 991.00 / Steps 250.00
Reward stats:
 {'max': '47.44', 'mean': '13.35', 'min': '-1.52', 'std': '9.56'}
Information gain stats:
 {'max': '1.66', 'mean': '0.93', 'min': '0.31', 'std': '0.21'}
Episode time 70.21
Saved _metrics_

=== Episode 44 ===
Training on [12000/48000] data points
> Train epoch 20 [ensemble -36.67 | reward 0.14]
> Train epoch 40 [ensemble -39.40 | reward 0.08]
> Train epoch 60 [ensemble -40.83 | reward 0.05]
> Train epoch 80 [ensemble -41.77 | reward 0.04]
> Train epoch 100 [ensemble -42.47 | reward 0.03]
Ensemble loss -42.47 / Reward Loss 0.03

=== Collecting data [44] ===
> Step 25 [reward 27.00]
> Step 50 [reward 127.00]
> Step 75 [reward 227.00]
> Step 100 [reward 327.00]
> Step 125 [reward 427.00]
> Step 150 [reward 527.00]
> Step 175 [reward 627.00]
> Step 200 [reward 727.00]
> Step 225 [reward 827.00]
> Step 250 [reward 927.00]
Rewards 927.00 / Steps 250.00
Reward stats:
 {'max': '45.00', 'mean': '11.36', 'min': '-3.36', 'std': '8.59'}
Information gain stats:
 {'max': '1.68', 'mean': '0.94', 'min': '0.31', 'std': '0.21'}
Episode time 71.20
Saved _metrics_

=== Episode 45 ===
Training on [12250/49000] data points
> Train epoch 20 [ensemble -36.70 | reward 0.13]
> Train epoch 40 [ensemble -39.43 | reward 0.07]
> Train epoch 60 [ensemble -40.85 | reward 0.05]
> Train epoch 80 [ensemble -41.80 | reward 0.04]
> Train epoch 100 [ensemble -42.49 | reward 0.03]
Ensemble loss -42.49 / Reward Loss 0.03

=== Collecting data [45] ===
> Step 25 [reward 59.00]
> Step 50 [reward 159.00]
> Step 75 [reward 259.00]
> Step 100 [reward 359.00]
> Step 125 [reward 459.00]
> Step 150 [reward 559.00]
> Step 175 [reward 659.00]
> Step 200 [reward 759.00]
> Step 225 [reward 859.00]
> Step 250 [reward 959.00]
Rewards 959.00 / Steps 250.00
Reward stats:
 {'max': '47.62', 'mean': '13.03', 'min': '-1.55', 'std': '9.57'}
Information gain stats:
 {'max': '1.68', 'mean': '0.95', 'min': '0.29', 'std': '0.22'}
Episode time 72.80
Saved _metrics_

=== Episode 46 ===
Training on [12500/50000] data points
> Train epoch 20 [ensemble -36.93 | reward 0.13]
> Train epoch 40 [ensemble -39.64 | reward 0.07]
> Train epoch 60 [ensemble -41.04 | reward 0.05]
> Train epoch 80 [ensemble -41.97 | reward 0.04]
> Train epoch 100 [ensemble -42.65 | reward 0.03]
Ensemble loss -42.65 / Reward Loss 0.03

=== Collecting data [46] ===
> Step 25 [reward 6.00]
> Step 50 [reward 106.00]
> Step 75 [reward 206.00]
> Step 100 [reward 306.00]
> Step 125 [reward 406.00]
> Step 150 [reward 506.00]
> Step 175 [reward 606.00]
> Step 200 [reward 706.00]
> Step 225 [reward 806.00]
> Step 250 [reward 906.00]
Rewards 906.00 / Steps 250.00
Reward stats:
 {'max': '46.65', 'mean': '13.26', 'min': '-1.49', 'std': '9.69'}
Information gain stats:
 {'max': '1.64', 'mean': '0.95', 'min': '0.32', 'std': '0.22'}
Episode time 73.58
Saved _metrics_

=== Episode 47 ===
Training on [12750/51000] data points
> Train epoch 20 [ensemble -37.10 | reward 0.12]
> Train epoch 40 [ensemble -39.72 | reward 0.07]
> Train epoch 60 [ensemble -41.09 | reward 0.05]
> Train epoch 80 [ensemble -41.99 | reward 0.04]
> Train epoch 100 [ensemble -42.66 | reward 0.03]
Ensemble loss -42.66 / Reward Loss 0.03

=== Collecting data [47] ===
> Step 25 [reward 87.00]
> Step 50 [reward 187.00]
> Step 75 [reward 287.00]
> Step 100 [reward 387.00]
> Step 125 [reward 487.00]
> Step 150 [reward 587.00]
> Step 175 [reward 687.00]
> Step 200 [reward 787.00]
> Step 225 [reward 887.00]
> Step 250 [reward 987.00]
Rewards 987.00 / Steps 250.00
Reward stats:
 {'max': '46.78', 'mean': '13.32', 'min': '-0.61', 'std': '9.04'}
Information gain stats:
 {'max': '1.63', 'mean': '0.94', 'min': '0.31', 'std': '0.21'}
Episode time 74.55
Saved _metrics_

=== Episode 48 ===
Training on [13000/52000] data points
> Train epoch 20 [ensemble -37.27 | reward 0.12]
> Train epoch 40 [ensemble -39.86 | reward 0.06]
> Train epoch 60 [ensemble -41.22 | reward 0.04]
> Train epoch 80 [ensemble -42.12 | reward 0.03]
> Train epoch 100 [ensemble -42.78 | reward 0.03]
Ensemble loss -42.78 / Reward Loss 0.03

=== Collecting data [48] ===
> Step 25 [reward 94.00]
> Step 50 [reward 194.00]
> Step 75 [reward 294.00]
> Step 100 [reward 394.00]
> Step 125 [reward 494.00]
> Step 150 [reward 594.00]
> Step 175 [reward 694.00]
> Step 200 [reward 794.00]
> Step 225 [reward 894.00]
> Step 250 [reward 994.00]
Rewards 994.00 / Steps 250.00
Reward stats:
 {'max': '47.18', 'mean': '14.25', 'min': '-0.91', 'std': '9.66'}
Information gain stats:
 {'max': '1.62', 'mean': '0.94', 'min': '0.29', 'std': '0.21'}
Episode time 75.63
Saved _metrics_

=== Episode 49 ===
Training on [13250/53000] data points
> Train epoch 20 [ensemble -37.54 | reward 0.11]
> Train epoch 40 [ensemble -40.04 | reward 0.06]
> Train epoch 60 [ensemble -41.36 | reward 0.04]
> Train epoch 80 [ensemble -42.23 | reward 0.03]
> Train epoch 100 [ensemble -42.88 | reward 0.03]
Ensemble loss -42.88 / Reward Loss 0.03

=== Collecting data [49] ===
> Step 25 [reward 52.00]
> Step 50 [reward 152.00]
> Step 75 [reward 252.00]
> Step 100 [reward 352.00]
> Step 125 [reward 452.00]
> Step 150 [reward 552.00]
> Step 175 [reward 652.00]
> Step 200 [reward 752.00]
> Step 225 [reward 852.00]
> Step 250 [reward 952.00]
Rewards 952.00 / Steps 250.00
Reward stats:
 {'max': '45.92', 'mean': '12.43', 'min': '-1.92', 'std': '9.06'}
Information gain stats:
 {'max': '1.67', 'mean': '0.97', 'min': '0.30', 'std': '0.21'}
Episode time 76.66
Saved _metrics_