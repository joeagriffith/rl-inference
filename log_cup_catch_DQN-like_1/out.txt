22:23:52

=== Loading experiment [device: cuda] ===

{'action_noise': None,
 'action_repeat': 4,
 'batch_size': 50,
 'coverage': False,
 'ensemble_size': 10,
 'env_name': 'DeepMindCatch',
 'epsilon': 1e-08,
 'expl_scale': 0.1,
 'expl_strategy': 'information',
 'grad_clip_norm': 1000,
 'hidden_size': 200,
 'learning_rate': 0.001,
 'logdir': 'cup_catch_DQN-like',
 'max_episode_len': 1000,
 'n_candidates': 500,
 'n_episodes': 50,
 'n_seed_episodes': 5,
 'n_train_epochs': 100,
 'optimisation_iters': 5,
 'plan_horizon': 12,
 'record_every': None,
 'reward_scale': 1.0,
 'seed': 1,
 'strategy': 'information',
 'top_candidates': 50,
 'use_exploration': True,
 'use_mean': False,
 'use_reward': True}

Collected seeds: [5 episodes | 1250 frames]

=== Episode 1 ===
Training on [1250/5000] data points
> Train epoch 20 [ensemble -20.99 | reward 0.00]
> Train epoch 40 [ensemble -28.93 | reward 0.00]
> Train epoch 60 [ensemble -32.72 | reward 0.00]
> Train epoch 80 [ensemble -35.11 | reward 0.00]
> Train epoch 100 [ensemble -36.81 | reward 0.00]
Ensemble loss -36.81 / Reward Loss 0.00

=== Collecting data [1] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '0.00', 'mean': '-0.60', 'min': '-1.21', 'std': '0.15'}
Information gain stats:
 {'max': '2.39', 'mean': '1.38', 'min': '0.51', 'std': '0.26'}
Episode time 25.70
Saved _metrics_

=== Episode 2 ===
Training on [1500/6000] data points
> Train epoch 20 [ensemble -18.61 | reward 0.00]
> Train epoch 40 [ensemble -27.24 | reward 0.00]
> Train epoch 60 [ensemble -31.17 | reward 0.00]
> Train epoch 80 [ensemble -33.57 | reward 0.00]
> Train epoch 100 [ensemble -35.27 | reward 0.00]
Ensemble loss -35.27 / Reward Loss 0.00

=== Collecting data [2] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '2.39', 'mean': '1.45', 'min': '0.77', 'std': '0.23'}
Information gain stats:
 {'max': '1.54', 'mean': '1.05', 'min': '0.56', 'std': '0.11'}
Episode time 26.01
Saved _metrics_

=== Episode 3 ===
Training on [1750/7000] data points
> Train epoch 20 [ensemble -19.91 | reward 0.00]
> Train epoch 40 [ensemble -28.32 | reward 0.00]
> Train epoch 60 [ensemble -32.18 | reward 0.00]
> Train epoch 80 [ensemble -34.52 | reward 0.00]
> Train epoch 100 [ensemble -36.17 | reward 0.00]
Ensemble loss -36.17 / Reward Loss 0.00

=== Collecting data [3] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '0.98', 'mean': '0.81', 'min': '0.44', 'std': '0.04'}
Information gain stats:
 {'max': '1.45', 'mean': '0.82', 'min': '0.41', 'std': '0.13'}
Episode time 27.63
Saved _metrics_

=== Episode 4 ===
Training on [2000/8000] data points
> Train epoch 20 [ensemble -19.45 | reward 0.00]
> Train epoch 40 [ensemble -28.40 | reward 0.00]
> Train epoch 60 [ensemble -32.34 | reward 0.00]
> Train epoch 80 [ensemble -34.71 | reward 0.00]
> Train epoch 100 [ensemble -36.34 | reward 0.00]
Ensemble loss -36.34 / Reward Loss 0.00

=== Collecting data [4] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '-0.20', 'mean': '-0.41', 'min': '-0.92', 'std': '0.06'}
Information gain stats:
 {'max': '1.47', 'mean': '0.80', 'min': '0.43', 'std': '0.12'}
Episode time 29.13
Saved _metrics_

=== Episode 5 ===
Training on [2250/9000] data points
> Train epoch 20 [ensemble -20.75 | reward 0.00]
> Train epoch 40 [ensemble -29.33 | reward 0.00]
> Train epoch 60 [ensemble -33.07 | reward 0.00]
> Train epoch 80 [ensemble -35.30 | reward 0.00]
> Train epoch 100 [ensemble -36.83 | reward 0.00]
Ensemble loss -36.83 / Reward Loss 0.00

=== Collecting data [5] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 16.00]
> Step 225 [reward 106.00]
> Step 250 [reward 167.00]
Rewards 167.00 / Steps 250.00
Reward stats:
 {'max': '0.21', 'mean': '0.07', 'min': '-0.04', 'std': '0.03'}
Information gain stats:
 {'max': '1.61', 'mean': '0.90', 'min': '0.44', 'std': '0.14'}
Episode time 30.65
Saved _metrics_

=== Episode 6 ===
Training on [2500/10000] data points
> Train epoch 20 [ensemble -20.76 | reward 0.08]
> Train epoch 40 [ensemble -28.92 | reward 0.06]
> Train epoch 60 [ensemble -32.57 | reward 0.06]
> Train epoch 80 [ensemble -34.76 | reward 0.06]
> Train epoch 100 [ensemble -36.30 | reward 0.06]
Ensemble loss -36.30 / Reward Loss 0.06

=== Collecting data [6] ===
> Step 25 [reward 55.00]
> Step 50 [reward 155.00]
> Step 75 [reward 255.00]
> Step 100 [reward 355.00]
> Step 125 [reward 455.00]
> Step 150 [reward 555.00]
> Step 175 [reward 655.00]
> Step 200 [reward 755.00]
> Step 225 [reward 855.00]
> Step 250 [reward 955.00]
Rewards 955.00 / Steps 250.00
Reward stats:
 {'max': '197.27', 'mean': '53.06', 'min': '-0.09', 'std': '35.43'}
Information gain stats:
 {'max': '1.33', 'mean': '0.90', 'min': '0.47', 'std': '0.09'}
Episode time 31.89
Saved _metrics_

=== Episode 7 ===
Training on [2750/11000] data points
> Train epoch 20 [ensemble -21.89 | reward 0.21]
> Train epoch 40 [ensemble -29.58 | reward 0.26]
> Train epoch 60 [ensemble -33.04 | reward 0.34]
> Train epoch 80 [ensemble -35.14 | reward 0.40]
> Train epoch 100 [ensemble -36.61 | reward 0.44]
Ensemble loss -36.61 / Reward Loss 0.44

=== Collecting data [7] ===
> Step 25 [reward 90.00]
> Step 50 [reward 190.00]
> Step 75 [reward 290.00]
> Step 100 [reward 390.00]
> Step 125 [reward 490.00]
> Step 150 [reward 590.00]
> Step 175 [reward 690.00]
> Step 200 [reward 790.00]
> Step 225 [reward 890.00]
> Step 250 [reward 990.00]
Rewards 990.00 / Steps 250.00
Reward stats:
 {'max': '362.14', 'mean': '109.43', 'min': '-3.11', 'std': '68.41'}
Information gain stats:
 {'max': '1.19', 'mean': '0.63', 'min': '0.34', 'std': '0.08'}
Episode time 33.38
Saved _metrics_

=== Episode 8 ===
Training on [3000/12000] data points
> Train epoch 20 [ensemble -22.97 | reward 0.28]
> Train epoch 40 [ensemble -30.25 | reward 0.41]
> Train epoch 60 [ensemble -33.52 | reward 0.63]
> Train epoch 80 [ensemble -35.51 | reward 0.81]
> Train epoch 100 [ensemble -36.92 | reward 0.92]
Ensemble loss -36.92 / Reward Loss 0.92

=== Collecting data [8] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 9.00]
> Step 100 [reward 109.00]
> Step 125 [reward 209.00]
> Step 150 [reward 309.00]
> Step 175 [reward 409.00]
> Step 200 [reward 509.00]
> Step 225 [reward 609.00]
> Step 250 [reward 709.00]
Rewards 709.00 / Steps 250.00
Reward stats:
 {'max': '415.83', 'mean': '104.53', 'min': '-1.34', 'std': '75.52'}
Information gain stats:
 {'max': '1.33', 'mean': '0.67', 'min': '0.29', 'std': '0.11'}
Episode time 34.53
Saved _metrics_

=== Episode 9 ===
Training on [3250/13000] data points
> Train epoch 20 [ensemble -24.15 | reward 0.35]
> Train epoch 40 [ensemble -30.98 | reward 0.66]
> Train epoch 60 [ensemble -34.06 | reward 1.03]
> Train epoch 80 [ensemble -35.95 | reward 1.32]
> Train epoch 100 [ensemble -37.30 | reward 1.50]
Ensemble loss -37.30 / Reward Loss 1.50

=== Collecting data [9] ===
> Step 25 [reward 53.00]
> Step 50 [reward 153.00]
> Step 75 [reward 253.00]
> Step 100 [reward 353.00]
> Step 125 [reward 453.00]
> Step 150 [reward 553.00]
> Step 175 [reward 653.00]
> Step 200 [reward 753.00]
> Step 225 [reward 853.00]
> Step 250 [reward 953.00]
Rewards 953.00 / Steps 250.00
Reward stats:
 {'max': '296.58', 'mean': '86.26', 'min': '0.76', 'std': '55.07'}
Information gain stats:
 {'max': '1.46', 'mean': '0.71', 'min': '0.42', 'std': '0.10'}
Episode time 36.16
Saved _metrics_

=== Episode 10 ===
Training on [3500/14000] data points
> Train epoch 20 [ensemble -25.00 | reward 0.48]
> Train epoch 40 [ensemble -31.54 | reward 0.97]
> Train epoch 60 [ensemble -34.49 | reward 1.55]
> Train epoch 80 [ensemble -36.30 | reward 2.01]
> Train epoch 100 [ensemble -37.60 | reward 2.29]
Ensemble loss -37.60 / Reward Loss 2.29

=== Collecting data [10] ===
> Step 25 [reward 38.00]
> Step 50 [reward 138.00]
> Step 75 [reward 238.00]
> Step 100 [reward 338.00]
> Step 125 [reward 438.00]
> Step 150 [reward 538.00]
> Step 175 [reward 638.00]
> Step 200 [reward 738.00]
> Step 225 [reward 838.00]
> Step 250 [reward 938.00]
Rewards 938.00 / Steps 250.00
Reward stats:
 {'max': '355.22', 'mean': '103.68', 'min': '-3.09', 'std': '60.38'}
Information gain stats:
 {'max': '1.37', 'mean': '0.71', 'min': '0.41', 'std': '0.10'}
Episode time 37.61
Saved _metrics_

=== Episode 11 ===
Training on [3750/15000] data points
> Train epoch 20 [ensemble -25.93 | reward 0.46]
> Train epoch 40 [ensemble -32.11 | reward 1.02]
> Train epoch 60 [ensemble -34.94 | reward 1.69]
> Train epoch 80 [ensemble -36.71 | reward 2.24]
> Train epoch 100 [ensemble -37.97 | reward 2.60]
Ensemble loss -37.97 / Reward Loss 2.60

=== Collecting data [11] ===
> Step 25 [reward 87.00]
> Step 50 [reward 187.00]
> Step 75 [reward 287.00]
> Step 100 [reward 387.00]
> Step 125 [reward 487.00]
> Step 150 [reward 587.00]
> Step 175 [reward 687.00]
> Step 200 [reward 787.00]
> Step 225 [reward 887.00]
> Step 250 [reward 987.00]
Rewards 987.00 / Steps 250.00
Reward stats:
 {'max': '324.48', 'mean': '91.00', 'min': '-3.40', 'std': '59.58'}
Information gain stats:
 {'max': '1.36', 'mean': '0.73', 'min': '0.45', 'std': '0.09'}
Episode time 39.05
Saved _metrics_

=== Episode 12 ===
Training on [4000/16000] data points
> Train epoch 20 [ensemble -26.89 | reward 0.52]
> Train epoch 40 [ensemble -32.77 | reward 1.26]
> Train epoch 60 [ensemble -35.46 | reward 2.17]
> Train epoch 80 [ensemble -37.14 | reward 2.93]
> Train epoch 100 [ensemble -38.36 | reward 3.43]
Ensemble loss -38.36 / Reward Loss 3.43

=== Collecting data [12] ===
> Step 25 [reward 52.00]
> Step 50 [reward 152.00]
> Step 75 [reward 252.00]
> Step 100 [reward 352.00]
> Step 125 [reward 452.00]
> Step 150 [reward 552.00]
> Step 175 [reward 652.00]
> Step 200 [reward 752.00]
> Step 225 [reward 852.00]
> Step 250 [reward 952.00]
Rewards 952.00 / Steps 250.00
Reward stats:
 {'max': '379.98', 'mean': '106.97', 'min': '-0.02', 'std': '63.59'}
Information gain stats:
 {'max': '1.36', 'mean': '0.75', 'min': '0.44', 'std': '0.10'}
Episode time 40.57
Saved _metrics_

=== Episode 13 ===
Training on [4250/17000] data points
> Train epoch 20 [ensemble -27.43 | reward 0.60]
> Train epoch 40 [ensemble -33.13 | reward 1.51]
> Train epoch 60 [ensemble -35.74 | reward 2.57]
> Train epoch 80 [ensemble -37.38 | reward 3.44]
> Train epoch 100 [ensemble -38.56 | reward 4.01]
Ensemble loss -38.56 / Reward Loss 4.01

=== Collecting data [13] ===
> Step 25 [reward 51.00]
> Step 50 [reward 151.00]
> Step 75 [reward 251.00]
> Step 100 [reward 351.00]
> Step 125 [reward 451.00]
> Step 150 [reward 551.00]
> Step 175 [reward 651.00]
> Step 200 [reward 751.00]
> Step 225 [reward 851.00]
> Step 250 [reward 951.00]
Rewards 951.00 / Steps 250.00
Reward stats:
 {'max': '437.00', 'mean': '125.34', 'min': '-6.23', 'std': '75.69'}
Information gain stats:
 {'max': '1.36', 'mean': '0.76', 'min': '0.42', 'std': '0.11'}
Episode time 41.86
Saved _metrics_

=== Episode 14 ===
Training on [4500/18000] data points
> Train epoch 20 [ensemble -28.26 | reward 0.69]
> Train epoch 40 [ensemble -33.68 | reward 1.81]
> Train epoch 60 [ensemble -36.21 | reward 3.09]
> Train epoch 80 [ensemble -37.79 | reward 4.15]
> Train epoch 100 [ensemble -38.94 | reward 4.83]
Ensemble loss -38.94 / Reward Loss 4.83

=== Collecting data [14] ===
> Step 25 [reward 9.00]
> Step 50 [reward 109.00]
> Step 75 [reward 209.00]
> Step 100 [reward 309.00]
> Step 125 [reward 409.00]
> Step 150 [reward 509.00]
> Step 175 [reward 609.00]
> Step 200 [reward 709.00]
> Step 225 [reward 809.00]
> Step 250 [reward 909.00]
Rewards 909.00 / Steps 250.00
Reward stats:
 {'max': '450.92', 'mean': '132.37', 'min': '-0.06', 'std': '74.20'}
Information gain stats:
 {'max': '1.36', 'mean': '0.78', 'min': '0.47', 'std': '0.11'}
Episode time 43.72
Saved _metrics_

=== Episode 15 ===
Training on [4750/19000] data points
> Train epoch 20 [ensemble -28.94 | reward 0.80]
> Train epoch 40 [ensemble -34.14 | reward 2.18]
> Train epoch 60 [ensemble -36.57 | reward 3.76]
> Train epoch 80 [ensemble -38.10 | reward 5.05]
> Train epoch 100 [ensemble -39.22 | reward 5.89]
Ensemble loss -39.22 / Reward Loss 5.89

=== Collecting data [15] ===
> Step 25 [reward 56.00]
> Step 50 [reward 156.00]
> Step 75 [reward 256.00]
> Step 100 [reward 356.00]
> Step 125 [reward 456.00]
> Step 150 [reward 556.00]
> Step 175 [reward 656.00]
> Step 200 [reward 756.00]
> Step 225 [reward 856.00]
> Step 250 [reward 956.00]
Rewards 956.00 / Steps 250.00
Reward stats:
 {'max': '460.62', 'mean': '133.88', 'min': '3.88', 'std': '78.22'}
Information gain stats:
 {'max': '1.41', 'mean': '0.81', 'min': '0.46', 'std': '0.11'}
Episode time 44.92
Saved _metrics_

=== Episode 16 ===
Training on [5000/20000] data points
> Train epoch 20 [ensemble -29.43 | reward 0.91]
> Train epoch 40 [ensemble -34.49 | reward 2.46]
> Train epoch 60 [ensemble -36.85 | reward 4.25]
> Train epoch 80 [ensemble -38.33 | reward 5.73]
> Train epoch 100 [ensemble -39.40 | reward 6.72]
Ensemble loss -39.40 / Reward Loss 6.72

=== Collecting data [16] ===
> Step 25 [reward 42.00]
> Step 50 [reward 142.00]
> Step 75 [reward 242.00]
> Step 100 [reward 342.00]
> Step 125 [reward 442.00]
> Step 150 [reward 542.00]
> Step 175 [reward 642.00]
> Step 200 [reward 742.00]
> Step 225 [reward 842.00]
> Step 250 [reward 942.00]
Rewards 942.00 / Steps 250.00
Reward stats:
 {'max': '497.61', 'mean': '155.16', 'min': '-0.18', 'std': '89.82'}
Information gain stats:
 {'max': '1.37', 'mean': '0.81', 'min': '0.44', 'std': '0.11'}
Episode time 46.49
Saved _metrics_

=== Episode 17 ===
Training on [5250/21000] data points
> Train epoch 20 [ensemble -30.29 | reward 0.95]
> Train epoch 40 [ensemble -35.05 | reward 2.68]
> Train epoch 60 [ensemble -37.28 | reward 4.69]
> Train epoch 80 [ensemble -38.71 | reward 6.36]
> Train epoch 100 [ensemble -39.75 | reward 7.46]
Ensemble loss -39.75 / Reward Loss 7.46

=== Collecting data [17] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 11.00]
> Step 100 [reward 111.00]
> Step 125 [reward 211.00]
> Step 150 [reward 311.00]
> Step 175 [reward 411.00]
> Step 200 [reward 511.00]
> Step 225 [reward 611.00]
> Step 250 [reward 711.00]
Rewards 711.00 / Steps 250.00
Reward stats:
 {'max': '586.87', 'mean': '197.66', 'min': '6.14', 'std': '99.56'}
Information gain stats:
 {'max': '1.48', 'mean': '0.87', 'min': '0.42', 'std': '0.13'}
Episode time 48.00
Saved _metrics_

=== Episode 18 ===
Training on [5500/22000] data points
> Train epoch 20 [ensemble -30.48 | reward 1.15]
> Train epoch 40 [ensemble -35.19 | reward 3.25]
> Train epoch 60 [ensemble -37.42 | reward 5.65]
> Train epoch 80 [ensemble -38.84 | reward 7.64]
> Train epoch 100 [ensemble -39.89 | reward 8.96]
Ensemble loss -39.89 / Reward Loss 8.96

=== Collecting data [18] ===
> Step 25 [reward 53.00]
> Step 50 [reward 153.00]
> Step 75 [reward 253.00]
> Step 100 [reward 353.00]
> Step 125 [reward 453.00]
> Step 150 [reward 553.00]
> Step 175 [reward 653.00]
> Step 200 [reward 753.00]
> Step 225 [reward 853.00]
> Step 250 [reward 953.00]
Rewards 953.00 / Steps 250.00
Reward stats:
 {'max': '623.99', 'mean': '206.96', 'min': '6.08', 'std': '107.32'}
Information gain stats:
 {'max': '1.37', 'mean': '0.83', 'min': '0.44', 'std': '0.12'}
Episode time 49.53
Saved _metrics_

=== Episode 19 ===
Training on [5750/23000] data points
> Train epoch 20 [ensemble -30.96 | reward 1.28]
> Train epoch 40 [ensemble -35.54 | reward 3.64]
> Train epoch 60 [ensemble -37.71 | reward 6.28]
> Train epoch 80 [ensemble -39.10 | reward 8.44]
> Train epoch 100 [ensemble -40.12 | reward 9.87]
Ensemble loss -40.12 / Reward Loss 9.87

=== Collecting data [19] ===
> Step 25 [reward 56.00]
> Step 50 [reward 156.00]
> Step 75 [reward 256.00]
> Step 100 [reward 356.00]
> Step 125 [reward 456.00]
> Step 150 [reward 556.00]
> Step 175 [reward 656.00]
> Step 200 [reward 756.00]
> Step 225 [reward 856.00]
> Step 250 [reward 956.00]
Rewards 956.00 / Steps 250.00
Reward stats:
 {'max': '717.64', 'mean': '259.24', 'min': '-6.01', 'std': '131.45'}
Information gain stats:
 {'max': '1.42', 'mean': '0.84', 'min': '0.43', 'std': '0.12'}
Episode time 50.95
Saved _metrics_

=== Episode 20 ===
Training on [6000/24000] data points
> Train epoch 20 [ensemble -31.49 | reward 1.32]
> Train epoch 40 [ensemble -35.92 | reward 3.89]
> Train epoch 60 [ensemble -38.02 | reward 6.82]
> Train epoch 80 [ensemble -39.35 | reward 9.22]
> Train epoch 100 [ensemble -40.34 | reward 10.80]
Ensemble loss -40.34 / Reward Loss 10.80

=== Collecting data [20] ===
> Step 25 [reward 8.00]
> Step 50 [reward 108.00]
> Step 75 [reward 208.00]
> Step 100 [reward 308.00]
> Step 125 [reward 408.00]
> Step 150 [reward 508.00]
> Step 175 [reward 608.00]
> Step 200 [reward 708.00]
> Step 225 [reward 808.00]
> Step 250 [reward 908.00]
Rewards 908.00 / Steps 250.00
Reward stats:
 {'max': '699.43', 'mean': '252.55', 'min': '0.20', 'std': '124.49'}
Information gain stats:
 {'max': '1.45', 'mean': '0.84', 'min': '0.40', 'std': '0.13'}
Episode time 52.37
Saved _metrics_

=== Episode 21 ===
Training on [6250/25000] data points
> Train epoch 20 [ensemble -31.66 | reward 1.50]
> Train epoch 40 [ensemble -36.04 | reward 4.41]
> Train epoch 60 [ensemble -38.10 | reward 7.71]
> Train epoch 80 [ensemble -39.41 | reward 10.40]
> Train epoch 100 [ensemble -40.38 | reward 12.16]
Ensemble loss -40.38 / Reward Loss 12.16

=== Collecting data [21] ===
> Step 25 [reward 57.00]
> Step 50 [reward 157.00]
> Step 75 [reward 257.00]
> Step 100 [reward 357.00]
> Step 125 [reward 457.00]
> Step 150 [reward 557.00]
> Step 175 [reward 657.00]
> Step 200 [reward 757.00]
> Step 225 [reward 857.00]
> Step 250 [reward 957.00]
Rewards 957.00 / Steps 250.00
Reward stats:
 {'max': '855.67', 'mean': '302.71', 'min': '-13.74', 'std': '159.82'}
Information gain stats:
 {'max': '1.45', 'mean': '0.82', 'min': '0.37', 'std': '0.13'}
Episode time 53.82
Saved _metrics_

=== Episode 22 ===
Training on [6500/26000] data points
> Train epoch 20 [ensemble -31.75 | reward 1.60]
> Train epoch 40 [ensemble -36.16 | reward 4.77]
> Train epoch 60 [ensemble -38.22 | reward 8.35]
> Train epoch 80 [ensemble -39.52 | reward 11.31]
> Train epoch 100 [ensemble -40.47 | reward 13.28]
Ensemble loss -40.47 / Reward Loss 13.28

=== Collecting data [22] ===
> Step 25 [reward 90.00]
> Step 50 [reward 190.00]
> Step 75 [reward 290.00]
> Step 100 [reward 390.00]
> Step 125 [reward 490.00]
> Step 150 [reward 590.00]
> Step 175 [reward 690.00]
> Step 200 [reward 790.00]
> Step 225 [reward 890.00]
> Step 250 [reward 990.00]
Rewards 990.00 / Steps 250.00
Reward stats:
 {'max': '912.70', 'mean': '333.92', 'min': '0.11', 'std': '163.10'}
Information gain stats:
 {'max': '1.48', 'mean': '0.83', 'min': '0.37', 'std': '0.13'}
Episode time 55.19
Saved _metrics_

=== Episode 23 ===
Training on [6750/27000] data points
> Train epoch 20 [ensemble -32.07 | reward 1.76]
> Train epoch 40 [ensemble -36.38 | reward 5.36]
> Train epoch 60 [ensemble -38.40 | reward 9.44]
> Train epoch 80 [ensemble -39.67 | reward 12.72]
> Train epoch 100 [ensemble -40.61 | reward 14.86]
Ensemble loss -40.61 / Reward Loss 14.86

=== Collecting data [23] ===
> Step 25 [reward 21.00]
> Step 50 [reward 121.00]
> Step 75 [reward 221.00]
> Step 100 [reward 321.00]
> Step 125 [reward 421.00]
> Step 150 [reward 521.00]
> Step 175 [reward 621.00]
> Step 200 [reward 721.00]
> Step 225 [reward 821.00]
> Step 250 [reward 921.00]
Rewards 921.00 / Steps 250.00
Reward stats:
 {'max': '919.67', 'mean': '326.00', 'min': '3.69', 'std': '162.87'}
Information gain stats:
 {'max': '1.46', 'mean': '0.82', 'min': '0.34', 'std': '0.13'}
Episode time 56.09
Saved _metrics_

=== Episode 24 ===
Training on [7000/28000] data points
> Train epoch 20 [ensemble -32.28 | reward 1.86]
> Train epoch 40 [ensemble -36.55 | reward 5.73]
> Train epoch 60 [ensemble -38.55 | reward 10.11]
> Train epoch 80 [ensemble -39.81 | reward 13.71]
> Train epoch 100 [ensemble -40.74 | reward 16.09]
Ensemble loss -40.74 / Reward Loss 16.09

=== Collecting data [24] ===
> Step 25 [reward 57.00]
> Step 50 [reward 157.00]
> Step 75 [reward 257.00]
> Step 100 [reward 357.00]
> Step 125 [reward 457.00]
> Step 150 [reward 557.00]
> Step 175 [reward 657.00]
> Step 200 [reward 757.00]
> Step 225 [reward 857.00]
> Step 250 [reward 957.00]
Rewards 957.00 / Steps 250.00
Reward stats:
 {'max': '908.91', 'mean': '329.70', 'min': '1.66', 'std': '161.20'}
Information gain stats:
 {'max': '1.47', 'mean': '0.84', 'min': '0.37', 'std': '0.14'}
Episode time 57.04
Saved _metrics_

=== Episode 25 ===
Training on [7250/29000] data points
> Train epoch 20 [ensemble -32.39 | reward 1.95]
> Train epoch 40 [ensemble -36.64 | reward 6.08]
> Train epoch 60 [ensemble -38.63 | reward 10.76]
> Train epoch 80 [ensemble -39.89 | reward 14.60]
> Train epoch 100 [ensemble -40.81 | reward 17.12]
Ensemble loss -40.81 / Reward Loss 17.12

=== Collecting data [25] ===
> Step 25 [reward 56.00]
> Step 50 [reward 156.00]
> Step 75 [reward 256.00]
> Step 100 [reward 356.00]
> Step 125 [reward 456.00]
> Step 150 [reward 556.00]
> Step 175 [reward 656.00]
> Step 200 [reward 756.00]
> Step 225 [reward 856.00]
> Step 250 [reward 956.00]
Rewards 956.00 / Steps 250.00
Reward stats:
 {'max': '957.43', 'mean': '351.26', 'min': '12.55', 'std': '162.64'}
Information gain stats:
 {'max': '1.47', 'mean': '0.83', 'min': '0.39', 'std': '0.13'}
Episode time 58.65
Saved _metrics_

=== Episode 26 ===
Training on [7500/30000] data points
> Train epoch 20 [ensemble -32.79 | reward 2.02]
> Train epoch 40 [ensemble -36.93 | reward 6.41]
> Train epoch 60 [ensemble -38.86 | reward 11.34]
> Train epoch 80 [ensemble -40.09 | reward 15.36]
> Train epoch 100 [ensemble -40.98 | reward 18.01]
Ensemble loss -40.98 / Reward Loss 18.01

=== Collecting data [26] ===
> Step 25 [reward 19.00]
> Step 50 [reward 119.00]
> Step 75 [reward 219.00]
> Step 100 [reward 319.00]
> Step 125 [reward 419.00]
> Step 150 [reward 519.00]
> Step 175 [reward 619.00]
> Step 200 [reward 719.00]
> Step 225 [reward 819.00]
> Step 250 [reward 919.00]
Rewards 919.00 / Steps 250.00
Reward stats:
 {'max': '993.57', 'mean': '332.72', 'min': '3.71', 'std': '164.72'}
Information gain stats:
 {'max': '1.50', 'mean': '0.87', 'min': '0.37', 'std': '0.13'}
Episode time 59.89
Saved _metrics_

=== Episode 27 ===
Training on [7750/31000] data points
> Train epoch 20 [ensemble -33.00 | reward 2.39]
> Train epoch 40 [ensemble -37.05 | reward 7.35]
> Train epoch 60 [ensemble -38.96 | reward 12.80]
> Train epoch 80 [ensemble -40.17 | reward 17.22]
> Train epoch 100 [ensemble -41.05 | reward 20.17]
Ensemble loss -41.05 / Reward Loss 20.17

=== Collecting data [27] ===
> Step 25 [reward 51.00]
> Step 50 [reward 151.00]
> Step 75 [reward 251.00]
> Step 100 [reward 351.00]
> Step 125 [reward 451.00]
> Step 150 [reward 551.00]
> Step 175 [reward 651.00]
> Step 200 [reward 751.00]
> Step 225 [reward 851.00]
> Step 250 [reward 951.00]
Rewards 951.00 / Steps 250.00
Reward stats:
 {'max': '1105.07', 'mean': '431.64', 'min': '22.98', 'std': '216.10'}
Information gain stats:
 {'max': '1.42', 'mean': '0.81', 'min': '0.31', 'std': '0.14'}
Episode time 61.63
Saved _metrics_

=== Episode 28 ===
Training on [8000/32000] data points
> Train epoch 20 [ensemble -33.37 | reward 2.50]
> Train epoch 40 [ensemble -37.32 | reward 7.85]
> Train epoch 60 [ensemble -39.17 | reward 13.83]
> Train epoch 80 [ensemble -40.34 | reward 18.66]
> Train epoch 100 [ensemble -41.20 | reward 21.87]
Ensemble loss -41.20 / Reward Loss 21.87

=== Collecting data [28] ===
> Step 25 [reward 84.00]
> Step 50 [reward 184.00]
> Step 75 [reward 284.00]
> Step 100 [reward 384.00]
> Step 125 [reward 484.00]
> Step 150 [reward 584.00]
> Step 175 [reward 684.00]
> Step 200 [reward 784.00]
> Step 225 [reward 884.00]
> Step 250 [reward 984.00]
Rewards 984.00 / Steps 250.00
Reward stats:
 {'max': '1174.84', 'mean': '427.52', 'min': '28.90', 'std': '193.55'}
Information gain stats:
 {'max': '1.45', 'mean': '0.83', 'min': '0.34', 'std': '0.13'}
Episode time 62.91
Saved _metrics_

=== Episode 29 ===
Training on [8250/33000] data points
> Train epoch 20 [ensemble -33.69 | reward 2.68]
> Train epoch 40 [ensemble -37.53 | reward 8.36]
> Train epoch 60 [ensemble -39.34 | reward 14.59]
> Train epoch 80 [ensemble -40.49 | reward 19.60]
> Train epoch 100 [ensemble -41.33 | reward 22.88]
Ensemble loss -41.33 / Reward Loss 22.88

=== Collecting data [29] ===
> Step 25 [reward 31.00]
> Step 50 [reward 131.00]
> Step 75 [reward 231.00]
> Step 100 [reward 331.00]
> Step 125 [reward 431.00]
> Step 150 [reward 531.00]
> Step 175 [reward 631.00]
> Step 200 [reward 731.00]
> Step 225 [reward 831.00]
> Step 250 [reward 931.00]
Rewards 931.00 / Steps 250.00
Reward stats:
 {'max': '1171.18', 'mean': '420.24', 'min': '9.07', 'std': '209.93'}
Information gain stats:
 {'max': '1.49', 'mean': '0.84', 'min': '0.29', 'std': '0.15'}
Episode time 64.38
Saved _metrics_

=== Episode 30 ===
Training on [8500/34000] data points
> Train epoch 20 [ensemble -33.98 | reward 2.76]
> Train epoch 40 [ensemble -37.70 | reward 8.80]
> Train epoch 60 [ensemble -39.46 | reward 15.49]
> Train epoch 80 [ensemble -40.58 | reward 20.87]
> Train epoch 100 [ensemble -41.41 | reward 24.36]
Ensemble loss -41.41 / Reward Loss 24.36

=== Collecting data [30] ===
> Step 25 [reward 46.00]
> Step 50 [reward 146.00]
> Step 75 [reward 246.00]
> Step 100 [reward 346.00]
> Step 125 [reward 446.00]
> Step 150 [reward 546.00]
> Step 175 [reward 646.00]
> Step 200 [reward 746.00]
> Step 225 [reward 846.00]
> Step 250 [reward 946.00]
Rewards 946.00 / Steps 250.00
Reward stats:
 {'max': '1212.27', 'mean': '439.24', 'min': '21.84', 'std': '203.25'}
Information gain stats:
 {'max': '1.46', 'mean': '0.85', 'min': '0.34', 'std': '0.14'}
Episode time 66.03
Saved _metrics_

=== Episode 31 ===
Training on [8750/35000] data points
> Train epoch 20 [ensemble -34.28 | reward 2.99]
> Train epoch 40 [ensemble -37.94 | reward 9.38]
> Train epoch 60 [ensemble -39.67 | reward 16.32]
> Train epoch 80 [ensemble -40.78 | reward 21.88]
> Train epoch 100 [ensemble -41.58 | reward 25.54]
Ensemble loss -41.58 / Reward Loss 25.54

=== Collecting data [31] ===
> Step 25 [reward 7.00]
> Step 50 [reward 107.00]
> Step 75 [reward 207.00]
> Step 100 [reward 307.00]
> Step 125 [reward 407.00]
> Step 150 [reward 507.00]
> Step 175 [reward 607.00]
> Step 200 [reward 707.00]
> Step 225 [reward 807.00]
> Step 250 [reward 907.00]
Rewards 907.00 / Steps 250.00
Reward stats:
 {'max': '1276.88', 'mean': '482.46', 'min': '24.55', 'std': '225.38'}
Information gain stats:
 {'max': '1.59', 'mean': '0.84', 'min': '0.34', 'std': '0.15'}
Episode time 67.51
Saved _metrics_

=== Episode 32 ===
Training on [9000/36000] data points
> Train epoch 20 [ensemble -34.51 | reward 3.26]
> Train epoch 40 [ensemble -38.14 | reward 10.08]
> Train epoch 60 [ensemble -39.85 | reward 17.48]
> Train epoch 80 [ensemble -40.95 | reward 23.45]
> Train epoch 100 [ensemble -41.75 | reward 27.40]
Ensemble loss -41.75 / Reward Loss 27.40

=== Collecting data [32] ===
> Step 25 [reward 56.00]
> Step 50 [reward 156.00]
> Step 75 [reward 256.00]
> Step 100 [reward 356.00]
> Step 125 [reward 456.00]
> Step 150 [reward 556.00]
> Step 175 [reward 656.00]
> Step 200 [reward 756.00]
> Step 225 [reward 856.00]
> Step 250 [reward 956.00]
Rewards 956.00 / Steps 250.00
Reward stats:
 {'max': '1280.10', 'mean': '492.77', 'min': '7.15', 'std': '239.44'}
Information gain stats:
 {'max': '1.46', 'mean': '0.83', 'min': '0.32', 'std': '0.15'}
Episode time 68.82
Saved _metrics_

=== Episode 33 ===
Training on [9250/37000] data points
> Train epoch 20 [ensemble -34.93 | reward 3.41]
> Train epoch 40 [ensemble -38.41 | reward 10.69]
> Train epoch 60 [ensemble -40.05 | reward 18.46]
> Train epoch 80 [ensemble -41.10 | reward 24.62]
> Train epoch 100 [ensemble -41.87 | reward 28.63]
Ensemble loss -41.87 / Reward Loss 28.63

=== Collecting data [33] ===
> Step 25 [reward 88.00]
> Step 50 [reward 188.00]
> Step 75 [reward 288.00]
> Step 100 [reward 388.00]
> Step 125 [reward 488.00]
> Step 150 [reward 588.00]
> Step 175 [reward 688.00]
> Step 200 [reward 788.00]
> Step 225 [reward 888.00]
> Step 250 [reward 988.00]
Rewards 988.00 / Steps 250.00
Reward stats:
 {'max': '1266.42', 'mean': '440.44', 'min': '23.31', 'std': '210.36'}
Information gain stats:
 {'max': '1.43', 'mean': '0.84', 'min': '0.30', 'std': '0.14'}
Episode time 70.20
Saved _metrics_

=== Episode 34 ===
Training on [9500/38000] data points
> Train epoch 20 [ensemble -35.18 | reward 3.62]
> Train epoch 40 [ensemble -38.59 | reward 11.35]
> Train epoch 60 [ensemble -40.21 | reward 19.54]
> Train epoch 80 [ensemble -41.25 | reward 26.01]
> Train epoch 100 [ensemble -42.01 | reward 30.21]
Ensemble loss -42.01 / Reward Loss 30.21

=== Collecting data [34] ===
> Step 25 [reward 0.00]
> Step 50 [reward 82.00]
> Step 75 [reward 182.00]
> Step 100 [reward 282.00]
> Step 125 [reward 382.00]
> Step 150 [reward 482.00]
> Step 175 [reward 582.00]
> Step 200 [reward 682.00]
> Step 225 [reward 782.00]
> Step 250 [reward 882.00]
Rewards 882.00 / Steps 250.00
Reward stats:
 {'max': '1395.68', 'mean': '523.85', 'min': '23.09', 'std': '242.48'}
Information gain stats:
 {'max': '1.49', 'mean': '0.86', 'min': '0.31', 'std': '0.15'}
Episode time 72.26
Saved _metrics_

=== Episode 35 ===
Training on [9750/39000] data points
> Train epoch 20 [ensemble -35.26 | reward 3.90]
> Train epoch 40 [ensemble -38.65 | reward 12.05]
> Train epoch 60 [ensemble -40.25 | reward 20.72]
> Train epoch 80 [ensemble -41.28 | reward 27.64]
> Train epoch 100 [ensemble -42.04 | reward 32.21]
Ensemble loss -42.04 / Reward Loss 32.21

=== Collecting data [35] ===
> Step 25 [reward 24.00]
> Step 50 [reward 124.00]
> Step 75 [reward 224.00]
> Step 100 [reward 324.00]
> Step 125 [reward 424.00]
> Step 150 [reward 524.00]
> Step 175 [reward 624.00]
> Step 200 [reward 724.00]
> Step 225 [reward 824.00]
> Step 250 [reward 924.00]
Rewards 924.00 / Steps 250.00
Reward stats:
 {'max': '1307.07', 'mean': '511.37', 'min': '35.65', 'std': '227.94'}
Information gain stats:
 {'max': '1.55', 'mean': '0.89', 'min': '0.35', 'std': '0.15'}
Episode time 72.52
Saved _metrics_

=== Episode 36 ===
Training on [10000/40000] data points
> Train epoch 20 [ensemble -35.63 | reward 3.98]
> Train epoch 40 [ensemble -38.91 | reward 12.53]
> Train epoch 60 [ensemble -40.47 | reward 21.50]
> Train epoch 80 [ensemble -41.47 | reward 28.54]
> Train epoch 100 [ensemble -42.21 | reward 33.17]
Ensemble loss -42.21 / Reward Loss 33.17

=== Collecting data [36] ===
> Step 25 [reward 87.00]
> Step 50 [reward 187.00]
> Step 75 [reward 287.00]
> Step 100 [reward 387.00]
> Step 125 [reward 487.00]
> Step 150 [reward 587.00]
> Step 175 [reward 687.00]
> Step 200 [reward 787.00]
> Step 225 [reward 887.00]
> Step 250 [reward 987.00]
Rewards 987.00 / Steps 250.00
Reward stats:
 {'max': '1378.81', 'mean': '487.99', 'min': '31.81', 'std': '226.12'}
Information gain stats:
 {'max': '1.45', 'mean': '0.86', 'min': '0.34', 'std': '0.14'}
Episode time 73.83
Saved _metrics_

=== Episode 37 ===
Training on [10250/41000] data points
> Train epoch 20 [ensemble -35.77 | reward 4.15]
> Train epoch 40 [ensemble -39.01 | reward 13.02]
> Train epoch 60 [ensemble -40.54 | reward 22.38]
> Train epoch 80 [ensemble -41.54 | reward 29.81]
> Train epoch 100 [ensemble -42.27 | reward 34.67]
Ensemble loss -42.27 / Reward Loss 34.67

=== Collecting data [37] ===
> Step 25 [reward 55.00]
> Step 50 [reward 155.00]
> Step 75 [reward 255.00]
> Step 100 [reward 355.00]
> Step 125 [reward 455.00]
> Step 150 [reward 555.00]
> Step 175 [reward 655.00]
> Step 200 [reward 755.00]
> Step 225 [reward 855.00]
> Step 250 [reward 955.00]
Rewards 955.00 / Steps 250.00
Reward stats:
 {'max': '1433.70', 'mean': '488.16', 'min': '25.05', 'std': '235.12'}
Information gain stats:
 {'max': '1.49', 'mean': '0.88', 'min': '0.32', 'std': '0.15'}
Episode time 75.55
Saved _metrics_

=== Episode 38 ===
Training on [10500/42000] data points
> Train epoch 20 [ensemble -36.12 | reward 4.37]
> Train epoch 40 [ensemble -39.25 | reward 13.60]
> Train epoch 60 [ensemble -40.73 | reward 23.27]
> Train epoch 80 [ensemble -41.70 | reward 30.92]
> Train epoch 100 [ensemble -42.42 | reward 35.96]
Ensemble loss -42.42 / Reward Loss 35.96

=== Collecting data [38] ===
> Step 25 [reward 84.00]
> Step 50 [reward 184.00]
> Step 75 [reward 284.00]
> Step 100 [reward 384.00]
> Step 125 [reward 484.00]
> Step 150 [reward 584.00]
> Step 175 [reward 684.00]
> Step 200 [reward 784.00]
> Step 225 [reward 884.00]
> Step 250 [reward 984.00]
Rewards 984.00 / Steps 250.00
Reward stats:
 {'max': '1443.58', 'mean': '519.70', 'min': '38.96', 'std': '233.42'}
Information gain stats:
 {'max': '1.47', 'mean': '0.89', 'min': '0.33', 'std': '0.14'}
Episode time 76.62
Saved _metrics_

=== Episode 39 ===
Training on [10750/43000] data points
> Train epoch 20 [ensemble -36.23 | reward 4.61]
> Train epoch 40 [ensemble -39.32 | reward 14.39]
> Train epoch 60 [ensemble -40.80 | reward 24.55]
> Train epoch 80 [ensemble -41.76 | reward 32.51]
> Train epoch 100 [ensemble -42.47 | reward 37.69]
Ensemble loss -42.47 / Reward Loss 37.69

=== Collecting data [39] ===
> Step 25 [reward 57.00]
> Step 50 [reward 157.00]
> Step 75 [reward 257.00]
> Step 100 [reward 357.00]
> Step 125 [reward 457.00]
> Step 150 [reward 557.00]
> Step 175 [reward 657.00]
> Step 200 [reward 757.00]
> Step 225 [reward 857.00]
> Step 250 [reward 957.00]
Rewards 957.00 / Steps 250.00
Reward stats:
 {'max': '1402.61', 'mean': '494.53', 'min': '25.50', 'std': '229.14'}
Information gain stats:
 {'max': '1.48', 'mean': '0.87', 'min': '0.33', 'std': '0.14'}
Episode time 77.94
Saved _metrics_

=== Episode 40 ===
Training on [11000/44000] data points
> Train epoch 20 [ensemble -36.48 | reward 4.77]
> Train epoch 40 [ensemble -39.50 | reward 14.90]
> Train epoch 60 [ensemble -40.95 | reward 25.44]
> Train epoch 80 [ensemble -41.89 | reward 33.76]
> Train epoch 100 [ensemble -42.59 | reward 39.25]
Ensemble loss -42.59 / Reward Loss 39.25

=== Collecting data [40] ===
> Step 25 [reward 86.00]
> Step 50 [reward 186.00]
> Step 75 [reward 286.00]
> Step 100 [reward 386.00]
> Step 125 [reward 486.00]
> Step 150 [reward 586.00]
> Step 175 [reward 686.00]
> Step 200 [reward 786.00]
> Step 225 [reward 886.00]
> Step 250 [reward 986.00]
Rewards 986.00 / Steps 250.00
Reward stats:
 {'max': '1513.22', 'mean': '528.82', 'min': '58.32', 'std': '239.16'}
Information gain stats:
 {'max': '1.48', 'mean': '0.89', 'min': '0.26', 'std': '0.14'}
Episode time 79.43
Saved _metrics_

=== Episode 41 ===
Training on [11250/45000] data points
> Train epoch 20 [ensemble -36.72 | reward 5.06]
> Train epoch 40 [ensemble -39.69 | reward 15.94]
> Train epoch 60 [ensemble -41.11 | reward 27.22]
> Train epoch 80 [ensemble -42.04 | reward 36.04]
> Train epoch 100 [ensemble -42.72 | reward 41.85]
Ensemble loss -42.72 / Reward Loss 41.85

=== Collecting data [41] ===
> Step 25 [reward 58.00]
> Step 50 [reward 158.00]
> Step 75 [reward 258.00]
> Step 100 [reward 358.00]
> Step 125 [reward 458.00]
> Step 150 [reward 558.00]
> Step 175 [reward 658.00]
> Step 200 [reward 758.00]
> Step 225 [reward 858.00]
> Step 250 [reward 958.00]
Rewards 958.00 / Steps 250.00
Reward stats:
 {'max': '1466.80', 'mean': '533.40', 'min': '58.07', 'std': '230.16'}
Information gain stats:
 {'max': '1.49', 'mean': '0.89', 'min': '0.36', 'std': '0.14'}
Episode time 80.74
Saved _metrics_

=== Episode 42 ===
Training on [11500/46000] data points
> Train epoch 20 [ensemble -37.04 | reward 5.13]
> Train epoch 40 [ensemble -39.92 | reward 16.05]
> Train epoch 60 [ensemble -41.29 | reward 27.39]
> Train epoch 80 [ensemble -42.19 | reward 36.19]
> Train epoch 100 [ensemble -42.85 | reward 41.96]
Ensemble loss -42.85 / Reward Loss 41.96

=== Collecting data [42] ===
> Step 25 [reward 34.00]
> Step 50 [reward 134.00]
> Step 75 [reward 234.00]
> Step 100 [reward 334.00]
> Step 125 [reward 434.00]
> Step 150 [reward 534.00]
> Step 175 [reward 634.00]
> Step 200 [reward 734.00]
> Step 225 [reward 834.00]
> Step 250 [reward 934.00]
Rewards 934.00 / Steps 250.00
Reward stats:
 {'max': '1531.42', 'mean': '555.77', 'min': '53.91', 'std': '250.54'}
Information gain stats:
 {'max': '1.54', 'mean': '0.89', 'min': '0.33', 'std': '0.15'}
Episode time 81.98
Saved _metrics_

=== Episode 43 ===
Training on [11750/47000] data points
> Train epoch 20 [ensemble -37.22 | reward 5.47]
> Train epoch 40 [ensemble -40.02 | reward 17.03]
> Train epoch 60 [ensemble -41.38 | reward 28.82]
> Train epoch 80 [ensemble -42.27 | reward 38.03]
> Train epoch 100 [ensemble -42.92 | reward 44.08]
Ensemble loss -42.92 / Reward Loss 44.08

=== Collecting data [43] ===
> Step 25 [reward 22.00]
> Step 50 [reward 122.00]
> Step 75 [reward 222.00]
> Step 100 [reward 322.00]
> Step 125 [reward 422.00]
> Step 150 [reward 522.00]
> Step 175 [reward 622.00]
> Step 200 [reward 722.00]
> Step 225 [reward 822.00]
> Step 250 [reward 922.00]
Rewards 922.00 / Steps 250.00
Reward stats:
 {'max': '1559.84', 'mean': '541.71', 'min': '45.74', 'std': '246.64'}
Information gain stats:
 {'max': '1.58', 'mean': '0.93', 'min': '0.34', 'std': '0.15'}
Episode time 83.50
Saved _metrics_

=== Episode 44 ===
Training on [12000/48000] data points
> Train epoch 20 [ensemble -37.33 | reward 5.83]
> Train epoch 40 [ensemble -40.12 | reward 18.04]
> Train epoch 60 [ensemble -41.47 | reward 30.47]
> Train epoch 80 [ensemble -42.36 | reward 40.05]
> Train epoch 100 [ensemble -43.01 | reward 46.31]
Ensemble loss -43.01 / Reward Loss 46.31

=== Collecting data [44] ===
> Step 25 [reward 47.00]
> Step 50 [reward 147.00]
> Step 75 [reward 247.00]
> Step 100 [reward 347.00]
> Step 125 [reward 447.00]
> Step 150 [reward 547.00]
> Step 175 [reward 647.00]
> Step 200 [reward 747.00]
> Step 225 [reward 847.00]
> Step 250 [reward 947.00]
Rewards 947.00 / Steps 250.00
Reward stats:
 {'max': '1602.22', 'mean': '631.18', 'min': '62.03', 'std': '264.24'}
Information gain stats:
 {'max': '1.50', 'mean': '0.91', 'min': '0.31', 'std': '0.15'}
Episode time 85.40
Saved _metrics_

=== Episode 45 ===
Training on [12250/49000] data points
> Train epoch 20 [ensemble -37.39 | reward 5.85]
> Train epoch 40 [ensemble -40.19 | reward 18.27]
> Train epoch 60 [ensemble -41.55 | reward 31.09]
> Train epoch 80 [ensemble -42.43 | reward 41.10]
> Train epoch 100 [ensemble -43.08 | reward 47.70]
Ensemble loss -43.08 / Reward Loss 47.70

=== Collecting data [45] ===
> Step 25 [reward 54.00]
> Step 50 [reward 154.00]
> Step 75 [reward 254.00]
> Step 100 [reward 354.00]
> Step 125 [reward 454.00]
> Step 150 [reward 554.00]
> Step 175 [reward 654.00]
> Step 200 [reward 754.00]
> Step 225 [reward 854.00]
> Step 250 [reward 954.00]
Rewards 954.00 / Steps 250.00
Reward stats:
 {'max': '1655.73', 'mean': '608.92', 'min': '29.53', 'std': '269.15'}
Information gain stats:
 {'max': '1.55', 'mean': '0.92', 'min': '0.33', 'std': '0.16'}
Episode time 86.72
Saved _metrics_

=== Episode 46 ===
Training on [12500/50000] data points
> Train epoch 20 [ensemble -37.58 | reward 6.10]
> Train epoch 40 [ensemble -40.31 | reward 18.89]
> Train epoch 60 [ensemble -41.64 | reward 31.99]
> Train epoch 80 [ensemble -42.51 | reward 42.29]
> Train epoch 100 [ensemble -43.14 | reward 49.11]
Ensemble loss -43.14 / Reward Loss 49.11

=== Collecting data [46] ===
> Step 25 [reward 0.00]
> Step 50 [reward 79.00]
> Step 75 [reward 179.00]
> Step 100 [reward 279.00]
> Step 125 [reward 379.00]
> Step 150 [reward 479.00]
> Step 175 [reward 579.00]
> Step 200 [reward 679.00]
> Step 225 [reward 779.00]
> Step 250 [reward 879.00]
Rewards 879.00 / Steps 250.00
Reward stats:
 {'max': '1576.46', 'mean': '571.41', 'min': '40.77', 'std': '246.97'}
Information gain stats:
 {'max': '1.55', 'mean': '0.92', 'min': '0.33', 'std': '0.15'}
Episode time 87.78
Saved _metrics_

=== Episode 47 ===
Training on [12750/51000] data points
> Train epoch 20 [ensemble -37.71 | reward 6.59]
> Train epoch 40 [ensemble -40.42 | reward 20.21]
> Train epoch 60 [ensemble -41.74 | reward 33.97]
> Train epoch 80 [ensemble -42.60 | reward 44.63]
> Train epoch 100 [ensemble -43.23 | reward 51.67]
Ensemble loss -43.23 / Reward Loss 51.67

=== Collecting data [47] ===
> Step 25 [reward 50.00]
> Step 50 [reward 150.00]
> Step 75 [reward 250.00]
> Step 100 [reward 350.00]
> Step 125 [reward 450.00]
> Step 150 [reward 550.00]
> Step 175 [reward 650.00]
> Step 200 [reward 750.00]
> Step 225 [reward 850.00]
> Step 250 [reward 950.00]
Rewards 950.00 / Steps 250.00
Reward stats:
 {'max': '1668.61', 'mean': '661.28', 'min': '43.03', 'std': '267.69'}
Information gain stats:
 {'max': '1.57', 'mean': '0.94', 'min': '0.35', 'std': '0.15'}
Episode time 89.33
Saved _metrics_

=== Episode 48 ===
Training on [13000/52000] data points
> Train epoch 20 [ensemble -37.95 | reward 6.57]
> Train epoch 40 [ensemble -40.58 | reward 20.43]
> Train epoch 60 [ensemble -41.85 | reward 34.58]
> Train epoch 80 [ensemble -42.68 | reward 45.49]
> Train epoch 100 [ensemble -43.29 | reward 52.68]
Ensemble loss -43.29 / Reward Loss 52.68

=== Collecting data [48] ===
> Step 25 [reward 53.00]
> Step 50 [reward 153.00]
> Step 75 [reward 253.00]
> Step 100 [reward 353.00]
> Step 125 [reward 453.00]
> Step 150 [reward 553.00]
> Step 175 [reward 653.00]
> Step 200 [reward 753.00]
> Step 225 [reward 853.00]
> Step 250 [reward 953.00]
Rewards 953.00 / Steps 250.00
Reward stats:
 {'max': '1627.15', 'mean': '590.50', 'min': '65.18', 'std': '248.33'}
Information gain stats:
 {'max': '1.49', 'mean': '0.90', 'min': '0.30', 'std': '0.14'}
Episode time 90.24
Saved _metrics_

=== Episode 49 ===
Training on [13250/53000] data points
> Train epoch 20 [ensemble -37.99 | reward 6.76]
> Train epoch 40 [ensemble -40.62 | reward 21.06]
> Train epoch 60 [ensemble -41.90 | reward 35.33]
> Train epoch 80 [ensemble -42.73 | reward 46.24]
> Train epoch 100 [ensemble -43.34 | reward 53.38]
Ensemble loss -43.34 / Reward Loss 53.38

=== Collecting data [49] ===
> Step 25 [reward 87.00]
> Step 50 [reward 187.00]
> Step 75 [reward 287.00]
> Step 100 [reward 387.00]
> Step 125 [reward 487.00]
> Step 150 [reward 587.00]
> Step 175 [reward 687.00]
> Step 200 [reward 787.00]
> Step 225 [reward 887.00]
> Step 250 [reward 987.00]
Rewards 987.00 / Steps 250.00
Reward stats:
 {'max': '1686.70', 'mean': '617.81', 'min': '87.59', 'std': '258.64'}
Information gain stats:
 {'max': '1.48', 'mean': '0.91', 'min': '0.34', 'std': '0.15'}
Episode time 91.75
Saved _metrics_