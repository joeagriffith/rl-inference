19:29:36

=== Loading experiment [device: cuda] ===

{'action_noise': None,
 'action_repeat': 3,
 'batch_size': 50,
 'coverage': False,
 'ensemble_size': 25,
 'env_name': 'SparseMountainCar',
 'epsilon': 1e-08,
 'expl_scale': 1.0,
 'expl_strategy': 'information',
 'grad_clip_norm': 1000,
 'hidden_size': 200,
 'learning_rate': 0.001,
 'logdir': 'mountain_car_DQN-like',
 'max_episode_len': 500,
 'n_candidates': 500,
 'n_episodes': 50,
 'n_seed_episodes': 1,
 'n_train_epochs': 100,
 'optimisation_iters': 5,
 'plan_horizon': 30,
 'record_every': None,
 'reward_scale': 1.0,
 'seed': 0,
 'strategy': 'information',
 'top_candidates': 50,
 'use_exploration': True,
 'use_mean': False,
 'use_reward': True}

Collected seeds: [1 episodes | 167 frames]

=== Episode 1 ===
Training on [167/501] data points
> Train epoch 20 [ensemble -15.80 | reward 0.00]
> Train epoch 40 [ensemble -44.78 | reward 0.00]
> Train epoch 60 [ensemble -58.11 | reward 0.00]
> Train epoch 80 [ensemble -71.84 | reward 0.00]
> Train epoch 100 [ensemble -81.28 | reward 0.00]
Ensemble loss -81.28 / Reward Loss 0.00

=== Collecting data [1] ===
Rewards 1.00 / Steps 23.00
Reward stats:
 {'max': '-1.00', 'mean': '-1.11', 'min': '-1.28', 'std': '0.04'}
Information gain stats:
 {'max': '152.83', 'mean': '55.18', 'min': '11.56', 'std': '23.35'}
Episode time 6.77
Saved _metrics_

=== Episode 2 ===
Training on [190/570] data points
> Train epoch 20 [ensemble 13.60 | reward 0.00]
> Train epoch 40 [ensemble -20.24 | reward 0.00]
> Train epoch 60 [ensemble -36.46 | reward 0.00]
> Train epoch 80 [ensemble -48.42 | reward 0.00]
> Train epoch 100 [ensemble -57.94 | reward 0.00]
Ensemble loss -57.94 / Reward Loss 0.00

=== Collecting data [2] ===
> Step 25 [reward 0.00]
Rewards 1.00 / Steps 34.00
Reward stats:
 {'max': '511.04', 'mean': '32.31', 'min': '2.47', 'std': '58.65'}
Information gain stats:
 {'max': '127.82', 'mean': '65.25', 'min': '12.75', 'std': '22.06'}
Episode time 7.38
Saved _metrics_

=== Episode 3 ===
Training on [224/672] data points
> Train epoch 20 [ensemble 12.97 | reward 0.00]
> Train epoch 40 [ensemble -16.67 | reward 0.00]
> Train epoch 60 [ensemble -29.08 | reward 0.00]
> Train epoch 80 [ensemble -37.84 | reward 0.00]
> Train epoch 100 [ensemble -45.85 | reward 0.00]
Ensemble loss -45.85 / Reward Loss 0.00

=== Collecting data [3] ===
> Step 25 [reward 1.00]
Rewards 1.00 / Steps 25.00
Reward stats:
 {'max': '910.04', 'mean': '76.90', 'min': '-0.87', 'std': '149.67'}
Information gain stats:
 {'max': '136.86', 'mean': '60.63', 'min': '15.48', 'std': '26.44'}
Episode time 6.21
Saved _metrics_

=== Episode 4 ===
Training on [249/747] data points
> Train epoch 20 [ensemble 16.25 | reward 0.01]
> Train epoch 40 [ensemble -14.85 | reward 0.01]
> Train epoch 60 [ensemble -27.61 | reward 0.00]
> Train epoch 80 [ensemble -36.35 | reward 0.00]
> Train epoch 100 [ensemble -43.56 | reward 0.00]
Ensemble loss -43.56 / Reward Loss 0.00

=== Collecting data [4] ===
Rewards 1.00 / Steps 24.00
Reward stats:
 {'max': '3458.11', 'mean': '480.13', 'min': '-6.41', 'std': '806.23'}
Information gain stats:
 {'max': '155.70', 'mean': '71.61', 'min': '17.24', 'std': '33.13'}
Episode time 5.76
Saved _metrics_

=== Episode 5 ===
Training on [273/819] data points
> Train epoch 20 [ensemble 4.79 | reward 0.01]
> Train epoch 40 [ensemble -21.13 | reward 0.00]
> Train epoch 60 [ensemble -33.86 | reward 0.00]
> Train epoch 80 [ensemble -43.24 | reward 0.00]
> Train epoch 100 [ensemble -52.07 | reward 0.00]
Ensemble loss -52.07 / Reward Loss 0.00

=== Collecting data [5] ===
Rewards 1.00 / Steps 24.00
Reward stats:
 {'max': '12401.09', 'mean': '1622.97', 'min': '2.64', 'std': '2921.97'}
Information gain stats:
 {'max': '215.06', 'mean': '85.05', 'min': '8.35', 'std': '54.61'}
Episode time 6.04
Saved _metrics_

=== Episode 6 ===
Training on [297/891] data points
> Train epoch 20 [ensemble 4.65 | reward 0.01]
> Train epoch 40 [ensemble -21.02 | reward 0.00]
> Train epoch 60 [ensemble -33.63 | reward 0.00]
> Train epoch 80 [ensemble -42.73 | reward 0.00]
> Train epoch 100 [ensemble -51.10 | reward 0.00]
Ensemble loss -51.10 / Reward Loss 0.00

=== Collecting data [6] ===
Rewards 1.00 / Steps 24.00
Reward stats:
 {'max': '12612.24', 'mean': '1422.44', 'min': '-2.56', 'std': '2764.82'}
Information gain stats:
 {'max': '216.33', 'mean': '79.68', 'min': '11.75', 'std': '54.49'}
Episode time 5.72
Saved _metrics_

=== Episode 7 ===
Training on [321/963] data points
> Train epoch 20 [ensemble -5.03 | reward 0.01]
> Train epoch 40 [ensemble -27.75 | reward 0.00]
> Train epoch 60 [ensemble -40.21 | reward 0.00]
> Train epoch 80 [ensemble -49.79 | reward 0.00]
> Train epoch 100 [ensemble -59.21 | reward 0.00]
Ensemble loss -59.21 / Reward Loss 0.00

=== Collecting data [7] ===
Rewards 1.00 / Steps 24.00
Reward stats:
 {'max': '4725.23', 'mean': '677.40', 'min': '-4.24', 'std': '1154.93'}
Information gain stats:
 {'max': '182.17', 'mean': '70.22', 'min': '8.81', 'std': '47.49'}
Episode time 6.18
Saved _metrics_

=== Episode 8 ===
Training on [345/1035] data points
> Train epoch 20 [ensemble -4.51 | reward 0.01]
> Train epoch 40 [ensemble -27.07 | reward 0.01]
> Train epoch 60 [ensemble -39.44 | reward 0.00]
> Train epoch 80 [ensemble -48.53 | reward 0.00]
> Train epoch 100 [ensemble -57.11 | reward 0.00]
Ensemble loss -57.11 / Reward Loss 0.00

=== Collecting data [8] ===
Rewards 1.00 / Steps 24.00
Reward stats:
 {'max': '4418.26', 'mean': '564.01', 'min': '-5.43', 'std': '1038.05'}
Information gain stats:
 {'max': '178.98', 'mean': '67.63', 'min': '10.39', 'std': '45.49'}
Episode time 6.85
Saved _metrics_

=== Episode 9 ===
Training on [369/1107] data points
> Train epoch 20 [ensemble -11.03 | reward 0.00]
> Train epoch 40 [ensemble -32.58 | reward 0.00]
> Train epoch 60 [ensemble -45.08 | reward 0.00]
> Train epoch 80 [ensemble -54.92 | reward 0.00]
> Train epoch 100 [ensemble -64.08 | reward 0.00]
Ensemble loss -64.08 / Reward Loss 0.00

=== Collecting data [9] ===
Rewards 1.00 / Steps 23.00
Reward stats:
 {'max': '1582.37', 'mean': '248.33', 'min': '2.91', 'std': '391.04'}
Information gain stats:
 {'max': '169.71', 'mean': '66.80', 'min': '7.42', 'std': '42.73'}
Episode time 6.56
Saved _metrics_

=== Episode 10 ===
Training on [392/1176] data points
> Train epoch 20 [ensemble -11.10 | reward 0.01]
> Train epoch 40 [ensemble -32.46 | reward 0.00]
> Train epoch 60 [ensemble -44.88 | reward 0.00]
> Train epoch 80 [ensemble -54.37 | reward 0.00]
> Train epoch 100 [ensemble -63.44 | reward 0.00]
Ensemble loss -63.44 / Reward Loss 0.00

=== Collecting data [10] ===
Rewards 1.00 / Steps 24.00
Reward stats:
 {'max': '2207.79', 'mean': '336.09', 'min': '-1.55', 'std': '548.59'}
Information gain stats:
 {'max': '160.51', 'mean': '60.87', 'min': '8.84', 'std': '40.08'}
Episode time 7.60
Saved _metrics_

=== Episode 11 ===
Training on [416/1248] data points
> Train epoch 20 [ensemble -15.39 | reward 0.01]
> Train epoch 40 [ensemble -36.47 | reward 0.00]
> Train epoch 60 [ensemble -49.03 | reward 0.00]
> Train epoch 80 [ensemble -59.32 | reward 0.00]
> Train epoch 100 [ensemble -68.51 | reward 0.00]
Ensemble loss -68.51 / Reward Loss 0.00

=== Collecting data [11] ===
Rewards 1.00 / Steps 24.00
Reward stats:
 {'max': '965.33', 'mean': '129.32', 'min': '-2.06', 'std': '224.27'}
Information gain stats:
 {'max': '136.91', 'mean': '49.30', 'min': '8.71', 'std': '33.07'}
Episode time 6.92
Saved _metrics_

=== Episode 12 ===
Training on [440/1320] data points
> Train epoch 20 [ensemble -15.67 | reward 0.00]
> Train epoch 40 [ensemble -36.67 | reward 0.00]
> Train epoch 60 [ensemble -49.29 | reward 0.00]
> Train epoch 80 [ensemble -59.61 | reward 0.00]
> Train epoch 100 [ensemble -68.82 | reward 0.00]
Ensemble loss -68.82 / Reward Loss 0.00

=== Collecting data [12] ===
Rewards 1.00 / Steps 23.00
Reward stats:
 {'max': '1061.23', 'mean': '184.58', 'min': '3.32', 'std': '272.01'}
Information gain stats:
 {'max': '142.75', 'mean': '53.71', 'min': '8.67', 'std': '35.88'}
Episode time 6.77
Saved _metrics_

=== Episode 13 ===
Training on [463/1389] data points
> Train epoch 20 [ensemble -20.67 | reward 0.00]
> Train epoch 40 [ensemble -41.03 | reward 0.00]
> Train epoch 60 [ensemble -53.54 | reward 0.00]
> Train epoch 80 [ensemble -64.32 | reward 0.00]
> Train epoch 100 [ensemble -73.10 | reward 0.00]
Ensemble loss -73.10 / Reward Loss 0.00

=== Collecting data [13] ===
> Step 25 [reward 0.00]
Rewards 1.00 / Steps 34.00
Reward stats:
 {'max': '763.30', 'mean': '93.12', 'min': '0.78', 'std': '172.52'}
Information gain stats:
 {'max': '127.22', 'mean': '46.55', 'min': '8.23', 'std': '26.45'}
Episode time 8.88
Saved _metrics_

=== Episode 14 ===
Training on [497/1491] data points
> Train epoch 20 [ensemble -19.37 | reward 0.01]
> Train epoch 40 [ensemble -40.28 | reward 0.00]
> Train epoch 60 [ensemble -53.51 | reward 0.00]
> Train epoch 80 [ensemble -64.94 | reward 0.00]
> Train epoch 100 [ensemble -73.66 | reward 0.00]
Ensemble loss -73.66 / Reward Loss 0.00

=== Collecting data [14] ===
> Step 25 [reward 0.00]
Rewards 1.00 / Steps 27.00
Reward stats:
 {'max': '1132.56', 'mean': '146.84', 'min': '-1.97', 'std': '261.37'}
Information gain stats:
 {'max': '135.60', 'mean': '43.03', 'min': '5.11', 'std': '33.46'}
Episode time 7.99
Saved _metrics_

=== Episode 15 ===
Training on [524/1572] data points
> Train epoch 20 [ensemble -23.09 | reward 0.01]
> Train epoch 40 [ensemble -43.95 | reward 0.00]
> Train epoch 60 [ensemble -57.40 | reward 0.00]
> Train epoch 80 [ensemble -68.61 | reward 0.00]
> Train epoch 100 [ensemble -76.68 | reward 0.00]
Ensemble loss -76.68 / Reward Loss 0.00

=== Collecting data [15] ===
> Step 25 [reward 0.00]
Rewards 1.00 / Steps 34.00
Reward stats:
 {'max': '1332.96', 'mean': '150.69', 'min': '-4.79', 'std': '295.33'}
Information gain stats:
 {'max': '142.91', 'mean': '46.81', 'min': '7.68', 'std': '32.10'}
Episode time 9.28
Saved _metrics_

=== Episode 16 ===
Training on [558/1674] data points
> Train epoch 20 [ensemble -26.21 | reward 0.00]
> Train epoch 40 [ensemble -47.67 | reward 0.00]
> Train epoch 60 [ensemble -62.70 | reward 0.00]
> Train epoch 80 [ensemble -73.80 | reward 0.00]
> Train epoch 100 [ensemble -81.30 | reward 0.00]
Ensemble loss -81.30 / Reward Loss 0.00

=== Collecting data [16] ===
> Step 25 [reward 0.00]
Rewards 1.00 / Steps 46.00
Reward stats:
 {'max': '1221.56', 'mean': '91.74', 'min': '-0.09', 'std': '229.70'}
Information gain stats:
 {'max': '152.69', 'mean': '34.53', 'min': '6.28', 'std': '33.52'}
Episode time 11.73
Saved _metrics_

=== Episode 17 ===
Training on [604/1812] data points
> Train epoch 20 [ensemble -28.75 | reward 0.01]
> Train epoch 40 [ensemble -50.56 | reward 0.00]
> Train epoch 60 [ensemble -66.12 | reward 0.00]
> Train epoch 80 [ensemble -76.83 | reward 0.00]
> Train epoch 100 [ensemble -83.90 | reward 0.00]
Ensemble loss -83.90 / Reward Loss 0.00

=== Collecting data [17] ===
> Step 25 [reward 0.00]
Rewards 1.00 / Steps 31.00
Reward stats:
 {'max': '1106.26', 'mean': '118.51', 'min': '-5.82', 'std': '241.62'}
Information gain stats:
 {'max': '144.76', 'mean': '42.08', 'min': '7.07', 'std': '35.43'}
Episode time 9.51
Saved _metrics_

=== Episode 18 ===
Training on [635/1905] data points
> Train epoch 20 [ensemble -28.82 | reward 0.00]
> Train epoch 40 [ensemble -50.79 | reward 0.00]
> Train epoch 60 [ensemble -66.55 | reward 0.00]
> Train epoch 80 [ensemble -77.06 | reward 0.00]
> Train epoch 100 [ensemble -83.98 | reward 0.00]
Ensemble loss -83.98 / Reward Loss 0.00

=== Collecting data [18] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
Rewards 1.00 / Steps 97.00
Reward stats:
 {'max': '1478.85', 'mean': '63.44', 'min': '1.68', 'std': '212.78'}
Information gain stats:
 {'max': '164.32', 'mean': '28.37', 'min': '5.63', 'std': '28.76'}
Episode time 22.00
Saved _metrics_

=== Episode 19 ===
Training on [732/2196] data points
> Train epoch 20 [ensemble -34.08 | reward 0.00]
> Train epoch 40 [ensemble -58.64 | reward 0.00]
> Train epoch 60 [ensemble -74.38 | reward 0.00]
> Train epoch 80 [ensemble -83.47 | reward 0.00]
> Train epoch 100 [ensemble -89.37 | reward 0.00]
Ensemble loss -89.37 / Reward Loss 0.00

=== Collecting data [19] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
Rewards 1.00 / Steps 51.00
Reward stats:
 {'max': '1179.92', 'mean': '81.10', 'min': '-0.38', 'std': '204.91'}
Information gain stats:
 {'max': '151.34', 'mean': '35.28', 'min': '7.65', 'std': '31.75'}
Episode time 14.13
Saved _metrics_

=== Episode 20 ===
Training on [783/2349] data points
> Train epoch 20 [ensemble -36.92 | reward 0.00]
> Train epoch 40 [ensemble -62.40 | reward 0.00]
> Train epoch 60 [ensemble -77.31 | reward 0.00]
> Train epoch 80 [ensemble -85.82 | reward 0.00]
> Train epoch 100 [ensemble -91.36 | reward 0.00]
Ensemble loss -91.36 / Reward Loss 0.00

=== Collecting data [20] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
Rewards 1.00 / Steps 54.00
Reward stats:
 {'max': '118.64', 'mean': '4.78', 'min': '1.19', 'std': '9.69'}
Information gain stats:
 {'max': '88.08', 'mean': '29.12', 'min': '4.73', 'std': '16.21'}
Episode time 14.22
Saved _metrics_

=== Episode 21 ===
Training on [837/2511] data points
> Train epoch 20 [ensemble -36.81 | reward 0.00]
> Train epoch 40 [ensemble -63.82 | reward 0.00]
> Train epoch 60 [ensemble -78.65 | reward 0.00]
> Train epoch 80 [ensemble -86.87 | reward 0.00]
> Train epoch 100 [ensemble -92.22 | reward 0.00]
Ensemble loss -92.22 / Reward Loss 0.00

=== Collecting data [21] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
Rewards 1.00 / Steps 55.00
Reward stats:
 {'max': '1061.34', 'mean': '73.88', 'min': '-0.10', 'std': '190.35'}
Information gain stats:
 {'max': '156.60', 'mean': '36.98', 'min': '5.81', 'std': '32.60'}
Episode time 14.84
Saved _metrics_

=== Episode 22 ===
Training on [892/2676] data points
> Train epoch 20 [ensemble -38.45 | reward 0.00]
> Train epoch 40 [ensemble -66.27 | reward 0.00]
> Train epoch 60 [ensemble -80.43 | reward 0.00]
> Train epoch 80 [ensemble -88.27 | reward 0.00]
> Train epoch 100 [ensemble -93.36 | reward 0.00]
Ensemble loss -93.36 / Reward Loss 0.00

=== Collecting data [22] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
Rewards 1.00 / Steps 63.00
Reward stats:
 {'max': '734.52', 'mean': '41.90', 'min': '0.93', 'std': '115.12'}
Information gain stats:
 {'max': '137.18', 'mean': '27.66', 'min': '4.72', 'std': '25.36'}
Episode time 16.96
Saved _metrics_

=== Episode 23 ===
Training on [955/2865] data points
> Train epoch 20 [ensemble -43.65 | reward 0.00]
> Train epoch 40 [ensemble -71.51 | reward 0.00]
> Train epoch 60 [ensemble -84.30 | reward 0.00]
> Train epoch 80 [ensemble -91.41 | reward 0.00]
> Train epoch 100 [ensemble -96.05 | reward 0.00]
Ensemble loss -96.05 / Reward Loss 0.00

=== Collecting data [23] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
Rewards 1.00 / Steps 51.00
Reward stats:
 {'max': '191.92', 'mean': '9.00', 'min': '-1.03', 'std': '28.39'}
Information gain stats:
 {'max': '99.54', 'mean': '25.96', 'min': '4.86', 'std': '17.27'}
Episode time 14.82
Saved _metrics_

=== Episode 24 ===
Training on [1006/3018] data points
> Train epoch 20 [ensemble -45.25 | reward 0.00]
> Train epoch 40 [ensemble -73.23 | reward 0.00]
> Train epoch 60 [ensemble -85.53 | reward 0.00]
> Train epoch 80 [ensemble -92.36 | reward 0.00]
> Train epoch 100 [ensemble -96.82 | reward 0.00]
Ensemble loss -96.82 / Reward Loss 0.00

=== Collecting data [24] ===
> Step 25 [reward 0.00]
Rewards 1.00 / Steps 35.00
Reward stats:
 {'max': '333.00', 'mean': '32.26', 'min': '0.46', 'std': '64.56'}
Information gain stats:
 {'max': '125.87', 'mean': '33.71', 'min': '7.18', 'std': '26.37'}
Episode time 12.38
Saved _metrics_

=== Episode 25 ===
Training on [1041/3123] data points
> Train epoch 20 [ensemble -45.14 | reward 0.00]
> Train epoch 40 [ensemble -73.11 | reward 0.00]
> Train epoch 60 [ensemble -85.44 | reward 0.00]
> Train epoch 80 [ensemble -92.27 | reward 0.00]
> Train epoch 100 [ensemble -96.73 | reward 0.00]
Ensemble loss -96.73 / Reward Loss 0.00

=== Collecting data [25] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
Rewards 1.00 / Steps 86.00
Reward stats:
 {'max': '220.99', 'mean': '9.21', 'min': '1.41', 'std': '27.59'}
Information gain stats:
 {'max': '106.40', 'mean': '22.70', 'min': '4.91', 'std': '16.10'}
Episode time 21.36
Saved _metrics_

=== Episode 26 ===
Training on [1127/3381] data points
> Train epoch 20 [ensemble -49.84 | reward 0.00]
> Train epoch 40 [ensemble -76.93 | reward 0.00]
> Train epoch 60 [ensemble -88.24 | reward 0.00]
> Train epoch 80 [ensemble -94.54 | reward 0.00]
> Train epoch 100 [ensemble -98.62 | reward 0.00]
Ensemble loss -98.62 / Reward Loss 0.00

=== Collecting data [26] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
Rewards 1.00 / Steps 80.00
Reward stats:
 {'max': '170.82', 'mean': '0.53', 'min': '-4.66', 'std': '18.87'}
Information gain stats:
 {'max': '87.36', 'mean': '23.25', 'min': '5.89', 'std': '14.01'}
Episode time 20.98
Saved _metrics_

=== Episode 27 ===
Training on [1207/3621] data points
> Train epoch 20 [ensemble -53.97 | reward 0.00]
> Train epoch 40 [ensemble -79.98 | reward 0.00]
> Train epoch 60 [ensemble -90.51 | reward 0.00]
> Train epoch 80 [ensemble -96.33 | reward 0.00]
> Train epoch 100 [ensemble -100.12 | reward 0.00]
Ensemble loss -100.12 / Reward Loss 0.00

=== Collecting data [27] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
Rewards 1.00 / Steps 57.00
Reward stats:
 {'max': '158.88', 'mean': '9.86', 'min': '3.16', 'std': '20.27'}
Information gain stats:
 {'max': '107.98', 'mean': '24.71', 'min': '5.03', 'std': '17.82'}
Episode time 17.31
Saved _metrics_

=== Episode 28 ===
Training on [1264/3792] data points
> Train epoch 20 [ensemble -55.03 | reward 0.00]
> Train epoch 40 [ensemble -80.75 | reward 0.00]
> Train epoch 60 [ensemble -91.04 | reward 0.00]
> Train epoch 80 [ensemble -96.71 | reward 0.00]
> Train epoch 100 [ensemble -100.42 | reward 0.00]
Ensemble loss -100.42 / Reward Loss 0.00

=== Collecting data [28] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
Rewards 1.00 / Steps 79.00
Reward stats:
 {'max': '1142.09', 'mean': '48.72', 'min': '-0.33', 'std': '158.00'}
Information gain stats:
 {'max': '156.14', 'mean': '28.97', 'min': '5.97', 'std': '27.40'}
Episode time 21.58
Saved _metrics_

=== Episode 29 ===
Training on [1343/4029] data points
> Train epoch 20 [ensemble -57.52 | reward 0.00]
> Train epoch 40 [ensemble -82.39 | reward 0.00]
> Train epoch 60 [ensemble -92.28 | reward 0.00]
> Train epoch 80 [ensemble -97.72 | reward 0.00]
> Train epoch 100 [ensemble -101.25 | reward 0.00]
Ensemble loss -101.25 / Reward Loss 0.00

=== Collecting data [29] ===
Rewards 1.00 / Steps 24.00
Reward stats:
 {'max': '632.96', 'mean': '75.37', 'min': '-2.43', 'std': '127.43'}
Information gain stats:
 {'max': '147.06', 'mean': '44.76', 'min': '7.51', 'std': '34.97'}
Episode time 12.27
Saved _metrics_

=== Episode 30 ===
Training on [1367/4101] data points
> Train epoch 20 [ensemble -59.32 | reward 0.00]
> Train epoch 40 [ensemble -83.52 | reward 0.00]
> Train epoch 60 [ensemble -93.11 | reward 0.00]
> Train epoch 80 [ensemble -98.45 | reward 0.00]
> Train epoch 100 [ensemble -101.91 | reward 0.00]
Ensemble loss -101.91 / Reward Loss 0.00

=== Collecting data [30] ===
> Step 25 [reward 0.00]
Rewards 1.00 / Steps 46.00
Reward stats:
 {'max': '1122.60', 'mean': '59.07', 'min': '-3.06', 'std': '160.09'}
Information gain stats:
 {'max': '170.07', 'mean': '39.52', 'min': '6.50', 'std': '36.67'}
Episode time 16.30
Saved _metrics_

=== Episode 31 ===
Training on [1413/4239] data points
> Train epoch 20 [ensemble -61.95 | reward 0.00]
> Train epoch 40 [ensemble -85.13 | reward 0.00]
> Train epoch 60 [ensemble -94.24 | reward 0.00]
> Train epoch 80 [ensemble -99.34 | reward 0.00]
> Train epoch 100 [ensemble -102.69 | reward 0.00]
Ensemble loss -102.69 / Reward Loss 0.00

=== Collecting data [31] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
Rewards 1.00 / Steps 58.00
Reward stats:
 {'max': '2049.77', 'mean': '89.08', 'min': '-4.10', 'std': '283.07'}
Information gain stats:
 {'max': '200.30', 'mean': '37.40', 'min': '4.04', 'std': '40.66'}
Episode time 18.79
Saved _metrics_

=== Episode 32 ===
Training on [1471/4413] data points
> Train epoch 20 [ensemble -62.17 | reward 0.00]
> Train epoch 40 [ensemble -84.97 | reward 0.00]
> Train epoch 60 [ensemble -94.05 | reward 0.00]
> Train epoch 80 [ensemble -99.14 | reward 0.00]
> Train epoch 100 [ensemble -102.52 | reward 0.00]
Ensemble loss -102.52 / Reward Loss 0.00

=== Collecting data [32] ===
> Step 25 [reward 0.00]
Rewards 1.00 / Steps 36.00
Reward stats:
 {'max': '2196.60', 'mean': '141.52', 'min': '-2.76', 'std': '356.93'}
Information gain stats:
 {'max': '193.56', 'mean': '49.25', 'min': '7.59', 'std': '45.32'}
Episode time 15.18
Saved _metrics_

=== Episode 33 ===
Training on [1507/4521] data points
> Train epoch 20 [ensemble -62.87 | reward 0.00]
> Train epoch 40 [ensemble -85.48 | reward 0.00]
> Train epoch 60 [ensemble -94.43 | reward 0.00]
> Train epoch 80 [ensemble -99.49 | reward 0.00]
> Train epoch 100 [ensemble -102.83 | reward 0.00]
Ensemble loss -102.83 / Reward Loss 0.00

=== Collecting data [33] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
Rewards 1.00 / Steps 65.00
Reward stats:
 {'max': '580.27', 'mean': '28.42', 'min': '-0.11', 'std': '80.11'}
Information gain stats:
 {'max': '162.54', 'mean': '33.67', 'min': '5.87', 'std': '30.34'}
Episode time 20.64
Saved _metrics_

=== Episode 34 ===
Training on [1572/4716] data points
> Train epoch 20 [ensemble -65.23 | reward 0.00]
> Train epoch 40 [ensemble -86.80 | reward 0.00]
> Train epoch 60 [ensemble -95.34 | reward 0.00]
> Train epoch 80 [ensemble -100.22 | reward 0.00]
> Train epoch 100 [ensemble -103.43 | reward 0.00]
Ensemble loss -103.43 / Reward Loss 0.00

=== Collecting data [34] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
Rewards 0.00 / Steps 167.00
Reward stats:
 {'max': '7.74', 'mean': '3.94', 'min': '3.68', 'std': '0.08'}
Information gain stats:
 {'max': '28.45', 'mean': '16.23', 'min': '4.55', 'std': '2.60'}
Episode time 39.34
Saved _metrics_

=== Episode 35 ===
Training on [1739/5217] data points
> Train epoch 20 [ensemble -70.30 | reward 0.00]
> Train epoch 40 [ensemble -89.89 | reward 0.00]
> Train epoch 60 [ensemble -97.69 | reward 0.00]
> Train epoch 80 [ensemble -102.15 | reward 0.00]
> Train epoch 100 [ensemble -105.07 | reward 0.00]
Ensemble loss -105.07 / Reward Loss 0.00

=== Collecting data [35] ===
> Step 25 [reward 0.00]
Rewards 1.00 / Steps 43.00
Reward stats:
 {'max': '2897.20', 'mean': '74.86', 'min': '2.85', 'std': '230.39'}
Information gain stats:
 {'max': '193.48', 'mean': '41.11', 'min': '5.01', 'std': '37.17'}
Episode time 17.89
Saved _metrics_

=== Episode 36 ===
Training on [1782/5346] data points
> Train epoch 20 [ensemble -71.45 | reward 0.00]
> Train epoch 40 [ensemble -90.51 | reward 0.00]
> Train epoch 60 [ensemble -98.08 | reward 0.00]
> Train epoch 80 [ensemble -102.40 | reward 0.00]
> Train epoch 100 [ensemble -105.08 | reward 0.00]
Ensemble loss -105.08 / Reward Loss 0.00

=== Collecting data [36] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
Rewards 1.00 / Steps 56.00
Reward stats:
 {'max': '31.09', 'mean': '7.99', 'min': '-8.04', 'std': '5.85'}
Information gain stats:
 {'max': '112.17', 'mean': '25.21', 'min': '4.96', 'std': '17.57'}
Episode time 20.77
Saved _metrics_

=== Episode 37 ===
Training on [1838/5514] data points
> Train epoch 20 [ensemble -72.20 | reward 0.00]
> Train epoch 40 [ensemble -90.91 | reward 0.00]
> Train epoch 60 [ensemble -98.43 | reward 0.00]
> Train epoch 80 [ensemble -102.74 | reward 0.00]
> Train epoch 100 [ensemble -105.60 | reward 0.00]
Ensemble loss -105.60 / Reward Loss 0.00

=== Collecting data [37] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
Rewards 0.00 / Steps 167.00
Reward stats:
 {'max': '5.25', 'mean': '-0.36', 'min': '-1.03', 'std': '0.09'}
Information gain stats:
 {'max': '29.32', 'mean': '16.37', 'min': '5.22', 'std': '2.59'}
Episode time 40.49
Saved _metrics_

=== Episode 38 ===
Training on [2005/6015] data points
> Train epoch 20 [ensemble -77.02 | reward 0.00]
> Train epoch 40 [ensemble -93.82 | reward 0.00]
> Train epoch 60 [ensemble -100.56 | reward 0.00]
> Train epoch 80 [ensemble -104.44 | reward 0.00]
> Train epoch 100 [ensemble -106.87 | reward 0.00]
Ensemble loss -106.87 / Reward Loss 0.00

=== Collecting data [38] ===
> Step 25 [reward 0.00]
Rewards 1.00 / Steps 28.00
Reward stats:
 {'max': '597.88', 'mean': '37.76', 'min': '0.87', 'std': '72.84'}
Information gain stats:
 {'max': '154.00', 'mean': '43.31', 'min': '7.28', 'std': '28.45'}
Episode time 17.30
Saved _metrics_

=== Episode 39 ===
Training on [2033/6099] data points
> Train epoch 20 [ensemble -76.40 | reward 0.00]
> Train epoch 40 [ensemble -93.43 | reward 0.00]
> Train epoch 60 [ensemble -100.17 | reward 0.00]
> Train epoch 80 [ensemble -104.12 | reward 0.00]
> Train epoch 100 [ensemble -106.72 | reward 0.00]
Ensemble loss -106.72 / Reward Loss 0.00

=== Collecting data [39] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
Rewards 1.00 / Steps 65.00
Reward stats:
 {'max': '1623.96', 'mean': '41.67', 'min': '-2.24', 'std': '151.49'}
Information gain stats:
 {'max': '162.48', 'mean': '30.41', 'min': '4.62', 'std': '25.44'}
Episode time 23.96
Saved _metrics_

=== Episode 40 ===
Training on [2098/6294] data points
> Train epoch 20 [ensemble -77.41 | reward 0.00]
> Train epoch 40 [ensemble -93.97 | reward 0.00]
> Train epoch 60 [ensemble -100.66 | reward 0.00]
> Train epoch 80 [ensemble -104.51 | reward 0.00]
> Train epoch 100 [ensemble -106.90 | reward 0.00]
Ensemble loss -106.90 / Reward Loss 0.00

=== Collecting data [40] ===
> Step 25 [reward 0.00]
Rewards 1.00 / Steps 45.00
Reward stats:
 {'max': '7501.01', 'mean': '120.93', 'min': '-1.07', 'std': '436.72'}
Information gain stats:
 {'max': '187.13', 'mean': '37.70', 'min': '4.93', 'std': '30.54'}
Episode time 20.46
Saved _metrics_

=== Episode 41 ===
Training on [2143/6429] data points
> Train epoch 20 [ensemble -78.62 | reward 0.00]
> Train epoch 40 [ensemble -94.73 | reward 0.00]
> Train epoch 60 [ensemble -101.30 | reward 0.00]
> Train epoch 80 [ensemble -105.02 | reward 0.00]
> Train epoch 100 [ensemble -107.47 | reward 0.00]
Ensemble loss -107.47 / Reward Loss 0.00

=== Collecting data [41] ===
> Step 25 [reward 0.00]
Rewards 1.00 / Steps 47.00
Reward stats:
 {'max': '31.63', 'mean': '5.68', 'min': '2.07', 'std': '5.22'}
Information gain stats:
 {'max': '83.28', 'mean': '27.05', 'min': '4.83', 'std': '17.20'}
Episode time 20.88
Saved _metrics_

=== Episode 42 ===
Training on [2190/6570] data points
> Train epoch 20 [ensemble -79.06 | reward 0.00]
> Train epoch 40 [ensemble -94.86 | reward 0.00]
> Train epoch 60 [ensemble -101.39 | reward 0.00]
> Train epoch 80 [ensemble -105.08 | reward 0.00]
> Train epoch 100 [ensemble -107.52 | reward 0.00]
Ensemble loss -107.52 / Reward Loss 0.00

=== Collecting data [42] ===
> Step 25 [reward 0.00]
Rewards 1.00 / Steps 26.00
Reward stats:
 {'max': '29.91', 'mean': '8.87', 'min': '-21.35', 'std': '8.41'}
Information gain stats:
 {'max': '92.18', 'mean': '34.02', 'min': '7.37', 'std': '19.36'}
Episode time 17.87
Saved _metrics_

=== Episode 43 ===
Training on [2216/6648] data points
> Train epoch 20 [ensemble -78.80 | reward 0.00]
> Train epoch 40 [ensemble -94.77 | reward 0.00]
> Train epoch 60 [ensemble -101.31 | reward 0.00]
> Train epoch 80 [ensemble -105.02 | reward 0.00]
> Train epoch 100 [ensemble -107.46 | reward 0.00]
Ensemble loss -107.46 / Reward Loss 0.00

=== Collecting data [43] ===
> Step 25 [reward 0.00]
Rewards 1.00 / Steps 37.00
Reward stats:
 {'max': '32.09', 'mean': '8.53', 'min': '-181.95', 'std': '12.16'}
Information gain stats:
 {'max': '128.19', 'mean': '39.65', 'min': '6.15', 'std': '24.56'}
Episode time 20.64
Saved _metrics_

=== Episode 44 ===
Training on [2253/6759] data points
> Train epoch 20 [ensemble -80.31 | reward 0.00]
> Train epoch 40 [ensemble -95.64 | reward 0.00]
> Train epoch 60 [ensemble -101.95 | reward 0.00]
> Train epoch 80 [ensemble -105.56 | reward 0.00]
> Train epoch 100 [ensemble -107.82 | reward 0.00]
Ensemble loss -107.82 / Reward Loss 0.00

=== Collecting data [44] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
Rewards 1.00 / Steps 64.00
Reward stats:
 {'max': '2017.22', 'mean': '49.72', 'min': '-1.45', 'std': '176.44'}
Information gain stats:
 {'max': '222.84', 'mean': '37.39', 'min': '5.02', 'std': '37.12'}
Episode time 25.32
Saved _metrics_

=== Episode 45 ===
Training on [2317/6951] data points
> Train epoch 20 [ensemble -80.11 | reward 0.00]
> Train epoch 40 [ensemble -96.00 | reward 0.00]
> Train epoch 60 [ensemble -102.43 | reward 0.00]
> Train epoch 80 [ensemble -105.99 | reward 0.00]
> Train epoch 100 [ensemble -108.32 | reward 0.00]
Ensemble loss -108.32 / Reward Loss 0.00

=== Collecting data [45] ===
> Step 25 [reward 0.00]
Rewards 1.00 / Steps 28.00
Reward stats:
 {'max': '35.67', 'mean': '6.83', 'min': '-0.13', 'std': '8.33'}
Information gain stats:
 {'max': '86.54', 'mean': '30.55', 'min': '4.75', 'std': '18.58'}
Episode time 19.16
Saved _metrics_

=== Episode 46 ===
Training on [2345/7035] data points
> Train epoch 20 [ensemble -79.51 | reward 0.00]
> Train epoch 40 [ensemble -95.43 | reward 0.00]
> Train epoch 60 [ensemble -101.92 | reward 0.00]
> Train epoch 80 [ensemble -105.54 | reward 0.00]
> Train epoch 100 [ensemble -107.84 | reward 0.00]
Ensemble loss -107.84 / Reward Loss 0.00

=== Collecting data [46] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
Rewards 1.00 / Steps 79.00
Reward stats:
 {'max': '1243.51', 'mean': '10.49', 'min': '-2.69', 'std': '50.08'}
Information gain stats:
 {'max': '142.84', 'mean': '22.82', 'min': '4.43', 'std': '19.28'}
Episode time 28.04
Saved _metrics_

=== Episode 47 ===
Training on [2424/7272] data points
> Train epoch 20 [ensemble -80.99 | reward 0.00]
> Train epoch 40 [ensemble -96.49 | reward 0.00]
> Train epoch 60 [ensemble -102.70 | reward 0.00]
> Train epoch 80 [ensemble -106.16 | reward 0.00]
> Train epoch 100 [ensemble -108.46 | reward 0.00]
Ensemble loss -108.46 / Reward Loss 0.00

=== Collecting data [47] ===
> Step 25 [reward 0.00]
Rewards 1.00 / Steps 33.00
Reward stats:
 {'max': '33.94', 'mean': '3.98', 'min': '-2.85', 'std': '7.63'}
Information gain stats:
 {'max': '86.75', 'mean': '29.47', 'min': '5.57', 'std': '16.52'}
Episode time 20.39
Saved _metrics_

=== Episode 48 ===
Training on [2457/7371] data points
> Train epoch 20 [ensemble -80.99 | reward 0.00]
> Train epoch 40 [ensemble -96.44 | reward 0.00]
> Train epoch 60 [ensemble -102.68 | reward 0.00]
> Train epoch 80 [ensemble -106.16 | reward 0.00]
> Train epoch 100 [ensemble -108.35 | reward 0.00]
Ensemble loss -108.35 / Reward Loss 0.00

=== Collecting data [48] ===
> Step 25 [reward 0.00]
Rewards 1.00 / Steps 37.00
Reward stats:
 {'max': '30.30', 'mean': '4.13', 'min': '-166.69', 'std': '14.83'}
Information gain stats:
 {'max': '154.44', 'mean': '40.28', 'min': '6.43', 'std': '31.67'}
Episode time 21.31
Saved _metrics_

=== Episode 49 ===
Training on [2494/7482] data points
> Train epoch 20 [ensemble -81.18 | reward 0.00]
> Train epoch 40 [ensemble -96.55 | reward 0.00]
> Train epoch 60 [ensemble -102.78 | reward 0.00]
> Train epoch 80 [ensemble -106.28 | reward 0.00]
> Train epoch 100 [ensemble -108.48 | reward 0.00]
Ensemble loss -108.48 / Reward Loss 0.00

=== Collecting data [49] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
Rewards 1.00 / Steps 52.00
Reward stats:
 {'max': '1551.36', 'mean': '63.86', 'min': '0.52', 'std': '191.05'}
Information gain stats:
 {'max': '208.34', 'mean': '39.53', 'min': '5.32', 'std': '41.84'}
Episode time 24.05
Saved _metrics_