02:20:58

=== Loading experiment [device: cuda] ===

{'action_noise': None,
 'action_repeat': 4,
 'batch_size': 50,
 'coverage': False,
 'ensemble_size': 10,
 'env_name': 'DeepMindCatch',
 'epsilon': 1e-08,
 'expl_scale': 0.1,
 'expl_strategy': 'information',
 'grad_clip_norm': 1000,
 'hidden_size': 200,
 'learning_rate': 0.001,
 'logdir': 'cup_catch_DQN-like',
 'max_episode_len': 1000,
 'n_candidates': 500,
 'n_episodes': 50,
 'n_seed_episodes': 5,
 'n_train_epochs': 100,
 'optimisation_iters': 5,
 'plan_horizon': 12,
 'record_every': None,
 'reward_scale': 1.0,
 'seed': 6,
 'strategy': 'information',
 'top_candidates': 50,
 'use_exploration': True,
 'use_mean': False,
 'use_reward': True}

Collected seeds: [5 episodes | 1250 frames]

=== Episode 1 ===
Training on [1250/5000] data points
> Train epoch 20 [ensemble -20.90 | reward 0.07]
> Train epoch 40 [ensemble -28.64 | reward 0.05]
> Train epoch 60 [ensemble -32.42 | reward 0.04]
> Train epoch 80 [ensemble -34.80 | reward 0.03]
> Train epoch 100 [ensemble -36.47 | reward 0.02]
Ensemble loss -36.47 / Reward Loss 0.02

=== Collecting data [1] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '71.92', 'mean': '8.53', 'min': '-13.74', 'std': '10.32'}
Information gain stats:
 {'max': '2.34', 'mean': '1.05', 'min': '0.42', 'std': '0.19'}
Episode time 23.71
Saved _metrics_

=== Episode 2 ===
Training on [1500/6000] data points
> Train epoch 20 [ensemble -18.92 | reward 0.06]
> Train epoch 40 [ensemble -26.79 | reward 0.05]
> Train epoch 60 [ensemble -30.79 | reward 0.03]
> Train epoch 80 [ensemble -33.30 | reward 0.03]
> Train epoch 100 [ensemble -35.08 | reward 0.02]
Ensemble loss -35.08 / Reward Loss 0.02

=== Collecting data [2] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 3.00]
> Step 125 [reward 86.00]
> Step 150 [reward 181.00]
> Step 175 [reward 278.00]
> Step 200 [reward 368.00]
> Step 225 [reward 468.00]
> Step 250 [reward 566.00]
Rewards 566.00 / Steps 250.00
Reward stats:
 {'max': '57.14', 'mean': '4.91', 'min': '-32.04', 'std': '7.40'}
Information gain stats:
 {'max': '1.74', 'mean': '1.13', 'min': '0.56', 'std': '0.15'}
Episode time 25.26
Saved _metrics_

=== Episode 3 ===
Training on [1750/7000] data points
> Train epoch 20 [ensemble -19.43 | reward 0.34]
> Train epoch 40 [ensemble -26.40 | reward 0.35]
> Train epoch 60 [ensemble -29.98 | reward 0.34]
> Train epoch 80 [ensemble -32.33 | reward 0.31]
> Train epoch 100 [ensemble -34.06 | reward 0.27]
Ensemble loss -34.06 / Reward Loss 0.27

=== Collecting data [3] ===
> Step 25 [reward 60.00]
> Step 50 [reward 92.00]
> Step 75 [reward 125.00]
> Step 100 [reward 220.00]
> Step 125 [reward 305.00]
> Step 150 [reward 387.00]
> Step 175 [reward 453.00]
> Step 200 [reward 453.00]
> Step 225 [reward 453.00]
> Step 250 [reward 453.00]
Rewards 453.00 / Steps 250.00
Reward stats:
 {'max': '364.63', 'mean': '105.83', 'min': '-15.81', 'std': '66.70'}
Information gain stats:
 {'max': '1.78', 'mean': '1.04', 'min': '0.48', 'std': '0.16'}
Episode time 26.59
Saved _metrics_

=== Episode 4 ===
Training on [2000/8000] data points
> Train epoch 20 [ensemble -19.59 | reward 0.62]
> Train epoch 40 [ensemble -26.46 | reward 0.71]
> Train epoch 60 [ensemble -30.03 | reward 0.76]
> Train epoch 80 [ensemble -32.39 | reward 0.76]
> Train epoch 100 [ensemble -34.11 | reward 0.73]
Ensemble loss -34.11 / Reward Loss 0.73

=== Collecting data [4] ===
> Step 25 [reward 50.00]
> Step 50 [reward 150.00]
> Step 75 [reward 249.00]
> Step 100 [reward 348.00]
> Step 125 [reward 439.00]
> Step 150 [reward 532.00]
> Step 175 [reward 630.00]
> Step 200 [reward 718.00]
> Step 225 [reward 813.00]
> Step 250 [reward 898.00]
Rewards 898.00 / Steps 250.00
Reward stats:
 {'max': '317.35', 'mean': '122.68', 'min': '-5.19', 'std': '54.80'}
Information gain stats:
 {'max': '1.57', 'mean': '0.89', 'min': '0.43', 'std': '0.15'}
Episode time 27.99
Saved _metrics_

=== Episode 5 ===
Training on [2250/9000] data points
> Train epoch 20 [ensemble -20.54 | reward 0.80]
> Train epoch 40 [ensemble -27.12 | reward 0.94]
> Train epoch 60 [ensemble -30.53 | reward 1.04]
> Train epoch 80 [ensemble -32.81 | reward 1.10]
> Train epoch 100 [ensemble -34.50 | reward 1.11]
Ensemble loss -34.50 / Reward Loss 1.11

=== Collecting data [5] ===
> Step 25 [reward 14.00]
> Step 50 [reward 114.00]
> Step 75 [reward 214.00]
> Step 100 [reward 314.00]
> Step 125 [reward 414.00]
> Step 150 [reward 514.00]
> Step 175 [reward 614.00]
> Step 200 [reward 714.00]
> Step 225 [reward 814.00]
> Step 250 [reward 914.00]
Rewards 914.00 / Steps 250.00
Reward stats:
 {'max': '399.20', 'mean': '185.45', 'min': '-16.44', 'std': '92.92'}
Information gain stats:
 {'max': '1.53', 'mean': '0.77', 'min': '0.32', 'std': '0.21'}
Episode time 29.57
Saved _metrics_

=== Episode 6 ===
Training on [2500/10000] data points
> Train epoch 20 [ensemble -22.23 | reward 0.78]
> Train epoch 40 [ensemble -28.30 | reward 0.94]
> Train epoch 60 [ensemble -31.40 | reward 1.14]
> Train epoch 80 [ensemble -33.47 | reward 1.29]
> Train epoch 100 [ensemble -35.01 | reward 1.38]
Ensemble loss -35.01 / Reward Loss 1.38

=== Collecting data [6] ===
> Step 25 [reward 81.00]
> Step 50 [reward 181.00]
> Step 75 [reward 281.00]
> Step 100 [reward 381.00]
> Step 125 [reward 481.00]
> Step 150 [reward 581.00]
> Step 175 [reward 681.00]
> Step 200 [reward 781.00]
> Step 225 [reward 881.00]
> Step 250 [reward 981.00]
Rewards 981.00 / Steps 250.00
Reward stats:
 {'max': '468.92', 'mean': '216.06', 'min': '-2.23', 'std': '109.41'}
Information gain stats:
 {'max': '1.52', 'mean': '0.74', 'min': '0.31', 'std': '0.22'}
Episode time 30.79
Saved _metrics_

=== Episode 7 ===
Training on [2750/11000] data points
> Train epoch 20 [ensemble -23.70 | reward 0.85]
> Train epoch 40 [ensemble -29.40 | reward 1.12]
> Train epoch 60 [ensemble -32.32 | reward 1.43]
> Train epoch 80 [ensemble -34.28 | reward 1.68]
> Train epoch 100 [ensemble -35.74 | reward 1.83]
Ensemble loss -35.74 / Reward Loss 1.83

=== Collecting data [7] ===
> Step 25 [reward 21.00]
> Step 50 [reward 121.00]
> Step 75 [reward 221.00]
> Step 100 [reward 321.00]
> Step 125 [reward 421.00]
> Step 150 [reward 521.00]
> Step 175 [reward 621.00]
> Step 200 [reward 721.00]
> Step 225 [reward 821.00]
> Step 250 [reward 921.00]
Rewards 921.00 / Steps 250.00
Reward stats:
 {'max': '468.05', 'mean': '208.57', 'min': '-22.07', 'std': '111.84'}
Information gain stats:
 {'max': '1.60', 'mean': '0.77', 'min': '0.27', 'std': '0.22'}
Episode time 32.25
Saved _metrics_

=== Episode 8 ===
Training on [3000/12000] data points
> Train epoch 20 [ensemble -24.73 | reward 0.92]
> Train epoch 40 [ensemble -30.17 | reward 1.39]
> Train epoch 60 [ensemble -32.96 | reward 1.90]
> Train epoch 80 [ensemble -34.84 | reward 2.29]
> Train epoch 100 [ensemble -36.24 | reward 2.52]
Ensemble loss -36.24 / Reward Loss 2.52

=== Collecting data [8] ===
> Step 25 [reward 86.00]
> Step 50 [reward 186.00]
> Step 75 [reward 286.00]
> Step 100 [reward 386.00]
> Step 125 [reward 486.00]
> Step 150 [reward 586.00]
> Step 175 [reward 686.00]
> Step 200 [reward 786.00]
> Step 225 [reward 886.00]
> Step 250 [reward 986.00]
Rewards 986.00 / Steps 250.00
Reward stats:
 {'max': '529.68', 'mean': '265.54', 'min': '-8.24', 'std': '130.92'}
Information gain stats:
 {'max': '1.55', 'mean': '0.75', 'min': '0.30', 'std': '0.23'}
Episode time 33.68
Saved _metrics_

=== Episode 9 ===
Training on [3250/13000] data points
> Train epoch 20 [ensemble -25.85 | reward 0.90]
> Train epoch 40 [ensemble -31.00 | reward 1.48]
> Train epoch 60 [ensemble -33.66 | reward 2.13]
> Train epoch 80 [ensemble -35.44 | reward 2.67]
> Train epoch 100 [ensemble -36.77 | reward 3.00]
Ensemble loss -36.77 / Reward Loss 3.00

=== Collecting data [9] ===
> Step 25 [reward 45.00]
> Step 50 [reward 145.00]
> Step 75 [reward 245.00]
> Step 100 [reward 345.00]
> Step 125 [reward 445.00]
> Step 150 [reward 545.00]
> Step 175 [reward 645.00]
> Step 200 [reward 745.00]
> Step 225 [reward 845.00]
> Step 250 [reward 945.00]
Rewards 945.00 / Steps 250.00
Reward stats:
 {'max': '549.41', 'mean': '251.51', 'min': '-13.89', 'std': '126.14'}
Information gain stats:
 {'max': '1.56', 'mean': '0.78', 'min': '0.30', 'std': '0.23'}
Episode time 35.14
Saved _metrics_

=== Episode 10 ===
Training on [3500/14000] data points
> Train epoch 20 [ensemble -26.75 | reward 0.97]
> Train epoch 40 [ensemble -31.77 | reward 1.68]
> Train epoch 60 [ensemble -34.32 | reward 2.48]
> Train epoch 80 [ensemble -36.03 | reward 3.15]
> Train epoch 100 [ensemble -37.30 | reward 3.58]
Ensemble loss -37.30 / Reward Loss 3.58

=== Collecting data [10] ===
> Step 25 [reward 43.00]
> Step 50 [reward 143.00]
> Step 75 [reward 243.00]
> Step 100 [reward 343.00]
> Step 125 [reward 443.00]
> Step 150 [reward 543.00]
> Step 175 [reward 643.00]
> Step 200 [reward 743.00]
> Step 225 [reward 843.00]
> Step 250 [reward 943.00]
Rewards 943.00 / Steps 250.00
Reward stats:
 {'max': '605.05', 'mean': '288.25', 'min': '-31.91', 'std': '144.64'}
Information gain stats:
 {'max': '1.56', 'mean': '0.77', 'min': '0.28', 'std': '0.24'}
Episode time 36.49
Saved _metrics_

=== Episode 11 ===
Training on [3750/15000] data points
> Train epoch 20 [ensemble -27.52 | reward 0.94]
> Train epoch 40 [ensemble -32.32 | reward 1.82]
> Train epoch 60 [ensemble -34.79 | reward 2.84]
> Train epoch 80 [ensemble -36.45 | reward 3.70]
> Train epoch 100 [ensemble -37.69 | reward 4.26]
Ensemble loss -37.69 / Reward Loss 4.26

=== Collecting data [11] ===
> Step 25 [reward 21.00]
> Step 50 [reward 121.00]
> Step 75 [reward 221.00]
> Step 100 [reward 321.00]
> Step 125 [reward 421.00]
> Step 150 [reward 521.00]
> Step 175 [reward 621.00]
> Step 200 [reward 721.00]
> Step 225 [reward 821.00]
> Step 250 [reward 921.00]
Rewards 921.00 / Steps 250.00
Reward stats:
 {'max': '647.03', 'mean': '315.65', 'min': '-39.85', 'std': '162.62'}
Information gain stats:
 {'max': '1.60', 'mean': '0.79', 'min': '0.31', 'std': '0.24'}
Episode time 38.01
Saved _metrics_

=== Episode 12 ===
Training on [4000/16000] data points
> Train epoch 20 [ensemble -28.22 | reward 1.08]
> Train epoch 40 [ensemble -32.87 | reward 2.17]
> Train epoch 60 [ensemble -35.25 | reward 3.41]
> Train epoch 80 [ensemble -36.86 | reward 4.44]
> Train epoch 100 [ensemble -38.05 | reward 5.11]
Ensemble loss -38.05 / Reward Loss 5.11

=== Collecting data [12] ===
> Step 25 [reward 88.00]
> Step 50 [reward 188.00]
> Step 75 [reward 288.00]
> Step 100 [reward 388.00]
> Step 125 [reward 488.00]
> Step 150 [reward 588.00]
> Step 175 [reward 688.00]
> Step 200 [reward 788.00]
> Step 225 [reward 888.00]
> Step 250 [reward 988.00]
Rewards 988.00 / Steps 250.00
Reward stats:
 {'max': '678.05', 'mean': '322.56', 'min': '-9.84', 'std': '157.28'}
Information gain stats:
 {'max': '1.62', 'mean': '0.80', 'min': '0.31', 'std': '0.24'}
Episode time 39.38
Saved _metrics_

=== Episode 13 ===
Training on [4250/17000] data points
> Train epoch 20 [ensemble -28.65 | reward 1.14]
> Train epoch 40 [ensemble -33.24 | reward 2.37]
> Train epoch 60 [ensemble -35.57 | reward 3.78]
> Train epoch 80 [ensemble -37.13 | reward 4.99]
> Train epoch 100 [ensemble -38.29 | reward 5.79]
Ensemble loss -38.29 / Reward Loss 5.79

=== Collecting data [13] ===
> Step 25 [reward 86.00]
> Step 50 [reward 186.00]
> Step 75 [reward 286.00]
> Step 100 [reward 386.00]
> Step 125 [reward 486.00]
> Step 150 [reward 586.00]
> Step 175 [reward 686.00]
> Step 200 [reward 786.00]
> Step 225 [reward 886.00]
> Step 250 [reward 986.00]
Rewards 986.00 / Steps 250.00
Reward stats:
 {'max': '719.84', 'mean': '356.76', 'min': '-2.13', 'std': '170.89'}
Information gain stats:
 {'max': '1.60', 'mean': '0.80', 'min': '0.31', 'std': '0.24'}
Episode time 40.78
Saved _metrics_

=== Episode 14 ===
Training on [4500/18000] data points
> Train epoch 20 [ensemble -29.51 | reward 1.27]
> Train epoch 40 [ensemble -33.90 | reward 2.72]
> Train epoch 60 [ensemble -36.16 | reward 4.39]
> Train epoch 80 [ensemble -37.66 | reward 5.79]
> Train epoch 100 [ensemble -38.78 | reward 6.71]
Ensemble loss -38.78 / Reward Loss 6.71

=== Collecting data [14] ===
> Step 25 [reward 53.00]
> Step 50 [reward 153.00]
> Step 75 [reward 253.00]
> Step 100 [reward 353.00]
> Step 125 [reward 453.00]
> Step 150 [reward 553.00]
> Step 175 [reward 653.00]
> Step 200 [reward 753.00]
> Step 225 [reward 853.00]
> Step 250 [reward 953.00]
Rewards 953.00 / Steps 250.00
Reward stats:
 {'max': '756.33', 'mean': '400.43', 'min': '-22.04', 'std': '182.70'}
Information gain stats:
 {'max': '1.58', 'mean': '0.79', 'min': '0.31', 'std': '0.24'}
Episode time 42.21
Saved _metrics_

=== Episode 15 ===
Training on [4750/19000] data points
> Train epoch 20 [ensemble -30.03 | reward 1.42]
> Train epoch 40 [ensemble -34.32 | reward 3.17]
> Train epoch 60 [ensemble -36.52 | reward 5.13]
> Train epoch 80 [ensemble -37.99 | reward 6.76]
> Train epoch 100 [ensemble -39.08 | reward 7.81]
Ensemble loss -39.08 / Reward Loss 7.81

=== Collecting data [15] ===
> Step 25 [reward 54.00]
> Step 50 [reward 154.00]
> Step 75 [reward 254.00]
> Step 100 [reward 354.00]
> Step 125 [reward 454.00]
> Step 150 [reward 554.00]
> Step 175 [reward 654.00]
> Step 200 [reward 754.00]
> Step 225 [reward 854.00]
> Step 250 [reward 954.00]
Rewards 954.00 / Steps 250.00
Reward stats:
 {'max': '772.34', 'mean': '399.06', 'min': '-54.79', 'std': '184.80'}
Information gain stats:
 {'max': '1.64', 'mean': '0.83', 'min': '0.30', 'std': '0.25'}
Episode time 43.78
Saved _metrics_

=== Episode 16 ===
Training on [5000/20000] data points
> Train epoch 20 [ensemble -30.47 | reward 1.46]
> Train epoch 40 [ensemble -34.66 | reward 3.34]
> Train epoch 60 [ensemble -36.82 | reward 5.50]
> Train epoch 80 [ensemble -38.25 | reward 7.30]
> Train epoch 100 [ensemble -39.32 | reward 8.47]
Ensemble loss -39.32 / Reward Loss 8.47

=== Collecting data [16] ===
> Step 25 [reward 0.00]
> Step 50 [reward 90.00]
> Step 75 [reward 190.00]
> Step 100 [reward 290.00]
> Step 125 [reward 390.00]
> Step 150 [reward 490.00]
> Step 175 [reward 590.00]
> Step 200 [reward 690.00]
> Step 225 [reward 790.00]
> Step 250 [reward 890.00]
Rewards 890.00 / Steps 250.00
Reward stats:
 {'max': '817.34', 'mean': '396.88', 'min': '-82.71', 'std': '193.94'}
Information gain stats:
 {'max': '1.64', 'mean': '0.85', 'min': '0.32', 'std': '0.25'}
Episode time 45.15
Saved _metrics_

=== Episode 17 ===
Training on [5250/21000] data points
> Train epoch 20 [ensemble -30.98 | reward 1.58]
> Train epoch 40 [ensemble -35.05 | reward 3.73]
> Train epoch 60 [ensemble -37.15 | reward 6.22]
> Train epoch 80 [ensemble -38.55 | reward 8.26]
> Train epoch 100 [ensemble -39.59 | reward 9.57]
Ensemble loss -39.59 / Reward Loss 9.57

=== Collecting data [17] ===
> Step 25 [reward 47.00]
> Step 50 [reward 147.00]
> Step 75 [reward 247.00]
> Step 100 [reward 347.00]
> Step 125 [reward 447.00]
> Step 150 [reward 547.00]
> Step 175 [reward 647.00]
> Step 200 [reward 747.00]
> Step 225 [reward 847.00]
> Step 250 [reward 947.00]
Rewards 947.00 / Steps 250.00
Reward stats:
 {'max': '852.83', 'mean': '423.75', 'min': '-122.67', 'std': '198.94'}
Information gain stats:
 {'max': '1.65', 'mean': '0.84', 'min': '0.32', 'std': '0.25'}
Episode time 46.64
Saved _metrics_

=== Episode 18 ===
Training on [5500/22000] data points
> Train epoch 20 [ensemble -31.23 | reward 1.64]
> Train epoch 40 [ensemble -35.25 | reward 4.03]
> Train epoch 60 [ensemble -37.33 | reward 6.78]
> Train epoch 80 [ensemble -38.72 | reward 9.04]
> Train epoch 100 [ensemble -39.73 | reward 10.50]
Ensemble loss -39.73 / Reward Loss 10.50

=== Collecting data [18] ===
> Step 25 [reward 89.00]
> Step 50 [reward 189.00]
> Step 75 [reward 289.00]
> Step 100 [reward 389.00]
> Step 125 [reward 489.00]
> Step 150 [reward 589.00]
> Step 175 [reward 689.00]
> Step 200 [reward 789.00]
> Step 225 [reward 889.00]
> Step 250 [reward 989.00]
Rewards 989.00 / Steps 250.00
Reward stats:
 {'max': '882.01', 'mean': '455.57', 'min': '-33.39', 'std': '195.77'}
Information gain stats:
 {'max': '1.63', 'mean': '0.84', 'min': '0.32', 'std': '0.24'}
Episode time 47.82
Saved _metrics_

=== Episode 19 ===
Training on [5750/23000] data points
> Train epoch 20 [ensemble -31.68 | reward 1.64]
> Train epoch 40 [ensemble -35.64 | reward 4.21]
> Train epoch 60 [ensemble -37.69 | reward 7.26]
> Train epoch 80 [ensemble -39.05 | reward 9.83]
> Train epoch 100 [ensemble -40.04 | reward 11.56]
Ensemble loss -40.04 / Reward Loss 11.56

=== Collecting data [19] ===
> Step 25 [reward 79.00]
> Step 50 [reward 179.00]
> Step 75 [reward 279.00]
> Step 100 [reward 379.00]
> Step 125 [reward 479.00]
> Step 150 [reward 579.00]
> Step 175 [reward 679.00]
> Step 200 [reward 779.00]
> Step 225 [reward 879.00]
> Step 250 [reward 979.00]
Rewards 979.00 / Steps 250.00
Reward stats:
 {'max': '916.32', 'mean': '482.79', 'min': '-65.58', 'std': '204.87'}
Information gain stats:
 {'max': '1.64', 'mean': '0.86', 'min': '0.35', 'std': '0.24'}
Episode time 49.46
Saved _metrics_

=== Episode 20 ===
Training on [6000/24000] data points
> Train epoch 20 [ensemble -32.30 | reward 1.91]
> Train epoch 40 [ensemble -36.09 | reward 4.80]
> Train epoch 60 [ensemble -38.05 | reward 8.18]
> Train epoch 80 [ensemble -39.36 | reward 11.02]
> Train epoch 100 [ensemble -40.31 | reward 12.90]
Ensemble loss -40.31 / Reward Loss 12.90

=== Collecting data [20] ===
> Step 25 [reward 52.00]
> Step 50 [reward 152.00]
> Step 75 [reward 252.00]
> Step 100 [reward 352.00]
> Step 125 [reward 452.00]
> Step 150 [reward 552.00]
> Step 175 [reward 652.00]
> Step 200 [reward 752.00]
> Step 225 [reward 852.00]
> Step 250 [reward 952.00]
Rewards 952.00 / Steps 250.00
Reward stats:
 {'max': '955.12', 'mean': '530.54', 'min': '-56.16', 'std': '212.61'}
Information gain stats:
 {'max': '1.69', 'mean': '0.86', 'min': '0.32', 'std': '0.25'}
Episode time 50.75
Saved _metrics_

=== Episode 21 ===
Training on [6250/25000] data points
> Train epoch 20 [ensemble -32.69 | reward 1.95]
> Train epoch 40 [ensemble -36.41 | reward 5.13]
> Train epoch 60 [ensemble -38.33 | reward 8.77]
> Train epoch 80 [ensemble -39.59 | reward 11.82]
> Train epoch 100 [ensemble -40.52 | reward 13.87]
Ensemble loss -40.52 / Reward Loss 13.87

=== Collecting data [21] ===
> Step 25 [reward 88.00]
> Step 50 [reward 188.00]
> Step 75 [reward 288.00]
> Step 100 [reward 388.00]
> Step 125 [reward 488.00]
> Step 150 [reward 588.00]
> Step 175 [reward 688.00]
> Step 200 [reward 788.00]
> Step 225 [reward 888.00]
> Step 250 [reward 988.00]
Rewards 988.00 / Steps 250.00
Reward stats:
 {'max': '987.10', 'mean': '539.44', 'min': '-50.64', 'std': '208.54'}
Information gain stats:
 {'max': '1.69', 'mean': '0.86', 'min': '0.33', 'std': '0.24'}
Episode time 52.29
Saved _metrics_

=== Episode 22 ===
Training on [6500/26000] data points
> Train epoch 20 [ensemble -33.12 | reward 2.03]
> Train epoch 40 [ensemble -36.75 | reward 5.46]
> Train epoch 60 [ensemble -38.63 | reward 9.49]
> Train epoch 80 [ensemble -39.86 | reward 12.82]
> Train epoch 100 [ensemble -40.76 | reward 15.01]
Ensemble loss -40.76 / Reward Loss 15.01

=== Collecting data [22] ===
> Step 25 [reward 86.00]
> Step 50 [reward 186.00]
> Step 75 [reward 286.00]
> Step 100 [reward 386.00]
> Step 125 [reward 486.00]
> Step 150 [reward 586.00]
> Step 175 [reward 686.00]
> Step 200 [reward 786.00]
> Step 225 [reward 886.00]
> Step 250 [reward 986.00]
Rewards 986.00 / Steps 250.00
Reward stats:
 {'max': '1029.78', 'mean': '585.53', 'min': '-14.29', 'std': '212.35'}
Information gain stats:
 {'max': '1.72', 'mean': '0.87', 'min': '0.33', 'std': '0.25'}
Episode time 53.41
Saved _metrics_

=== Episode 23 ===
Training on [6750/27000] data points
> Train epoch 20 [ensemble -33.60 | reward 2.18]
> Train epoch 40 [ensemble -37.09 | reward 5.98]
> Train epoch 60 [ensemble -38.90 | reward 10.32]
> Train epoch 80 [ensemble -40.09 | reward 13.96]
> Train epoch 100 [ensemble -40.95 | reward 16.39]
Ensemble loss -40.95 / Reward Loss 16.39

=== Collecting data [23] ===
> Step 25 [reward 51.00]
> Step 50 [reward 151.00]
> Step 75 [reward 251.00]
> Step 100 [reward 351.00]
> Step 125 [reward 451.00]
> Step 150 [reward 551.00]
> Step 175 [reward 651.00]
> Step 200 [reward 751.00]
> Step 225 [reward 851.00]
> Step 250 [reward 951.00]
Rewards 951.00 / Steps 250.00
Reward stats:
 {'max': '1043.49', 'mean': '579.26', 'min': '-44.11', 'std': '225.35'}
Information gain stats:
 {'max': '1.73', 'mean': '0.88', 'min': '0.35', 'std': '0.23'}
Episode time 54.75
Saved _metrics_

=== Episode 24 ===
Training on [7000/28000] data points
> Train epoch 20 [ensemble -34.04 | reward 2.35]
> Train epoch 40 [ensemble -37.43 | reward 6.58]
> Train epoch 60 [ensemble -39.17 | reward 11.35]
> Train epoch 80 [ensemble -40.31 | reward 15.25]
> Train epoch 100 [ensemble -41.15 | reward 17.83]
Ensemble loss -41.15 / Reward Loss 17.83

=== Collecting data [24] ===
> Step 25 [reward 45.00]
> Step 50 [reward 145.00]
> Step 75 [reward 245.00]
> Step 100 [reward 345.00]
> Step 125 [reward 445.00]
> Step 150 [reward 545.00]
> Step 175 [reward 645.00]
> Step 200 [reward 745.00]
> Step 225 [reward 845.00]
> Step 250 [reward 945.00]
Rewards 945.00 / Steps 250.00
Reward stats:
 {'max': '1091.28', 'mean': '608.38', 'min': '-150.71', 'std': '224.03'}
Information gain stats:
 {'max': '1.68', 'mean': '0.89', 'min': '0.35', 'std': '0.24'}
Episode time 56.43
Saved _metrics_

=== Episode 25 ===
Training on [7250/29000] data points
> Train epoch 20 [ensemble -34.34 | reward 2.47]
> Train epoch 40 [ensemble -37.65 | reward 7.06]
> Train epoch 60 [ensemble -39.36 | reward 12.22]
> Train epoch 80 [ensemble -40.49 | reward 16.41]
> Train epoch 100 [ensemble -41.31 | reward 19.15]
Ensemble loss -41.31 / Reward Loss 19.15

=== Collecting data [25] ===
> Step 25 [reward 86.00]
> Step 50 [reward 186.00]
> Step 75 [reward 286.00]
> Step 100 [reward 386.00]
> Step 125 [reward 486.00]
> Step 150 [reward 586.00]
> Step 175 [reward 686.00]
> Step 200 [reward 786.00]
> Step 225 [reward 886.00]
> Step 250 [reward 986.00]
Rewards 986.00 / Steps 250.00
Reward stats:
 {'max': '1145.14', 'mean': '629.36', 'min': '-63.11', 'std': '235.10'}
Information gain stats:
 {'max': '1.70', 'mean': '0.86', 'min': '0.32', 'std': '0.25'}
Episode time 57.81
Saved _metrics_

=== Episode 26 ===
Training on [7500/30000] data points
> Train epoch 20 [ensemble -34.63 | reward 2.59]
> Train epoch 40 [ensemble -37.90 | reward 7.36]
> Train epoch 60 [ensemble -39.57 | reward 12.71]
> Train epoch 80 [ensemble -40.67 | reward 17.09]
> Train epoch 100 [ensemble -41.47 | reward 19.99]
Ensemble loss -41.47 / Reward Loss 19.99

=== Collecting data [26] ===
> Step 25 [reward 88.00]
> Step 50 [reward 188.00]
> Step 75 [reward 288.00]
> Step 100 [reward 388.00]
> Step 125 [reward 488.00]
> Step 150 [reward 588.00]
> Step 175 [reward 688.00]
> Step 200 [reward 788.00]
> Step 225 [reward 888.00]
> Step 250 [reward 988.00]
Rewards 988.00 / Steps 250.00
Reward stats:
 {'max': '1163.35', 'mean': '692.40', 'min': '-31.83', 'std': '240.63'}
Information gain stats:
 {'max': '1.73', 'mean': '0.89', 'min': '0.34', 'std': '0.25'}
Episode time 59.30
Saved _metrics_

=== Episode 27 ===
Training on [7750/31000] data points
> Train epoch 20 [ensemble -35.03 | reward 2.77]
> Train epoch 40 [ensemble -38.18 | reward 7.99]
> Train epoch 60 [ensemble -39.81 | reward 13.81]
> Train epoch 80 [ensemble -40.88 | reward 18.55]
> Train epoch 100 [ensemble -41.65 | reward 21.69]
Ensemble loss -41.65 / Reward Loss 21.69

=== Collecting data [27] ===
> Step 25 [reward 49.00]
> Step 50 [reward 149.00]
> Step 75 [reward 249.00]
> Step 100 [reward 349.00]
> Step 125 [reward 449.00]
> Step 150 [reward 549.00]
> Step 175 [reward 649.00]
> Step 200 [reward 749.00]
> Step 225 [reward 849.00]
> Step 250 [reward 949.00]
Rewards 949.00 / Steps 250.00
Reward stats:
 {'max': '1191.34', 'mean': '697.36', 'min': '-109.57', 'std': '259.76'}
Information gain stats:
 {'max': '1.73', 'mean': '0.88', 'min': '0.34', 'std': '0.25'}
Episode time 60.91
Saved _metrics_

=== Episode 28 ===
Training on [8000/32000] data points
> Train epoch 20 [ensemble -35.32 | reward 2.90]
> Train epoch 40 [ensemble -38.40 | reward 8.36]
> Train epoch 60 [ensemble -39.99 | reward 14.51]
> Train epoch 80 [ensemble -41.02 | reward 19.52]
> Train epoch 100 [ensemble -41.77 | reward 22.85]
Ensemble loss -41.77 / Reward Loss 22.85

=== Collecting data [28] ===
> Step 25 [reward 53.00]
> Step 50 [reward 153.00]
> Step 75 [reward 253.00]
> Step 100 [reward 353.00]
> Step 125 [reward 453.00]
> Step 150 [reward 553.00]
> Step 175 [reward 653.00]
> Step 200 [reward 753.00]
> Step 225 [reward 853.00]
> Step 250 [reward 953.00]
Rewards 953.00 / Steps 250.00
Reward stats:
 {'max': '1231.80', 'mean': '729.79', 'min': '-40.09', 'std': '261.43'}
Information gain stats:
 {'max': '1.75', 'mean': '0.88', 'min': '0.32', 'std': '0.24'}
Episode time 62.45
Saved _metrics_

=== Episode 29 ===
Training on [8250/33000] data points
> Train epoch 20 [ensemble -35.88 | reward 3.03]
> Train epoch 40 [ensemble -38.81 | reward 8.97]
> Train epoch 60 [ensemble -40.31 | reward 15.48]
> Train epoch 80 [ensemble -41.29 | reward 20.73]
> Train epoch 100 [ensemble -42.01 | reward 24.19]
Ensemble loss -42.01 / Reward Loss 24.19

=== Collecting data [29] ===
> Step 25 [reward 88.00]
> Step 50 [reward 188.00]
> Step 75 [reward 288.00]
> Step 100 [reward 388.00]
> Step 125 [reward 488.00]
> Step 150 [reward 588.00]
> Step 175 [reward 688.00]
> Step 200 [reward 788.00]
> Step 225 [reward 888.00]
> Step 250 [reward 988.00]
Rewards 988.00 / Steps 250.00
Reward stats:
 {'max': '1239.88', 'mean': '773.71', 'min': '-19.07', 'std': '240.83'}
Information gain stats:
 {'max': '1.73', 'mean': '0.88', 'min': '0.36', 'std': '0.23'}
Episode time 63.81
Saved _metrics_

=== Episode 30 ===
Training on [8500/34000] data points
> Train epoch 20 [ensemble -36.19 | reward 3.21]
> Train epoch 40 [ensemble -39.05 | reward 9.41]
> Train epoch 60 [ensemble -40.51 | reward 16.27]
> Train epoch 80 [ensemble -41.47 | reward 21.85]
> Train epoch 100 [ensemble -42.17 | reward 25.57]
Ensemble loss -42.17 / Reward Loss 25.57

=== Collecting data [30] ===
> Step 25 [reward 85.00]
> Step 50 [reward 185.00]
> Step 75 [reward 285.00]
> Step 100 [reward 385.00]
> Step 125 [reward 485.00]
> Step 150 [reward 585.00]
> Step 175 [reward 685.00]
> Step 200 [reward 785.00]
> Step 225 [reward 885.00]
> Step 250 [reward 985.00]
Rewards 985.00 / Steps 250.00
Reward stats:
 {'max': '1264.28', 'mean': '767.44', 'min': '12.05', 'std': '242.71'}
Information gain stats:
 {'max': '1.74', 'mean': '0.90', 'min': '0.35', 'std': '0.23'}
Episode time 65.23
Saved _metrics_

=== Episode 31 ===
Training on [8750/35000] data points
> Train epoch 20 [ensemble -36.39 | reward 3.50]
> Train epoch 40 [ensemble -39.21 | reward 10.19]
> Train epoch 60 [ensemble -40.65 | reward 17.49]
> Train epoch 80 [ensemble -41.59 | reward 23.38]
> Train epoch 100 [ensemble -42.29 | reward 27.30]
Ensemble loss -42.29 / Reward Loss 27.30

=== Collecting data [31] ===
> Step 25 [reward 47.00]
> Step 50 [reward 147.00]
> Step 75 [reward 247.00]
> Step 100 [reward 347.00]
> Step 125 [reward 447.00]
> Step 150 [reward 547.00]
> Step 175 [reward 647.00]
> Step 200 [reward 747.00]
> Step 225 [reward 847.00]
> Step 250 [reward 947.00]
Rewards 947.00 / Steps 250.00
Reward stats:
 {'max': '1299.46', 'mean': '810.13', 'min': '-122.85', 'std': '274.99'}
Information gain stats:
 {'max': '1.75', 'mean': '0.89', 'min': '0.34', 'std': '0.25'}
Episode time 66.47
Saved _metrics_

=== Episode 32 ===
Training on [9000/36000] data points
> Train epoch 20 [ensemble -36.72 | reward 3.55]
> Train epoch 40 [ensemble -39.46 | reward 10.53]
> Train epoch 60 [ensemble -40.86 | reward 18.15]
> Train epoch 80 [ensemble -41.76 | reward 24.32]
> Train epoch 100 [ensemble -42.42 | reward 28.44]
Ensemble loss -42.42 / Reward Loss 28.44

=== Collecting data [32] ===
> Step 25 [reward 41.00]
> Step 50 [reward 141.00]
> Step 75 [reward 241.00]
> Step 100 [reward 341.00]
> Step 125 [reward 441.00]
> Step 150 [reward 541.00]
> Step 175 [reward 641.00]
> Step 200 [reward 741.00]
> Step 225 [reward 841.00]
> Step 250 [reward 941.00]
Rewards 941.00 / Steps 250.00
Reward stats:
 {'max': '1342.06', 'mean': '850.26', 'min': '-59.33', 'std': '284.32'}
Information gain stats:
 {'max': '1.74', 'mean': '0.90', 'min': '0.33', 'std': '0.25'}
Episode time 67.80
Saved _metrics_

=== Episode 33 ===
Training on [9250/37000] data points
> Train epoch 20 [ensemble -36.90 | reward 3.61]
> Train epoch 40 [ensemble -39.61 | reward 11.02]
> Train epoch 60 [ensemble -40.99 | reward 19.11]
> Train epoch 80 [ensemble -41.89 | reward 25.67]
> Train epoch 100 [ensemble -42.54 | reward 30.07]
Ensemble loss -42.54 / Reward Loss 30.07

=== Collecting data [33] ===
> Step 25 [reward 89.00]
> Step 50 [reward 189.00]
> Step 75 [reward 289.00]
> Step 100 [reward 389.00]
> Step 125 [reward 489.00]
> Step 150 [reward 589.00]
> Step 175 [reward 689.00]
> Step 200 [reward 789.00]
> Step 225 [reward 889.00]
> Step 250 [reward 989.00]
Rewards 989.00 / Steps 250.00
Reward stats:
 {'max': '1385.20', 'mean': '876.46', 'min': '22.29', 'std': '283.26'}
Information gain stats:
 {'max': '1.74', 'mean': '0.90', 'min': '0.34', 'std': '0.25'}
Episode time 69.59
Saved _metrics_

=== Episode 34 ===
Training on [9500/38000] data points
> Train epoch 20 [ensemble -37.20 | reward 3.94]
> Train epoch 40 [ensemble -39.81 | reward 11.84]
> Train epoch 60 [ensemble -41.14 | reward 20.36]
> Train epoch 80 [ensemble -42.01 | reward 27.12]
> Train epoch 100 [ensemble -42.66 | reward 31.61]
Ensemble loss -42.66 / Reward Loss 31.61

=== Collecting data [34] ===
> Step 25 [reward 54.00]
> Step 50 [reward 154.00]
> Step 75 [reward 254.00]
> Step 100 [reward 354.00]
> Step 125 [reward 454.00]
> Step 150 [reward 554.00]
> Step 175 [reward 654.00]
> Step 200 [reward 754.00]
> Step 225 [reward 854.00]
> Step 250 [reward 954.00]
Rewards 954.00 / Steps 250.00
Reward stats:
 {'max': '1373.27', 'mean': '859.64', 'min': '-171.42', 'std': '284.16'}
Information gain stats:
 {'max': '1.74', 'mean': '0.92', 'min': '0.35', 'std': '0.25'}
Episode time 70.96
Saved _metrics_

=== Episode 35 ===
Training on [9750/39000] data points
> Train epoch 20 [ensemble -37.35 | reward 4.06]
> Train epoch 40 [ensemble -39.96 | reward 12.29]
> Train epoch 60 [ensemble -41.27 | reward 21.11]
> Train epoch 80 [ensemble -42.12 | reward 28.18]
> Train epoch 100 [ensemble -42.75 | reward 32.92]
Ensemble loss -42.75 / Reward Loss 32.92

=== Collecting data [35] ===
> Step 25 [reward 88.00]
> Step 50 [reward 188.00]
> Step 75 [reward 288.00]
> Step 100 [reward 388.00]
> Step 125 [reward 488.00]
> Step 150 [reward 588.00]
> Step 175 [reward 688.00]
> Step 200 [reward 788.00]
> Step 225 [reward 888.00]
> Step 250 [reward 988.00]
Rewards 988.00 / Steps 250.00
Reward stats:
 {'max': '1445.17', 'mean': '942.99', 'min': '6.01', 'std': '283.23'}
Information gain stats:
 {'max': '1.75', 'mean': '0.90', 'min': '0.35', 'std': '0.24'}
Episode time 72.08
Saved _metrics_

=== Episode 36 ===
Training on [10000/40000] data points
> Train epoch 20 [ensemble -37.60 | reward 4.18]
> Train epoch 40 [ensemble -40.15 | reward 12.67]
> Train epoch 60 [ensemble -41.43 | reward 21.94]
> Train epoch 80 [ensemble -42.26 | reward 29.40]
> Train epoch 100 [ensemble -42.87 | reward 34.35]
Ensemble loss -42.87 / Reward Loss 34.35

=== Collecting data [36] ===
> Step 25 [reward 87.00]
> Step 50 [reward 187.00]
> Step 75 [reward 287.00]
> Step 100 [reward 387.00]
> Step 125 [reward 487.00]
> Step 150 [reward 587.00]
> Step 175 [reward 687.00]
> Step 200 [reward 787.00]
> Step 225 [reward 887.00]
> Step 250 [reward 987.00]
Rewards 987.00 / Steps 250.00
Reward stats:
 {'max': '1458.33', 'mean': '948.07', 'min': '9.59', 'std': '289.00'}
Information gain stats:
 {'max': '1.73', 'mean': '0.90', 'min': '0.35', 'std': '0.23'}
Episode time 73.53
Saved _metrics_

=== Episode 37 ===
Training on [10250/41000] data points
> Train epoch 20 [ensemble -37.90 | reward 4.55]
> Train epoch 40 [ensemble -40.35 | reward 13.69]
> Train epoch 60 [ensemble -41.60 | reward 23.38]
> Train epoch 80 [ensemble -42.41 | reward 31.02]
> Train epoch 100 [ensemble -43.00 | reward 36.07]
Ensemble loss -43.00 / Reward Loss 36.07

=== Collecting data [37] ===
> Step 25 [reward 88.00]
> Step 50 [reward 188.00]
> Step 75 [reward 288.00]
> Step 100 [reward 388.00]
> Step 125 [reward 488.00]
> Step 150 [reward 588.00]
> Step 175 [reward 688.00]
> Step 200 [reward 788.00]
> Step 225 [reward 888.00]
> Step 250 [reward 988.00]
Rewards 988.00 / Steps 250.00
Reward stats:
 {'max': '1472.03', 'mean': '980.41', 'min': '44.17', 'std': '281.10'}
Information gain stats:
 {'max': '1.73', 'mean': '0.89', 'min': '0.34', 'std': '0.24'}
Episode time 75.35
Saved _metrics_

=== Episode 38 ===
Training on [10500/42000] data points
> Train epoch 20 [ensemble -38.05 | reward 4.63]
> Train epoch 40 [ensemble -40.48 | reward 14.09]
> Train epoch 60 [ensemble -41.70 | reward 24.15]
> Train epoch 80 [ensemble -42.50 | reward 32.09]
> Train epoch 100 [ensemble -43.09 | reward 37.37]
Ensemble loss -43.09 / Reward Loss 37.37

=== Collecting data [38] ===
> Step 25 [reward 49.00]
> Step 50 [reward 149.00]
> Step 75 [reward 249.00]
> Step 100 [reward 349.00]
> Step 125 [reward 449.00]
> Step 150 [reward 549.00]
> Step 175 [reward 649.00]
> Step 200 [reward 749.00]
> Step 225 [reward 849.00]
> Step 250 [reward 949.00]
Rewards 949.00 / Steps 250.00
Reward stats:
 {'max': '1524.88', 'mean': '989.89', 'min': '-14.92', 'std': '314.05'}
Information gain stats:
 {'max': '1.72', 'mean': '0.91', 'min': '0.35', 'std': '0.24'}
Episode time 76.59
Saved _metrics_

=== Episode 39 ===
Training on [10750/43000] data points
> Train epoch 20 [ensemble -38.27 | reward 4.90]
> Train epoch 40 [ensemble -40.64 | reward 14.78]
> Train epoch 60 [ensemble -41.83 | reward 25.14]
> Train epoch 80 [ensemble -42.61 | reward 33.33]
> Train epoch 100 [ensemble -43.19 | reward 38.79]
Ensemble loss -43.19 / Reward Loss 38.79

=== Collecting data [39] ===
> Step 25 [reward 89.00]
> Step 50 [reward 189.00]
> Step 75 [reward 289.00]
> Step 100 [reward 389.00]
> Step 125 [reward 489.00]
> Step 150 [reward 589.00]
> Step 175 [reward 689.00]
> Step 200 [reward 789.00]
> Step 225 [reward 889.00]
> Step 250 [reward 989.00]
Rewards 989.00 / Steps 250.00
Reward stats:
 {'max': '1599.66', 'mean': '1033.88', 'min': '-108.82', 'std': '294.38'}
Information gain stats:
 {'max': '1.73', 'mean': '0.90', 'min': '0.33', 'std': '0.24'}
Episode time 77.95
Saved _metrics_

=== Episode 40 ===
Training on [11000/44000] data points
> Train epoch 20 [ensemble -38.45 | reward 4.96]
> Train epoch 40 [ensemble -40.80 | reward 15.31]
> Train epoch 60 [ensemble -41.97 | reward 26.21]
> Train epoch 80 [ensemble -42.73 | reward 34.83]
> Train epoch 100 [ensemble -43.30 | reward 40.54]
Ensemble loss -43.30 / Reward Loss 40.54

=== Collecting data [40] ===
> Step 25 [reward 50.00]
> Step 50 [reward 150.00]
> Step 75 [reward 250.00]
> Step 100 [reward 350.00]
> Step 125 [reward 450.00]
> Step 150 [reward 550.00]
> Step 175 [reward 650.00]
> Step 200 [reward 750.00]
> Step 225 [reward 850.00]
> Step 250 [reward 950.00]
Rewards 950.00 / Steps 250.00
Reward stats:
 {'max': '1580.88', 'mean': '1056.62', 'min': '-169.64', 'std': '309.95'}
Information gain stats:
 {'max': '1.76', 'mean': '0.90', 'min': '0.35', 'std': '0.24'}
Episode time 79.36
Saved _metrics_

=== Episode 41 ===
Training on [11250/45000] data points
> Train epoch 20 [ensemble -38.60 | reward 5.19]
> Train epoch 40 [ensemble -40.90 | reward 15.82]
> Train epoch 60 [ensemble -42.06 | reward 27.03]
> Train epoch 80 [ensemble -42.81 | reward 35.93]
> Train epoch 100 [ensemble -43.37 | reward 41.86]
Ensemble loss -43.37 / Reward Loss 41.86

=== Collecting data [41] ===
> Step 25 [reward 85.00]
> Step 50 [reward 185.00]
> Step 75 [reward 285.00]
> Step 100 [reward 385.00]
> Step 125 [reward 485.00]
> Step 150 [reward 585.00]
> Step 175 [reward 685.00]
> Step 200 [reward 785.00]
> Step 225 [reward 885.00]
> Step 250 [reward 985.00]
Rewards 985.00 / Steps 250.00
Reward stats:
 {'max': '1667.74', 'mean': '1090.17', 'min': '109.70', 'std': '315.10'}
Information gain stats:
 {'max': '1.71', 'mean': '0.91', 'min': '0.34', 'std': '0.23'}
Episode time 80.44
Saved _metrics_

=== Episode 42 ===
Training on [11500/46000] data points
> Train epoch 20 [ensemble -38.76 | reward 5.49]
> Train epoch 40 [ensemble -41.02 | reward 16.68]
> Train epoch 60 [ensemble -42.15 | reward 28.29]
> Train epoch 80 [ensemble -42.89 | reward 37.36]
> Train epoch 100 [ensemble -43.44 | reward 43.37]
Ensemble loss -43.44 / Reward Loss 43.37

=== Collecting data [42] ===
> Step 25 [reward 35.00]
> Step 50 [reward 135.00]
> Step 75 [reward 235.00]
> Step 100 [reward 335.00]
> Step 125 [reward 435.00]
> Step 150 [reward 535.00]
> Step 175 [reward 635.00]
> Step 200 [reward 735.00]
> Step 225 [reward 835.00]
> Step 250 [reward 935.00]
Rewards 935.00 / Steps 250.00
Reward stats:
 {'max': '1641.41', 'mean': '1101.36', 'min': '-183.18', 'std': '328.28'}
Information gain stats:
 {'max': '1.77', 'mean': '0.93', 'min': '0.36', 'std': '0.24'}
Episode time 81.78
Saved _metrics_

=== Episode 43 ===
Training on [11750/47000] data points
> Train epoch 20 [ensemble -39.00 | reward 6.13]
> Train epoch 40 [ensemble -41.19 | reward 18.02]
> Train epoch 60 [ensemble -42.28 | reward 29.96]
> Train epoch 80 [ensemble -43.00 | reward 39.27]
> Train epoch 100 [ensemble -43.53 | reward 45.48]
Ensemble loss -43.53 / Reward Loss 45.48

=== Collecting data [43] ===
> Step 25 [reward 44.00]
> Step 50 [reward 144.00]
> Step 75 [reward 244.00]
> Step 100 [reward 344.00]
> Step 125 [reward 444.00]
> Step 150 [reward 544.00]
> Step 175 [reward 644.00]
> Step 200 [reward 744.00]
> Step 225 [reward 844.00]
> Step 250 [reward 944.00]
Rewards 944.00 / Steps 250.00
Reward stats:
 {'max': '1649.74', 'mean': '1101.68', 'min': '34.13', 'std': '303.35'}
Information gain stats:
 {'max': '1.75', 'mean': '0.91', 'min': '0.35', 'std': '0.23'}
Episode time 83.57
Saved _metrics_

=== Episode 44 ===
Training on [12000/48000] data points
> Train epoch 20 [ensemble -39.09 | reward 5.97]
> Train epoch 40 [ensemble -41.27 | reward 18.08]
> Train epoch 60 [ensemble -42.36 | reward 30.60]
> Train epoch 80 [ensemble -43.07 | reward 40.42]
> Train epoch 100 [ensemble -43.59 | reward 47.03]
Ensemble loss -43.59 / Reward Loss 47.03

=== Collecting data [44] ===
> Step 25 [reward 3.00]
> Step 50 [reward 103.00]
> Step 75 [reward 203.00]
> Step 100 [reward 303.00]
> Step 125 [reward 403.00]
> Step 150 [reward 503.00]
> Step 175 [reward 603.00]
> Step 200 [reward 703.00]
> Step 225 [reward 803.00]
> Step 250 [reward 903.00]
Rewards 903.00 / Steps 250.00
Reward stats:
 {'max': '1675.94', 'mean': '1087.59', 'min': '-81.45', 'std': '352.92'}
Information gain stats:
 {'max': '1.90', 'mean': '0.93', 'min': '0.36', 'std': '0.25'}
Episode time 84.98
Saved _metrics_

=== Episode 45 ===
Training on [12250/49000] data points
> Train epoch 20 [ensemble -39.21 | reward 6.37]
> Train epoch 40 [ensemble -41.35 | reward 18.93]
> Train epoch 60 [ensemble -42.41 | reward 31.80]
> Train epoch 80 [ensemble -43.11 | reward 41.89]
> Train epoch 100 [ensemble -43.63 | reward 48.63]
Ensemble loss -43.63 / Reward Loss 48.63

=== Collecting data [45] ===
> Step 25 [reward 88.00]
> Step 50 [reward 188.00]
> Step 75 [reward 288.00]
> Step 100 [reward 388.00]
> Step 125 [reward 488.00]
> Step 150 [reward 588.00]
> Step 175 [reward 688.00]
> Step 200 [reward 788.00]
> Step 225 [reward 888.00]
> Step 250 [reward 988.00]
Rewards 988.00 / Steps 250.00
Reward stats:
 {'max': '1740.98', 'mean': '1214.81', 'min': '32.14', 'std': '319.72'}
Information gain stats:
 {'max': '1.76', 'mean': '0.92', 'min': '0.32', 'std': '0.24'}
Episode time 86.46
Saved _metrics_

=== Episode 46 ===
Training on [12500/50000] data points
> Train epoch 20 [ensemble -39.35 | reward 6.36]
> Train epoch 40 [ensemble -41.46 | reward 19.43]
> Train epoch 60 [ensemble -42.51 | reward 32.94]
> Train epoch 80 [ensemble -43.20 | reward 43.48]
> Train epoch 100 [ensemble -43.71 | reward 50.47]
Ensemble loss -43.71 / Reward Loss 50.47

=== Collecting data [46] ===
> Step 25 [reward 47.00]
> Step 50 [reward 147.00]
> Step 75 [reward 247.00]
> Step 100 [reward 347.00]
> Step 125 [reward 447.00]
> Step 150 [reward 547.00]
> Step 175 [reward 647.00]
> Step 200 [reward 747.00]
> Step 225 [reward 847.00]
> Step 250 [reward 947.00]
Rewards 947.00 / Steps 250.00
Reward stats:
 {'max': '1749.15', 'mean': '1206.74', 'min': '39.95', 'std': '340.61'}
Information gain stats:
 {'max': '1.77', 'mean': '0.90', 'min': '0.34', 'std': '0.24'}
Episode time 87.62
Saved _metrics_

=== Episode 47 ===
Training on [12750/51000] data points
> Train epoch 20 [ensemble -39.52 | reward 6.81]
> Train epoch 40 [ensemble -41.59 | reward 20.43]
> Train epoch 60 [ensemble -42.61 | reward 34.20]
> Train epoch 80 [ensemble -43.29 | reward 44.94]
> Train epoch 100 [ensemble -43.78 | reward 52.08]
Ensemble loss -43.78 / Reward Loss 52.08

=== Collecting data [47] ===
> Step 25 [reward 32.00]
> Step 50 [reward 132.00]
> Step 75 [reward 232.00]
> Step 100 [reward 332.00]
> Step 125 [reward 432.00]
> Step 150 [reward 532.00]
> Step 175 [reward 632.00]
> Step 200 [reward 732.00]
> Step 225 [reward 832.00]
> Step 250 [reward 932.00]
Rewards 932.00 / Steps 250.00
Reward stats:
 {'max': '1773.76', 'mean': '1220.44', 'min': '43.11', 'std': '323.40'}
Information gain stats:
 {'max': '1.81', 'mean': '0.93', 'min': '0.36', 'std': '0.24'}
Episode time 89.42
Saved _metrics_

=== Episode 48 ===
Training on [13000/52000] data points
> Train epoch 20 [ensemble -39.62 | reward 6.92]
> Train epoch 40 [ensemble -41.66 | reward 20.92]
> Train epoch 60 [ensemble -42.68 | reward 35.06]
> Train epoch 80 [ensemble -43.34 | reward 45.97]
> Train epoch 100 [ensemble -43.83 | reward 53.23]
Ensemble loss -43.83 / Reward Loss 53.23

=== Collecting data [48] ===
> Step 25 [reward 47.00]
> Step 50 [reward 147.00]
> Step 75 [reward 247.00]
> Step 100 [reward 347.00]
> Step 125 [reward 447.00]
> Step 150 [reward 547.00]
> Step 175 [reward 647.00]
> Step 200 [reward 747.00]
> Step 225 [reward 847.00]
> Step 250 [reward 947.00]
Rewards 947.00 / Steps 250.00
Reward stats:
 {'max': '1804.04', 'mean': '1240.12', 'min': '-192.89', 'std': '340.86'}
Information gain stats:
 {'max': '1.78', 'mean': '0.92', 'min': '0.33', 'std': '0.24'}
Episode time 90.53
Saved _metrics_

=== Episode 49 ===
Training on [13250/53000] data points
> Train epoch 20 [ensemble -39.75 | reward 7.13]
> Train epoch 40 [ensemble -41.76 | reward 21.56]
> Train epoch 60 [ensemble -42.77 | reward 36.10]
> Train epoch 80 [ensemble -43.43 | reward 47.28]
> Train epoch 100 [ensemble -43.91 | reward 54.65]
Ensemble loss -43.91 / Reward Loss 54.65

=== Collecting data [49] ===
> Step 25 [reward 54.00]
> Step 50 [reward 154.00]
> Step 75 [reward 254.00]
> Step 100 [reward 354.00]
> Step 125 [reward 454.00]
> Step 150 [reward 554.00]
> Step 175 [reward 654.00]
> Step 200 [reward 754.00]
> Step 225 [reward 854.00]
> Step 250 [reward 954.00]
Rewards 954.00 / Steps 250.00
Reward stats:
 {'max': '1821.05', 'mean': '1262.06', 'min': '-47.07', 'std': '352.95'}
Information gain stats:
 {'max': '1.76', 'mean': '0.92', 'min': '0.35', 'std': '0.24'}
Episode time 91.89
Saved _metrics_