04:42:47

=== Loading experiment [device: cuda] ===

{'action_noise': None,
 'action_repeat': 4,
 'batch_size': 50,
 'coverage': False,
 'ensemble_size': 10,
 'env_name': 'DeepMindCatch',
 'epsilon': 1e-08,
 'expl_scale': 0.1,
 'expl_strategy': 'information',
 'grad_clip_norm': 1000,
 'hidden_size': 200,
 'learning_rate': 0.001,
 'logdir': 'cup_catch_DQN-like',
 'max_episode_len': 1000,
 'n_candidates': 500,
 'n_episodes': 50,
 'n_seed_episodes': 5,
 'n_train_epochs': 100,
 'optimisation_iters': 5,
 'plan_horizon': 12,
 'record_every': None,
 'reward_scale': 1.0,
 'seed': 9,
 'strategy': 'information',
 'top_candidates': 50,
 'use_exploration': True,
 'use_mean': False,
 'use_reward': True}

Collected seeds: [5 episodes | 1250 frames]

=== Episode 1 ===
Training on [1250/5000] data points
> Train epoch 20 [ensemble -21.32 | reward 0.00]
> Train epoch 40 [ensemble -29.46 | reward 0.00]
> Train epoch 60 [ensemble -33.36 | reward 0.00]
> Train epoch 80 [ensemble -35.80 | reward 0.00]
> Train epoch 100 [ensemble -37.51 | reward 0.00]
Ensemble loss -37.51 / Reward Loss 0.00

=== Collecting data [1] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '-0.81', 'mean': '-1.19', 'min': '-2.32', 'std': '0.09'}
Information gain stats:
 {'max': '2.94', 'mean': '1.10', 'min': '0.40', 'std': '0.32'}
Episode time 23.80
Saved _metrics_

=== Episode 2 ===
Training on [1500/6000] data points
> Train epoch 20 [ensemble -15.50 | reward 0.00]
> Train epoch 40 [ensemble -25.87 | reward 0.00]
> Train epoch 60 [ensemble -30.62 | reward 0.00]
> Train epoch 80 [ensemble -33.47 | reward 0.00]
> Train epoch 100 [ensemble -35.42 | reward 0.00]
Ensemble loss -35.42 / Reward Loss 0.00

=== Collecting data [2] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '0.96', 'mean': '0.72', 'min': '0.39', 'std': '0.06'}
Information gain stats:
 {'max': '1.91', 'mean': '1.27', 'min': '0.51', 'std': '0.16'}
Episode time 25.28
Saved _metrics_

=== Episode 3 ===
Training on [1750/7000] data points
> Train epoch 20 [ensemble -17.42 | reward 0.00]
> Train epoch 40 [ensemble -27.07 | reward 0.00]
> Train epoch 60 [ensemble -31.35 | reward 0.00]
> Train epoch 80 [ensemble -33.92 | reward 0.00]
> Train epoch 100 [ensemble -35.70 | reward 0.00]
Ensemble loss -35.70 / Reward Loss 0.00

=== Collecting data [3] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 21.00]
> Step 100 [reward 89.00]
> Step 125 [reward 157.00]
> Step 150 [reward 175.00]
> Step 175 [reward 175.00]
> Step 200 [reward 175.00]
> Step 225 [reward 175.00]
> Step 250 [reward 175.00]
Rewards 175.00 / Steps 250.00
Reward stats:
 {'max': '0.86', 'mean': '0.67', 'min': '0.29', 'std': '0.06'}
Information gain stats:
 {'max': '1.64', 'mean': '0.93', 'min': '0.43', 'std': '0.14'}
Episode time 26.67
Saved _metrics_

=== Episode 4 ===
Training on [2000/8000] data points
> Train epoch 20 [ensemble -16.80 | reward 0.12]
> Train epoch 40 [ensemble -25.96 | reward 0.12]
> Train epoch 60 [ensemble -30.14 | reward 0.12]
> Train epoch 80 [ensemble -32.71 | reward 0.11]
> Train epoch 100 [ensemble -34.53 | reward 0.11]
Ensemble loss -34.53 / Reward Loss 0.11

=== Collecting data [4] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 13.00]
> Step 100 [reward 113.00]
> Step 125 [reward 213.00]
> Step 150 [reward 313.00]
> Step 175 [reward 413.00]
> Step 200 [reward 513.00]
> Step 225 [reward 613.00]
> Step 250 [reward 713.00]
Rewards 713.00 / Steps 250.00
Reward stats:
 {'max': '250.63', 'mean': '52.26', 'min': '-13.15', 'std': '30.94'}
Information gain stats:
 {'max': '1.39', 'mean': '0.87', 'min': '0.54', 'std': '0.10'}
Episode time 27.96
Saved _metrics_

=== Episode 5 ===
Training on [2250/9000] data points
> Train epoch 20 [ensemble -17.61 | reward 0.28]
> Train epoch 40 [ensemble -26.35 | reward 0.28]
> Train epoch 60 [ensemble -30.33 | reward 0.34]
> Train epoch 80 [ensemble -32.78 | reward 0.41]
> Train epoch 100 [ensemble -34.52 | reward 0.44]
Ensemble loss -34.52 / Reward Loss 0.44

=== Collecting data [5] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '219.63', 'mean': '37.80', 'min': '-9.64', 'std': '29.74'}
Information gain stats:
 {'max': '1.35', 'mean': '0.74', 'min': '0.45', 'std': '0.09'}
Episode time 29.46
Saved _metrics_

=== Episode 6 ===
Training on [2500/10000] data points
> Train epoch 20 [ensemble -18.51 | reward 0.27]
> Train epoch 40 [ensemble -26.96 | reward 0.30]
> Train epoch 60 [ensemble -30.79 | reward 0.39]
> Train epoch 80 [ensemble -33.12 | reward 0.47]
> Train epoch 100 [ensemble -34.77 | reward 0.52]
Ensemble loss -34.77 / Reward Loss 0.52

=== Collecting data [6] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '200.30', 'mean': '54.81', 'min': '-4.77', 'std': '40.17'}
Information gain stats:
 {'max': '1.53', 'mean': '1.07', 'min': '0.53', 'std': '0.10'}
Episode time 30.92
Saved _metrics_

=== Episode 7 ===
Training on [2750/11000] data points
> Train epoch 20 [ensemble -20.94 | reward 0.28]
> Train epoch 40 [ensemble -29.10 | reward 0.32]
> Train epoch 60 [ensemble -32.74 | reward 0.43]
> Train epoch 80 [ensemble -34.94 | reward 0.51]
> Train epoch 100 [ensemble -36.48 | reward 0.56]
Ensemble loss -36.48 / Reward Loss 0.56

=== Collecting data [7] ===
> Step 25 [reward 0.00]
> Step 50 [reward 47.00]
> Step 75 [reward 147.00]
> Step 100 [reward 247.00]
> Step 125 [reward 347.00]
> Step 150 [reward 447.00]
> Step 175 [reward 547.00]
> Step 200 [reward 647.00]
> Step 225 [reward 747.00]
> Step 250 [reward 847.00]
Rewards 847.00 / Steps 250.00
Reward stats:
 {'max': '173.19', 'mean': '55.02', 'min': '-14.93', 'std': '34.61'}
Information gain stats:
 {'max': '1.39', 'mean': '0.83', 'min': '0.47', 'std': '0.11'}
Episode time 32.26
Saved _metrics_

=== Episode 8 ===
Training on [3000/12000] data points
> Train epoch 20 [ensemble -21.58 | reward 0.36]
> Train epoch 40 [ensemble -29.43 | reward 0.50]
> Train epoch 60 [ensemble -32.95 | reward 0.71]
> Train epoch 80 [ensemble -35.08 | reward 0.90]
> Train epoch 100 [ensemble -36.56 | reward 1.02]
Ensemble loss -36.56 / Reward Loss 1.02

=== Collecting data [8] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 96.00]
> Step 200 [reward 196.00]
> Step 225 [reward 296.00]
> Step 250 [reward 396.00]
Rewards 396.00 / Steps 250.00
Reward stats:
 {'max': '235.60', 'mean': '41.89', 'min': '-15.53', 'std': '42.48'}
Information gain stats:
 {'max': '1.43', 'mean': '0.87', 'min': '0.43', 'std': '0.11'}
Episode time 33.74
Saved _metrics_

=== Episode 9 ===
Training on [3250/13000] data points
> Train epoch 20 [ensemble -22.38 | reward 0.47]
> Train epoch 40 [ensemble -29.87 | reward 0.78]
> Train epoch 60 [ensemble -33.22 | reward 1.13]
> Train epoch 80 [ensemble -35.25 | reward 1.40]
> Train epoch 100 [ensemble -36.69 | reward 1.58]
Ensemble loss -36.69 / Reward Loss 1.58

=== Collecting data [9] ===
> Step 25 [reward 21.00]
> Step 50 [reward 121.00]
> Step 75 [reward 221.00]
> Step 100 [reward 321.00]
> Step 125 [reward 421.00]
> Step 150 [reward 521.00]
> Step 175 [reward 621.00]
> Step 200 [reward 721.00]
> Step 225 [reward 821.00]
> Step 250 [reward 921.00]
Rewards 921.00 / Steps 250.00
Reward stats:
 {'max': '73.57', 'mean': '14.58', 'min': '-17.66', 'std': '8.05'}
Information gain stats:
 {'max': '1.38', 'mean': '0.91', 'min': '0.52', 'std': '0.08'}
Episode time 35.17
Saved _metrics_

=== Episode 10 ===
Training on [3500/14000] data points
> Train epoch 20 [ensemble -22.64 | reward 0.54]
> Train epoch 40 [ensemble -30.09 | reward 1.00]
> Train epoch 60 [ensemble -33.42 | reward 1.54]
> Train epoch 80 [ensemble -35.45 | reward 1.98]
> Train epoch 100 [ensemble -36.89 | reward 2.26]
Ensemble loss -36.89 / Reward Loss 2.26

=== Collecting data [10] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 1.00]
> Step 175 [reward 1.00]
> Step 200 [reward 1.00]
> Step 225 [reward 2.00]
> Step 250 [reward 3.00]
Rewards 3.00 / Steps 250.00
Reward stats:
 {'max': '230.64', 'mean': '38.06', 'min': '-7.74', 'std': '27.77'}
Information gain stats:
 {'max': '1.40', 'mean': '0.85', 'min': '0.46', 'std': '0.12'}
Episode time 36.40
Saved _metrics_

=== Episode 11 ===
Training on [3750/15000] data points
> Train epoch 20 [ensemble -23.53 | reward 0.57]
> Train epoch 40 [ensemble -30.49 | reward 1.09]
> Train epoch 60 [ensemble -33.63 | reward 1.67]
> Train epoch 80 [ensemble -35.55 | reward 2.13]
> Train epoch 100 [ensemble -36.91 | reward 2.40]
Ensemble loss -36.91 / Reward Loss 2.40

=== Collecting data [11] ===
> Step 25 [reward 0.00]
> Step 50 [reward 52.00]
> Step 75 [reward 152.00]
> Step 100 [reward 252.00]
> Step 125 [reward 352.00]
> Step 150 [reward 452.00]
> Step 175 [reward 552.00]
> Step 200 [reward 652.00]
> Step 225 [reward 752.00]
> Step 250 [reward 852.00]
Rewards 852.00 / Steps 250.00
Reward stats:
 {'max': '229.50', 'mean': '70.79', 'min': '-10.37', 'std': '43.93'}
Information gain stats:
 {'max': '1.46', 'mean': '0.90', 'min': '0.51', 'std': '0.11'}
Episode time 38.04
Saved _metrics_

=== Episode 12 ===
Training on [4000/16000] data points
> Train epoch 20 [ensemble -24.19 | reward 0.68]
> Train epoch 40 [ensemble -30.86 | reward 1.44]
> Train epoch 60 [ensemble -33.89 | reward 2.28]
> Train epoch 80 [ensemble -35.75 | reward 2.92]
> Train epoch 100 [ensemble -37.08 | reward 3.32]
Ensemble loss -37.08 / Reward Loss 3.32

=== Collecting data [12] ===
> Step 25 [reward 9.00]
> Step 50 [reward 100.00]
> Step 75 [reward 200.00]
> Step 100 [reward 300.00]
> Step 125 [reward 400.00]
> Step 150 [reward 500.00]
> Step 175 [reward 600.00]
> Step 200 [reward 700.00]
> Step 225 [reward 800.00]
> Step 250 [reward 900.00]
Rewards 900.00 / Steps 250.00
Reward stats:
 {'max': '199.11', 'mean': '52.38', 'min': '-18.94', 'std': '33.14'}
Information gain stats:
 {'max': '1.49', 'mean': '0.92', 'min': '0.52', 'std': '0.10'}
Episode time 39.33
Saved _metrics_

=== Episode 13 ===
Training on [4250/17000] data points
> Train epoch 20 [ensemble -24.53 | reward 0.86]
> Train epoch 40 [ensemble -31.16 | reward 1.81]
> Train epoch 60 [ensemble -34.16 | reward 2.90]
> Train epoch 80 [ensemble -36.01 | reward 3.79]
> Train epoch 100 [ensemble -37.32 | reward 4.36]
Ensemble loss -37.32 / Reward Loss 4.36

=== Collecting data [13] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 8.00]
> Step 150 [reward 108.00]
> Step 175 [reward 208.00]
> Step 200 [reward 308.00]
> Step 225 [reward 408.00]
> Step 250 [reward 508.00]
Rewards 508.00 / Steps 250.00
Reward stats:
 {'max': '243.74', 'mean': '59.25', 'min': '-21.37', 'std': '37.29'}
Information gain stats:
 {'max': '1.48', 'mean': '0.93', 'min': '0.50', 'std': '0.10'}
Episode time 40.66
Saved _metrics_

=== Episode 14 ===
Training on [4500/18000] data points
> Train epoch 20 [ensemble -24.90 | reward 0.96]
> Train epoch 40 [ensemble -31.31 | reward 2.26]
> Train epoch 60 [ensemble -34.23 | reward 3.79]
> Train epoch 80 [ensemble -36.04 | reward 5.06]
> Train epoch 100 [ensemble -37.34 | reward 5.87]
Ensemble loss -37.34 / Reward Loss 5.87

=== Collecting data [14] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 66.00]
> Step 100 [reward 166.00]
> Step 125 [reward 266.00]
> Step 150 [reward 366.00]
> Step 175 [reward 466.00]
> Step 200 [reward 566.00]
> Step 225 [reward 666.00]
> Step 250 [reward 766.00]
Rewards 766.00 / Steps 250.00
Reward stats:
 {'max': '201.77', 'mean': '55.37', 'min': '-20.65', 'std': '29.90'}
Information gain stats:
 {'max': '1.41', 'mean': '0.91', 'min': '0.47', 'std': '0.10'}
Episode time 42.34
Saved _metrics_

=== Episode 15 ===
Training on [4750/19000] data points
> Train epoch 20 [ensemble -25.72 | reward 1.09]
> Train epoch 40 [ensemble -31.86 | reward 2.54]
> Train epoch 60 [ensemble -34.68 | reward 4.27]
> Train epoch 80 [ensemble -36.43 | reward 5.67]
> Train epoch 100 [ensemble -37.69 | reward 6.57]
Ensemble loss -37.69 / Reward Loss 6.57

=== Collecting data [15] ===
> Step 25 [reward 48.00]
> Step 50 [reward 148.00]
> Step 75 [reward 248.00]
> Step 100 [reward 348.00]
> Step 125 [reward 448.00]
> Step 150 [reward 548.00]
> Step 175 [reward 648.00]
> Step 200 [reward 748.00]
> Step 225 [reward 848.00]
> Step 250 [reward 948.00]
Rewards 948.00 / Steps 250.00
Reward stats:
 {'max': '230.52', 'mean': '68.24', 'min': '-0.82', 'std': '32.13'}
Information gain stats:
 {'max': '1.46', 'mean': '0.92', 'min': '0.54', 'std': '0.10'}
Episode time 43.66
Saved _metrics_

=== Episode 16 ===
Training on [5000/20000] data points
> Train epoch 20 [ensemble -25.89 | reward 1.10]
> Train epoch 40 [ensemble -32.03 | reward 2.89]
> Train epoch 60 [ensemble -34.86 | reward 4.92]
> Train epoch 80 [ensemble -36.63 | reward 6.52]
> Train epoch 100 [ensemble -37.90 | reward 7.52]
Ensemble loss -37.90 / Reward Loss 7.52

=== Collecting data [16] ===
> Step 25 [reward 12.00]
> Step 50 [reward 112.00]
> Step 75 [reward 212.00]
> Step 100 [reward 312.00]
> Step 125 [reward 412.00]
> Step 150 [reward 512.00]
> Step 175 [reward 612.00]
> Step 200 [reward 712.00]
> Step 225 [reward 812.00]
> Step 250 [reward 912.00]
Rewards 912.00 / Steps 250.00
Reward stats:
 {'max': '269.97', 'mean': '76.85', 'min': '-11.95', 'std': '39.52'}
Information gain stats:
 {'max': '1.48', 'mean': '0.93', 'min': '0.54', 'std': '0.11'}
Episode time 45.30
Saved _metrics_

=== Episode 17 ===
Training on [5250/21000] data points
> Train epoch 20 [ensemble -26.85 | reward 1.25]
> Train epoch 40 [ensemble -32.64 | reward 3.19]
> Train epoch 60 [ensemble -35.31 | reward 5.46]
> Train epoch 80 [ensemble -36.97 | reward 7.28]
> Train epoch 100 [ensemble -38.18 | reward 8.40]
Ensemble loss -38.18 / Reward Loss 8.40

=== Collecting data [17] ===
> Step 25 [reward 49.00]
> Step 50 [reward 149.00]
> Step 75 [reward 249.00]
> Step 100 [reward 349.00]
> Step 125 [reward 449.00]
> Step 150 [reward 549.00]
> Step 175 [reward 649.00]
> Step 200 [reward 749.00]
> Step 225 [reward 849.00]
> Step 250 [reward 949.00]
Rewards 949.00 / Steps 250.00
Reward stats:
 {'max': '341.25', 'mean': '86.84', 'min': '-37.17', 'std': '48.54'}
Information gain stats:
 {'max': '1.44', 'mean': '0.93', 'min': '0.55', 'std': '0.11'}
Episode time 46.43
Saved _metrics_

=== Episode 18 ===
Training on [5500/22000] data points
> Train epoch 20 [ensemble -27.33 | reward 1.36]
> Train epoch 40 [ensemble -32.99 | reward 3.60]
> Train epoch 60 [ensemble -35.60 | reward 6.22]
> Train epoch 80 [ensemble -37.23 | reward 8.40]
> Train epoch 100 [ensemble -38.40 | reward 9.82]
Ensemble loss -38.40 / Reward Loss 9.82

=== Collecting data [18] ===
> Step 25 [reward 0.00]
> Step 50 [reward 67.00]
> Step 75 [reward 167.00]
> Step 100 [reward 267.00]
> Step 125 [reward 367.00]
> Step 150 [reward 467.00]
> Step 175 [reward 567.00]
> Step 200 [reward 667.00]
> Step 225 [reward 767.00]
> Step 250 [reward 867.00]
Rewards 867.00 / Steps 250.00
Reward stats:
 {'max': '359.33', 'mean': '100.49', 'min': '-21.18', 'std': '52.80'}
Information gain stats:
 {'max': '1.50', 'mean': '0.94', 'min': '0.53', 'std': '0.11'}
Episode time 47.97
Saved _metrics_

=== Episode 19 ===
Training on [5750/23000] data points
> Train epoch 20 [ensemble -28.26 | reward 1.50]
> Train epoch 40 [ensemble -33.59 | reward 4.21]
> Train epoch 60 [ensemble -36.09 | reward 7.36]
> Train epoch 80 [ensemble -37.66 | reward 9.94]
> Train epoch 100 [ensemble -38.80 | reward 11.60]
Ensemble loss -38.80 / Reward Loss 11.60

=== Collecting data [19] ===
> Step 25 [reward 33.00]
> Step 50 [reward 133.00]
> Step 75 [reward 233.00]
> Step 100 [reward 333.00]
> Step 125 [reward 433.00]
> Step 150 [reward 533.00]
> Step 175 [reward 633.00]
> Step 200 [reward 733.00]
> Step 225 [reward 833.00]
> Step 250 [reward 933.00]
Rewards 933.00 / Steps 250.00
Reward stats:
 {'max': '336.21', 'mean': '109.97', 'min': '-14.50', 'std': '52.86'}
Information gain stats:
 {'max': '1.46', 'mean': '0.95', 'min': '0.56', 'std': '0.11'}
Episode time 49.57
Saved _metrics_

=== Episode 20 ===
Training on [6000/24000] data points
> Train epoch 20 [ensemble -28.91 | reward 1.69]
> Train epoch 40 [ensemble -34.04 | reward 4.73]
> Train epoch 60 [ensemble -36.44 | reward 8.08]
> Train epoch 80 [ensemble -37.95 | reward 10.77]
> Train epoch 100 [ensemble -39.05 | reward 12.43]
Ensemble loss -39.05 / Reward Loss 12.43

=== Collecting data [20] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 53.00]
> Step 100 [reward 153.00]
> Step 125 [reward 253.00]
> Step 150 [reward 353.00]
> Step 175 [reward 453.00]
> Step 200 [reward 553.00]
> Step 225 [reward 653.00]
> Step 250 [reward 753.00]
Rewards 753.00 / Steps 250.00
Reward stats:
 {'max': '392.04', 'mean': '131.31', 'min': '4.17', 'std': '66.49'}
Information gain stats:
 {'max': '1.50', 'mean': '0.94', 'min': '0.54', 'std': '0.12'}
Episode time 50.75
Saved _metrics_

=== Episode 21 ===
Training on [6250/25000] data points
> Train epoch 20 [ensemble -29.55 | reward 1.81]
> Train epoch 40 [ensemble -34.48 | reward 5.04]
> Train epoch 60 [ensemble -36.76 | reward 8.72]
> Train epoch 80 [ensemble -38.21 | reward 11.76]
> Train epoch 100 [ensemble -39.27 | reward 13.74]
Ensemble loss -39.27 / Reward Loss 13.74

=== Collecting data [21] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 98.00]
> Step 150 [reward 198.00]
> Step 175 [reward 298.00]
> Step 200 [reward 398.00]
> Step 225 [reward 498.00]
> Step 250 [reward 598.00]
Rewards 598.00 / Steps 250.00
Reward stats:
 {'max': '467.36', 'mean': '126.07', 'min': '-16.28', 'std': '81.84'}
Information gain stats:
 {'max': '1.47', 'mean': '0.93', 'min': '0.51', 'std': '0.11'}
Episode time 52.20
Saved _metrics_

=== Episode 22 ===
Training on [6500/26000] data points
> Train epoch 20 [ensemble -29.90 | reward 1.83]
> Train epoch 40 [ensemble -34.69 | reward 5.57]
> Train epoch 60 [ensemble -36.93 | reward 9.67]
> Train epoch 80 [ensemble -38.36 | reward 12.92]
> Train epoch 100 [ensemble -39.41 | reward 14.94]
Ensemble loss -39.41 / Reward Loss 14.94

=== Collecting data [22] ===
> Step 25 [reward 87.00]
> Step 50 [reward 187.00]
> Step 75 [reward 287.00]
> Step 100 [reward 387.00]
> Step 125 [reward 487.00]
> Step 150 [reward 587.00]
> Step 175 [reward 687.00]
> Step 200 [reward 787.00]
> Step 225 [reward 887.00]
> Step 250 [reward 987.00]
Rewards 987.00 / Steps 250.00
Reward stats:
 {'max': '418.38', 'mean': '140.82', 'min': '-15.13', 'std': '75.17'}
Information gain stats:
 {'max': '1.51', 'mean': '0.95', 'min': '0.57', 'std': '0.12'}
Episode time 53.81
Saved _metrics_

=== Episode 23 ===
Training on [6750/27000] data points
> Train epoch 20 [ensemble -30.42 | reward 1.96]
> Train epoch 40 [ensemble -35.07 | reward 5.80]
> Train epoch 60 [ensemble -37.23 | reward 10.00]
> Train epoch 80 [ensemble -38.61 | reward 13.25]
> Train epoch 100 [ensemble -39.63 | reward 15.24]
Ensemble loss -39.63 / Reward Loss 15.24

=== Collecting data [23] ===
> Step 25 [reward 0.00]
> Step 50 [reward 91.00]
> Step 75 [reward 191.00]
> Step 100 [reward 291.00]
> Step 125 [reward 391.00]
> Step 150 [reward 491.00]
> Step 175 [reward 591.00]
> Step 200 [reward 691.00]
> Step 225 [reward 791.00]
> Step 250 [reward 891.00]
Rewards 891.00 / Steps 250.00
Reward stats:
 {'max': '447.00', 'mean': '150.54', 'min': '-75.90', 'std': '70.31'}
Information gain stats:
 {'max': '1.52', 'mean': '0.98', 'min': '0.57', 'std': '0.12'}
Episode time 54.81
Saved _metrics_

=== Episode 24 ===
Training on [7000/28000] data points
> Train epoch 20 [ensemble -30.65 | reward 2.20]
> Train epoch 40 [ensemble -35.27 | reward 6.55]
> Train epoch 60 [ensemble -37.42 | reward 11.43]
> Train epoch 80 [ensemble -38.79 | reward 15.35]
> Train epoch 100 [ensemble -39.80 | reward 17.90]
Ensemble loss -39.80 / Reward Loss 17.90

=== Collecting data [24] ===
> Step 25 [reward 34.00]
> Step 50 [reward 134.00]
> Step 75 [reward 234.00]
> Step 100 [reward 334.00]
> Step 125 [reward 434.00]
> Step 150 [reward 534.00]
> Step 175 [reward 634.00]
> Step 200 [reward 734.00]
> Step 225 [reward 834.00]
> Step 250 [reward 934.00]
Rewards 934.00 / Steps 250.00
Reward stats:
 {'max': '500.67', 'mean': '159.98', 'min': '8.01', 'std': '79.40'}
Information gain stats:
 {'max': '1.57', 'mean': '0.98', 'min': '0.49', 'std': '0.12'}
Episode time 56.53
Saved _metrics_

=== Episode 25 ===
Training on [7250/29000] data points
> Train epoch 20 [ensemble -30.66 | reward 2.29]
> Train epoch 40 [ensemble -35.36 | reward 6.90]
> Train epoch 60 [ensemble -37.54 | reward 12.07]
> Train epoch 80 [ensemble -38.92 | reward 16.22]
> Train epoch 100 [ensemble -39.92 | reward 18.85]
Ensemble loss -39.92 / Reward Loss 18.85

=== Collecting data [25] ===
> Step 25 [reward 47.00]
> Step 50 [reward 147.00]
> Step 75 [reward 247.00]
> Step 100 [reward 347.00]
> Step 125 [reward 447.00]
> Step 150 [reward 547.00]
> Step 175 [reward 647.00]
> Step 200 [reward 747.00]
> Step 225 [reward 847.00]
> Step 250 [reward 947.00]
Rewards 947.00 / Steps 250.00
Reward stats:
 {'max': '583.43', 'mean': '216.85', 'min': '14.20', 'std': '102.60'}
Information gain stats:
 {'max': '1.57', 'mean': '0.98', 'min': '0.57', 'std': '0.13'}
Episode time 57.78
Saved _metrics_

=== Episode 26 ===
Training on [7500/30000] data points
> Train epoch 20 [ensemble -31.03 | reward 2.47]
> Train epoch 40 [ensemble -35.57 | reward 7.69]
> Train epoch 60 [ensemble -37.69 | reward 13.20]
> Train epoch 80 [ensemble -39.04 | reward 17.46]
> Train epoch 100 [ensemble -40.03 | reward 20.12]
Ensemble loss -40.03 / Reward Loss 20.12

=== Collecting data [26] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 11.00]
> Step 150 [reward 111.00]
> Step 175 [reward 211.00]
> Step 200 [reward 311.00]
> Step 225 [reward 411.00]
> Step 250 [reward 511.00]
Rewards 511.00 / Steps 250.00
Reward stats:
 {'max': '559.07', 'mean': '181.07', 'min': '-42.34', 'std': '80.11'}
Information gain stats:
 {'max': '1.58', 'mean': '1.02', 'min': '0.58', 'std': '0.11'}
Episode time 59.17
Saved _metrics_

=== Episode 27 ===
Training on [7750/31000] data points
> Train epoch 20 [ensemble -31.31 | reward 2.86]
> Train epoch 40 [ensemble -35.79 | reward 8.55]
> Train epoch 60 [ensemble -37.86 | reward 14.75]
> Train epoch 80 [ensemble -39.18 | reward 19.71]
> Train epoch 100 [ensemble -40.16 | reward 22.92]
Ensemble loss -40.16 / Reward Loss 22.92

=== Collecting data [27] ===
> Step 25 [reward 0.00]
> Step 50 [reward 64.00]
> Step 75 [reward 164.00]
> Step 100 [reward 264.00]
> Step 125 [reward 364.00]
> Step 150 [reward 464.00]
> Step 175 [reward 564.00]
> Step 200 [reward 664.00]
> Step 225 [reward 764.00]
> Step 250 [reward 864.00]
Rewards 864.00 / Steps 250.00
Reward stats:
 {'max': '533.91', 'mean': '193.42', 'min': '2.95', 'std': '92.52'}
Information gain stats:
 {'max': '1.50', 'mean': '0.97', 'min': '0.57', 'std': '0.12'}
Episode time 60.82
Saved _metrics_

=== Episode 28 ===
Training on [8000/32000] data points
> Train epoch 20 [ensemble -31.64 | reward 2.95]
> Train epoch 40 [ensemble -36.03 | reward 8.85]
> Train epoch 60 [ensemble -38.07 | reward 15.28]
> Train epoch 80 [ensemble -39.38 | reward 20.44]
> Train epoch 100 [ensemble -40.33 | reward 23.75]
Ensemble loss -40.33 / Reward Loss 23.75

=== Collecting data [28] ===
> Step 25 [reward 47.00]
> Step 50 [reward 147.00]
> Step 75 [reward 247.00]
> Step 100 [reward 347.00]
> Step 125 [reward 447.00]
> Step 150 [reward 547.00]
> Step 175 [reward 647.00]
> Step 200 [reward 747.00]
> Step 225 [reward 847.00]
> Step 250 [reward 947.00]
Rewards 947.00 / Steps 250.00
Reward stats:
 {'max': '553.44', 'mean': '224.68', 'min': '13.77', 'std': '99.46'}
Information gain stats:
 {'max': '1.54', 'mean': '0.97', 'min': '0.57', 'std': '0.11'}
Episode time 62.19
Saved _metrics_

=== Episode 29 ===
Training on [8250/33000] data points
> Train epoch 20 [ensemble -32.05 | reward 3.09]
> Train epoch 40 [ensemble -36.32 | reward 9.47]
> Train epoch 60 [ensemble -38.32 | reward 16.21]
> Train epoch 80 [ensemble -39.60 | reward 21.44]
> Train epoch 100 [ensemble -40.54 | reward 24.77]
Ensemble loss -40.54 / Reward Loss 24.77

=== Collecting data [29] ===
> Step 25 [reward 43.00]
> Step 50 [reward 143.00]
> Step 75 [reward 243.00]
> Step 100 [reward 343.00]
> Step 125 [reward 443.00]
> Step 150 [reward 543.00]
> Step 175 [reward 643.00]
> Step 200 [reward 743.00]
> Step 225 [reward 843.00]
> Step 250 [reward 943.00]
Rewards 943.00 / Steps 250.00
Reward stats:
 {'max': '583.61', 'mean': '233.49', 'min': '-3.98', 'std': '105.42'}
Information gain stats:
 {'max': '1.57', 'mean': '1.00', 'min': '0.59', 'std': '0.11'}
Episode time 63.62
Saved _metrics_

=== Episode 30 ===
Training on [8500/34000] data points
> Train epoch 20 [ensemble -32.16 | reward 3.31]
> Train epoch 40 [ensemble -36.42 | reward 10.33]
> Train epoch 60 [ensemble -38.41 | reward 17.81]
> Train epoch 80 [ensemble -39.68 | reward 23.72]
> Train epoch 100 [ensemble -40.61 | reward 27.49]
Ensemble loss -40.61 / Reward Loss 27.49

=== Collecting data [30] ===
> Step 25 [reward 45.00]
> Step 50 [reward 145.00]
> Step 75 [reward 245.00]
> Step 100 [reward 345.00]
> Step 125 [reward 445.00]
> Step 150 [reward 545.00]
> Step 175 [reward 645.00]
> Step 200 [reward 745.00]
> Step 225 [reward 845.00]
> Step 250 [reward 945.00]
Rewards 945.00 / Steps 250.00
Reward stats:
 {'max': '582.95', 'mean': '229.77', 'min': '-32.53', 'std': '99.65'}
Information gain stats:
 {'max': '1.64', 'mean': '1.01', 'min': '0.61', 'std': '0.12'}
Episode time 65.12
Saved _metrics_

=== Episode 31 ===
Training on [8750/35000] data points
> Train epoch 20 [ensemble -32.35 | reward 3.52]
> Train epoch 40 [ensemble -36.58 | reward 10.82]
> Train epoch 60 [ensemble -38.55 | reward 18.46]
> Train epoch 80 [ensemble -39.82 | reward 24.39]
> Train epoch 100 [ensemble -40.74 | reward 28.18]
Ensemble loss -40.74 / Reward Loss 28.18

=== Collecting data [31] ===
> Step 25 [reward 11.00]
> Step 50 [reward 111.00]
> Step 75 [reward 211.00]
> Step 100 [reward 311.00]
> Step 125 [reward 411.00]
> Step 150 [reward 511.00]
> Step 175 [reward 611.00]
> Step 200 [reward 711.00]
> Step 225 [reward 811.00]
> Step 250 [reward 911.00]
Rewards 911.00 / Steps 250.00
Reward stats:
 {'max': '633.19', 'mean': '252.01', 'min': '39.77', 'std': '106.87'}
Information gain stats:
 {'max': '1.54', 'mean': '1.01', 'min': '0.59', 'std': '0.11'}
Episode time 66.64
Saved _metrics_

=== Episode 32 ===
Training on [9000/36000] data points
> Train epoch 20 [ensemble -32.80 | reward 3.78]
> Train epoch 40 [ensemble -36.93 | reward 11.73]
> Train epoch 60 [ensemble -38.84 | reward 20.11]
> Train epoch 80 [ensemble -40.06 | reward 26.78]
> Train epoch 100 [ensemble -40.95 | reward 31.18]
Ensemble loss -40.95 / Reward Loss 31.18

=== Collecting data [32] ===
> Step 25 [reward 0.00]
> Step 50 [reward 70.00]
> Step 75 [reward 170.00]
> Step 100 [reward 270.00]
> Step 125 [reward 370.00]
> Step 150 [reward 470.00]
> Step 175 [reward 570.00]
> Step 200 [reward 670.00]
> Step 225 [reward 770.00]
> Step 250 [reward 870.00]
Rewards 870.00 / Steps 250.00
Reward stats:
 {'max': '687.00', 'mean': '259.34', 'min': '-27.16', 'std': '118.75'}
Information gain stats:
 {'max': '1.63', 'mean': '1.03', 'min': '0.57', 'std': '0.13'}
Episode time 67.90
Saved _metrics_

=== Episode 33 ===
Training on [9250/37000] data points
> Train epoch 20 [ensemble -32.83 | reward 3.92]
> Train epoch 40 [ensemble -36.95 | reward 12.23]
> Train epoch 60 [ensemble -38.87 | reward 20.87]
> Train epoch 80 [ensemble -40.10 | reward 27.68]
> Train epoch 100 [ensemble -40.99 | reward 31.94]
Ensemble loss -40.99 / Reward Loss 31.94

=== Collecting data [33] ===
> Step 25 [reward 0.00]
> Step 50 [reward 79.00]
> Step 75 [reward 179.00]
> Step 100 [reward 279.00]
> Step 125 [reward 379.00]
> Step 150 [reward 479.00]
> Step 175 [reward 579.00]
> Step 200 [reward 679.00]
> Step 225 [reward 779.00]
> Step 250 [reward 879.00]
Rewards 879.00 / Steps 250.00
Reward stats:
 {'max': '737.69', 'mean': '287.39', 'min': '13.63', 'std': '122.72'}
Information gain stats:
 {'max': '1.62', 'mean': '1.02', 'min': '0.60', 'std': '0.13'}
Episode time 69.40
Saved _metrics_

=== Episode 34 ===
Training on [9500/38000] data points
> Train epoch 20 [ensemble -33.29 | reward 4.09]
> Train epoch 40 [ensemble -37.24 | reward 12.63]
> Train epoch 60 [ensemble -39.10 | reward 21.30]
> Train epoch 80 [ensemble -40.30 | reward 27.78]
> Train epoch 100 [ensemble -41.17 | reward 31.92]
Ensemble loss -41.17 / Reward Loss 31.92

=== Collecting data [34] ===
> Step 25 [reward 23.00]
> Step 50 [reward 123.00]
> Step 75 [reward 223.00]
> Step 100 [reward 323.00]
> Step 125 [reward 423.00]
> Step 150 [reward 523.00]
> Step 175 [reward 623.00]
> Step 200 [reward 723.00]
> Step 225 [reward 823.00]
> Step 250 [reward 923.00]
Rewards 923.00 / Steps 250.00
Reward stats:
 {'max': '717.55', 'mean': '286.66', 'min': '20.18', 'std': '117.93'}
Information gain stats:
 {'max': '1.61', 'mean': '1.03', 'min': '0.61', 'std': '0.12'}
Episode time 70.79
Saved _metrics_

=== Episode 35 ===
Training on [9750/39000] data points
> Train epoch 20 [ensemble -33.49 | reward 4.24]
> Train epoch 40 [ensemble -37.38 | reward 13.16]
> Train epoch 60 [ensemble -39.20 | reward 22.23]
> Train epoch 80 [ensemble -40.38 | reward 29.25]
> Train epoch 100 [ensemble -41.23 | reward 33.76]
Ensemble loss -41.23 / Reward Loss 33.76

=== Collecting data [35] ===
> Step 25 [reward 3.00]
> Step 50 [reward 103.00]
> Step 75 [reward 203.00]
> Step 100 [reward 303.00]
> Step 125 [reward 403.00]
> Step 150 [reward 503.00]
> Step 175 [reward 603.00]
> Step 200 [reward 703.00]
> Step 225 [reward 803.00]
> Step 250 [reward 903.00]
Rewards 903.00 / Steps 250.00
Reward stats:
 {'max': '797.54', 'mean': '313.78', 'min': '38.05', 'std': '127.58'}
Information gain stats:
 {'max': '1.58', 'mean': '1.03', 'min': '0.56', 'std': '0.13'}
Episode time 72.00
Saved _metrics_

=== Episode 36 ===
Training on [10000/40000] data points
> Train epoch 20 [ensemble -33.62 | reward 4.53]
> Train epoch 40 [ensemble -37.50 | reward 14.16]
> Train epoch 60 [ensemble -39.32 | reward 24.14]
> Train epoch 80 [ensemble -40.49 | reward 31.93]
> Train epoch 100 [ensemble -41.34 | reward 36.89]
Ensemble loss -41.34 / Reward Loss 36.89

=== Collecting data [36] ===
> Step 25 [reward 85.00]
> Step 50 [reward 185.00]
> Step 75 [reward 285.00]
> Step 100 [reward 385.00]
> Step 125 [reward 485.00]
> Step 150 [reward 585.00]
> Step 175 [reward 685.00]
> Step 200 [reward 785.00]
> Step 225 [reward 885.00]
> Step 250 [reward 985.00]
Rewards 985.00 / Steps 250.00
Reward stats:
 {'max': '783.66', 'mean': '293.07', 'min': '39.54', 'std': '124.30'}
Information gain stats:
 {'max': '1.67', 'mean': '1.04', 'min': '0.57', 'std': '0.13'}
Episode time 73.57
Saved _metrics_

=== Episode 37 ===
Training on [10250/41000] data points
> Train epoch 20 [ensemble -33.86 | reward 4.80]
> Train epoch 40 [ensemble -37.68 | reward 14.95]
> Train epoch 60 [ensemble -39.47 | reward 25.29]
> Train epoch 80 [ensemble -40.62 | reward 33.17]
> Train epoch 100 [ensemble -41.45 | reward 38.16]
Ensemble loss -41.45 / Reward Loss 38.16

=== Collecting data [37] ===
> Step 25 [reward 34.00]
> Step 50 [reward 134.00]
> Step 75 [reward 234.00]
> Step 100 [reward 334.00]
> Step 125 [reward 434.00]
> Step 150 [reward 534.00]
> Step 175 [reward 634.00]
> Step 200 [reward 734.00]
> Step 225 [reward 834.00]
> Step 250 [reward 934.00]
Rewards 934.00 / Steps 250.00
Reward stats:
 {'max': '800.60', 'mean': '326.59', 'min': '18.30', 'std': '133.21'}
Information gain stats:
 {'max': '1.61', 'mean': '1.04', 'min': '0.57', 'std': '0.13'}
Episode time 75.18
Saved _metrics_

=== Episode 38 ===
Training on [10500/42000] data points
> Train epoch 20 [ensemble -34.28 | reward 5.06]
> Train epoch 40 [ensemble -37.98 | reward 15.42]
> Train epoch 60 [ensemble -39.72 | reward 26.08]
> Train epoch 80 [ensemble -40.85 | reward 34.41]
> Train epoch 100 [ensemble -41.67 | reward 39.79]
Ensemble loss -41.67 / Reward Loss 39.79

=== Collecting data [38] ===
> Step 25 [reward 85.00]
> Step 50 [reward 185.00]
> Step 75 [reward 285.00]
> Step 100 [reward 385.00]
> Step 125 [reward 485.00]
> Step 150 [reward 585.00]
> Step 175 [reward 685.00]
> Step 200 [reward 785.00]
> Step 225 [reward 885.00]
> Step 250 [reward 985.00]
Rewards 985.00 / Steps 250.00
Reward stats:
 {'max': '884.29', 'mean': '357.15', 'min': '67.76', 'std': '129.71'}
Information gain stats:
 {'max': '1.63', 'mean': '1.07', 'min': '0.61', 'std': '0.13'}
Episode time 76.31
Saved _metrics_

=== Episode 39 ===
Training on [10750/43000] data points
> Train epoch 20 [ensemble -34.42 | reward 5.37]
> Train epoch 40 [ensemble -38.08 | reward 16.86]
> Train epoch 60 [ensemble -39.79 | reward 28.54]
> Train epoch 80 [ensemble -40.89 | reward 37.30]
> Train epoch 100 [ensemble -41.69 | reward 42.69]
Ensemble loss -41.69 / Reward Loss 42.69

=== Collecting data [39] ===
> Step 25 [reward 5.00]
> Step 50 [reward 105.00]
> Step 75 [reward 205.00]
> Step 100 [reward 305.00]
> Step 125 [reward 405.00]
> Step 150 [reward 505.00]
> Step 175 [reward 605.00]
> Step 200 [reward 705.00]
> Step 225 [reward 805.00]
> Step 250 [reward 905.00]
Rewards 905.00 / Steps 250.00
Reward stats:
 {'max': '905.72', 'mean': '337.00', 'min': '49.89', 'std': '123.30'}
Information gain stats:
 {'max': '1.62', 'mean': '1.07', 'min': '0.66', 'std': '0.12'}
Episode time 77.86
Saved _metrics_

=== Episode 40 ===
Training on [11000/44000] data points
> Train epoch 20 [ensemble -34.65 | reward 5.35]
> Train epoch 40 [ensemble -38.21 | reward 16.88]
> Train epoch 60 [ensemble -39.89 | reward 28.57]
> Train epoch 80 [ensemble -40.97 | reward 37.51]
> Train epoch 100 [ensemble -41.77 | reward 43.27]
Ensemble loss -41.77 / Reward Loss 43.27

=== Collecting data [40] ===
> Step 25 [reward 86.00]
> Step 50 [reward 186.00]
> Step 75 [reward 286.00]
> Step 100 [reward 386.00]
> Step 125 [reward 486.00]
> Step 150 [reward 586.00]
> Step 175 [reward 686.00]
> Step 200 [reward 786.00]
> Step 225 [reward 886.00]
> Step 250 [reward 986.00]
Rewards 986.00 / Steps 250.00
Reward stats:
 {'max': '967.54', 'mean': '355.75', 'min': '67.32', 'std': '127.30'}
Information gain stats:
 {'max': '1.63', 'mean': '1.06', 'min': '0.60', 'std': '0.12'}
Episode time 79.38
Saved _metrics_

=== Episode 41 ===
Training on [11250/45000] data points
> Train epoch 20 [ensemble -34.83 | reward 5.79]
> Train epoch 40 [ensemble -38.36 | reward 17.96]
> Train epoch 60 [ensemble -40.03 | reward 30.48]
> Train epoch 80 [ensemble -41.11 | reward 40.21]
> Train epoch 100 [ensemble -41.89 | reward 46.54]
Ensemble loss -41.89 / Reward Loss 46.54

=== Collecting data [41] ===
> Step 25 [reward 20.00]
> Step 50 [reward 120.00]
> Step 75 [reward 220.00]
> Step 100 [reward 320.00]
> Step 125 [reward 420.00]
> Step 150 [reward 520.00]
> Step 175 [reward 620.00]
> Step 200 [reward 720.00]
> Step 225 [reward 820.00]
> Step 250 [reward 920.00]
Rewards 920.00 / Steps 250.00
Reward stats:
 {'max': '1017.72', 'mean': '414.41', 'min': '59.31', 'std': '156.71'}
Information gain stats:
 {'max': '1.61', 'mean': '1.05', 'min': '0.53', 'std': '0.14'}
Episode time 80.35
Saved _metrics_

=== Episode 42 ===
Training on [11500/46000] data points
> Train epoch 20 [ensemble -35.04 | reward 6.09]
> Train epoch 40 [ensemble -38.51 | reward 18.88]
> Train epoch 60 [ensemble -40.16 | reward 31.64]
> Train epoch 80 [ensemble -41.21 | reward 41.28]
> Train epoch 100 [ensemble -41.99 | reward 47.36]
Ensemble loss -41.99 / Reward Loss 47.36

=== Collecting data [42] ===
> Step 25 [reward 40.00]
> Step 50 [reward 140.00]
> Step 75 [reward 240.00]
> Step 100 [reward 340.00]
> Step 125 [reward 440.00]
> Step 150 [reward 540.00]
> Step 175 [reward 640.00]
> Step 200 [reward 740.00]
> Step 225 [reward 840.00]
> Step 250 [reward 940.00]
Rewards 940.00 / Steps 250.00
Reward stats:
 {'max': '1083.50', 'mean': '414.43', 'min': '81.19', 'std': '166.99'}
Information gain stats:
 {'max': '1.63', 'mean': '1.05', 'min': '0.57', 'std': '0.14'}
Episode time 81.76
Saved _metrics_

=== Episode 43 ===
Training on [11750/47000] data points
> Train epoch 20 [ensemble -35.23 | reward 6.44]
> Train epoch 40 [ensemble -38.63 | reward 19.65]
> Train epoch 60 [ensemble -40.25 | reward 32.50]
> Train epoch 80 [ensemble -41.30 | reward 42.20]
> Train epoch 100 [ensemble -42.06 | reward 48.33]
Ensemble loss -42.06 / Reward Loss 48.33

=== Collecting data [43] ===
> Step 25 [reward 43.00]
> Step 50 [reward 143.00]
> Step 75 [reward 243.00]
> Step 100 [reward 343.00]
> Step 125 [reward 443.00]
> Step 150 [reward 543.00]
> Step 175 [reward 643.00]
> Step 200 [reward 743.00]
> Step 225 [reward 843.00]
> Step 250 [reward 943.00]
Rewards 943.00 / Steps 250.00
Reward stats:
 {'max': '1313.68', 'mean': '472.78', 'min': '70.77', 'std': '200.73'}
Information gain stats:
 {'max': '1.65', 'mean': '1.03', 'min': '0.42', 'std': '0.14'}
Episode time 83.22
Saved _metrics_

=== Episode 44 ===
Training on [12000/48000] data points
> Train epoch 20 [ensemble -35.24 | reward 6.57]
> Train epoch 40 [ensemble -38.68 | reward 19.97]
> Train epoch 60 [ensemble -40.31 | reward 33.20]
> Train epoch 80 [ensemble -41.37 | reward 43.42]
> Train epoch 100 [ensemble -42.13 | reward 50.03]
Ensemble loss -42.13 / Reward Loss 50.03

=== Collecting data [44] ===
> Step 25 [reward 85.00]
> Step 50 [reward 185.00]
> Step 75 [reward 285.00]
> Step 100 [reward 385.00]
> Step 125 [reward 485.00]
> Step 150 [reward 585.00]
> Step 175 [reward 685.00]
> Step 200 [reward 785.00]
> Step 225 [reward 885.00]
> Step 250 [reward 985.00]
Rewards 985.00 / Steps 250.00
Reward stats:
 {'max': '1218.64', 'mean': '477.64', 'min': '60.60', 'std': '191.86'}
Information gain stats:
 {'max': '1.62', 'mean': '1.04', 'min': '0.51', 'std': '0.15'}
Episode time 85.11
Saved _metrics_

=== Episode 45 ===
Training on [12250/49000] data points
> Train epoch 20 [ensemble -35.40 | reward 7.04]
> Train epoch 40 [ensemble -38.78 | reward 21.47]
> Train epoch 60 [ensemble -40.38 | reward 35.52]
> Train epoch 80 [ensemble -41.42 | reward 45.97]
> Train epoch 100 [ensemble -42.18 | reward 52.61]
Ensemble loss -42.18 / Reward Loss 52.61

=== Collecting data [45] ===
> Step 25 [reward 85.00]
> Step 50 [reward 185.00]
> Step 75 [reward 285.00]
> Step 100 [reward 385.00]
> Step 125 [reward 485.00]
> Step 150 [reward 585.00]
> Step 175 [reward 685.00]
> Step 200 [reward 785.00]
> Step 225 [reward 885.00]
> Step 250 [reward 985.00]
Rewards 985.00 / Steps 250.00
Reward stats:
 {'max': '1230.45', 'mean': '493.09', 'min': '101.85', 'std': '188.15'}
Information gain stats:
 {'max': '1.66', 'mean': '1.04', 'min': '0.47', 'std': '0.15'}
Episode time 86.43
Saved _metrics_

=== Episode 46 ===
Training on [12500/50000] data points
> Train epoch 20 [ensemble -35.53 | reward 7.11]
> Train epoch 40 [ensemble -38.87 | reward 21.87]
> Train epoch 60 [ensemble -40.47 | reward 36.50]
> Train epoch 80 [ensemble -41.49 | reward 47.54]
> Train epoch 100 [ensemble -42.24 | reward 54.63]
Ensemble loss -42.24 / Reward Loss 54.63

=== Collecting data [46] ===
> Step 25 [reward 55.00]
> Step 50 [reward 155.00]
> Step 75 [reward 255.00]
> Step 100 [reward 355.00]
> Step 125 [reward 455.00]
> Step 150 [reward 555.00]
> Step 175 [reward 655.00]
> Step 200 [reward 755.00]
> Step 225 [reward 855.00]
> Step 250 [reward 955.00]
Rewards 955.00 / Steps 250.00
Reward stats:
 {'max': '1341.14', 'mean': '554.40', 'min': '121.17', 'std': '211.57'}
Information gain stats:
 {'max': '1.61', 'mean': '1.03', 'min': '0.41', 'std': '0.16'}
Episode time 87.46
Saved _metrics_

=== Episode 47 ===
Training on [12750/51000] data points
> Train epoch 20 [ensemble -35.60 | reward 7.68]
> Train epoch 40 [ensemble -38.94 | reward 23.69]
> Train epoch 60 [ensemble -40.54 | reward 39.35]
> Train epoch 80 [ensemble -41.56 | reward 51.23]
> Train epoch 100 [ensemble -42.31 | reward 58.98]
Ensemble loss -42.31 / Reward Loss 58.98

=== Collecting data [47] ===
> Step 25 [reward 87.00]
> Step 50 [reward 187.00]
> Step 75 [reward 287.00]
> Step 100 [reward 387.00]
> Step 125 [reward 487.00]
> Step 150 [reward 587.00]
> Step 175 [reward 687.00]
> Step 200 [reward 787.00]
> Step 225 [reward 887.00]
> Step 250 [reward 987.00]
Rewards 987.00 / Steps 250.00
Reward stats:
 {'max': '1317.92', 'mean': '536.15', 'min': '104.30', 'std': '196.15'}
Information gain stats:
 {'max': '1.67', 'mean': '1.05', 'min': '0.41', 'std': '0.16'}
Episode time 89.42
Saved _metrics_

=== Episode 48 ===
Training on [13000/52000] data points
> Train epoch 20 [ensemble -35.64 | reward 8.19]
> Train epoch 40 [ensemble -38.98 | reward 25.12]
> Train epoch 60 [ensemble -40.56 | reward 41.20]
> Train epoch 80 [ensemble -41.58 | reward 53.29]
> Train epoch 100 [ensemble -42.32 | reward 61.04]
Ensemble loss -42.32 / Reward Loss 61.04

=== Collecting data [48] ===
> Step 25 [reward 86.00]
> Step 50 [reward 186.00]
> Step 75 [reward 286.00]
> Step 100 [reward 386.00]
> Step 125 [reward 486.00]
> Step 150 [reward 586.00]
> Step 175 [reward 686.00]
> Step 200 [reward 786.00]
> Step 225 [reward 886.00]
> Step 250 [reward 986.00]
Rewards 986.00 / Steps 250.00
Reward stats:
 {'max': '1430.22', 'mean': '555.81', 'min': '120.20', 'std': '211.09'}
Information gain stats:
 {'max': '1.66', 'mean': '1.04', 'min': '0.40', 'std': '0.16'}
Episode time 90.21
Saved _metrics_

=== Episode 49 ===
Training on [13250/53000] data points
> Train epoch 20 [ensemble -35.80 | reward 8.13]
> Train epoch 40 [ensemble -39.12 | reward 24.24]
> Train epoch 60 [ensemble -40.68 | reward 39.86]
> Train epoch 80 [ensemble -41.69 | reward 51.50]
> Train epoch 100 [ensemble -42.42 | reward 58.95]
Ensemble loss -42.42 / Reward Loss 58.95

=== Collecting data [49] ===
> Step 25 [reward 87.00]
> Step 50 [reward 187.00]
> Step 75 [reward 287.00]
> Step 100 [reward 387.00]
> Step 125 [reward 487.00]
> Step 150 [reward 587.00]
> Step 175 [reward 687.00]
> Step 200 [reward 787.00]
> Step 225 [reward 887.00]
> Step 250 [reward 987.00]
Rewards 987.00 / Steps 250.00
Reward stats:
 {'max': '1181.94', 'mean': '482.15', 'min': '134.96', 'std': '154.51'}
Information gain stats:
 {'max': '1.62', 'mean': '1.09', 'min': '0.53', 'std': '0.14'}
Episode time 91.98
Saved _metrics_