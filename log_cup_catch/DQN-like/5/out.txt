01:33:37

=== Loading experiment [device: cuda] ===

{'action_noise': None,
 'action_repeat': 4,
 'batch_size': 50,
 'coverage': False,
 'ensemble_size': 10,
 'env_name': 'DeepMindCatch',
 'epsilon': 1e-08,
 'expl_scale': 0.1,
 'expl_strategy': 'information',
 'grad_clip_norm': 1000,
 'hidden_size': 200,
 'learning_rate': 0.001,
 'logdir': 'cup_catch_DQN-like',
 'max_episode_len': 1000,
 'n_candidates': 500,
 'n_episodes': 50,
 'n_seed_episodes': 5,
 'n_train_epochs': 100,
 'optimisation_iters': 5,
 'plan_horizon': 12,
 'record_every': None,
 'reward_scale': 1.0,
 'seed': 5,
 'strategy': 'information',
 'top_candidates': 50,
 'use_exploration': True,
 'use_mean': False,
 'use_reward': True}

Collected seeds: [5 episodes | 1250 frames]

=== Episode 1 ===
Training on [1250/5000] data points
> Train epoch 20 [ensemble -18.79 | reward 0.22]
> Train epoch 40 [ensemble -26.43 | reward 0.17]
> Train epoch 60 [ensemble -30.28 | reward 0.14]
> Train epoch 80 [ensemble -32.77 | reward 0.11]
> Train epoch 100 [ensemble -34.58 | reward 0.09]
Ensemble loss -34.58 / Reward Loss 0.09

=== Collecting data [1] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '138.80', 'mean': '43.08', 'min': '-12.21', 'std': '25.59'}
Information gain stats:
 {'max': '2.05', 'mean': '1.24', 'min': '0.57', 'std': '0.16'}
Episode time 23.85
Saved _metrics_

=== Episode 2 ===
Training on [1500/6000] data points
> Train epoch 20 [ensemble -20.49 | reward 0.18]
> Train epoch 40 [ensemble -27.65 | reward 0.14]
> Train epoch 60 [ensemble -31.21 | reward 0.12]
> Train epoch 80 [ensemble -33.49 | reward 0.09]
> Train epoch 100 [ensemble -35.16 | reward 0.08]
Ensemble loss -35.16 / Reward Loss 0.08

=== Collecting data [2] ===
> Step 25 [reward 0.00]
> Step 50 [reward 15.00]
> Step 75 [reward 15.00]
> Step 100 [reward 45.00]
> Step 125 [reward 48.00]
> Step 150 [reward 128.00]
> Step 175 [reward 164.00]
> Step 200 [reward 164.00]
> Step 225 [reward 178.00]
> Step 250 [reward 178.00]
Rewards 178.00 / Steps 250.00
Reward stats:
 {'max': '90.49', 'mean': '22.37', 'min': '-5.68', 'std': '14.31'}
Information gain stats:
 {'max': '1.62', 'mean': '1.01', 'min': '0.45', 'std': '0.11'}
Episode time 25.31
Saved _metrics_

=== Episode 3 ===
Training on [1750/7000] data points
> Train epoch 20 [ensemble -20.40 | reward 0.33]
> Train epoch 40 [ensemble -27.47 | reward 0.30]
> Train epoch 60 [ensemble -31.01 | reward 0.29]
> Train epoch 80 [ensemble -33.27 | reward 0.27]
> Train epoch 100 [ensemble -34.90 | reward 0.23]
Ensemble loss -34.90 / Reward Loss 0.23

=== Collecting data [3] ===
> Step 25 [reward 49.00]
> Step 50 [reward 144.00]
> Step 75 [reward 228.00]
> Step 100 [reward 318.00]
> Step 125 [reward 413.00]
> Step 150 [reward 490.00]
> Step 175 [reward 582.00]
> Step 200 [reward 667.00]
> Step 225 [reward 732.00]
> Step 250 [reward 762.00]
Rewards 762.00 / Steps 250.00
Reward stats:
 {'max': '123.10', 'mean': '35.03', 'min': '-5.46', 'std': '18.20'}
Information gain stats:
 {'max': '1.58', 'mean': '1.00', 'min': '0.46', 'std': '0.11'}
Episode time 26.58
Saved _metrics_

=== Episode 4 ===
Training on [2000/8000] data points
> Train epoch 20 [ensemble -20.61 | reward 0.59]
> Train epoch 40 [ensemble -27.71 | reward 0.60]
> Train epoch 60 [ensemble -31.21 | reward 0.66]
> Train epoch 80 [ensemble -33.43 | reward 0.69]
> Train epoch 100 [ensemble -35.03 | reward 0.68]
Ensemble loss -35.03 / Reward Loss 0.68

=== Collecting data [4] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '232.36', 'mean': '49.85', 'min': '-16.97', 'std': '35.10'}
Information gain stats:
 {'max': '1.52', 'mean': '0.88', 'min': '0.46', 'std': '0.12'}
Episode time 28.00
Saved _metrics_

=== Episode 5 ===
Training on [2250/9000] data points
> Train epoch 20 [ensemble -20.66 | reward 0.66]
> Train epoch 40 [ensemble -27.51 | reward 0.74]
> Train epoch 60 [ensemble -30.87 | reward 0.82]
> Train epoch 80 [ensemble -33.02 | reward 0.85]
> Train epoch 100 [ensemble -34.59 | reward 0.83]
Ensemble loss -34.59 / Reward Loss 0.83

=== Collecting data [5] ===
> Step 25 [reward 44.00]
> Step 50 [reward 123.00]
> Step 75 [reward 191.00]
> Step 100 [reward 280.00]
> Step 125 [reward 363.00]
> Step 150 [reward 432.00]
> Step 175 [reward 511.00]
> Step 200 [reward 598.00]
> Step 225 [reward 673.00]
> Step 250 [reward 755.00]
Rewards 755.00 / Steps 250.00
Reward stats:
 {'max': '198.86', 'mean': '49.24', 'min': '-1.27', 'std': '28.67'}
Information gain stats:
 {'max': '1.49', 'mean': '0.98', 'min': '0.54', 'std': '0.11'}
Episode time 29.45
Saved _metrics_

=== Episode 6 ===
Training on [2500/10000] data points
> Train epoch 20 [ensemble -21.67 | reward 0.93]
> Train epoch 40 [ensemble -28.22 | reward 1.18]
> Train epoch 60 [ensemble -31.40 | reward 1.42]
> Train epoch 80 [ensemble -33.45 | reward 1.54]
> Train epoch 100 [ensemble -34.96 | reward 1.56]
Ensemble loss -34.96 / Reward Loss 1.56

=== Collecting data [6] ===
> Step 25 [reward 14.00]
> Step 50 [reward 14.00]
> Step 75 [reward 14.00]
> Step 100 [reward 62.00]
> Step 125 [reward 121.00]
> Step 150 [reward 172.00]
> Step 175 [reward 228.00]
> Step 200 [reward 302.00]
> Step 225 [reward 362.00]
> Step 250 [reward 432.00]
Rewards 432.00 / Steps 250.00
Reward stats:
 {'max': '250.94', 'mean': '80.63', 'min': '-27.17', 'std': '40.79'}
Information gain stats:
 {'max': '1.47', 'mean': '0.92', 'min': '0.49', 'std': '0.11'}
Episode time 30.81
Saved _metrics_

=== Episode 7 ===
Training on [2750/11000] data points
> Train epoch 20 [ensemble -22.37 | reward 1.22]
> Train epoch 40 [ensemble -28.52 | reward 1.62]
> Train epoch 60 [ensemble -31.51 | reward 2.03]
> Train epoch 80 [ensemble -33.48 | reward 2.29]
> Train epoch 100 [ensemble -34.95 | reward 2.38]
Ensemble loss -34.95 / Reward Loss 2.38

=== Collecting data [7] ===
> Step 25 [reward 31.00]
> Step 50 [reward 124.00]
> Step 75 [reward 221.00]
> Step 100 [reward 314.00]
> Step 125 [reward 411.00]
> Step 150 [reward 511.00]
> Step 175 [reward 611.00]
> Step 200 [reward 709.00]
> Step 225 [reward 804.00]
> Step 250 [reward 898.00]
Rewards 898.00 / Steps 250.00
Reward stats:
 {'max': '257.77', 'mean': '98.47', 'min': '-4.80', 'std': '38.74'}
Information gain stats:
 {'max': '1.44', 'mean': '0.92', 'min': '0.46', 'std': '0.10'}
Episode time 32.21
Saved _metrics_

=== Episode 8 ===
Training on [3000/12000] data points
> Train epoch 20 [ensemble -23.26 | reward 1.43]
> Train epoch 40 [ensemble -29.02 | reward 2.02]
> Train epoch 60 [ensemble -31.94 | reward 2.61]
> Train epoch 80 [ensemble -33.88 | reward 3.04]
> Train epoch 100 [ensemble -35.34 | reward 3.23]
Ensemble loss -35.34 / Reward Loss 3.23

=== Collecting data [8] ===
> Step 25 [reward 25.00]
> Step 50 [reward 125.00]
> Step 75 [reward 225.00]
> Step 100 [reward 325.00]
> Step 125 [reward 425.00]
> Step 150 [reward 525.00]
> Step 175 [reward 625.00]
> Step 200 [reward 725.00]
> Step 225 [reward 825.00]
> Step 250 [reward 925.00]
Rewards 925.00 / Steps 250.00
Reward stats:
 {'max': '438.35', 'mean': '155.67', 'min': '-20.90', 'std': '73.85'}
Information gain stats:
 {'max': '1.53', 'mean': '0.77', 'min': '0.32', 'std': '0.16'}
Episode time 33.68
Saved _metrics_

=== Episode 9 ===
Training on [3250/13000] data points
> Train epoch 20 [ensemble -24.19 | reward 1.41]
> Train epoch 40 [ensemble -29.79 | reward 2.14]
> Train epoch 60 [ensemble -32.61 | reward 2.90]
> Train epoch 80 [ensemble -34.48 | reward 3.45]
> Train epoch 100 [ensemble -35.88 | reward 3.73]
Ensemble loss -35.88 / Reward Loss 3.73

=== Collecting data [9] ===
> Step 25 [reward 54.00]
> Step 50 [reward 154.00]
> Step 75 [reward 254.00]
> Step 100 [reward 354.00]
> Step 125 [reward 454.00]
> Step 150 [reward 554.00]
> Step 175 [reward 654.00]
> Step 200 [reward 754.00]
> Step 225 [reward 854.00]
> Step 250 [reward 954.00]
Rewards 954.00 / Steps 250.00
Reward stats:
 {'max': '483.09', 'mean': '179.36', 'min': '-13.73', 'std': '88.86'}
Information gain stats:
 {'max': '1.50', 'mean': '0.76', 'min': '0.28', 'std': '0.17'}
Episode time 35.17
Saved _metrics_

=== Episode 10 ===
Training on [3500/14000] data points
> Train epoch 20 [ensemble -25.07 | reward 1.48]
> Train epoch 40 [ensemble -30.49 | reward 2.50]
> Train epoch 60 [ensemble -33.20 | reward 3.60]
> Train epoch 80 [ensemble -35.00 | reward 4.40]
> Train epoch 100 [ensemble -36.34 | reward 4.83]
Ensemble loss -36.34 / Reward Loss 4.83

=== Collecting data [10] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '496.47', 'mean': '95.98', 'min': '-56.00', 'std': '74.57'}
Information gain stats:
 {'max': '1.51', 'mean': '0.88', 'min': '0.34', 'std': '0.14'}
Episode time 36.40
Saved _metrics_

=== Episode 11 ===
Training on [3750/15000] data points
> Train epoch 20 [ensemble -25.16 | reward 1.59]
> Train epoch 40 [ensemble -30.58 | reward 2.51]
> Train epoch 60 [ensemble -33.32 | reward 3.48]
> Train epoch 80 [ensemble -35.16 | reward 4.21]
> Train epoch 100 [ensemble -36.54 | reward 4.61]
Ensemble loss -36.54 / Reward Loss 4.61

=== Collecting data [11] ===
> Step 25 [reward 49.00]
> Step 50 [reward 149.00]
> Step 75 [reward 249.00]
> Step 100 [reward 349.00]
> Step 125 [reward 449.00]
> Step 150 [reward 549.00]
> Step 175 [reward 649.00]
> Step 200 [reward 749.00]
> Step 225 [reward 849.00]
> Step 250 [reward 949.00]
Rewards 949.00 / Steps 250.00
Reward stats:
 {'max': '516.86', 'mean': '211.19', 'min': '-29.24', 'std': '91.50'}
Information gain stats:
 {'max': '1.55', 'mean': '0.82', 'min': '0.36', 'std': '0.16'}
Episode time 38.01
Saved _metrics_

=== Episode 12 ===
Training on [4000/16000] data points
> Train epoch 20 [ensemble -26.07 | reward 1.71]
> Train epoch 40 [ensemble -31.23 | reward 2.97]
> Train epoch 60 [ensemble -33.85 | reward 4.21]
> Train epoch 80 [ensemble -35.61 | reward 5.12]
> Train epoch 100 [ensemble -36.93 | reward 5.65]
Ensemble loss -36.93 / Reward Loss 5.65

=== Collecting data [12] ===
> Step 25 [reward 95.00]
> Step 50 [reward 195.00]
> Step 75 [reward 295.00]
> Step 100 [reward 395.00]
> Step 125 [reward 495.00]
> Step 150 [reward 595.00]
> Step 175 [reward 695.00]
> Step 200 [reward 795.00]
> Step 225 [reward 895.00]
> Step 250 [reward 995.00]
Rewards 995.00 / Steps 250.00
Reward stats:
 {'max': '600.87', 'mean': '229.39', 'min': '7.34', 'std': '105.23'}
Information gain stats:
 {'max': '1.51', 'mean': '0.79', 'min': '0.30', 'std': '0.18'}
Episode time 39.22
Saved _metrics_

=== Episode 13 ===
Training on [4250/17000] data points
> Train epoch 20 [ensemble -26.82 | reward 1.84]
> Train epoch 40 [ensemble -31.86 | reward 3.34]
> Train epoch 60 [ensemble -34.41 | reward 4.77]
> Train epoch 80 [ensemble -36.11 | reward 5.84]
> Train epoch 100 [ensemble -37.39 | reward 6.46]
Ensemble loss -37.39 / Reward Loss 6.46

=== Collecting data [13] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 1.00]
> Step 125 [reward 100.00]
> Step 150 [reward 200.00]
> Step 175 [reward 300.00]
> Step 200 [reward 400.00]
> Step 225 [reward 500.00]
> Step 250 [reward 600.00]
Rewards 600.00 / Steps 250.00
Reward stats:
 {'max': '670.46', 'mean': '213.30', 'min': '10.79', 'std': '115.81'}
Information gain stats:
 {'max': '1.59', 'mean': '0.89', 'min': '0.34', 'std': '0.20'}
Episode time 40.57
Saved _metrics_

=== Episode 14 ===
Training on [4500/18000] data points
> Train epoch 20 [ensemble -27.32 | reward 1.67]
> Train epoch 40 [ensemble -32.22 | reward 3.16]
> Train epoch 60 [ensemble -34.69 | reward 4.78]
> Train epoch 80 [ensemble -36.34 | reward 6.05]
> Train epoch 100 [ensemble -37.58 | reward 6.82]
Ensemble loss -37.58 / Reward Loss 6.82

=== Collecting data [14] ===
> Step 25 [reward 29.00]
> Step 50 [reward 129.00]
> Step 75 [reward 229.00]
> Step 100 [reward 329.00]
> Step 125 [reward 429.00]
> Step 150 [reward 529.00]
> Step 175 [reward 629.00]
> Step 200 [reward 729.00]
> Step 225 [reward 829.00]
> Step 250 [reward 929.00]
Rewards 929.00 / Steps 250.00
Reward stats:
 {'max': '668.38', 'mean': '256.98', 'min': '-36.76', 'std': '123.15'}
Information gain stats:
 {'max': '1.60', 'mean': '0.81', 'min': '0.32', 'std': '0.18'}
Episode time 42.22
Saved _metrics_

=== Episode 15 ===
Training on [4750/19000] data points
> Train epoch 20 [ensemble -27.86 | reward 1.92]
> Train epoch 40 [ensemble -32.61 | reward 3.67]
> Train epoch 60 [ensemble -35.00 | reward 5.51]
> Train epoch 80 [ensemble -36.60 | reward 6.96]
> Train epoch 100 [ensemble -37.80 | reward 7.84]
Ensemble loss -37.80 / Reward Loss 7.84

=== Collecting data [15] ===
> Step 25 [reward 51.00]
> Step 50 [reward 151.00]
> Step 75 [reward 251.00]
> Step 100 [reward 351.00]
> Step 125 [reward 451.00]
> Step 150 [reward 551.00]
> Step 175 [reward 651.00]
> Step 200 [reward 751.00]
> Step 225 [reward 851.00]
> Step 250 [reward 951.00]
Rewards 951.00 / Steps 250.00
Reward stats:
 {'max': '733.51', 'mean': '267.88', 'min': '-19.07', 'std': '130.30'}
Information gain stats:
 {'max': '1.53', 'mean': '0.81', 'min': '0.32', 'std': '0.18'}
Episode time 43.78
Saved _metrics_

=== Episode 16 ===
Training on [5000/20000] data points
> Train epoch 20 [ensemble -28.57 | reward 1.91]
> Train epoch 40 [ensemble -33.14 | reward 3.79]
> Train epoch 60 [ensemble -35.46 | reward 5.79]
> Train epoch 80 [ensemble -37.01 | reward 7.43]
> Train epoch 100 [ensemble -38.18 | reward 8.47]
Ensemble loss -38.18 / Reward Loss 8.47

=== Collecting data [16] ===
> Step 25 [reward 52.00]
> Step 50 [reward 152.00]
> Step 75 [reward 252.00]
> Step 100 [reward 352.00]
> Step 125 [reward 452.00]
> Step 150 [reward 552.00]
> Step 175 [reward 652.00]
> Step 200 [reward 752.00]
> Step 225 [reward 852.00]
> Step 250 [reward 952.00]
Rewards 952.00 / Steps 250.00
Reward stats:
 {'max': '711.11', 'mean': '278.79', 'min': '-6.94', 'std': '122.66'}
Information gain stats:
 {'max': '1.50', 'mean': '0.82', 'min': '0.30', 'std': '0.18'}
Episode time 45.23
Saved _metrics_

=== Episode 17 ===
Training on [5250/21000] data points
> Train epoch 20 [ensemble -29.11 | reward 2.01]
> Train epoch 40 [ensemble -33.58 | reward 4.32]
> Train epoch 60 [ensemble -35.84 | reward 6.76]
> Train epoch 80 [ensemble -37.34 | reward 8.69]
> Train epoch 100 [ensemble -38.48 | reward 9.87]
Ensemble loss -38.48 / Reward Loss 9.87

=== Collecting data [17] ===
> Step 25 [reward 52.00]
> Step 50 [reward 152.00]
> Step 75 [reward 252.00]
> Step 100 [reward 352.00]
> Step 125 [reward 452.00]
> Step 150 [reward 552.00]
> Step 175 [reward 652.00]
> Step 200 [reward 752.00]
> Step 225 [reward 852.00]
> Step 250 [reward 952.00]
Rewards 952.00 / Steps 250.00
Reward stats:
 {'max': '778.49', 'mean': '318.20', 'min': '-2.77', 'std': '143.34'}
Information gain stats:
 {'max': '1.54', 'mean': '0.81', 'min': '0.33', 'std': '0.19'}
Episode time 46.70
Saved _metrics_

=== Episode 18 ===
Training on [5500/22000] data points
> Train epoch 20 [ensemble -29.63 | reward 1.98]
> Train epoch 40 [ensemble -33.96 | reward 4.53]
> Train epoch 60 [ensemble -36.14 | reward 7.28]
> Train epoch 80 [ensemble -37.60 | reward 9.50]
> Train epoch 100 [ensemble -38.70 | reward 10.91]
Ensemble loss -38.70 / Reward Loss 10.91

=== Collecting data [18] ===
> Step 25 [reward 51.00]
> Step 50 [reward 151.00]
> Step 75 [reward 251.00]
> Step 100 [reward 351.00]
> Step 125 [reward 451.00]
> Step 150 [reward 551.00]
> Step 175 [reward 651.00]
> Step 200 [reward 751.00]
> Step 225 [reward 851.00]
> Step 250 [reward 951.00]
Rewards 951.00 / Steps 250.00
Reward stats:
 {'max': '808.91', 'mean': '315.30', 'min': '-24.53', 'std': '140.51'}
Information gain stats:
 {'max': '1.52', 'mean': '0.82', 'min': '0.30', 'std': '0.18'}
Episode time 47.97
Saved _metrics_

=== Episode 19 ===
Training on [5750/23000] data points
> Train epoch 20 [ensemble -30.16 | reward 2.32]
> Train epoch 40 [ensemble -34.37 | reward 5.20]
> Train epoch 60 [ensemble -36.48 | reward 8.23]
> Train epoch 80 [ensemble -37.90 | reward 10.59]
> Train epoch 100 [ensemble -38.98 | reward 12.09]
Ensemble loss -38.98 / Reward Loss 12.09

=== Collecting data [19] ===
> Step 25 [reward 51.00]
> Step 50 [reward 151.00]
> Step 75 [reward 251.00]
> Step 100 [reward 351.00]
> Step 125 [reward 451.00]
> Step 150 [reward 551.00]
> Step 175 [reward 651.00]
> Step 200 [reward 751.00]
> Step 225 [reward 851.00]
> Step 250 [reward 951.00]
Rewards 951.00 / Steps 250.00
Reward stats:
 {'max': '836.87', 'mean': '333.64', 'min': '-54.42', 'std': '151.28'}
Information gain stats:
 {'max': '1.57', 'mean': '0.83', 'min': '0.32', 'std': '0.20'}
Episode time 49.44
Saved _metrics_

=== Episode 20 ===
Training on [6000/24000] data points
> Train epoch 20 [ensemble -30.48 | reward 2.34]
> Train epoch 40 [ensemble -34.64 | reward 5.56]
> Train epoch 60 [ensemble -36.74 | reward 8.86]
> Train epoch 80 [ensemble -38.16 | reward 11.42]
> Train epoch 100 [ensemble -39.22 | reward 12.98]
Ensemble loss -39.22 / Reward Loss 12.98

=== Collecting data [20] ===
> Step 25 [reward 53.00]
> Step 50 [reward 153.00]
> Step 75 [reward 253.00]
> Step 100 [reward 353.00]
> Step 125 [reward 453.00]
> Step 150 [reward 553.00]
> Step 175 [reward 653.00]
> Step 200 [reward 753.00]
> Step 225 [reward 853.00]
> Step 250 [reward 953.00]
Rewards 953.00 / Steps 250.00
Reward stats:
 {'max': '847.34', 'mean': '354.37', 'min': '-16.68', 'std': '145.93'}
Information gain stats:
 {'max': '1.67', 'mean': '0.84', 'min': '0.34', 'std': '0.18'}
Episode time 50.62
Saved _metrics_

=== Episode 21 ===
Training on [6250/25000] data points
> Train epoch 20 [ensemble -30.99 | reward 2.63]
> Train epoch 40 [ensemble -35.00 | reward 6.24]
> Train epoch 60 [ensemble -37.04 | reward 9.91]
> Train epoch 80 [ensemble -38.41 | reward 12.71]
> Train epoch 100 [ensemble -39.43 | reward 14.45]
Ensemble loss -39.43 / Reward Loss 14.45

=== Collecting data [21] ===
> Step 25 [reward 40.00]
> Step 50 [reward 140.00]
> Step 75 [reward 240.00]
> Step 100 [reward 340.00]
> Step 125 [reward 440.00]
> Step 150 [reward 540.00]
> Step 175 [reward 640.00]
> Step 200 [reward 740.00]
> Step 225 [reward 840.00]
> Step 250 [reward 940.00]
Rewards 940.00 / Steps 250.00
Reward stats:
 {'max': '899.30', 'mean': '378.08', 'min': '16.71', 'std': '159.18'}
Information gain stats:
 {'max': '1.61', 'mean': '0.85', 'min': '0.32', 'std': '0.19'}
Episode time 52.36
Saved _metrics_

=== Episode 22 ===
Training on [6500/26000] data points
> Train epoch 20 [ensemble -31.42 | reward 2.66]
> Train epoch 40 [ensemble -35.35 | reward 6.34]
> Train epoch 60 [ensemble -37.35 | reward 10.22]
> Train epoch 80 [ensemble -38.69 | reward 13.34]
> Train epoch 100 [ensemble -39.69 | reward 15.33]
Ensemble loss -39.69 / Reward Loss 15.33

=== Collecting data [22] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 80.00]
> Step 100 [reward 180.00]
> Step 125 [reward 280.00]
> Step 150 [reward 380.00]
> Step 175 [reward 480.00]
> Step 200 [reward 580.00]
> Step 225 [reward 680.00]
> Step 250 [reward 780.00]
Rewards 780.00 / Steps 250.00
Reward stats:
 {'max': '912.16', 'mean': '374.08', 'min': '-63.77', 'std': '174.77'}
Information gain stats:
 {'max': '1.61', 'mean': '0.89', 'min': '0.33', 'std': '0.20'}
Episode time 53.60
Saved _metrics_

=== Episode 23 ===
Training on [6750/27000] data points
> Train epoch 20 [ensemble -31.70 | reward 2.72]
> Train epoch 40 [ensemble -35.53 | reward 6.70]
> Train epoch 60 [ensemble -37.48 | reward 10.97]
> Train epoch 80 [ensemble -38.79 | reward 14.40]
> Train epoch 100 [ensemble -39.77 | reward 16.60]
Ensemble loss -39.77 / Reward Loss 16.60

=== Collecting data [23] ===
> Step 25 [reward 76.00]
> Step 50 [reward 176.00]
> Step 75 [reward 276.00]
> Step 100 [reward 376.00]
> Step 125 [reward 476.00]
> Step 150 [reward 576.00]
> Step 175 [reward 676.00]
> Step 200 [reward 776.00]
> Step 225 [reward 876.00]
> Step 250 [reward 976.00]
Rewards 976.00 / Steps 250.00
Reward stats:
 {'max': '958.76', 'mean': '401.05', 'min': '30.73', 'std': '162.65'}
Information gain stats:
 {'max': '1.56', 'mean': '0.86', 'min': '0.32', 'std': '0.19'}
Episode time 55.12
Saved _metrics_

=== Episode 24 ===
Training on [7000/28000] data points
> Train epoch 20 [ensemble -32.03 | reward 2.89]
> Train epoch 40 [ensemble -35.80 | reward 7.22]
> Train epoch 60 [ensemble -37.72 | reward 11.82]
> Train epoch 80 [ensemble -39.00 | reward 15.51]
> Train epoch 100 [ensemble -39.97 | reward 17.90]
Ensemble loss -39.97 / Reward Loss 17.90

=== Collecting data [24] ===
> Step 25 [reward 91.00]
> Step 50 [reward 191.00]
> Step 75 [reward 291.00]
> Step 100 [reward 391.00]
> Step 125 [reward 491.00]
> Step 150 [reward 591.00]
> Step 175 [reward 691.00]
> Step 200 [reward 791.00]
> Step 225 [reward 891.00]
> Step 250 [reward 991.00]
Rewards 991.00 / Steps 250.00
Reward stats:
 {'max': '984.61', 'mean': '398.24', 'min': '36.55', 'std': '159.46'}
Information gain stats:
 {'max': '1.60', 'mean': '0.87', 'min': '0.35', 'std': '0.18'}
Episode time 56.46
Saved _metrics_

=== Episode 25 ===
Training on [7250/29000] data points
> Train epoch 20 [ensemble -32.54 | reward 3.04]
> Train epoch 40 [ensemble -36.16 | reward 7.67]
> Train epoch 60 [ensemble -38.01 | reward 12.56]
> Train epoch 80 [ensemble -39.25 | reward 16.48]
> Train epoch 100 [ensemble -40.19 | reward 19.02]
Ensemble loss -40.19 / Reward Loss 19.02

=== Collecting data [25] ===
> Step 25 [reward 46.00]
> Step 50 [reward 146.00]
> Step 75 [reward 246.00]
> Step 100 [reward 346.00]
> Step 125 [reward 446.00]
> Step 150 [reward 546.00]
> Step 175 [reward 646.00]
> Step 200 [reward 746.00]
> Step 225 [reward 846.00]
> Step 250 [reward 946.00]
Rewards 946.00 / Steps 250.00
Reward stats:
 {'max': '1005.78', 'mean': '402.39', 'min': '39.81', 'std': '150.44'}
Information gain stats:
 {'max': '1.62', 'mean': '0.89', 'min': '0.36', 'std': '0.17'}
Episode time 57.74
Saved _metrics_

=== Episode 26 ===
Training on [7500/30000] data points
> Train epoch 20 [ensemble -32.96 | reward 3.22]
> Train epoch 40 [ensemble -36.48 | reward 8.28]
> Train epoch 60 [ensemble -38.27 | reward 13.64]
> Train epoch 80 [ensemble -39.48 | reward 17.88]
> Train epoch 100 [ensemble -40.38 | reward 20.60]
Ensemble loss -40.38 / Reward Loss 20.60

=== Collecting data [26] ===
> Step 25 [reward 54.00]
> Step 50 [reward 154.00]
> Step 75 [reward 254.00]
> Step 100 [reward 354.00]
> Step 125 [reward 454.00]
> Step 150 [reward 554.00]
> Step 175 [reward 654.00]
> Step 200 [reward 754.00]
> Step 225 [reward 854.00]
> Step 250 [reward 954.00]
Rewards 954.00 / Steps 250.00
Reward stats:
 {'max': '1009.20', 'mean': '423.71', 'min': '28.84', 'std': '167.63'}
Information gain stats:
 {'max': '1.57', 'mean': '0.88', 'min': '0.34', 'std': '0.18'}
Episode time 60.20
Saved _metrics_

=== Episode 27 ===
Training on [7750/31000] data points
> Train epoch 20 [ensemble -33.25 | reward 3.32]
> Train epoch 40 [ensemble -36.71 | reward 8.72]
> Train epoch 60 [ensemble -38.48 | reward 14.41]
> Train epoch 80 [ensemble -39.67 | reward 18.95]
> Train epoch 100 [ensemble -40.57 | reward 21.88]
Ensemble loss -40.57 / Reward Loss 21.88

=== Collecting data [27] ===
> Step 25 [reward 97.00]
> Step 50 [reward 197.00]
> Step 75 [reward 297.00]
> Step 100 [reward 397.00]
> Step 125 [reward 497.00]
> Step 150 [reward 597.00]
> Step 175 [reward 697.00]
> Step 200 [reward 797.00]
> Step 225 [reward 897.00]
> Step 250 [reward 997.00]
Rewards 997.00 / Steps 250.00
Reward stats:
 {'max': '1083.39', 'mean': '470.34', 'min': '54.29', 'std': '177.18'}
Information gain stats:
 {'max': '1.70', 'mean': '0.87', 'min': '0.33', 'std': '0.19'}
Episode time 61.18
Saved _metrics_

=== Episode 28 ===
Training on [8000/32000] data points
> Train epoch 20 [ensemble -33.65 | reward 3.68]
> Train epoch 40 [ensemble -36.99 | reward 9.54]
> Train epoch 60 [ensemble -38.70 | reward 15.59]
> Train epoch 80 [ensemble -39.85 | reward 20.41]
> Train epoch 100 [ensemble -40.72 | reward 23.51]
Ensemble loss -40.72 / Reward Loss 23.51

=== Collecting data [28] ===
> Step 25 [reward 52.00]
> Step 50 [reward 152.00]
> Step 75 [reward 252.00]
> Step 100 [reward 352.00]
> Step 125 [reward 452.00]
> Step 150 [reward 552.00]
> Step 175 [reward 652.00]
> Step 200 [reward 752.00]
> Step 225 [reward 852.00]
> Step 250 [reward 952.00]
Rewards 952.00 / Steps 250.00
Reward stats:
 {'max': '1123.07', 'mean': '456.17', 'min': '-17.57', 'std': '185.46'}
Information gain stats:
 {'max': '1.64', 'mean': '0.90', 'min': '0.34', 'std': '0.19'}
Episode time 62.43
Saved _metrics_

=== Episode 29 ===
Training on [8250/33000] data points
> Train epoch 20 [ensemble -33.90 | reward 3.72]
> Train epoch 40 [ensemble -37.23 | reward 9.71]
> Train epoch 60 [ensemble -38.92 | reward 16.16]
> Train epoch 80 [ensemble -40.06 | reward 21.34]
> Train epoch 100 [ensemble -40.91 | reward 24.67]
Ensemble loss -40.91 / Reward Loss 24.67

=== Collecting data [29] ===
> Step 25 [reward 54.00]
> Step 50 [reward 154.00]
> Step 75 [reward 254.00]
> Step 100 [reward 354.00]
> Step 125 [reward 454.00]
> Step 150 [reward 554.00]
> Step 175 [reward 654.00]
> Step 200 [reward 754.00]
> Step 225 [reward 854.00]
> Step 250 [reward 954.00]
Rewards 954.00 / Steps 250.00
Reward stats:
 {'max': '1151.31', 'mean': '525.21', 'min': '56.31', 'std': '200.35'}
Information gain stats:
 {'max': '1.60', 'mean': '0.89', 'min': '0.33', 'std': '0.20'}
Episode time 63.77
Saved _metrics_

=== Episode 30 ===
Training on [8500/34000] data points
> Train epoch 20 [ensemble -34.11 | reward 3.88]
> Train epoch 40 [ensemble -37.41 | reward 10.35]
> Train epoch 60 [ensemble -39.07 | reward 17.18]
> Train epoch 80 [ensemble -40.19 | reward 22.61]
> Train epoch 100 [ensemble -41.02 | reward 26.15]
Ensemble loss -41.02 / Reward Loss 26.15

=== Collecting data [30] ===
> Step 25 [reward 42.00]
> Step 50 [reward 142.00]
> Step 75 [reward 242.00]
> Step 100 [reward 342.00]
> Step 125 [reward 442.00]
> Step 150 [reward 542.00]
> Step 175 [reward 642.00]
> Step 200 [reward 742.00]
> Step 225 [reward 842.00]
> Step 250 [reward 942.00]
Rewards 942.00 / Steps 250.00
Reward stats:
 {'max': '1200.78', 'mean': '545.27', 'min': '65.32', 'std': '204.40'}
Information gain stats:
 {'max': '1.54', 'mean': '0.89', 'min': '0.32', 'std': '0.19'}
Episode time 65.43
Saved _metrics_

=== Episode 31 ===
Training on [8750/35000] data points
> Train epoch 20 [ensemble -34.47 | reward 4.11]
> Train epoch 40 [ensemble -37.65 | reward 11.09]
> Train epoch 60 [ensemble -39.26 | reward 18.34]
> Train epoch 80 [ensemble -40.34 | reward 24.15]
> Train epoch 100 [ensemble -41.15 | reward 27.94]
Ensemble loss -41.15 / Reward Loss 27.94

=== Collecting data [31] ===
> Step 25 [reward 96.00]
> Step 50 [reward 196.00]
> Step 75 [reward 296.00]
> Step 100 [reward 396.00]
> Step 125 [reward 496.00]
> Step 150 [reward 596.00]
> Step 175 [reward 696.00]
> Step 200 [reward 796.00]
> Step 225 [reward 896.00]
> Step 250 [reward 996.00]
Rewards 996.00 / Steps 250.00
Reward stats:
 {'max': '1224.92', 'mean': '562.50', 'min': '76.65', 'std': '200.90'}
Information gain stats:
 {'max': '1.57', 'mean': '0.89', 'min': '0.33', 'std': '0.19'}
Episode time 66.84
Saved _metrics_

=== Episode 32 ===
Training on [9000/36000] data points
> Train epoch 20 [ensemble -34.70 | reward 4.13]
> Train epoch 40 [ensemble -37.83 | reward 11.42]
> Train epoch 60 [ensemble -39.42 | reward 19.05]
> Train epoch 80 [ensemble -40.49 | reward 25.12]
> Train epoch 100 [ensemble -41.29 | reward 29.12]
Ensemble loss -41.29 / Reward Loss 29.12

=== Collecting data [32] ===
> Step 25 [reward 47.00]
> Step 50 [reward 147.00]
> Step 75 [reward 247.00]
> Step 100 [reward 347.00]
> Step 125 [reward 447.00]
> Step 150 [reward 547.00]
> Step 175 [reward 647.00]
> Step 200 [reward 747.00]
> Step 225 [reward 847.00]
> Step 250 [reward 947.00]
Rewards 947.00 / Steps 250.00
Reward stats:
 {'max': '1181.72', 'mean': '544.10', 'min': '59.56', 'std': '194.21'}
Information gain stats:
 {'max': '1.58', 'mean': '0.90', 'min': '0.36', 'std': '0.18'}
Episode time 68.22
Saved _metrics_

=== Episode 33 ===
Training on [9250/37000] data points
> Train epoch 20 [ensemble -35.04 | reward 4.60]
> Train epoch 40 [ensemble -38.06 | reward 12.44]
> Train epoch 60 [ensemble -39.60 | reward 20.58]
> Train epoch 80 [ensemble -40.64 | reward 27.05]
> Train epoch 100 [ensemble -41.42 | reward 31.31]
Ensemble loss -41.42 / Reward Loss 31.31

=== Collecting data [33] ===
> Step 25 [reward 37.00]
> Step 50 [reward 137.00]
> Step 75 [reward 237.00]
> Step 100 [reward 337.00]
> Step 125 [reward 437.00]
> Step 150 [reward 537.00]
> Step 175 [reward 637.00]
> Step 200 [reward 737.00]
> Step 225 [reward 837.00]
> Step 250 [reward 937.00]
Rewards 937.00 / Steps 250.00
Reward stats:
 {'max': '1291.71', 'mean': '640.34', 'min': '99.34', 'std': '214.15'}
Information gain stats:
 {'max': '1.62', 'mean': '0.90', 'min': '0.33', 'std': '0.20'}
Episode time 69.62
Saved _metrics_

=== Episode 34 ===
Training on [9500/38000] data points
> Train epoch 20 [ensemble -35.23 | reward 4.67]
> Train epoch 40 [ensemble -38.18 | reward 12.88]
> Train epoch 60 [ensemble -39.69 | reward 21.22]
> Train epoch 80 [ensemble -40.70 | reward 27.79]
> Train epoch 100 [ensemble -41.47 | reward 32.09]
Ensemble loss -41.47 / Reward Loss 32.09

=== Collecting data [34] ===
> Step 25 [reward 50.00]
> Step 50 [reward 150.00]
> Step 75 [reward 250.00]
> Step 100 [reward 350.00]
> Step 125 [reward 450.00]
> Step 150 [reward 550.00]
> Step 175 [reward 650.00]
> Step 200 [reward 750.00]
> Step 225 [reward 850.00]
> Step 250 [reward 950.00]
Rewards 950.00 / Steps 250.00
Reward stats:
 {'max': '1251.08', 'mean': '608.25', 'min': '-11.88', 'std': '194.11'}
Information gain stats:
 {'max': '1.66', 'mean': '0.90', 'min': '0.35', 'std': '0.19'}
Episode time 70.96
Saved _metrics_

=== Episode 35 ===
Training on [9750/39000] data points
> Train epoch 20 [ensemble -35.42 | reward 4.69]
> Train epoch 40 [ensemble -38.34 | reward 12.91]
> Train epoch 60 [ensemble -39.84 | reward 21.58]
> Train epoch 80 [ensemble -40.85 | reward 28.47]
> Train epoch 100 [ensemble -41.61 | reward 32.98]
Ensemble loss -41.61 / Reward Loss 32.98

=== Collecting data [35] ===
> Step 25 [reward 94.00]
> Step 50 [reward 194.00]
> Step 75 [reward 294.00]
> Step 100 [reward 394.00]
> Step 125 [reward 494.00]
> Step 150 [reward 594.00]
> Step 175 [reward 694.00]
> Step 200 [reward 794.00]
> Step 225 [reward 894.00]
> Step 250 [reward 994.00]
Rewards 994.00 / Steps 250.00
Reward stats:
 {'max': '1274.13', 'mean': '615.21', 'min': '112.42', 'std': '199.03'}
Information gain stats:
 {'max': '1.66', 'mean': '0.89', 'min': '0.35', 'std': '0.19'}
Episode time 72.39
Saved _metrics_

=== Episode 36 ===
Training on [10000/40000] data points
> Train epoch 20 [ensemble -35.74 | reward 4.80]
> Train epoch 40 [ensemble -38.59 | reward 13.46]
> Train epoch 60 [ensemble -40.05 | reward 22.73]
> Train epoch 80 [ensemble -41.04 | reward 30.15]
> Train epoch 100 [ensemble -41.78 | reward 35.00]
Ensemble loss -41.78 / Reward Loss 35.00

=== Collecting data [36] ===
> Step 25 [reward 49.00]
> Step 50 [reward 149.00]
> Step 75 [reward 249.00]
> Step 100 [reward 349.00]
> Step 125 [reward 449.00]
> Step 150 [reward 549.00]
> Step 175 [reward 649.00]
> Step 200 [reward 749.00]
> Step 225 [reward 849.00]
> Step 250 [reward 949.00]
Rewards 949.00 / Steps 250.00
Reward stats:
 {'max': '1311.25', 'mean': '623.02', 'min': '26.06', 'std': '194.98'}
Information gain stats:
 {'max': '1.69', 'mean': '0.93', 'min': '0.37', 'std': '0.19'}
Episode time 73.89
Saved _metrics_

=== Episode 37 ===
Training on [10250/41000] data points
> Train epoch 20 [ensemble -35.96 | reward 5.19]
> Train epoch 40 [ensemble -38.76 | reward 14.31]
> Train epoch 60 [ensemble -40.20 | reward 23.87]
> Train epoch 80 [ensemble -41.16 | reward 31.50]
> Train epoch 100 [ensemble -41.89 | reward 36.52]
Ensemble loss -41.89 / Reward Loss 36.52

=== Collecting data [37] ===
> Step 25 [reward 44.00]
> Step 50 [reward 144.00]
> Step 75 [reward 244.00]
> Step 100 [reward 344.00]
> Step 125 [reward 444.00]
> Step 150 [reward 544.00]
> Step 175 [reward 644.00]
> Step 200 [reward 744.00]
> Step 225 [reward 844.00]
> Step 250 [reward 944.00]
Rewards 944.00 / Steps 250.00
Reward stats:
 {'max': '1387.37', 'mean': '683.16', 'min': '78.62', 'std': '225.73'}
Information gain stats:
 {'max': '1.67', 'mean': '0.92', 'min': '0.34', 'std': '0.20'}
Episode time 75.31
Saved _metrics_

=== Episode 38 ===
Training on [10500/42000] data points
> Train epoch 20 [ensemble -36.18 | reward 5.34]
> Train epoch 40 [ensemble -38.93 | reward 15.03]
> Train epoch 60 [ensemble -40.34 | reward 25.27]
> Train epoch 80 [ensemble -41.29 | reward 33.40]
> Train epoch 100 [ensemble -42.00 | reward 38.76]
Ensemble loss -42.00 / Reward Loss 38.76

=== Collecting data [38] ===
> Step 25 [reward 95.00]
> Step 50 [reward 195.00]
> Step 75 [reward 295.00]
> Step 100 [reward 395.00]
> Step 125 [reward 495.00]
> Step 150 [reward 595.00]
> Step 175 [reward 695.00]
> Step 200 [reward 795.00]
> Step 225 [reward 895.00]
> Step 250 [reward 995.00]
Rewards 995.00 / Steps 250.00
Reward stats:
 {'max': '1462.70', 'mean': '708.06', 'min': '163.81', 'std': '223.07'}
Information gain stats:
 {'max': '1.60', 'mean': '0.91', 'min': '0.35', 'std': '0.19'}
Episode time 76.75
Saved _metrics_

=== Episode 39 ===
Training on [10750/43000] data points
> Train epoch 20 [ensemble -36.35 | reward 5.65]
> Train epoch 40 [ensemble -39.05 | reward 15.76]
> Train epoch 60 [ensemble -40.43 | reward 26.19]
> Train epoch 80 [ensemble -41.36 | reward 34.37]
> Train epoch 100 [ensemble -42.06 | reward 39.71]
Ensemble loss -42.06 / Reward Loss 39.71

=== Collecting data [39] ===
> Step 25 [reward 100.00]
> Step 50 [reward 200.00]
> Step 75 [reward 300.00]
> Step 100 [reward 400.00]
> Step 125 [reward 500.00]
> Step 150 [reward 600.00]
> Step 175 [reward 700.00]
> Step 200 [reward 800.00]
> Step 225 [reward 900.00]
> Step 250 [reward 1000.00]
Rewards 1000.00 / Steps 250.00
Reward stats:
 {'max': '1425.13', 'mean': '763.37', 'min': '189.90', 'std': '227.16'}
Information gain stats:
 {'max': '1.63', 'mean': '0.92', 'min': '0.35', 'std': '0.19'}
Episode time 78.06
Saved _metrics_

=== Episode 40 ===
Training on [11000/44000] data points
> Train epoch 20 [ensemble -36.54 | reward 5.86]
> Train epoch 40 [ensemble -39.20 | reward 16.51]
> Train epoch 60 [ensemble -40.56 | reward 27.40]
> Train epoch 80 [ensemble -41.47 | reward 35.99]
> Train epoch 100 [ensemble -42.16 | reward 41.64]
Ensemble loss -42.16 / Reward Loss 41.64

=== Collecting data [40] ===
> Step 25 [reward 51.00]
> Step 50 [reward 151.00]
> Step 75 [reward 251.00]
> Step 100 [reward 351.00]
> Step 125 [reward 451.00]
> Step 150 [reward 551.00]
> Step 175 [reward 651.00]
> Step 200 [reward 751.00]
> Step 225 [reward 851.00]
> Step 250 [reward 951.00]
Rewards 951.00 / Steps 250.00
Reward stats:
 {'max': '1433.62', 'mean': '712.99', 'min': '131.28', 'std': '221.30'}
Information gain stats:
 {'max': '1.61', 'mean': '0.91', 'min': '0.33', 'std': '0.20'}
Episode time 79.37
Saved _metrics_

=== Episode 41 ===
Training on [11250/45000] data points
> Train epoch 20 [ensemble -36.79 | reward 6.05]
> Train epoch 40 [ensemble -39.40 | reward 17.03]
> Train epoch 60 [ensemble -40.72 | reward 28.25]
> Train epoch 80 [ensemble -41.62 | reward 37.01]
> Train epoch 100 [ensemble -42.29 | reward 42.67]
Ensemble loss -42.29 / Reward Loss 42.67

=== Collecting data [41] ===
> Step 25 [reward 41.00]
> Step 50 [reward 141.00]
> Step 75 [reward 241.00]
> Step 100 [reward 341.00]
> Step 125 [reward 441.00]
> Step 150 [reward 541.00]
> Step 175 [reward 641.00]
> Step 200 [reward 741.00]
> Step 225 [reward 841.00]
> Step 250 [reward 941.00]
Rewards 941.00 / Steps 250.00
Reward stats:
 {'max': '1495.32', 'mean': '792.90', 'min': '157.66', 'std': '237.88'}
Information gain stats:
 {'max': '1.63', 'mean': '0.92', 'min': '0.35', 'std': '0.20'}
Episode time 80.22
Saved _metrics_

=== Episode 42 ===
Training on [11500/46000] data points
> Train epoch 20 [ensemble -37.01 | reward 6.14]
> Train epoch 40 [ensemble -39.57 | reward 17.65]
> Train epoch 60 [ensemble -40.88 | reward 29.46]
> Train epoch 80 [ensemble -41.77 | reward 38.60]
> Train epoch 100 [ensemble -42.43 | reward 44.50]
Ensemble loss -42.43 / Reward Loss 44.50

=== Collecting data [42] ===
> Step 25 [reward 50.00]
> Step 50 [reward 150.00]
> Step 75 [reward 250.00]
> Step 100 [reward 350.00]
> Step 125 [reward 450.00]
> Step 150 [reward 550.00]
> Step 175 [reward 650.00]
> Step 200 [reward 750.00]
> Step 225 [reward 850.00]
> Step 250 [reward 950.00]
Rewards 950.00 / Steps 250.00
Reward stats:
 {'max': '1496.06', 'mean': '787.79', 'min': '35.31', 'std': '230.33'}
Information gain stats:
 {'max': '1.67', 'mean': '0.94', 'min': '0.36', 'std': '0.19'}
Episode time 81.52
Saved _metrics_

=== Episode 43 ===
Training on [11750/47000] data points
> Train epoch 20 [ensemble -37.17 | reward 6.33]
> Train epoch 40 [ensemble -39.69 | reward 18.21]
> Train epoch 60 [ensemble -40.98 | reward 30.41]
> Train epoch 80 [ensemble -41.85 | reward 39.90]
> Train epoch 100 [ensemble -42.51 | reward 46.10]
Ensemble loss -42.51 / Reward Loss 46.10

=== Collecting data [43] ===
> Step 25 [reward 90.00]
> Step 50 [reward 190.00]
> Step 75 [reward 290.00]
> Step 100 [reward 390.00]
> Step 125 [reward 490.00]
> Step 150 [reward 590.00]
> Step 175 [reward 690.00]
> Step 200 [reward 790.00]
> Step 225 [reward 890.00]
> Step 250 [reward 990.00]
Rewards 990.00 / Steps 250.00
Reward stats:
 {'max': '1533.36', 'mean': '785.40', 'min': '166.93', 'std': '217.02'}
Information gain stats:
 {'max': '1.63', 'mean': '0.99', 'min': '0.41', 'std': '0.18'}
Episode time 83.59
Saved _metrics_

=== Episode 44 ===
Training on [12000/48000] data points
> Train epoch 20 [ensemble -37.27 | reward 6.68]
> Train epoch 40 [ensemble -39.79 | reward 19.07]
> Train epoch 60 [ensemble -41.07 | reward 31.67]
> Train epoch 80 [ensemble -41.94 | reward 41.49]
> Train epoch 100 [ensemble -42.59 | reward 47.92]
Ensemble loss -42.59 / Reward Loss 47.92

=== Collecting data [44] ===
> Step 25 [reward 95.00]
> Step 50 [reward 195.00]
> Step 75 [reward 295.00]
> Step 100 [reward 395.00]
> Step 125 [reward 495.00]
> Step 150 [reward 595.00]
> Step 175 [reward 695.00]
> Step 200 [reward 795.00]
> Step 225 [reward 895.00]
> Step 250 [reward 995.00]
Rewards 995.00 / Steps 250.00
Reward stats:
 {'max': '1609.59', 'mean': '860.61', 'min': '242.40', 'std': '247.80'}
Information gain stats:
 {'max': '1.60', 'mean': '0.93', 'min': '0.35', 'std': '0.20'}
Episode time 85.16
Saved _metrics_

=== Episode 45 ===
Training on [12250/49000] data points
> Train epoch 20 [ensemble -37.33 | reward 7.32]
> Train epoch 40 [ensemble -39.85 | reward 20.44]
> Train epoch 60 [ensemble -41.12 | reward 33.41]
> Train epoch 80 [ensemble -41.98 | reward 43.36]
> Train epoch 100 [ensemble -42.62 | reward 49.78]
Ensemble loss -42.62 / Reward Loss 49.78

=== Collecting data [45] ===
> Step 25 [reward 0.00]
> Step 50 [reward 84.00]
> Step 75 [reward 184.00]
> Step 100 [reward 284.00]
> Step 125 [reward 384.00]
> Step 150 [reward 484.00]
> Step 175 [reward 584.00]
> Step 200 [reward 684.00]
> Step 225 [reward 784.00]
> Step 250 [reward 884.00]
Rewards 884.00 / Steps 250.00
Reward stats:
 {'max': '1663.59', 'mean': '829.87', 'min': '6.72', 'std': '253.71'}
Information gain stats:
 {'max': '1.75', 'mean': '0.96', 'min': '0.34', 'std': '0.20'}
Episode time 86.60
Saved _metrics_

=== Episode 46 ===
Training on [12500/50000] data points
> Train epoch 20 [ensemble -37.48 | reward 7.47]
> Train epoch 40 [ensemble -39.94 | reward 20.53]
> Train epoch 60 [ensemble -41.19 | reward 33.79]
> Train epoch 80 [ensemble -42.04 | reward 44.09]
> Train epoch 100 [ensemble -42.67 | reward 50.85]
Ensemble loss -42.67 / Reward Loss 50.85

=== Collecting data [46] ===
> Step 25 [reward 98.00]
> Step 50 [reward 198.00]
> Step 75 [reward 298.00]
> Step 100 [reward 398.00]
> Step 125 [reward 498.00]
> Step 150 [reward 598.00]
> Step 175 [reward 698.00]
> Step 200 [reward 798.00]
> Step 225 [reward 898.00]
> Step 250 [reward 998.00]
Rewards 998.00 / Steps 250.00
Reward stats:
 {'max': '1656.50', 'mean': '917.05', 'min': '210.24', 'std': '253.12'}
Information gain stats:
 {'max': '1.70', 'mean': '0.93', 'min': '0.35', 'std': '0.20'}
Episode time 87.58
Saved _metrics_

=== Episode 47 ===
Training on [12750/51000] data points
> Train epoch 20 [ensemble -37.69 | reward 7.33]
> Train epoch 40 [ensemble -40.11 | reward 21.33]
> Train epoch 60 [ensemble -41.35 | reward 35.27]
> Train epoch 80 [ensemble -42.18 | reward 45.92]
> Train epoch 100 [ensemble -42.81 | reward 52.85]
Ensemble loss -42.81 / Reward Loss 52.85

=== Collecting data [47] ===
> Step 25 [reward 90.00]
> Step 50 [reward 190.00]
> Step 75 [reward 290.00]
> Step 100 [reward 390.00]
> Step 125 [reward 490.00]
> Step 150 [reward 590.00]
> Step 175 [reward 690.00]
> Step 200 [reward 790.00]
> Step 225 [reward 890.00]
> Step 250 [reward 990.00]
Rewards 990.00 / Steps 250.00
Reward stats:
 {'max': '1737.60', 'mean': '912.69', 'min': '222.43', 'std': '268.78'}
Information gain stats:
 {'max': '1.68', 'mean': '0.97', 'min': '0.36', 'std': '0.22'}
Episode time 89.29
Saved _metrics_

=== Episode 48 ===
Training on [13000/52000] data points
> Train epoch 20 [ensemble -37.82 | reward 7.69]
> Train epoch 40 [ensemble -40.20 | reward 21.70]
> Train epoch 60 [ensemble -41.41 | reward 35.89]
> Train epoch 80 [ensemble -42.22 | reward 46.88]
> Train epoch 100 [ensemble -42.83 | reward 54.03]
Ensemble loss -42.83 / Reward Loss 54.03

=== Collecting data [48] ===
> Step 25 [reward 92.00]
> Step 50 [reward 192.00]
> Step 75 [reward 292.00]
> Step 100 [reward 392.00]
> Step 125 [reward 492.00]
> Step 150 [reward 592.00]
> Step 175 [reward 692.00]
> Step 200 [reward 792.00]
> Step 225 [reward 892.00]
> Step 250 [reward 992.00]
Rewards 992.00 / Steps 250.00
Reward stats:
 {'max': '1668.75', 'mean': '969.92', 'min': '267.14', 'std': '264.03'}
Information gain stats:
 {'max': '1.64', 'mean': '0.94', 'min': '0.35', 'std': '0.20'}
Episode time 90.51
Saved _metrics_

=== Episode 49 ===
Training on [13250/53000] data points
> Train epoch 20 [ensemble -37.93 | reward 7.86]
> Train epoch 40 [ensemble -40.30 | reward 22.55]
> Train epoch 60 [ensemble -41.50 | reward 37.23]
> Train epoch 80 [ensemble -42.30 | reward 48.47]
> Train epoch 100 [ensemble -42.90 | reward 55.80]
Ensemble loss -42.90 / Reward Loss 55.80

=== Collecting data [49] ===
> Step 25 [reward 92.00]
> Step 50 [reward 192.00]
> Step 75 [reward 292.00]
> Step 100 [reward 392.00]
> Step 125 [reward 492.00]
> Step 150 [reward 592.00]
> Step 175 [reward 692.00]
> Step 200 [reward 792.00]
> Step 225 [reward 892.00]
> Step 250 [reward 992.00]
Rewards 992.00 / Steps 250.00
Reward stats:
 {'max': '1750.18', 'mean': '981.20', 'min': '279.50', 'std': '256.91'}
Information gain stats:
 {'max': '1.68', 'mean': '0.95', 'min': '0.33', 'std': '0.21'}
Episode time 91.68
Saved _metrics_