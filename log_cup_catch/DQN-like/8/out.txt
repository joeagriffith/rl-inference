03:55:31

=== Loading experiment [device: cuda] ===

{'action_noise': None,
 'action_repeat': 4,
 'batch_size': 50,
 'coverage': False,
 'ensemble_size': 10,
 'env_name': 'DeepMindCatch',
 'epsilon': 1e-08,
 'expl_scale': 0.1,
 'expl_strategy': 'information',
 'grad_clip_norm': 1000,
 'hidden_size': 200,
 'learning_rate': 0.001,
 'logdir': 'cup_catch_DQN-like',
 'max_episode_len': 1000,
 'n_candidates': 500,
 'n_episodes': 50,
 'n_seed_episodes': 5,
 'n_train_epochs': 100,
 'optimisation_iters': 5,
 'plan_horizon': 12,
 'record_every': None,
 'reward_scale': 1.0,
 'seed': 8,
 'strategy': 'information',
 'top_candidates': 50,
 'use_exploration': True,
 'use_mean': False,
 'use_reward': True}

Collected seeds: [5 episodes | 1250 frames]

=== Episode 1 ===
Training on [1250/5000] data points
> Train epoch 20 [ensemble -19.98 | reward 0.19]
> Train epoch 40 [ensemble -27.75 | reward 0.14]
> Train epoch 60 [ensemble -31.59 | reward 0.10]
> Train epoch 80 [ensemble -34.02 | reward 0.08]
> Train epoch 100 [ensemble -35.75 | reward 0.07]
Ensemble loss -35.75 / Reward Loss 0.07

=== Collecting data [1] ===
> Step 25 [reward 0.00]
> Step 50 [reward 14.00]
> Step 75 [reward 114.00]
> Step 100 [reward 214.00]
> Step 125 [reward 277.00]
> Step 150 [reward 286.00]
> Step 175 [reward 295.00]
> Step 200 [reward 295.00]
> Step 225 [reward 295.00]
> Step 250 [reward 295.00]
Rewards 295.00 / Steps 250.00
Reward stats:
 {'max': '258.19', 'mean': '49.05', 'min': '-0.36', 'std': '43.01'}
Information gain stats:
 {'max': '2.13', 'mean': '1.16', 'min': '0.41', 'std': '0.20'}
Episode time 23.80
Saved _metrics_

=== Episode 2 ===
Training on [1500/6000] data points
> Train epoch 20 [ensemble -16.51 | reward 0.37]
> Train epoch 40 [ensemble -24.65 | reward 0.37]
> Train epoch 60 [ensemble -28.60 | reward 0.37]
> Train epoch 80 [ensemble -31.16 | reward 0.35]
> Train epoch 100 [ensemble -33.01 | reward 0.33]
Ensemble loss -33.01 / Reward Loss 0.33

=== Collecting data [2] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 3.00]
> Step 100 [reward 3.00]
> Step 125 [reward 3.00]
> Step 150 [reward 3.00]
> Step 175 [reward 3.00]
> Step 200 [reward 3.00]
> Step 225 [reward 3.00]
> Step 250 [reward 3.00]
Rewards 3.00 / Steps 250.00
Reward stats:
 {'max': '90.23', 'mean': '17.02', 'min': '-10.33', 'std': '13.42'}
Information gain stats:
 {'max': '1.86', 'mean': '1.00', 'min': '0.46', 'std': '0.14'}
Episode time 25.19
Saved _metrics_

=== Episode 3 ===
Training on [1750/7000] data points
> Train epoch 20 [ensemble -16.92 | reward 0.33]
> Train epoch 40 [ensemble -24.55 | reward 0.35]
> Train epoch 60 [ensemble -28.30 | reward 0.36]
> Train epoch 80 [ensemble -30.73 | reward 0.36]
> Train epoch 100 [ensemble -32.51 | reward 0.35]
Ensemble loss -32.51 / Reward Loss 0.35

=== Collecting data [3] ===
> Step 25 [reward 34.00]
> Step 50 [reward 131.00]
> Step 75 [reward 231.00]
> Step 100 [reward 331.00]
> Step 125 [reward 431.00]
> Step 150 [reward 531.00]
> Step 175 [reward 631.00]
> Step 200 [reward 731.00]
> Step 225 [reward 831.00]
> Step 250 [reward 931.00]
Rewards 931.00 / Steps 250.00
Reward stats:
 {'max': '206.18', 'mean': '53.64', 'min': '-3.00', 'std': '34.50'}
Information gain stats:
 {'max': '1.57', 'mean': '1.01', 'min': '0.48', 'std': '0.13'}
Episode time 26.58
Saved _metrics_

=== Episode 4 ===
Training on [2000/8000] data points
> Train epoch 20 [ensemble -18.09 | reward 0.55]
> Train epoch 40 [ensemble -25.52 | reward 0.65]
> Train epoch 60 [ensemble -29.21 | reward 0.74]
> Train epoch 80 [ensemble -31.61 | reward 0.78]
> Train epoch 100 [ensemble -33.36 | reward 0.78]
Ensemble loss -33.36 / Reward Loss 0.78

=== Collecting data [4] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 55.00]
> Step 150 [reward 155.00]
> Step 175 [reward 255.00]
> Step 200 [reward 355.00]
> Step 225 [reward 455.00]
> Step 250 [reward 555.00]
Rewards 555.00 / Steps 250.00
Reward stats:
 {'max': '339.35', 'mean': '101.19', 'min': '-12.83', 'std': '69.86'}
Information gain stats:
 {'max': '1.84', 'mean': '0.91', 'min': '0.33', 'std': '0.19'}
Episode time 28.07
Saved _metrics_

=== Episode 5 ===
Training on [2250/9000] data points
> Train epoch 20 [ensemble -19.73 | reward 0.64]
> Train epoch 40 [ensemble -26.58 | reward 0.77]
> Train epoch 60 [ensemble -29.96 | reward 0.94]
> Train epoch 80 [ensemble -32.17 | reward 1.07]
> Train epoch 100 [ensemble -33.80 | reward 1.13]
Ensemble loss -33.80 / Reward Loss 1.13

=== Collecting data [5] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 77.00]
> Step 100 [reward 177.00]
> Step 125 [reward 277.00]
> Step 150 [reward 377.00]
> Step 175 [reward 477.00]
> Step 200 [reward 577.00]
> Step 225 [reward 677.00]
> Step 250 [reward 777.00]
Rewards 777.00 / Steps 250.00
Reward stats:
 {'max': '305.77', 'mean': '93.72', 'min': '-25.38', 'std': '65.15'}
Information gain stats:
 {'max': '1.57', 'mean': '0.94', 'min': '0.42', 'std': '0.15'}
Episode time 29.48
Saved _metrics_

=== Episode 6 ===
Training on [2500/10000] data points
> Train epoch 20 [ensemble -21.26 | reward 0.72]
> Train epoch 40 [ensemble -27.66 | reward 1.00]
> Train epoch 60 [ensemble -30.82 | reward 1.35]
> Train epoch 80 [ensemble -32.89 | reward 1.60]
> Train epoch 100 [ensemble -34.43 | reward 1.71]
Ensemble loss -34.43 / Reward Loss 1.71

=== Collecting data [6] ===
> Step 25 [reward 80.00]
> Step 50 [reward 180.00]
> Step 75 [reward 280.00]
> Step 100 [reward 380.00]
> Step 125 [reward 480.00]
> Step 150 [reward 580.00]
> Step 175 [reward 680.00]
> Step 200 [reward 780.00]
> Step 225 [reward 880.00]
> Step 250 [reward 980.00]
Rewards 980.00 / Steps 250.00
Reward stats:
 {'max': '334.71', 'mean': '112.28', 'min': '-30.87', 'std': '67.06'}
Information gain stats:
 {'max': '1.54', 'mean': '0.94', 'min': '0.40', 'std': '0.16'}
Episode time 30.84
Saved _metrics_

=== Episode 7 ===
Training on [2750/11000] data points
> Train epoch 20 [ensemble -22.64 | reward 0.79]
> Train epoch 40 [ensemble -28.65 | reward 1.20]
> Train epoch 60 [ensemble -31.65 | reward 1.67]
> Train epoch 80 [ensemble -33.64 | reward 2.02]
> Train epoch 100 [ensemble -35.12 | reward 2.20]
Ensemble loss -35.12 / Reward Loss 2.20

=== Collecting data [7] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '151.06', 'mean': '50.72', 'min': '-51.70', 'std': '25.36'}
Information gain stats:
 {'max': '1.79', 'mean': '1.14', 'min': '0.58', 'std': '0.11'}
Episode time 32.33
Saved _metrics_

=== Episode 8 ===
Training on [3000/12000] data points
> Train epoch 20 [ensemble -23.75 | reward 0.79]
> Train epoch 40 [ensemble -29.59 | reward 1.28]
> Train epoch 60 [ensemble -32.50 | reward 1.82]
> Train epoch 80 [ensemble -34.40 | reward 2.22]
> Train epoch 100 [ensemble -35.81 | reward 2.43]
Ensemble loss -35.81 / Reward Loss 2.43

=== Collecting data [8] ===
> Step 25 [reward 36.00]
> Step 50 [reward 136.00]
> Step 75 [reward 236.00]
> Step 100 [reward 336.00]
> Step 125 [reward 436.00]
> Step 150 [reward 536.00]
> Step 175 [reward 636.00]
> Step 200 [reward 736.00]
> Step 225 [reward 836.00]
> Step 250 [reward 936.00]
Rewards 936.00 / Steps 250.00
Reward stats:
 {'max': '384.43', 'mean': '132.87', 'min': '-15.74', 'std': '77.45'}
Information gain stats:
 {'max': '1.47', 'mean': '0.89', 'min': '0.37', 'std': '0.16'}
Episode time 33.78
Saved _metrics_

=== Episode 9 ===
Training on [3250/13000] data points
> Train epoch 20 [ensemble -24.91 | reward 0.82]
> Train epoch 40 [ensemble -30.42 | reward 1.45]
> Train epoch 60 [ensemble -33.17 | reward 2.09]
> Train epoch 80 [ensemble -34.97 | reward 2.60]
> Train epoch 100 [ensemble -36.31 | reward 2.89]
Ensemble loss -36.31 / Reward Loss 2.89

=== Collecting data [9] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '250.93', 'mean': '87.41', 'min': '-15.25', 'std': '49.91'}
Information gain stats:
 {'max': '1.81', 'mean': '1.30', 'min': '0.58', 'std': '0.12'}
Episode time 35.16
Saved _metrics_

=== Episode 10 ===
Training on [3500/14000] data points
> Train epoch 20 [ensemble -26.82 | reward 0.86]
> Train epoch 40 [ensemble -32.32 | reward 1.60]
> Train epoch 60 [ensemble -34.95 | reward 2.42]
> Train epoch 80 [ensemble -36.63 | reward 3.03]
> Train epoch 100 [ensemble -37.86 | reward 3.37]
Ensemble loss -37.86 / Reward Loss 3.37

=== Collecting data [10] ===
> Step 25 [reward 84.00]
> Step 50 [reward 184.00]
> Step 75 [reward 284.00]
> Step 100 [reward 384.00]
> Step 125 [reward 484.00]
> Step 150 [reward 584.00]
> Step 175 [reward 684.00]
> Step 200 [reward 784.00]
> Step 225 [reward 884.00]
> Step 250 [reward 984.00]
Rewards 984.00 / Steps 250.00
Reward stats:
 {'max': '443.10', 'mean': '158.36', 'min': '-0.10', 'std': '86.64'}
Information gain stats:
 {'max': '1.39', 'mean': '0.84', 'min': '0.35', 'std': '0.15'}
Episode time 36.44
Saved _metrics_

=== Episode 11 ===
Training on [3750/15000] data points
> Train epoch 20 [ensemble -27.63 | reward 0.88]
> Train epoch 40 [ensemble -32.90 | reward 1.73]
> Train epoch 60 [ensemble -35.43 | reward 2.61]
> Train epoch 80 [ensemble -37.07 | reward 3.28]
> Train epoch 100 [ensemble -38.27 | reward 3.67]
Ensemble loss -38.27 / Reward Loss 3.67

=== Collecting data [11] ===
> Step 25 [reward 91.00]
> Step 50 [reward 191.00]
> Step 75 [reward 291.00]
> Step 100 [reward 391.00]
> Step 125 [reward 491.00]
> Step 150 [reward 591.00]
> Step 175 [reward 691.00]
> Step 200 [reward 791.00]
> Step 225 [reward 891.00]
> Step 250 [reward 991.00]
Rewards 991.00 / Steps 250.00
Reward stats:
 {'max': '460.44', 'mean': '149.04', 'min': '0.23', 'std': '81.86'}
Information gain stats:
 {'max': '1.43', 'mean': '0.87', 'min': '0.34', 'std': '0.15'}
Episode time 38.01
Saved _metrics_

=== Episode 12 ===
Training on [4000/16000] data points
> Train epoch 20 [ensemble -28.28 | reward 0.93]
> Train epoch 40 [ensemble -33.36 | reward 1.97]
> Train epoch 60 [ensemble -35.80 | reward 3.11]
> Train epoch 80 [ensemble -37.38 | reward 4.02]
> Train epoch 100 [ensemble -38.54 | reward 4.59]
Ensemble loss -38.54 / Reward Loss 4.59

=== Collecting data [12] ===
> Step 25 [reward 0.00]
> Step 50 [reward 82.00]
> Step 75 [reward 182.00]
> Step 100 [reward 282.00]
> Step 125 [reward 382.00]
> Step 150 [reward 482.00]
> Step 175 [reward 582.00]
> Step 200 [reward 682.00]
> Step 225 [reward 782.00]
> Step 250 [reward 882.00]
Rewards 882.00 / Steps 250.00
Reward stats:
 {'max': '513.49', 'mean': '166.85', 'min': '-6.89', 'std': '103.05'}
Information gain stats:
 {'max': '1.47', 'mean': '0.87', 'min': '0.36', 'std': '0.15'}
Episode time 39.34
Saved _metrics_

=== Episode 13 ===
Training on [4250/17000] data points
> Train epoch 20 [ensemble -28.87 | reward 0.98]
> Train epoch 40 [ensemble -33.72 | reward 2.28]
> Train epoch 60 [ensemble -36.08 | reward 3.66]
> Train epoch 80 [ensemble -37.61 | reward 4.76]
> Train epoch 100 [ensemble -38.75 | reward 5.46]
Ensemble loss -38.75 / Reward Loss 5.46

=== Collecting data [13] ===
> Step 25 [reward 86.00]
> Step 50 [reward 186.00]
> Step 75 [reward 286.00]
> Step 100 [reward 386.00]
> Step 125 [reward 486.00]
> Step 150 [reward 586.00]
> Step 175 [reward 686.00]
> Step 200 [reward 786.00]
> Step 225 [reward 886.00]
> Step 250 [reward 986.00]
Rewards 986.00 / Steps 250.00
Reward stats:
 {'max': '525.90', 'mean': '187.09', 'min': '2.86', 'std': '99.14'}
Information gain stats:
 {'max': '1.45', 'mean': '0.87', 'min': '0.32', 'std': '0.15'}
Episode time 40.85
Saved _metrics_

=== Episode 14 ===
Training on [4500/18000] data points
> Train epoch 20 [ensemble -29.48 | reward 1.15]
> Train epoch 40 [ensemble -34.19 | reward 2.62]
> Train epoch 60 [ensemble -36.48 | reward 4.24]
> Train epoch 80 [ensemble -37.98 | reward 5.54]
> Train epoch 100 [ensemble -39.10 | reward 6.35]
Ensemble loss -39.10 / Reward Loss 6.35

=== Collecting data [14] ===
> Step 25 [reward 84.00]
> Step 50 [reward 184.00]
> Step 75 [reward 284.00]
> Step 100 [reward 384.00]
> Step 125 [reward 484.00]
> Step 150 [reward 584.00]
> Step 175 [reward 684.00]
> Step 200 [reward 784.00]
> Step 225 [reward 884.00]
> Step 250 [reward 984.00]
Rewards 984.00 / Steps 250.00
Reward stats:
 {'max': '581.13', 'mean': '196.22', 'min': '7.04', 'std': '102.42'}
Information gain stats:
 {'max': '1.44', 'mean': '0.89', 'min': '0.38', 'std': '0.15'}
Episode time 42.32
Saved _metrics_

=== Episode 15 ===
Training on [4750/19000] data points
> Train epoch 20 [ensemble -30.04 | reward 1.16]
> Train epoch 40 [ensemble -34.58 | reward 2.85]
> Train epoch 60 [ensemble -36.79 | reward 4.72]
> Train epoch 80 [ensemble -38.22 | reward 6.22]
> Train epoch 100 [ensemble -39.30 | reward 7.17]
Ensemble loss -39.30 / Reward Loss 7.17

=== Collecting data [15] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '352.57', 'mean': '131.45', 'min': '-37.29', 'std': '72.18'}
Information gain stats:
 {'max': '1.55', 'mean': '1.05', 'min': '0.64', 'std': '0.10'}
Episode time 43.61
Saved _metrics_

=== Episode 16 ===
Training on [5000/20000] data points
> Train epoch 20 [ensemble -30.37 | reward 1.19]
> Train epoch 40 [ensemble -34.99 | reward 2.97]
> Train epoch 60 [ensemble -37.19 | reward 4.95]
> Train epoch 80 [ensemble -38.63 | reward 6.56]
> Train epoch 100 [ensemble -39.69 | reward 7.60]
Ensemble loss -39.69 / Reward Loss 7.60

=== Collecting data [16] ===
> Step 25 [reward 88.00]
> Step 50 [reward 188.00]
> Step 75 [reward 288.00]
> Step 100 [reward 388.00]
> Step 125 [reward 488.00]
> Step 150 [reward 588.00]
> Step 175 [reward 688.00]
> Step 200 [reward 788.00]
> Step 225 [reward 888.00]
> Step 250 [reward 988.00]
Rewards 988.00 / Steps 250.00
Reward stats:
 {'max': '636.37', 'mean': '234.28', 'min': '14.38', 'std': '112.69'}
Information gain stats:
 {'max': '1.46', 'mean': '0.88', 'min': '0.38', 'std': '0.14'}
Episode time 45.11
Saved _metrics_

=== Episode 17 ===
Training on [5250/21000] data points
> Train epoch 20 [ensemble -31.04 | reward 1.35]
> Train epoch 40 [ensemble -35.47 | reward 3.53]
> Train epoch 60 [ensemble -37.60 | reward 5.87]
> Train epoch 80 [ensemble -38.99 | reward 7.75]
> Train epoch 100 [ensemble -40.02 | reward 8.92]
Ensemble loss -40.02 / Reward Loss 8.92

=== Collecting data [17] ===
> Step 25 [reward 6.00]
> Step 50 [reward 106.00]
> Step 75 [reward 206.00]
> Step 100 [reward 306.00]
> Step 125 [reward 406.00]
> Step 150 [reward 506.00]
> Step 175 [reward 606.00]
> Step 200 [reward 706.00]
> Step 225 [reward 806.00]
> Step 250 [reward 906.00]
Rewards 906.00 / Steps 250.00
Reward stats:
 {'max': '675.35', 'mean': '251.65', 'min': '-6.07', 'std': '125.16'}
Information gain stats:
 {'max': '1.51', 'mean': '0.88', 'min': '0.38', 'std': '0.15'}
Episode time 46.49
Saved _metrics_

=== Episode 18 ===
Training on [5500/22000] data points
> Train epoch 20 [ensemble -31.24 | reward 1.39]
> Train epoch 40 [ensemble -35.59 | reward 3.60]
> Train epoch 60 [ensemble -37.68 | reward 6.04]
> Train epoch 80 [ensemble -39.05 | reward 8.05]
> Train epoch 100 [ensemble -40.07 | reward 9.34]
Ensemble loss -40.07 / Reward Loss 9.34

=== Collecting data [18] ===
> Step 25 [reward 31.00]
> Step 50 [reward 131.00]
> Step 75 [reward 231.00]
> Step 100 [reward 331.00]
> Step 125 [reward 431.00]
> Step 150 [reward 531.00]
> Step 175 [reward 631.00]
> Step 200 [reward 731.00]
> Step 225 [reward 831.00]
> Step 250 [reward 931.00]
Rewards 931.00 / Steps 250.00
Reward stats:
 {'max': '692.64', 'mean': '243.24', 'min': '0.79', 'std': '126.57'}
Information gain stats:
 {'max': '1.54', 'mean': '0.90', 'min': '0.38', 'std': '0.15'}
Episode time 47.99
Saved _metrics_

=== Episode 19 ===
Training on [5750/23000] data points
> Train epoch 20 [ensemble -31.75 | reward 1.52]
> Train epoch 40 [ensemble -35.91 | reward 4.09]
> Train epoch 60 [ensemble -37.94 | reward 6.92]
> Train epoch 80 [ensemble -39.28 | reward 9.22]
> Train epoch 100 [ensemble -40.27 | reward 10.69]
Ensemble loss -40.27 / Reward Loss 10.69

=== Collecting data [19] ===
> Step 25 [reward 85.00]
> Step 50 [reward 185.00]
> Step 75 [reward 285.00]
> Step 100 [reward 385.00]
> Step 125 [reward 485.00]
> Step 150 [reward 585.00]
> Step 175 [reward 685.00]
> Step 200 [reward 785.00]
> Step 225 [reward 885.00]
> Step 250 [reward 985.00]
Rewards 985.00 / Steps 250.00
Reward stats:
 {'max': '714.15', 'mean': '270.53', 'min': '11.57', 'std': '132.24'}
Information gain stats:
 {'max': '1.48', 'mean': '0.90', 'min': '0.38', 'std': '0.15'}
Episode time 49.53
Saved _metrics_

=== Episode 20 ===
Training on [6000/24000] data points
> Train epoch 20 [ensemble -32.10 | reward 1.66]
> Train epoch 40 [ensemble -36.18 | reward 4.54]
> Train epoch 60 [ensemble -38.17 | reward 7.73]
> Train epoch 80 [ensemble -39.47 | reward 10.32]
> Train epoch 100 [ensemble -40.45 | reward 12.00]
Ensemble loss -40.45 / Reward Loss 12.00

=== Collecting data [20] ===
> Step 25 [reward 51.00]
> Step 50 [reward 151.00]
> Step 75 [reward 251.00]
> Step 100 [reward 351.00]
> Step 125 [reward 451.00]
> Step 150 [reward 551.00]
> Step 175 [reward 651.00]
> Step 200 [reward 751.00]
> Step 225 [reward 851.00]
> Step 250 [reward 951.00]
Rewards 951.00 / Steps 250.00
Reward stats:
 {'max': '809.06', 'mean': '288.38', 'min': '3.04', 'std': '151.98'}
Information gain stats:
 {'max': '1.51', 'mean': '0.90', 'min': '0.34', 'std': '0.16'}
Episode time 50.77
Saved _metrics_

=== Episode 21 ===
Training on [6250/25000] data points
> Train epoch 20 [ensemble -32.57 | reward 1.73]
> Train epoch 40 [ensemble -36.51 | reward 4.86]
> Train epoch 60 [ensemble -38.43 | reward 8.41]
> Train epoch 80 [ensemble -39.70 | reward 11.30]
> Train epoch 100 [ensemble -40.65 | reward 13.15]
Ensemble loss -40.65 / Reward Loss 13.15

=== Collecting data [21] ===
> Step 25 [reward 100.00]
> Step 50 [reward 200.00]
> Step 75 [reward 300.00]
> Step 100 [reward 400.00]
> Step 125 [reward 500.00]
> Step 150 [reward 600.00]
> Step 175 [reward 700.00]
> Step 200 [reward 800.00]
> Step 225 [reward 900.00]
> Step 250 [reward 1000.00]
Rewards 1000.00 / Steps 250.00
Reward stats:
 {'max': '803.54', 'mean': '278.81', 'min': '0.42', 'std': '149.27'}
Information gain stats:
 {'max': '1.46', 'mean': '0.90', 'min': '0.35', 'std': '0.15'}
Episode time 52.21
Saved _metrics_

=== Episode 22 ===
Training on [6500/26000] data points
> Train epoch 20 [ensemble -33.08 | reward 1.97]
> Train epoch 40 [ensemble -36.88 | reward 5.59]
> Train epoch 60 [ensemble -38.75 | reward 9.53]
> Train epoch 80 [ensemble -39.99 | reward 12.70]
> Train epoch 100 [ensemble -40.91 | reward 14.72]
Ensemble loss -40.91 / Reward Loss 14.72

=== Collecting data [22] ===
> Step 25 [reward 55.00]
> Step 50 [reward 155.00]
> Step 75 [reward 255.00]
> Step 100 [reward 355.00]
> Step 125 [reward 455.00]
> Step 150 [reward 555.00]
> Step 175 [reward 655.00]
> Step 200 [reward 755.00]
> Step 225 [reward 855.00]
> Step 250 [reward 955.00]
Rewards 955.00 / Steps 250.00
Reward stats:
 {'max': '880.89', 'mean': '315.28', 'min': '-1.40', 'std': '157.36'}
Information gain stats:
 {'max': '1.46', 'mean': '0.90', 'min': '0.35', 'std': '0.15'}
Episode time 53.53
Saved _metrics_

=== Episode 23 ===
Training on [6750/27000] data points
> Train epoch 20 [ensemble -33.45 | reward 2.14]
> Train epoch 40 [ensemble -37.14 | reward 6.23]
> Train epoch 60 [ensemble -38.94 | reward 10.71]
> Train epoch 80 [ensemble -40.13 | reward 14.25]
> Train epoch 100 [ensemble -41.02 | reward 16.51]
Ensemble loss -41.02 / Reward Loss 16.51

=== Collecting data [23] ===
> Step 25 [reward 48.00]
> Step 50 [reward 148.00]
> Step 75 [reward 248.00]
> Step 100 [reward 348.00]
> Step 125 [reward 448.00]
> Step 150 [reward 548.00]
> Step 175 [reward 648.00]
> Step 200 [reward 748.00]
> Step 225 [reward 848.00]
> Step 250 [reward 948.00]
Rewards 948.00 / Steps 250.00
Reward stats:
 {'max': '971.95', 'mean': '355.50', 'min': '-38.66', 'std': '180.75'}
Information gain stats:
 {'max': '1.47', 'mean': '0.89', 'min': '0.30', 'std': '0.17'}
Episode time 55.03
Saved _metrics_

=== Episode 24 ===
Training on [7000/28000] data points
> Train epoch 20 [ensemble -34.01 | reward 2.11]
> Train epoch 40 [ensemble -37.50 | reward 6.13]
> Train epoch 60 [ensemble -39.23 | reward 10.63]
> Train epoch 80 [ensemble -40.39 | reward 14.30]
> Train epoch 100 [ensemble -41.26 | reward 16.71]
Ensemble loss -41.26 / Reward Loss 16.71

=== Collecting data [24] ===
> Step 25 [reward 89.00]
> Step 50 [reward 189.00]
> Step 75 [reward 289.00]
> Step 100 [reward 389.00]
> Step 125 [reward 489.00]
> Step 150 [reward 589.00]
> Step 175 [reward 689.00]
> Step 200 [reward 789.00]
> Step 225 [reward 889.00]
> Step 250 [reward 989.00]
Rewards 989.00 / Steps 250.00
Reward stats:
 {'max': '874.50', 'mean': '329.53', 'min': '16.02', 'std': '152.35'}
Information gain stats:
 {'max': '1.57', 'mean': '0.94', 'min': '0.38', 'std': '0.16'}
Episode time 56.54
Saved _metrics_

=== Episode 25 ===
Training on [7250/29000] data points
> Train epoch 20 [ensemble -34.24 | reward 2.33]
> Train epoch 40 [ensemble -37.72 | reward 6.73]
> Train epoch 60 [ensemble -39.44 | reward 11.67]
> Train epoch 80 [ensemble -40.59 | reward 15.68]
> Train epoch 100 [ensemble -41.44 | reward 18.27]
Ensemble loss -41.44 / Reward Loss 18.27

=== Collecting data [25] ===
> Step 25 [reward 87.00]
> Step 50 [reward 187.00]
> Step 75 [reward 287.00]
> Step 100 [reward 387.00]
> Step 125 [reward 487.00]
> Step 150 [reward 587.00]
> Step 175 [reward 687.00]
> Step 200 [reward 787.00]
> Step 225 [reward 887.00]
> Step 250 [reward 987.00]
Rewards 987.00 / Steps 250.00
Reward stats:
 {'max': '910.16', 'mean': '344.66', 'min': '39.20', 'std': '153.69'}
Information gain stats:
 {'max': '1.55', 'mean': '0.93', 'min': '0.33', 'std': '0.15'}
Episode time 57.63
Saved _metrics_

=== Episode 26 ===
Training on [7500/30000] data points
> Train epoch 20 [ensemble -34.51 | reward 2.60]
> Train epoch 40 [ensemble -37.89 | reward 7.54]
> Train epoch 60 [ensemble -39.56 | reward 12.88]
> Train epoch 80 [ensemble -40.68 | reward 17.14]
> Train epoch 100 [ensemble -41.51 | reward 19.93]
Ensemble loss -41.51 / Reward Loss 19.93

=== Collecting data [26] ===
> Step 25 [reward 53.00]
> Step 50 [reward 153.00]
> Step 75 [reward 253.00]
> Step 100 [reward 353.00]
> Step 125 [reward 453.00]
> Step 150 [reward 553.00]
> Step 175 [reward 653.00]
> Step 200 [reward 753.00]
> Step 225 [reward 853.00]
> Step 250 [reward 953.00]
Rewards 953.00 / Steps 250.00
Reward stats:
 {'max': '1008.53', 'mean': '373.83', 'min': '24.75', 'std': '172.64'}
Information gain stats:
 {'max': '1.56', 'mean': '0.93', 'min': '0.37', 'std': '0.17'}
Episode time 59.24
Saved _metrics_

=== Episode 27 ===
Training on [7750/31000] data points
> Train epoch 20 [ensemble -34.86 | reward 2.76]
> Train epoch 40 [ensemble -38.14 | reward 8.07]
> Train epoch 60 [ensemble -39.76 | reward 13.84]
> Train epoch 80 [ensemble -40.84 | reward 18.51]
> Train epoch 100 [ensemble -41.65 | reward 21.55]
Ensemble loss -41.65 / Reward Loss 21.55

=== Collecting data [27] ===
> Step 25 [reward 94.00]
> Step 50 [reward 194.00]
> Step 75 [reward 294.00]
> Step 100 [reward 394.00]
> Step 125 [reward 494.00]
> Step 150 [reward 594.00]
> Step 175 [reward 694.00]
> Step 200 [reward 794.00]
> Step 225 [reward 894.00]
> Step 250 [reward 994.00]
Rewards 994.00 / Steps 250.00
Reward stats:
 {'max': '1074.39', 'mean': '404.48', 'min': '0.80', 'std': '190.26'}
Information gain stats:
 {'max': '1.51', 'mean': '0.92', 'min': '0.32', 'std': '0.16'}
Episode time 60.71
Saved _metrics_

=== Episode 28 ===
Training on [8000/32000] data points
> Train epoch 20 [ensemble -35.08 | reward 2.90]
> Train epoch 40 [ensemble -38.32 | reward 8.44]
> Train epoch 60 [ensemble -39.92 | reward 14.41]
> Train epoch 80 [ensemble -41.00 | reward 19.26]
> Train epoch 100 [ensemble -41.80 | reward 22.45]
Ensemble loss -41.80 / Reward Loss 22.45

=== Collecting data [28] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '821.73', 'mean': '367.70', 'min': '29.33', 'std': '135.87'}
Information gain stats:
 {'max': '1.53', 'mean': '1.06', 'min': '0.67', 'std': '0.09'}
Episode time 62.23
Saved _metrics_

=== Episode 29 ===
Training on [8250/33000] data points
> Train epoch 20 [ensemble -35.14 | reward 2.89]
> Train epoch 40 [ensemble -38.41 | reward 8.62]
> Train epoch 60 [ensemble -40.04 | reward 14.91]
> Train epoch 80 [ensemble -41.13 | reward 19.96]
> Train epoch 100 [ensemble -41.94 | reward 23.28]
Ensemble loss -41.94 / Reward Loss 23.28

=== Collecting data [29] ===
> Step 25 [reward 87.00]
> Step 50 [reward 187.00]
> Step 75 [reward 287.00]
> Step 100 [reward 387.00]
> Step 125 [reward 487.00]
> Step 150 [reward 587.00]
> Step 175 [reward 687.00]
> Step 200 [reward 787.00]
> Step 225 [reward 887.00]
> Step 250 [reward 987.00]
Rewards 987.00 / Steps 250.00
Reward stats:
 {'max': '1042.90', 'mean': '390.36', 'min': '24.03', 'std': '181.30'}
Information gain stats:
 {'max': '1.51', 'mean': '0.92', 'min': '0.36', 'std': '0.16'}
Episode time 63.71
Saved _metrics_

=== Episode 30 ===
Training on [8500/34000] data points
> Train epoch 20 [ensemble -35.50 | reward 3.08]
> Train epoch 40 [ensemble -38.66 | reward 9.26]
> Train epoch 60 [ensemble -40.23 | reward 16.03]
> Train epoch 80 [ensemble -41.29 | reward 21.49]
> Train epoch 100 [ensemble -42.07 | reward 25.09]
Ensemble loss -42.07 / Reward Loss 25.09

=== Collecting data [30] ===
> Step 25 [reward 88.00]
> Step 50 [reward 188.00]
> Step 75 [reward 288.00]
> Step 100 [reward 388.00]
> Step 125 [reward 488.00]
> Step 150 [reward 588.00]
> Step 175 [reward 688.00]
> Step 200 [reward 788.00]
> Step 225 [reward 888.00]
> Step 250 [reward 988.00]
Rewards 988.00 / Steps 250.00
Reward stats:
 {'max': '1121.67', 'mean': '416.92', 'min': '48.62', 'std': '191.51'}
Information gain stats:
 {'max': '1.51', 'mean': '0.92', 'min': '0.38', 'std': '0.15'}
Episode time 65.04
Saved _metrics_

=== Episode 31 ===
Training on [8750/35000] data points
> Train epoch 20 [ensemble -35.64 | reward 3.40]
> Train epoch 40 [ensemble -38.78 | reward 10.33]
> Train epoch 60 [ensemble -40.35 | reward 17.60]
> Train epoch 80 [ensemble -41.40 | reward 23.36]
> Train epoch 100 [ensemble -42.18 | reward 27.11]
Ensemble loss -42.18 / Reward Loss 27.11

=== Collecting data [31] ===
> Step 25 [reward 86.00]
> Step 50 [reward 186.00]
> Step 75 [reward 286.00]
> Step 100 [reward 386.00]
> Step 125 [reward 486.00]
> Step 150 [reward 586.00]
> Step 175 [reward 686.00]
> Step 200 [reward 786.00]
> Step 225 [reward 886.00]
> Step 250 [reward 986.00]
Rewards 986.00 / Steps 250.00
Reward stats:
 {'max': '1195.79', 'mean': '484.92', 'min': '31.33', 'std': '218.75'}
Information gain stats:
 {'max': '1.58', 'mean': '0.90', 'min': '0.32', 'std': '0.18'}
Episode time 66.53
Saved _metrics_

=== Episode 32 ===
Training on [9000/36000] data points
> Train epoch 20 [ensemble -36.02 | reward 3.40]
> Train epoch 40 [ensemble -39.03 | reward 10.34]
> Train epoch 60 [ensemble -40.54 | reward 17.82]
> Train epoch 80 [ensemble -41.56 | reward 23.72]
> Train epoch 100 [ensemble -42.31 | reward 27.53]
Ensemble loss -42.31 / Reward Loss 27.53

=== Collecting data [32] ===
> Step 25 [reward 52.00]
> Step 50 [reward 152.00]
> Step 75 [reward 252.00]
> Step 100 [reward 352.00]
> Step 125 [reward 452.00]
> Step 150 [reward 552.00]
> Step 175 [reward 652.00]
> Step 200 [reward 752.00]
> Step 225 [reward 852.00]
> Step 250 [reward 952.00]
Rewards 952.00 / Steps 250.00
Reward stats:
 {'max': '1165.07', 'mean': '468.23', 'min': '40.04', 'std': '206.26'}
Information gain stats:
 {'max': '1.49', 'mean': '0.92', 'min': '0.35', 'std': '0.16'}
Episode time 67.77
Saved _metrics_

=== Episode 33 ===
Training on [9250/37000] data points
> Train epoch 20 [ensemble -36.17 | reward 3.59]
> Train epoch 40 [ensemble -39.16 | reward 10.96]
> Train epoch 60 [ensemble -40.65 | reward 18.86]
> Train epoch 80 [ensemble -41.65 | reward 25.20]
> Train epoch 100 [ensemble -42.39 | reward 29.41]
Ensemble loss -42.39 / Reward Loss 29.41

=== Collecting data [33] ===
> Step 25 [reward 88.00]
> Step 50 [reward 188.00]
> Step 75 [reward 288.00]
> Step 100 [reward 388.00]
> Step 125 [reward 488.00]
> Step 150 [reward 588.00]
> Step 175 [reward 688.00]
> Step 200 [reward 788.00]
> Step 225 [reward 888.00]
> Step 250 [reward 988.00]
Rewards 988.00 / Steps 250.00
Reward stats:
 {'max': '1171.58', 'mean': '449.32', 'min': '44.47', 'std': '202.71'}
Information gain stats:
 {'max': '1.52', 'mean': '0.92', 'min': '0.37', 'std': '0.16'}
Episode time 69.26
Saved _metrics_

=== Episode 34 ===
Training on [9500/38000] data points
> Train epoch 20 [ensemble -36.48 | reward 3.77]
> Train epoch 40 [ensemble -39.36 | reward 11.50]
> Train epoch 60 [ensemble -40.82 | reward 19.68]
> Train epoch 80 [ensemble -41.79 | reward 26.15]
> Train epoch 100 [ensemble -42.52 | reward 30.39]
Ensemble loss -42.52 / Reward Loss 30.39

=== Collecting data [34] ===
> Step 25 [reward 86.00]
> Step 50 [reward 186.00]
> Step 75 [reward 286.00]
> Step 100 [reward 386.00]
> Step 125 [reward 486.00]
> Step 150 [reward 586.00]
> Step 175 [reward 686.00]
> Step 200 [reward 786.00]
> Step 225 [reward 886.00]
> Step 250 [reward 986.00]
Rewards 986.00 / Steps 250.00
Reward stats:
 {'max': '1152.34', 'mean': '436.25', 'min': '61.46', 'std': '182.28'}
Information gain stats:
 {'max': '1.54', 'mean': '0.95', 'min': '0.38', 'std': '0.15'}
Episode time 70.88
Saved _metrics_

=== Episode 35 ===
Training on [9750/39000] data points
> Train epoch 20 [ensemble -36.66 | reward 3.78]
> Train epoch 40 [ensemble -39.49 | reward 11.86]
> Train epoch 60 [ensemble -40.92 | reward 20.45]
> Train epoch 80 [ensemble -41.89 | reward 27.22]
> Train epoch 100 [ensemble -42.60 | reward 31.63]
Ensemble loss -42.60 / Reward Loss 31.63

=== Collecting data [35] ===
> Step 25 [reward 84.00]
> Step 50 [reward 184.00]
> Step 75 [reward 284.00]
> Step 100 [reward 384.00]
> Step 125 [reward 484.00]
> Step 150 [reward 584.00]
> Step 175 [reward 684.00]
> Step 200 [reward 784.00]
> Step 225 [reward 884.00]
> Step 250 [reward 984.00]
Rewards 984.00 / Steps 250.00
Reward stats:
 {'max': '1187.88', 'mean': '461.64', 'min': '59.04', 'std': '195.75'}
Information gain stats:
 {'max': '1.51', 'mean': '0.95', 'min': '0.35', 'std': '0.16'}
Episode time 72.23
Saved _metrics_

=== Episode 36 ===
Training on [10000/40000] data points
> Train epoch 20 [ensemble -37.00 | reward 4.12]
> Train epoch 40 [ensemble -39.73 | reward 12.61]
> Train epoch 60 [ensemble -41.12 | reward 21.64]
> Train epoch 80 [ensemble -42.05 | reward 28.75]
> Train epoch 100 [ensemble -42.74 | reward 33.39]
Ensemble loss -42.74 / Reward Loss 33.39

=== Collecting data [36] ===
> Step 25 [reward 48.00]
> Step 50 [reward 148.00]
> Step 75 [reward 248.00]
> Step 100 [reward 348.00]
> Step 125 [reward 448.00]
> Step 150 [reward 548.00]
> Step 175 [reward 648.00]
> Step 200 [reward 748.00]
> Step 225 [reward 848.00]
> Step 250 [reward 948.00]
Rewards 948.00 / Steps 250.00
Reward stats:
 {'max': '1157.70', 'mean': '473.39', 'min': '51.01', 'std': '187.57'}
Information gain stats:
 {'max': '1.54', 'mean': '0.95', 'min': '0.38', 'std': '0.15'}
Episode time 73.50
Saved _metrics_

=== Episode 37 ===
Training on [10250/41000] data points
> Train epoch 20 [ensemble -37.04 | reward 4.49]
> Train epoch 40 [ensemble -39.78 | reward 13.79]
> Train epoch 60 [ensemble -41.17 | reward 23.46]
> Train epoch 80 [ensemble -42.11 | reward 31.05]
> Train epoch 100 [ensemble -42.80 | reward 36.06]
Ensemble loss -42.80 / Reward Loss 36.06

=== Collecting data [37] ===
> Step 25 [reward 86.00]
> Step 50 [reward 186.00]
> Step 75 [reward 286.00]
> Step 100 [reward 386.00]
> Step 125 [reward 486.00]
> Step 150 [reward 586.00]
> Step 175 [reward 686.00]
> Step 200 [reward 786.00]
> Step 225 [reward 886.00]
> Step 250 [reward 986.00]
Rewards 986.00 / Steps 250.00
Reward stats:
 {'max': '1306.24', 'mean': '503.05', 'min': '38.05', 'std': '224.00'}
Information gain stats:
 {'max': '1.52', 'mean': '0.94', 'min': '0.29', 'std': '0.17'}
Episode time 74.99
Saved _metrics_

=== Episode 38 ===
Training on [10500/42000] data points
> Train epoch 20 [ensemble -37.36 | reward 4.62]
> Train epoch 40 [ensemble -40.02 | reward 14.24]
> Train epoch 60 [ensemble -41.36 | reward 24.28]
> Train epoch 80 [ensemble -42.26 | reward 32.17]
> Train epoch 100 [ensemble -42.93 | reward 37.34]
Ensemble loss -42.93 / Reward Loss 37.34

=== Collecting data [38] ===
> Step 25 [reward 89.00]
> Step 50 [reward 189.00]
> Step 75 [reward 289.00]
> Step 100 [reward 389.00]
> Step 125 [reward 489.00]
> Step 150 [reward 589.00]
> Step 175 [reward 689.00]
> Step 200 [reward 789.00]
> Step 225 [reward 889.00]
> Step 250 [reward 989.00]
Rewards 989.00 / Steps 250.00
Reward stats:
 {'max': '1286.44', 'mean': '528.14', 'min': '73.19', 'std': '210.18'}
Information gain stats:
 {'max': '1.57', 'mean': '0.97', 'min': '0.37', 'std': '0.17'}
Episode time 76.20
Saved _metrics_

=== Episode 39 ===
Training on [10750/43000] data points
> Train epoch 20 [ensemble -37.46 | reward 4.74]
> Train epoch 40 [ensemble -40.08 | reward 14.63]
> Train epoch 60 [ensemble -41.42 | reward 24.97]
> Train epoch 80 [ensemble -42.32 | reward 33.11]
> Train epoch 100 [ensemble -42.98 | reward 38.47]
Ensemble loss -42.98 / Reward Loss 38.47

=== Collecting data [39] ===
> Step 25 [reward 87.00]
> Step 50 [reward 187.00]
> Step 75 [reward 287.00]
> Step 100 [reward 387.00]
> Step 125 [reward 487.00]
> Step 150 [reward 587.00]
> Step 175 [reward 687.00]
> Step 200 [reward 787.00]
> Step 225 [reward 887.00]
> Step 250 [reward 987.00]
Rewards 987.00 / Steps 250.00
Reward stats:
 {'max': '1287.28', 'mean': '491.84', 'min': '74.86', 'std': '205.33'}
Information gain stats:
 {'max': '1.58', 'mean': '0.95', 'min': '0.37', 'std': '0.15'}
Episode time 78.03
Saved _metrics_

=== Episode 40 ===
Training on [11000/44000] data points
> Train epoch 20 [ensemble -37.70 | reward 5.02]
> Train epoch 40 [ensemble -40.27 | reward 15.46]
> Train epoch 60 [ensemble -41.58 | reward 26.36]
> Train epoch 80 [ensemble -42.45 | reward 34.92]
> Train epoch 100 [ensemble -43.10 | reward 40.52]
Ensemble loss -43.10 / Reward Loss 40.52

=== Collecting data [40] ===
> Step 25 [reward 51.00]
> Step 50 [reward 151.00]
> Step 75 [reward 251.00]
> Step 100 [reward 351.00]
> Step 125 [reward 451.00]
> Step 150 [reward 551.00]
> Step 175 [reward 651.00]
> Step 200 [reward 751.00]
> Step 225 [reward 851.00]
> Step 250 [reward 951.00]
Rewards 951.00 / Steps 250.00
Reward stats:
 {'max': '1378.58', 'mean': '547.30', 'min': '-29.02', 'std': '211.08'}
Information gain stats:
 {'max': '1.55', 'mean': '0.97', 'min': '0.38', 'std': '0.16'}
Episode time 79.37
Saved _metrics_

=== Episode 41 ===
Training on [11250/45000] data points
> Train epoch 20 [ensemble -37.95 | reward 5.28]
> Train epoch 40 [ensemble -40.42 | reward 16.26]
> Train epoch 60 [ensemble -41.69 | reward 27.65]
> Train epoch 80 [ensemble -42.55 | reward 36.46]
> Train epoch 100 [ensemble -43.18 | reward 42.16]
Ensemble loss -43.18 / Reward Loss 42.16

=== Collecting data [41] ===
> Step 25 [reward 59.00]
> Step 50 [reward 159.00]
> Step 75 [reward 259.00]
> Step 100 [reward 359.00]
> Step 125 [reward 459.00]
> Step 150 [reward 559.00]
> Step 175 [reward 659.00]
> Step 200 [reward 759.00]
> Step 225 [reward 859.00]
> Step 250 [reward 959.00]
Rewards 959.00 / Steps 250.00
Reward stats:
 {'max': '1334.86', 'mean': '503.01', 'min': '47.11', 'std': '201.90'}
Information gain stats:
 {'max': '1.56', 'mean': '0.97', 'min': '0.37', 'std': '0.15'}
Episode time 80.39
Saved _metrics_

=== Episode 42 ===
Training on [11500/46000] data points
> Train epoch 20 [ensemble -38.14 | reward 5.48]
> Train epoch 40 [ensemble -40.55 | reward 16.71]
> Train epoch 60 [ensemble -41.80 | reward 28.15]
> Train epoch 80 [ensemble -42.65 | reward 37.05]
> Train epoch 100 [ensemble -43.27 | reward 42.88]
Ensemble loss -43.27 / Reward Loss 42.88

=== Collecting data [42] ===
> Step 25 [reward 85.00]
> Step 50 [reward 185.00]
> Step 75 [reward 285.00]
> Step 100 [reward 385.00]
> Step 125 [reward 485.00]
> Step 150 [reward 585.00]
> Step 175 [reward 685.00]
> Step 200 [reward 785.00]
> Step 225 [reward 885.00]
> Step 250 [reward 985.00]
Rewards 985.00 / Steps 250.00
Reward stats:
 {'max': '1445.31', 'mean': '591.40', 'min': '85.82', 'std': '227.80'}
Information gain stats:
 {'max': '1.56', 'mean': '0.97', 'min': '0.35', 'std': '0.16'}
Episode time 81.76
Saved _metrics_

=== Episode 43 ===
Training on [11750/47000] data points
> Train epoch 20 [ensemble -38.29 | reward 5.57]
> Train epoch 40 [ensemble -40.68 | reward 17.30]
> Train epoch 60 [ensemble -41.91 | reward 29.40]
> Train epoch 80 [ensemble -42.74 | reward 38.85]
> Train epoch 100 [ensemble -43.35 | reward 45.05]
Ensemble loss -43.35 / Reward Loss 45.05

=== Collecting data [43] ===
> Step 25 [reward 9.00]
> Step 50 [reward 109.00]
> Step 75 [reward 209.00]
> Step 100 [reward 309.00]
> Step 125 [reward 409.00]
> Step 150 [reward 509.00]
> Step 175 [reward 609.00]
> Step 200 [reward 709.00]
> Step 225 [reward 809.00]
> Step 250 [reward 909.00]
Rewards 909.00 / Steps 250.00
Reward stats:
 {'max': '1426.12', 'mean': '560.77', 'min': '98.59', 'std': '226.40'}
Information gain stats:
 {'max': '1.60', 'mean': '0.99', 'min': '0.34', 'std': '0.17'}
Episode time 83.15
Saved _metrics_

=== Episode 44 ===
Training on [12000/48000] data points
> Train epoch 20 [ensemble -38.39 | reward 5.93]
> Train epoch 40 [ensemble -40.77 | reward 18.21]
> Train epoch 60 [ensemble -41.99 | reward 30.74]
> Train epoch 80 [ensemble -42.80 | reward 40.49]
> Train epoch 100 [ensemble -43.41 | reward 46.88]
Ensemble loss -43.41 / Reward Loss 46.88

=== Collecting data [44] ===
> Step 25 [reward 99.00]
> Step 50 [reward 199.00]
> Step 75 [reward 299.00]
> Step 100 [reward 399.00]
> Step 125 [reward 499.00]
> Step 150 [reward 599.00]
> Step 175 [reward 699.00]
> Step 200 [reward 799.00]
> Step 225 [reward 899.00]
> Step 250 [reward 999.00]
Rewards 999.00 / Steps 250.00
Reward stats:
 {'max': '1483.33', 'mean': '604.57', 'min': '139.18', 'std': '220.33'}
Information gain stats:
 {'max': '1.55', 'mean': '0.98', 'min': '0.36', 'std': '0.16'}
Episode time 84.98
Saved _metrics_

=== Episode 45 ===
Training on [12250/49000] data points
> Train epoch 20 [ensemble -38.57 | reward 6.17]
> Train epoch 40 [ensemble -40.88 | reward 19.06]
> Train epoch 60 [ensemble -42.07 | reward 32.16]
> Train epoch 80 [ensemble -42.87 | reward 42.26]
> Train epoch 100 [ensemble -43.46 | reward 48.92]
Ensemble loss -43.46 / Reward Loss 48.92

=== Collecting data [45] ===
> Step 25 [reward 48.00]
> Step 50 [reward 148.00]
> Step 75 [reward 246.00]
> Step 100 [reward 346.00]
> Step 125 [reward 445.00]
> Step 150 [reward 545.00]
> Step 175 [reward 641.00]
> Step 200 [reward 741.00]
> Step 225 [reward 840.00]
> Step 250 [reward 939.00]
Rewards 939.00 / Steps 250.00
Reward stats:
 {'max': '1242.93', 'mean': '637.42', 'min': '27.24', 'std': '172.84'}
Information gain stats:
 {'max': '1.63', 'mean': '0.98', 'min': '0.51', 'std': '0.15'}
Episode time 86.36
Saved _metrics_

=== Episode 46 ===
Training on [12500/50000] data points
> Train epoch 20 [ensemble -38.19 | reward 6.52]
> Train epoch 40 [ensemble -40.63 | reward 19.77]
> Train epoch 60 [ensemble -41.89 | reward 33.16]
> Train epoch 80 [ensemble -42.73 | reward 43.50]
> Train epoch 100 [ensemble -43.34 | reward 50.30]
Ensemble loss -43.34 / Reward Loss 50.30

=== Collecting data [46] ===
> Step 25 [reward 56.00]
> Step 50 [reward 156.00]
> Step 75 [reward 256.00]
> Step 100 [reward 356.00]
> Step 125 [reward 456.00]
> Step 150 [reward 556.00]
> Step 175 [reward 656.00]
> Step 200 [reward 756.00]
> Step 225 [reward 856.00]
> Step 250 [reward 956.00]
Rewards 956.00 / Steps 250.00
Reward stats:
 {'max': '1601.07', 'mean': '733.82', 'min': '82.50', 'std': '244.37'}
Information gain stats:
 {'max': '1.56', 'mean': '0.95', 'min': '0.35', 'std': '0.17'}
Episode time 87.37
Saved _metrics_

=== Episode 47 ===
Training on [12750/51000] data points
> Train epoch 20 [ensemble -38.49 | reward 6.94]
> Train epoch 40 [ensemble -40.85 | reward 20.52]
> Train epoch 60 [ensemble -42.07 | reward 34.08]
> Train epoch 80 [ensemble -42.88 | reward 44.48]
> Train epoch 100 [ensemble -43.48 | reward 51.33]
Ensemble loss -43.48 / Reward Loss 51.33

=== Collecting data [47] ===
> Step 25 [reward 85.00]
> Step 50 [reward 185.00]
> Step 75 [reward 285.00]
> Step 100 [reward 385.00]
> Step 125 [reward 485.00]
> Step 150 [reward 585.00]
> Step 175 [reward 685.00]
> Step 200 [reward 785.00]
> Step 225 [reward 885.00]
> Step 250 [reward 985.00]
Rewards 985.00 / Steps 250.00
Reward stats:
 {'max': '1594.36', 'mean': '733.70', 'min': '141.12', 'std': '241.48'}
Information gain stats:
 {'max': '1.58', 'mean': '0.95', 'min': '0.35', 'std': '0.19'}
Episode time 89.17
Saved _metrics_

=== Episode 48 ===
Training on [13000/52000] data points
> Train epoch 20 [ensemble -38.46 | reward 7.12]
> Train epoch 40 [ensemble -40.85 | reward 21.20]
> Train epoch 60 [ensemble -42.07 | reward 35.21]
> Train epoch 80 [ensemble -42.89 | reward 46.06]
> Train epoch 100 [ensemble -43.48 | reward 53.19]
Ensemble loss -43.48 / Reward Loss 53.19

=== Collecting data [48] ===
> Step 25 [reward 52.00]
> Step 50 [reward 152.00]
> Step 75 [reward 252.00]
> Step 100 [reward 352.00]
> Step 125 [reward 452.00]
> Step 150 [reward 552.00]
> Step 175 [reward 652.00]
> Step 200 [reward 752.00]
> Step 225 [reward 852.00]
> Step 250 [reward 952.00]
Rewards 952.00 / Steps 250.00
Reward stats:
 {'max': '1555.57', 'mean': '842.81', 'min': '9.21', 'std': '228.42'}
Information gain stats:
 {'max': '1.55', 'mean': '0.92', 'min': '0.39', 'std': '0.18'}
Episode time 90.19
Saved _metrics_

=== Episode 49 ===
Training on [13250/53000] data points
> Train epoch 20 [ensemble -38.96 | reward 7.43]
> Train epoch 40 [ensemble -41.18 | reward 21.99]
> Train epoch 60 [ensemble -42.33 | reward 36.63]
> Train epoch 80 [ensemble -43.10 | reward 47.83]
> Train epoch 100 [ensemble -43.66 | reward 55.17]
Ensemble loss -43.66 / Reward Loss 55.17

=== Collecting data [49] ===
> Step 25 [reward 48.00]
> Step 50 [reward 148.00]
> Step 75 [reward 248.00]
> Step 100 [reward 348.00]
> Step 125 [reward 448.00]
> Step 150 [reward 548.00]
> Step 175 [reward 648.00]
> Step 200 [reward 748.00]
> Step 225 [reward 848.00]
> Step 250 [reward 948.00]
Rewards 948.00 / Steps 250.00
Reward stats:
 {'max': '1688.25', 'mean': '852.84', 'min': '150.20', 'std': '253.69'}
Information gain stats:
 {'max': '1.59', 'mean': '0.90', 'min': '0.35', 'std': '0.20'}
Episode time 91.94
Saved _metrics_