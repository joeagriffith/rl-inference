03:08:17

=== Loading experiment [device: cuda] ===

{'action_noise': None,
 'action_repeat': 4,
 'batch_size': 50,
 'coverage': False,
 'ensemble_size': 10,
 'env_name': 'DeepMindCatch',
 'epsilon': 1e-08,
 'expl_scale': 0.1,
 'expl_strategy': 'information',
 'grad_clip_norm': 1000,
 'hidden_size': 200,
 'learning_rate': 0.001,
 'logdir': 'cup_catch_DQN-like',
 'max_episode_len': 1000,
 'n_candidates': 500,
 'n_episodes': 50,
 'n_seed_episodes': 5,
 'n_train_epochs': 100,
 'optimisation_iters': 5,
 'plan_horizon': 12,
 'record_every': None,
 'reward_scale': 1.0,
 'seed': 7,
 'strategy': 'information',
 'top_candidates': 50,
 'use_exploration': True,
 'use_mean': False,
 'use_reward': True}

Collected seeds: [5 episodes | 1250 frames]

=== Episode 1 ===
Training on [1250/5000] data points
> Train epoch 20 [ensemble -21.86 | reward 0.00]
> Train epoch 40 [ensemble -29.67 | reward 0.00]
> Train epoch 60 [ensemble -33.37 | reward 0.00]
> Train epoch 80 [ensemble -35.72 | reward 0.00]
> Train epoch 100 [ensemble -37.42 | reward 0.00]
Ensemble loss -37.42 / Reward Loss 0.00

=== Collecting data [1] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '-0.22', 'mean': '-0.59', 'min': '-2.58', 'std': '0.08'}
Information gain stats:
 {'max': '3.20', 'mean': '1.06', 'min': '0.38', 'std': '0.33'}
Episode time 23.83
Saved _metrics_

=== Episode 2 ===
Training on [1500/6000] data points
> Train epoch 20 [ensemble -15.01 | reward 0.00]
> Train epoch 40 [ensemble -25.38 | reward 0.00]
> Train epoch 60 [ensemble -29.97 | reward 0.00]
> Train epoch 80 [ensemble -32.72 | reward 0.00]
> Train epoch 100 [ensemble -34.64 | reward 0.00]
Ensemble loss -34.64 / Reward Loss 0.00

=== Collecting data [2] ===
> Step 25 [reward 30.00]
> Step 50 [reward 30.00]
> Step 75 [reward 30.00]
> Step 100 [reward 30.00]
> Step 125 [reward 30.00]
> Step 150 [reward 30.00]
> Step 175 [reward 30.00]
> Step 200 [reward 30.00]
> Step 225 [reward 30.00]
> Step 250 [reward 30.00]
Rewards 30.00 / Steps 250.00
Reward stats:
 {'max': '-0.31', 'mean': '-0.60', 'min': '-0.76', 'std': '0.04'}
Information gain stats:
 {'max': '1.80', 'mean': '1.26', 'min': '0.56', 'std': '0.14'}
Episode time 25.22
Saved _metrics_

=== Episode 3 ===
Training on [1750/7000] data points
> Train epoch 20 [ensemble -17.76 | reward 0.03]
> Train epoch 40 [ensemble -26.92 | reward 0.02]
> Train epoch 60 [ensemble -31.01 | reward 0.02]
> Train epoch 80 [ensemble -33.49 | reward 0.01]
> Train epoch 100 [ensemble -35.23 | reward 0.01]
Ensemble loss -35.23 / Reward Loss 0.01

=== Collecting data [3] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '80.85', 'mean': '20.42', 'min': '-1.64', 'std': '14.02'}
Information gain stats:
 {'max': '1.44', 'mean': '1.04', 'min': '0.55', 'std': '0.10'}
Episode time 26.60
Saved _metrics_

=== Episode 4 ===
Training on [2000/8000] data points
> Train epoch 20 [ensemble -20.07 | reward 0.02]
> Train epoch 40 [ensemble -28.85 | reward 0.02]
> Train epoch 60 [ensemble -32.74 | reward 0.01]
> Train epoch 80 [ensemble -35.09 | reward 0.01]
> Train epoch 100 [ensemble -36.73 | reward 0.01]
Ensemble loss -36.73 / Reward Loss 0.01

=== Collecting data [4] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 2.00]
> Step 175 [reward 88.00]
> Step 200 [reward 158.00]
> Step 225 [reward 236.00]
> Step 250 [reward 307.00]
Rewards 307.00 / Steps 250.00
Reward stats:
 {'max': '59.04', 'mean': '7.91', 'min': '-0.93', 'std': '9.34'}
Information gain stats:
 {'max': '1.33', 'mean': '0.82', 'min': '0.45', 'std': '0.09'}
Episode time 27.97
Saved _metrics_

=== Episode 5 ===
Training on [2250/9000] data points
> Train epoch 20 [ensemble -20.23 | reward 0.18]
> Train epoch 40 [ensemble -28.29 | reward 0.23]
> Train epoch 60 [ensemble -31.99 | reward 0.25]
> Train epoch 80 [ensemble -34.26 | reward 0.24]
> Train epoch 100 [ensemble -35.85 | reward 0.22]
Ensemble loss -35.85 / Reward Loss 0.22

=== Collecting data [5] ===
> Step 25 [reward 83.00]
> Step 50 [reward 183.00]
> Step 75 [reward 283.00]
> Step 100 [reward 383.00]
> Step 125 [reward 483.00]
> Step 150 [reward 583.00]
> Step 175 [reward 683.00]
> Step 200 [reward 783.00]
> Step 225 [reward 883.00]
> Step 250 [reward 983.00]
Rewards 983.00 / Steps 250.00
Reward stats:
 {'max': '169.22', 'mean': '52.63', 'min': '0.21', 'std': '23.32'}
Information gain stats:
 {'max': '1.36', 'mean': '0.92', 'min': '0.56', 'std': '0.09'}
Episode time 29.54
Saved _metrics_

=== Episode 6 ===
Training on [2500/10000] data points
> Train epoch 20 [ensemble -21.27 | reward 0.28]
> Train epoch 40 [ensemble -28.97 | reward 0.40]
> Train epoch 60 [ensemble -32.53 | reward 0.52]
> Train epoch 80 [ensemble -34.72 | reward 0.56]
> Train epoch 100 [ensemble -36.27 | reward 0.55]
Ensemble loss -36.27 / Reward Loss 0.55

=== Collecting data [6] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '275.24', 'mean': '39.33', 'min': '-0.92', 'std': '36.35'}
Information gain stats:
 {'max': '1.39', 'mean': '0.81', 'min': '0.39', 'std': '0.12'}
Episode time 30.95
Saved _metrics_

=== Episode 7 ===
Training on [2750/11000] data points
> Train epoch 20 [ensemble -21.87 | reward 0.38]
> Train epoch 40 [ensemble -28.97 | reward 0.58]
> Train epoch 60 [ensemble -32.37 | reward 0.71]
> Train epoch 80 [ensemble -34.49 | reward 0.77]
> Train epoch 100 [ensemble -36.02 | reward 0.76]
Ensemble loss -36.02 / Reward Loss 0.76

=== Collecting data [7] ===
> Step 25 [reward 13.00]
> Step 50 [reward 113.00]
> Step 75 [reward 213.00]
> Step 100 [reward 313.00]
> Step 125 [reward 413.00]
> Step 150 [reward 513.00]
> Step 175 [reward 613.00]
> Step 200 [reward 713.00]
> Step 225 [reward 813.00]
> Step 250 [reward 913.00]
Rewards 913.00 / Steps 250.00
Reward stats:
 {'max': '132.55', 'mean': '30.40', 'min': '-1.98', 'std': '15.05'}
Information gain stats:
 {'max': '1.45', 'mean': '0.89', 'min': '0.50', 'std': '0.10'}
Episode time 32.26
Saved _metrics_

=== Episode 8 ===
Training on [3000/12000] data points
> Train epoch 20 [ensemble -22.49 | reward 0.60]
> Train epoch 40 [ensemble -29.27 | reward 1.00]
> Train epoch 60 [ensemble -32.52 | reward 1.24]
> Train epoch 80 [ensemble -34.59 | reward 1.33]
> Train epoch 100 [ensemble -36.08 | reward 1.33]
Ensemble loss -36.08 / Reward Loss 1.33

=== Collecting data [8] ===
> Step 25 [reward 82.00]
> Step 50 [reward 182.00]
> Step 75 [reward 282.00]
> Step 100 [reward 382.00]
> Step 125 [reward 482.00]
> Step 150 [reward 582.00]
> Step 175 [reward 682.00]
> Step 200 [reward 782.00]
> Step 225 [reward 882.00]
> Step 250 [reward 982.00]
Rewards 982.00 / Steps 250.00
Reward stats:
 {'max': '360.88', 'mean': '111.42', 'min': '4.36', 'std': '50.04'}
Information gain stats:
 {'max': '1.38', 'mean': '0.82', 'min': '0.43', 'std': '0.09'}
Episode time 33.64
Saved _metrics_

=== Episode 9 ===
Training on [3250/13000] data points
> Train epoch 20 [ensemble -23.42 | reward 0.70]
> Train epoch 40 [ensemble -29.94 | reward 1.22]
> Train epoch 60 [ensemble -33.10 | reward 1.63]
> Train epoch 80 [ensemble -35.13 | reward 1.88]
> Train epoch 100 [ensemble -36.60 | reward 1.99]
Ensemble loss -36.60 / Reward Loss 1.99

=== Collecting data [9] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '477.31', 'mean': '80.61', 'min': '-0.19', 'std': '76.14'}
Information gain stats:
 {'max': '1.41', 'mean': '0.84', 'min': '0.36', 'std': '0.12'}
Episode time 35.09
Saved _metrics_

=== Episode 10 ===
Training on [3500/14000] data points
> Train epoch 20 [ensemble -23.18 | reward 0.87]
> Train epoch 40 [ensemble -29.59 | reward 1.45]
> Train epoch 60 [ensemble -32.79 | reward 1.86]
> Train epoch 80 [ensemble -34.85 | reward 2.07]
> Train epoch 100 [ensemble -36.35 | reward 2.15]
Ensemble loss -36.35 / Reward Loss 2.15

=== Collecting data [10] ===
> Step 25 [reward 85.00]
> Step 50 [reward 185.00]
> Step 75 [reward 285.00]
> Step 100 [reward 385.00]
> Step 125 [reward 485.00]
> Step 150 [reward 585.00]
> Step 175 [reward 685.00]
> Step 200 [reward 785.00]
> Step 225 [reward 885.00]
> Step 250 [reward 985.00]
Rewards 985.00 / Steps 250.00
Reward stats:
 {'max': '307.69', 'mean': '114.56', 'min': '1.38', 'std': '48.66'}
Information gain stats:
 {'max': '1.38', 'mean': '0.83', 'min': '0.37', 'std': '0.11'}
Episode time 36.46
Saved _metrics_

=== Episode 11 ===
Training on [3750/15000] data points
> Train epoch 20 [ensemble -24.29 | reward 1.11]
> Train epoch 40 [ensemble -30.43 | reward 2.01]
> Train epoch 60 [ensemble -33.48 | reward 2.66]
> Train epoch 80 [ensemble -35.46 | reward 3.07]
> Train epoch 100 [ensemble -36.90 | reward 3.23]
Ensemble loss -36.90 / Reward Loss 3.23

=== Collecting data [11] ===
> Step 25 [reward 52.00]
> Step 50 [reward 152.00]
> Step 75 [reward 252.00]
> Step 100 [reward 352.00]
> Step 125 [reward 452.00]
> Step 150 [reward 552.00]
> Step 175 [reward 652.00]
> Step 200 [reward 752.00]
> Step 225 [reward 852.00]
> Step 250 [reward 952.00]
Rewards 952.00 / Steps 250.00
Reward stats:
 {'max': '339.03', 'mean': '127.22', 'min': '5.44', 'std': '55.97'}
Information gain stats:
 {'max': '1.43', 'mean': '0.81', 'min': '0.37', 'std': '0.14'}
Episode time 37.91
Saved _metrics_

=== Episode 12 ===
Training on [4000/16000] data points
> Train epoch 20 [ensemble -25.09 | reward 1.15]
> Train epoch 40 [ensemble -30.96 | reward 2.29]
> Train epoch 60 [ensemble -33.88 | reward 3.19]
> Train epoch 80 [ensemble -35.77 | reward 3.74]
> Train epoch 100 [ensemble -37.14 | reward 3.99]
Ensemble loss -37.14 / Reward Loss 3.99

=== Collecting data [12] ===
> Step 25 [reward 87.00]
> Step 50 [reward 187.00]
> Step 75 [reward 287.00]
> Step 100 [reward 387.00]
> Step 125 [reward 487.00]
> Step 150 [reward 587.00]
> Step 175 [reward 687.00]
> Step 200 [reward 787.00]
> Step 225 [reward 887.00]
> Step 250 [reward 987.00]
Rewards 987.00 / Steps 250.00
Reward stats:
 {'max': '425.97', 'mean': '153.41', 'min': '3.45', 'std': '66.50'}
Information gain stats:
 {'max': '1.42', 'mean': '0.80', 'min': '0.31', 'std': '0.14'}
Episode time 39.27
Saved _metrics_

=== Episode 13 ===
Training on [4250/17000] data points
> Train epoch 20 [ensemble -26.25 | reward 1.30]
> Train epoch 40 [ensemble -31.85 | reward 2.60]
> Train epoch 60 [ensemble -34.63 | reward 3.66]
> Train epoch 80 [ensemble -36.44 | reward 4.32]
> Train epoch 100 [ensemble -37.75 | reward 4.64]
Ensemble loss -37.75 / Reward Loss 4.64

=== Collecting data [13] ===
> Step 25 [reward 85.00]
> Step 50 [reward 185.00]
> Step 75 [reward 285.00]
> Step 100 [reward 385.00]
> Step 125 [reward 485.00]
> Step 150 [reward 585.00]
> Step 175 [reward 685.00]
> Step 200 [reward 785.00]
> Step 225 [reward 885.00]
> Step 250 [reward 985.00]
Rewards 985.00 / Steps 250.00
Reward stats:
 {'max': '429.18', 'mean': '159.54', 'min': '0.59', 'std': '70.08'}
Information gain stats:
 {'max': '1.47', 'mean': '0.81', 'min': '0.31', 'std': '0.15'}
Episode time 40.70
Saved _metrics_

=== Episode 14 ===
Training on [4500/18000] data points
> Train epoch 20 [ensemble -26.89 | reward 1.34]
> Train epoch 40 [ensemble -32.31 | reward 2.82]
> Train epoch 60 [ensemble -35.02 | reward 4.05]
> Train epoch 80 [ensemble -36.78 | reward 4.84]
> Train epoch 100 [ensemble -38.07 | reward 5.25]
Ensemble loss -38.07 / Reward Loss 5.25

=== Collecting data [14] ===
> Step 25 [reward 87.00]
> Step 50 [reward 187.00]
> Step 75 [reward 287.00]
> Step 100 [reward 387.00]
> Step 125 [reward 487.00]
> Step 150 [reward 587.00]
> Step 175 [reward 687.00]
> Step 200 [reward 787.00]
> Step 225 [reward 887.00]
> Step 250 [reward 987.00]
Rewards 987.00 / Steps 250.00
Reward stats:
 {'max': '546.61', 'mean': '197.58', 'min': '2.42', 'std': '89.60'}
Information gain stats:
 {'max': '1.48', 'mean': '0.80', 'min': '0.29', 'std': '0.16'}
Episode time 42.20
Saved _metrics_

=== Episode 15 ===
Training on [4750/19000] data points
> Train epoch 20 [ensemble -27.75 | reward 1.48]
> Train epoch 40 [ensemble -32.95 | reward 3.21]
> Train epoch 60 [ensemble -35.54 | reward 4.74]
> Train epoch 80 [ensemble -37.22 | reward 5.82]
> Train epoch 100 [ensemble -38.46 | reward 6.43]
Ensemble loss -38.46 / Reward Loss 6.43

=== Collecting data [15] ===
> Step 25 [reward 46.00]
> Step 50 [reward 146.00]
> Step 75 [reward 246.00]
> Step 100 [reward 346.00]
> Step 125 [reward 446.00]
> Step 150 [reward 546.00]
> Step 175 [reward 646.00]
> Step 200 [reward 746.00]
> Step 225 [reward 846.00]
> Step 250 [reward 946.00]
Rewards 946.00 / Steps 250.00
Reward stats:
 {'max': '595.21', 'mean': '219.04', 'min': '3.86', 'std': '102.16'}
Information gain stats:
 {'max': '1.47', 'mean': '0.81', 'min': '0.30', 'std': '0.17'}
Episode time 43.63
Saved _metrics_

=== Episode 16 ===
Training on [5000/20000] data points
> Train epoch 20 [ensemble -28.44 | reward 1.57]
> Train epoch 40 [ensemble -33.42 | reward 3.53]
> Train epoch 60 [ensemble -35.92 | reward 5.34]
> Train epoch 80 [ensemble -37.55 | reward 6.67]
> Train epoch 100 [ensemble -38.75 | reward 7.45]
Ensemble loss -38.75 / Reward Loss 7.45

=== Collecting data [16] ===
> Step 25 [reward 87.00]
> Step 50 [reward 187.00]
> Step 75 [reward 287.00]
> Step 100 [reward 387.00]
> Step 125 [reward 487.00]
> Step 150 [reward 587.00]
> Step 175 [reward 687.00]
> Step 200 [reward 787.00]
> Step 225 [reward 887.00]
> Step 250 [reward 987.00]
Rewards 987.00 / Steps 250.00
Reward stats:
 {'max': '600.79', 'mean': '231.42', 'min': '11.51', 'std': '100.19'}
Information gain stats:
 {'max': '1.47', 'mean': '0.80', 'min': '0.28', 'std': '0.17'}
Episode time 45.00
Saved _metrics_

=== Episode 17 ===
Training on [5250/21000] data points
> Train epoch 20 [ensemble -29.13 | reward 1.83]
> Train epoch 40 [ensemble -33.97 | reward 4.31]
> Train epoch 60 [ensemble -36.36 | reward 6.54]
> Train epoch 80 [ensemble -37.93 | reward 8.04]
> Train epoch 100 [ensemble -39.08 | reward 8.89]
Ensemble loss -39.08 / Reward Loss 8.89

=== Collecting data [17] ===
> Step 25 [reward 88.00]
> Step 50 [reward 188.00]
> Step 75 [reward 288.00]
> Step 100 [reward 388.00]
> Step 125 [reward 488.00]
> Step 150 [reward 588.00]
> Step 175 [reward 688.00]
> Step 200 [reward 788.00]
> Step 225 [reward 888.00]
> Step 250 [reward 988.00]
Rewards 988.00 / Steps 250.00
Reward stats:
 {'max': '649.66', 'mean': '250.37', 'min': '4.47', 'std': '112.23'}
Information gain stats:
 {'max': '1.45', 'mean': '0.80', 'min': '0.28', 'std': '0.17'}
Episode time 46.55
Saved _metrics_

=== Episode 18 ===
Training on [5500/22000] data points
> Train epoch 20 [ensemble -29.67 | reward 1.85]
> Train epoch 40 [ensemble -34.38 | reward 4.34]
> Train epoch 60 [ensemble -36.73 | reward 6.68]
> Train epoch 80 [ensemble -38.26 | reward 8.39]
> Train epoch 100 [ensemble -39.38 | reward 9.40]
Ensemble loss -39.38 / Reward Loss 9.40

=== Collecting data [18] ===
> Step 25 [reward 44.00]
> Step 50 [reward 144.00]
> Step 75 [reward 244.00]
> Step 100 [reward 344.00]
> Step 125 [reward 444.00]
> Step 150 [reward 544.00]
> Step 175 [reward 644.00]
> Step 200 [reward 744.00]
> Step 225 [reward 844.00]
> Step 250 [reward 944.00]
Rewards 944.00 / Steps 250.00
Reward stats:
 {'max': '715.22', 'mean': '259.78', 'min': '9.79', 'std': '118.91'}
Information gain stats:
 {'max': '1.52', 'mean': '0.81', 'min': '0.30', 'std': '0.18'}
Episode time 47.81
Saved _metrics_

=== Episode 19 ===
Training on [5750/23000] data points
> Train epoch 20 [ensemble -30.22 | reward 1.86]
> Train epoch 40 [ensemble -34.75 | reward 4.44]
> Train epoch 60 [ensemble -37.01 | reward 6.93]
> Train epoch 80 [ensemble -38.50 | reward 8.83]
> Train epoch 100 [ensemble -39.59 | reward 10.01]
Ensemble loss -39.59 / Reward Loss 10.01

=== Collecting data [19] ===
> Step 25 [reward 9.00]
> Step 50 [reward 109.00]
> Step 75 [reward 209.00]
> Step 100 [reward 309.00]
> Step 125 [reward 409.00]
> Step 150 [reward 509.00]
> Step 175 [reward 609.00]
> Step 200 [reward 709.00]
> Step 225 [reward 809.00]
> Step 250 [reward 909.00]
Rewards 909.00 / Steps 250.00
Reward stats:
 {'max': '746.68', 'mean': '271.45', 'min': '1.32', 'std': '134.59'}
Information gain stats:
 {'max': '1.63', 'mean': '0.83', 'min': '0.30', 'std': '0.18'}
Episode time 49.28
Saved _metrics_

=== Episode 20 ===
Training on [6000/24000] data points
> Train epoch 20 [ensemble -30.62 | reward 2.11]
> Train epoch 40 [ensemble -35.09 | reward 5.26]
> Train epoch 60 [ensemble -37.31 | reward 8.20]
> Train epoch 80 [ensemble -38.76 | reward 10.33]
> Train epoch 100 [ensemble -39.82 | reward 11.60]
Ensemble loss -39.82 / Reward Loss 11.60

=== Collecting data [20] ===
> Step 25 [reward 52.00]
> Step 50 [reward 152.00]
> Step 75 [reward 252.00]
> Step 100 [reward 352.00]
> Step 125 [reward 452.00]
> Step 150 [reward 552.00]
> Step 175 [reward 652.00]
> Step 200 [reward 752.00]
> Step 225 [reward 852.00]
> Step 250 [reward 952.00]
Rewards 952.00 / Steps 250.00
Reward stats:
 {'max': '812.84', 'mean': '295.10', 'min': '8.62', 'std': '131.62'}
Information gain stats:
 {'max': '1.49', 'mean': '0.83', 'min': '0.27', 'std': '0.18'}
Episode time 50.51
Saved _metrics_

=== Episode 21 ===
Training on [6250/25000] data points
> Train epoch 20 [ensemble -31.15 | reward 2.23]
> Train epoch 40 [ensemble -35.44 | reward 5.45]
> Train epoch 60 [ensemble -37.58 | reward 8.58]
> Train epoch 80 [ensemble -38.98 | reward 11.01]
> Train epoch 100 [ensemble -40.02 | reward 12.54]
Ensemble loss -40.02 / Reward Loss 12.54

=== Collecting data [21] ===
> Step 25 [reward 50.00]
> Step 50 [reward 150.00]
> Step 75 [reward 250.00]
> Step 100 [reward 350.00]
> Step 125 [reward 450.00]
> Step 150 [reward 550.00]
> Step 175 [reward 650.00]
> Step 200 [reward 750.00]
> Step 225 [reward 850.00]
> Step 250 [reward 950.00]
Rewards 950.00 / Steps 250.00
Reward stats:
 {'max': '818.53', 'mean': '303.99', 'min': '15.63', 'std': '130.11'}
Information gain stats:
 {'max': '1.57', 'mean': '0.83', 'min': '0.29', 'std': '0.18'}
Episode time 52.20
Saved _metrics_

=== Episode 22 ===
Training on [6500/26000] data points
> Train epoch 20 [ensemble -31.63 | reward 2.41]
> Train epoch 40 [ensemble -35.80 | reward 6.01]
> Train epoch 60 [ensemble -37.89 | reward 9.50]
> Train epoch 80 [ensemble -39.26 | reward 12.11]
> Train epoch 100 [ensemble -40.27 | reward 13.72]
Ensemble loss -40.27 / Reward Loss 13.72

=== Collecting data [22] ===
> Step 25 [reward 56.00]
> Step 50 [reward 156.00]
> Step 75 [reward 256.00]
> Step 100 [reward 356.00]
> Step 125 [reward 456.00]
> Step 150 [reward 556.00]
> Step 175 [reward 656.00]
> Step 200 [reward 756.00]
> Step 225 [reward 856.00]
> Step 250 [reward 956.00]
Rewards 956.00 / Steps 250.00
Reward stats:
 {'max': '888.50', 'mean': '345.69', 'min': '20.31', 'std': '146.16'}
Information gain stats:
 {'max': '1.54', 'mean': '0.83', 'min': '0.28', 'std': '0.18'}
Episode time 53.68
Saved _metrics_

=== Episode 23 ===
Training on [6750/27000] data points
> Train epoch 20 [ensemble -32.17 | reward 2.52]
> Train epoch 40 [ensemble -36.22 | reward 6.50]
> Train epoch 60 [ensemble -38.24 | reward 10.29]
> Train epoch 80 [ensemble -39.56 | reward 13.13]
> Train epoch 100 [ensemble -40.52 | reward 14.89]
Ensemble loss -40.52 / Reward Loss 14.89

=== Collecting data [23] ===
> Step 25 [reward 0.00]
> Step 50 [reward 65.00]
> Step 75 [reward 165.00]
> Step 100 [reward 265.00]
> Step 125 [reward 365.00]
> Step 150 [reward 465.00]
> Step 175 [reward 565.00]
> Step 200 [reward 665.00]
> Step 225 [reward 765.00]
> Step 250 [reward 865.00]
Rewards 865.00 / Steps 250.00
Reward stats:
 {'max': '929.83', 'mean': '335.04', 'min': '20.38', 'std': '159.99'}
Information gain stats:
 {'max': '1.49', 'mean': '0.85', 'min': '0.30', 'std': '0.19'}
Episode time 54.81
Saved _metrics_

=== Episode 24 ===
Training on [7000/28000] data points
> Train epoch 20 [ensemble -32.42 | reward 2.74]
> Train epoch 40 [ensemble -36.37 | reward 7.06]
> Train epoch 60 [ensemble -38.36 | reward 11.23]
> Train epoch 80 [ensemble -39.67 | reward 14.37]
> Train epoch 100 [ensemble -40.63 | reward 16.35]
Ensemble loss -40.63 / Reward Loss 16.35

=== Collecting data [24] ===
> Step 25 [reward 30.00]
> Step 50 [reward 130.00]
> Step 75 [reward 230.00]
> Step 100 [reward 330.00]
> Step 125 [reward 430.00]
> Step 150 [reward 530.00]
> Step 175 [reward 630.00]
> Step 200 [reward 730.00]
> Step 225 [reward 830.00]
> Step 250 [reward 930.00]
Rewards 930.00 / Steps 250.00
Reward stats:
 {'max': '896.84', 'mean': '347.39', 'min': '5.74', 'std': '150.08'}
Information gain stats:
 {'max': '1.50', 'mean': '0.85', 'min': '0.28', 'std': '0.18'}
Episode time 56.35
Saved _metrics_

=== Episode 25 ===
Training on [7250/29000] data points
> Train epoch 20 [ensemble -32.78 | reward 2.89]
> Train epoch 40 [ensemble -36.62 | reward 7.68]
> Train epoch 60 [ensemble -38.57 | reward 12.39]
> Train epoch 80 [ensemble -39.86 | reward 16.02]
> Train epoch 100 [ensemble -40.80 | reward 18.25]
Ensemble loss -40.80 / Reward Loss 18.25

=== Collecting data [25] ===
> Step 25 [reward 32.00]
> Step 50 [reward 132.00]
> Step 75 [reward 232.00]
> Step 100 [reward 332.00]
> Step 125 [reward 432.00]
> Step 150 [reward 532.00]
> Step 175 [reward 632.00]
> Step 200 [reward 732.00]
> Step 225 [reward 832.00]
> Step 250 [reward 932.00]
Rewards 932.00 / Steps 250.00
Reward stats:
 {'max': '939.58', 'mean': '354.48', 'min': '18.55', 'std': '144.82'}
Information gain stats:
 {'max': '1.54', 'mean': '0.85', 'min': '0.27', 'std': '0.19'}
Episode time 57.71
Saved _metrics_

=== Episode 26 ===
Training on [7500/30000] data points
> Train epoch 20 [ensemble -33.16 | reward 3.08]
> Train epoch 40 [ensemble -36.91 | reward 8.13]
> Train epoch 60 [ensemble -38.80 | reward 13.14]
> Train epoch 80 [ensemble -40.05 | reward 16.99]
> Train epoch 100 [ensemble -40.96 | reward 19.39]
Ensemble loss -40.96 / Reward Loss 19.39

=== Collecting data [26] ===
> Step 25 [reward 28.00]
> Step 50 [reward 128.00]
> Step 75 [reward 228.00]
> Step 100 [reward 328.00]
> Step 125 [reward 428.00]
> Step 150 [reward 528.00]
> Step 175 [reward 628.00]
> Step 200 [reward 728.00]
> Step 225 [reward 828.00]
> Step 250 [reward 928.00]
Rewards 928.00 / Steps 250.00
Reward stats:
 {'max': '1009.82', 'mean': '385.32', 'min': '23.85', 'std': '163.82'}
Information gain stats:
 {'max': '1.64', 'mean': '0.86', 'min': '0.30', 'std': '0.19'}
Episode time 59.35
Saved _metrics_

=== Episode 27 ===
Training on [7750/31000] data points
> Train epoch 20 [ensemble -33.48 | reward 3.20]
> Train epoch 40 [ensemble -37.16 | reward 8.46]
> Train epoch 60 [ensemble -39.01 | reward 13.59]
> Train epoch 80 [ensemble -40.24 | reward 17.56]
> Train epoch 100 [ensemble -41.13 | reward 20.09]
Ensemble loss -41.13 / Reward Loss 20.09

=== Collecting data [27] ===
> Step 25 [reward 87.00]
> Step 50 [reward 187.00]
> Step 75 [reward 287.00]
> Step 100 [reward 387.00]
> Step 125 [reward 487.00]
> Step 150 [reward 587.00]
> Step 175 [reward 687.00]
> Step 200 [reward 787.00]
> Step 225 [reward 887.00]
> Step 250 [reward 987.00]
Rewards 987.00 / Steps 250.00
Reward stats:
 {'max': '1053.32', 'mean': '422.74', 'min': '20.59', 'std': '163.78'}
Information gain stats:
 {'max': '1.52', 'mean': '0.85', 'min': '0.30', 'std': '0.19'}
Episode time 60.77
Saved _metrics_

=== Episode 28 ===
Training on [8000/32000] data points
> Train epoch 20 [ensemble -33.89 | reward 3.46]
> Train epoch 40 [ensemble -37.44 | reward 9.32]
> Train epoch 60 [ensemble -39.24 | reward 15.01]
> Train epoch 80 [ensemble -40.41 | reward 19.31]
> Train epoch 100 [ensemble -41.28 | reward 22.03]
Ensemble loss -41.28 / Reward Loss 22.03

=== Collecting data [28] ===
> Step 25 [reward 57.00]
> Step 50 [reward 157.00]
> Step 75 [reward 257.00]
> Step 100 [reward 357.00]
> Step 125 [reward 457.00]
> Step 150 [reward 557.00]
> Step 175 [reward 657.00]
> Step 200 [reward 757.00]
> Step 225 [reward 857.00]
> Step 250 [reward 957.00]
Rewards 957.00 / Steps 250.00
Reward stats:
 {'max': '1001.63', 'mean': '408.83', 'min': '33.39', 'std': '160.19'}
Information gain stats:
 {'max': '1.57', 'mean': '0.87', 'min': '0.30', 'std': '0.19'}
Episode time 62.16
Saved _metrics_

=== Episode 29 ===
Training on [8250/33000] data points
> Train epoch 20 [ensemble -34.21 | reward 3.55]
> Train epoch 40 [ensemble -37.68 | reward 9.86]
> Train epoch 60 [ensemble -39.43 | reward 16.01]
> Train epoch 80 [ensemble -40.58 | reward 20.64]
> Train epoch 100 [ensemble -41.43 | reward 23.54]
Ensemble loss -41.43 / Reward Loss 23.54

=== Collecting data [29] ===
> Step 25 [reward 86.00]
> Step 50 [reward 186.00]
> Step 75 [reward 286.00]
> Step 100 [reward 386.00]
> Step 125 [reward 486.00]
> Step 150 [reward 586.00]
> Step 175 [reward 686.00]
> Step 200 [reward 786.00]
> Step 225 [reward 886.00]
> Step 250 [reward 986.00]
Rewards 986.00 / Steps 250.00
Reward stats:
 {'max': '1108.76', 'mean': '469.62', 'min': '39.09', 'std': '176.53'}
Information gain stats:
 {'max': '1.54', 'mean': '0.87', 'min': '0.32', 'std': '0.19'}
Episode time 63.62
Saved _metrics_

=== Episode 30 ===
Training on [8500/34000] data points
> Train epoch 20 [ensemble -34.48 | reward 3.75]
> Train epoch 40 [ensemble -37.90 | reward 10.30]
> Train epoch 60 [ensemble -39.62 | reward 16.75]
> Train epoch 80 [ensemble -40.76 | reward 21.71]
> Train epoch 100 [ensemble -41.59 | reward 24.86]
Ensemble loss -41.59 / Reward Loss 24.86

=== Collecting data [30] ===
> Step 25 [reward 46.00]
> Step 50 [reward 146.00]
> Step 75 [reward 246.00]
> Step 100 [reward 346.00]
> Step 125 [reward 446.00]
> Step 150 [reward 546.00]
> Step 175 [reward 646.00]
> Step 200 [reward 746.00]
> Step 225 [reward 846.00]
> Step 250 [reward 946.00]
Rewards 946.00 / Steps 250.00
Reward stats:
 {'max': '1095.93', 'mean': '457.46', 'min': '31.06', 'std': '175.76'}
Information gain stats:
 {'max': '1.53', 'mean': '0.88', 'min': '0.32', 'std': '0.19'}
Episode time 64.95
Saved _metrics_

=== Episode 31 ===
Training on [8750/35000] data points
> Train epoch 20 [ensemble -34.85 | reward 4.08]
> Train epoch 40 [ensemble -38.16 | reward 11.00]
> Train epoch 60 [ensemble -39.84 | reward 17.72]
> Train epoch 80 [ensemble -40.94 | reward 22.85]
> Train epoch 100 [ensemble -41.74 | reward 26.17]
Ensemble loss -41.74 / Reward Loss 26.17

=== Collecting data [31] ===
> Step 25 [reward 87.00]
> Step 50 [reward 187.00]
> Step 75 [reward 287.00]
> Step 100 [reward 387.00]
> Step 125 [reward 487.00]
> Step 150 [reward 587.00]
> Step 175 [reward 687.00]
> Step 200 [reward 787.00]
> Step 225 [reward 887.00]
> Step 250 [reward 987.00]
Rewards 987.00 / Steps 250.00
Reward stats:
 {'max': '1147.53', 'mean': '489.31', 'min': '45.34', 'std': '183.28'}
Information gain stats:
 {'max': '1.53', 'mean': '0.85', 'min': '0.29', 'std': '0.19'}
Episode time 66.21
Saved _metrics_

=== Episode 32 ===
Training on [9000/36000] data points
> Train epoch 20 [ensemble -35.05 | reward 4.12]
> Train epoch 40 [ensemble -38.31 | reward 11.40]
> Train epoch 60 [ensemble -39.95 | reward 18.47]
> Train epoch 80 [ensemble -41.04 | reward 23.95]
> Train epoch 100 [ensemble -41.84 | reward 27.46]
Ensemble loss -41.84 / Reward Loss 27.46

=== Collecting data [32] ===
> Step 25 [reward 86.00]
> Step 50 [reward 186.00]
> Step 75 [reward 286.00]
> Step 100 [reward 386.00]
> Step 125 [reward 486.00]
> Step 150 [reward 586.00]
> Step 175 [reward 686.00]
> Step 200 [reward 786.00]
> Step 225 [reward 886.00]
> Step 250 [reward 986.00]
Rewards 986.00 / Steps 250.00
Reward stats:
 {'max': '1233.17', 'mean': '505.82', 'min': '58.25', 'std': '193.69'}
Information gain stats:
 {'max': '1.52', 'mean': '0.86', 'min': '0.31', 'std': '0.19'}
Episode time 67.73
Saved _metrics_

=== Episode 33 ===
Training on [9250/37000] data points
> Train epoch 20 [ensemble -35.38 | reward 4.27]
> Train epoch 40 [ensemble -38.53 | reward 11.85]
> Train epoch 60 [ensemble -40.14 | reward 19.35]
> Train epoch 80 [ensemble -41.20 | reward 25.11]
> Train epoch 100 [ensemble -41.98 | reward 28.78]
Ensemble loss -41.98 / Reward Loss 28.78

=== Collecting data [33] ===
> Step 25 [reward 31.00]
> Step 50 [reward 131.00]
> Step 75 [reward 231.00]
> Step 100 [reward 331.00]
> Step 125 [reward 431.00]
> Step 150 [reward 531.00]
> Step 175 [reward 631.00]
> Step 200 [reward 731.00]
> Step 225 [reward 831.00]
> Step 250 [reward 931.00]
Rewards 931.00 / Steps 250.00
Reward stats:
 {'max': '1216.74', 'mean': '513.22', 'min': '48.32', 'std': '191.21'}
Information gain stats:
 {'max': '1.64', 'mean': '0.88', 'min': '0.33', 'std': '0.19'}
Episode time 69.34
Saved _metrics_

=== Episode 34 ===
Training on [9500/38000] data points
> Train epoch 20 [ensemble -35.65 | reward 4.38]
> Train epoch 40 [ensemble -38.76 | reward 12.26]
> Train epoch 60 [ensemble -40.35 | reward 19.98]
> Train epoch 80 [ensemble -41.40 | reward 26.02]
> Train epoch 100 [ensemble -42.16 | reward 29.94]
Ensemble loss -42.16 / Reward Loss 29.94

=== Collecting data [34] ===
> Step 25 [reward 87.00]
> Step 50 [reward 187.00]
> Step 75 [reward 287.00]
> Step 100 [reward 387.00]
> Step 125 [reward 487.00]
> Step 150 [reward 587.00]
> Step 175 [reward 687.00]
> Step 200 [reward 787.00]
> Step 225 [reward 887.00]
> Step 250 [reward 987.00]
Rewards 987.00 / Steps 250.00
Reward stats:
 {'max': '1255.99', 'mean': '521.66', 'min': '36.13', 'std': '197.28'}
Information gain stats:
 {'max': '1.57', 'mean': '0.88', 'min': '0.29', 'std': '0.19'}
Episode time 70.59
Saved _metrics_

=== Episode 35 ===
Training on [9750/39000] data points
> Train epoch 20 [ensemble -35.89 | reward 4.71]
> Train epoch 40 [ensemble -38.93 | reward 13.19]
> Train epoch 60 [ensemble -40.47 | reward 21.59]
> Train epoch 80 [ensemble -41.49 | reward 28.06]
> Train epoch 100 [ensemble -42.24 | reward 32.25]
Ensemble loss -42.24 / Reward Loss 32.25

=== Collecting data [35] ===
> Step 25 [reward 89.00]
> Step 50 [reward 189.00]
> Step 75 [reward 289.00]
> Step 100 [reward 389.00]
> Step 125 [reward 489.00]
> Step 150 [reward 589.00]
> Step 175 [reward 689.00]
> Step 200 [reward 789.00]
> Step 225 [reward 889.00]
> Step 250 [reward 989.00]
Rewards 989.00 / Steps 250.00
Reward stats:
 {'max': '1262.33', 'mean': '549.48', 'min': '53.32', 'std': '206.75'}
Information gain stats:
 {'max': '1.59', 'mean': '0.86', 'min': '0.29', 'std': '0.19'}
Episode time 72.15
Saved _metrics_

=== Episode 36 ===
Training on [10000/40000] data points
> Train epoch 20 [ensemble -36.15 | reward 4.94]
> Train epoch 40 [ensemble -39.11 | reward 13.62]
> Train epoch 60 [ensemble -40.62 | reward 22.12]
> Train epoch 80 [ensemble -41.62 | reward 28.75]
> Train epoch 100 [ensemble -42.35 | reward 33.08]
Ensemble loss -42.35 / Reward Loss 33.08

=== Collecting data [36] ===
> Step 25 [reward 33.00]
> Step 50 [reward 133.00]
> Step 75 [reward 233.00]
> Step 100 [reward 333.00]
> Step 125 [reward 433.00]
> Step 150 [reward 533.00]
> Step 175 [reward 633.00]
> Step 200 [reward 733.00]
> Step 225 [reward 833.00]
> Step 250 [reward 933.00]
Rewards 933.00 / Steps 250.00
Reward stats:
 {'max': '1360.62', 'mean': '583.99', 'min': '43.70', 'std': '208.61'}
Information gain stats:
 {'max': '1.59', 'mean': '0.88', 'min': '0.31', 'std': '0.19'}
Episode time 73.39
Saved _metrics_

=== Episode 37 ===
Training on [10250/41000] data points
> Train epoch 20 [ensemble -36.34 | reward 5.16]
> Train epoch 40 [ensemble -39.27 | reward 14.87]
> Train epoch 60 [ensemble -40.76 | reward 24.22]
> Train epoch 80 [ensemble -41.74 | reward 31.23]
> Train epoch 100 [ensemble -42.46 | reward 35.70]
Ensemble loss -42.46 / Reward Loss 35.70

=== Collecting data [37] ===
> Step 25 [reward 52.00]
> Step 50 [reward 152.00]
> Step 75 [reward 252.00]
> Step 100 [reward 352.00]
> Step 125 [reward 452.00]
> Step 150 [reward 552.00]
> Step 175 [reward 652.00]
> Step 200 [reward 752.00]
> Step 225 [reward 852.00]
> Step 250 [reward 952.00]
Rewards 952.00 / Steps 250.00
Reward stats:
 {'max': '1293.26', 'mean': '552.89', 'min': '60.39', 'std': '195.09'}
Information gain stats:
 {'max': '1.59', 'mean': '0.88', 'min': '0.31', 'std': '0.20'}
Episode time 74.96
Saved _metrics_

=== Episode 38 ===
Training on [10500/42000] data points
> Train epoch 20 [ensemble -36.58 | reward 5.55]
> Train epoch 40 [ensemble -39.44 | reward 15.76]
> Train epoch 60 [ensemble -40.89 | reward 25.60]
> Train epoch 80 [ensemble -41.84 | reward 33.02]
> Train epoch 100 [ensemble -42.55 | reward 37.71]
Ensemble loss -42.55 / Reward Loss 37.71

=== Collecting data [38] ===
> Step 25 [reward 87.00]
> Step 50 [reward 187.00]
> Step 75 [reward 287.00]
> Step 100 [reward 387.00]
> Step 125 [reward 487.00]
> Step 150 [reward 587.00]
> Step 175 [reward 687.00]
> Step 200 [reward 787.00]
> Step 225 [reward 887.00]
> Step 250 [reward 987.00]
Rewards 987.00 / Steps 250.00
Reward stats:
 {'max': '1403.69', 'mean': '610.89', 'min': '81.28', 'std': '209.10'}
Information gain stats:
 {'max': '1.56', 'mean': '0.87', 'min': '0.30', 'std': '0.19'}
Episode time 76.44
Saved _metrics_

=== Episode 39 ===
Training on [10750/43000] data points
> Train epoch 20 [ensemble -36.79 | reward 5.71]
> Train epoch 40 [ensemble -39.57 | reward 16.02]
> Train epoch 60 [ensemble -41.01 | reward 25.93]
> Train epoch 80 [ensemble -41.95 | reward 33.44]
> Train epoch 100 [ensemble -42.65 | reward 38.27]
Ensemble loss -42.65 / Reward Loss 38.27

=== Collecting data [39] ===
> Step 25 [reward 3.00]
> Step 50 [reward 103.00]
> Step 75 [reward 203.00]
> Step 100 [reward 303.00]
> Step 125 [reward 403.00]
> Step 150 [reward 503.00]
> Step 175 [reward 603.00]
> Step 200 [reward 703.00]
> Step 225 [reward 803.00]
> Step 250 [reward 903.00]
Rewards 903.00 / Steps 250.00
Reward stats:
 {'max': '1406.52', 'mean': '636.80', 'min': '78.10', 'std': '221.94'}
Information gain stats:
 {'max': '1.56', 'mean': '0.89', 'min': '0.34', 'std': '0.19'}
Episode time 77.95
Saved _metrics_

=== Episode 40 ===
Training on [11000/44000] data points
> Train epoch 20 [ensemble -36.90 | reward 6.08]
> Train epoch 40 [ensemble -39.67 | reward 17.25]
> Train epoch 60 [ensemble -41.09 | reward 28.03]
> Train epoch 80 [ensemble -42.02 | reward 36.20]
> Train epoch 100 [ensemble -42.71 | reward 41.40]
Ensemble loss -42.71 / Reward Loss 41.40

=== Collecting data [40] ===
> Step 25 [reward 25.00]
> Step 50 [reward 125.00]
> Step 75 [reward 225.00]
> Step 100 [reward 325.00]
> Step 125 [reward 425.00]
> Step 150 [reward 525.00]
> Step 175 [reward 625.00]
> Step 200 [reward 725.00]
> Step 225 [reward 825.00]
> Step 250 [reward 925.00]
Rewards 925.00 / Steps 250.00
Reward stats:
 {'max': '1416.95', 'mean': '639.69', 'min': '41.24', 'std': '232.04'}
Information gain stats:
 {'max': '1.59', 'mean': '0.87', 'min': '0.30', 'std': '0.20'}
Episode time 79.18
Saved _metrics_

=== Episode 41 ===
Training on [11250/45000] data points
> Train epoch 20 [ensemble -37.12 | reward 6.00]
> Train epoch 40 [ensemble -39.82 | reward 17.23]
> Train epoch 60 [ensemble -41.21 | reward 28.10]
> Train epoch 80 [ensemble -42.13 | reward 36.34]
> Train epoch 100 [ensemble -42.79 | reward 41.68]
Ensemble loss -42.79 / Reward Loss 41.68

=== Collecting data [41] ===
> Step 25 [reward 90.00]
> Step 50 [reward 190.00]
> Step 75 [reward 290.00]
> Step 100 [reward 390.00]
> Step 125 [reward 490.00]
> Step 150 [reward 590.00]
> Step 175 [reward 690.00]
> Step 200 [reward 790.00]
> Step 225 [reward 890.00]
> Step 250 [reward 990.00]
Rewards 990.00 / Steps 250.00
Reward stats:
 {'max': '1405.51', 'mean': '650.71', 'min': '117.06', 'std': '208.65'}
Information gain stats:
 {'max': '1.54', 'mean': '0.88', 'min': '0.32', 'std': '0.20'}
Episode time 80.35
Saved _metrics_

=== Episode 42 ===
Training on [11500/46000] data points
> Train epoch 20 [ensemble -37.30 | reward 6.31]
> Train epoch 40 [ensemble -39.95 | reward 17.62]
> Train epoch 60 [ensemble -41.31 | reward 28.64]
> Train epoch 80 [ensemble -42.21 | reward 37.06]
> Train epoch 100 [ensemble -42.87 | reward 42.51]
Ensemble loss -42.87 / Reward Loss 42.51

=== Collecting data [42] ===
> Step 25 [reward 87.00]
> Step 50 [reward 187.00]
> Step 75 [reward 287.00]
> Step 100 [reward 387.00]
> Step 125 [reward 487.00]
> Step 150 [reward 587.00]
> Step 175 [reward 687.00]
> Step 200 [reward 787.00]
> Step 225 [reward 887.00]
> Step 250 [reward 987.00]
Rewards 987.00 / Steps 250.00
Reward stats:
 {'max': '1494.73', 'mean': '677.37', 'min': '101.32', 'std': '226.32'}
Information gain stats:
 {'max': '1.56', 'mean': '0.89', 'min': '0.30', 'std': '0.20'}
Episode time 81.57
Saved _metrics_

=== Episode 43 ===
Training on [11750/47000] data points
> Train epoch 20 [ensemble -37.56 | reward 6.60]
> Train epoch 40 [ensemble -40.17 | reward 18.70]
> Train epoch 60 [ensemble -41.51 | reward 30.34]
> Train epoch 80 [ensemble -42.39 | reward 39.21]
> Train epoch 100 [ensemble -43.03 | reward 44.98]
Ensemble loss -43.03 / Reward Loss 44.98

=== Collecting data [43] ===
> Step 25 [reward 32.00]
> Step 50 [reward 132.00]
> Step 75 [reward 232.00]
> Step 100 [reward 332.00]
> Step 125 [reward 432.00]
> Step 150 [reward 532.00]
> Step 175 [reward 632.00]
> Step 200 [reward 732.00]
> Step 225 [reward 832.00]
> Step 250 [reward 932.00]
Rewards 932.00 / Steps 250.00
Reward stats:
 {'max': '1497.72', 'mean': '698.04', 'min': '91.60', 'std': '234.24'}
Information gain stats:
 {'max': '1.66', 'mean': '0.90', 'min': '0.31', 'std': '0.20'}
Episode time 83.40
Saved _metrics_

=== Episode 44 ===
Training on [12000/48000] data points
> Train epoch 20 [ensemble -37.73 | reward 6.82]
> Train epoch 40 [ensemble -40.30 | reward 19.30]
> Train epoch 60 [ensemble -41.62 | reward 31.34]
> Train epoch 80 [ensemble -42.48 | reward 40.61]
> Train epoch 100 [ensemble -43.11 | reward 46.65]
Ensemble loss -43.11 / Reward Loss 46.65

=== Collecting data [44] ===
> Step 25 [reward 59.00]
> Step 50 [reward 159.00]
> Step 75 [reward 259.00]
> Step 100 [reward 359.00]
> Step 125 [reward 459.00]
> Step 150 [reward 559.00]
> Step 175 [reward 659.00]
> Step 200 [reward 759.00]
> Step 225 [reward 859.00]
> Step 250 [reward 959.00]
Rewards 959.00 / Steps 250.00
Reward stats:
 {'max': '1497.26', 'mean': '703.88', 'min': '105.28', 'std': '227.07'}
Information gain stats:
 {'max': '1.59', 'mean': '0.90', 'min': '0.30', 'std': '0.20'}
Episode time 84.95
Saved _metrics_

=== Episode 45 ===
Training on [12250/49000] data points
> Train epoch 20 [ensemble -37.87 | reward 6.88]
> Train epoch 40 [ensemble -40.38 | reward 19.41]
> Train epoch 60 [ensemble -41.68 | reward 31.88]
> Train epoch 80 [ensemble -42.53 | reward 41.42]
> Train epoch 100 [ensemble -43.15 | reward 47.66]
Ensemble loss -43.15 / Reward Loss 47.66

=== Collecting data [45] ===
> Step 25 [reward 28.00]
> Step 50 [reward 128.00]
> Step 75 [reward 228.00]
> Step 100 [reward 328.00]
> Step 125 [reward 428.00]
> Step 150 [reward 528.00]
> Step 175 [reward 628.00]
> Step 200 [reward 728.00]
> Step 225 [reward 828.00]
> Step 250 [reward 928.00]
Rewards 928.00 / Steps 250.00
Reward stats:
 {'max': '1577.80', 'mean': '716.34', 'min': '115.43', 'std': '234.19'}
Information gain stats:
 {'max': '1.60', 'mean': '0.90', 'min': '0.30', 'std': '0.20'}
Episode time 86.38
Saved _metrics_

=== Episode 46 ===
Training on [12500/50000] data points
> Train epoch 20 [ensemble -38.00 | reward 7.29]
> Train epoch 40 [ensemble -40.47 | reward 20.53]
> Train epoch 60 [ensemble -41.74 | reward 33.27]
> Train epoch 80 [ensemble -42.58 | reward 42.95]
> Train epoch 100 [ensemble -43.20 | reward 49.27]
Ensemble loss -43.20 / Reward Loss 49.27

=== Collecting data [46] ===
> Step 25 [reward 86.00]
> Step 50 [reward 186.00]
> Step 75 [reward 286.00]
> Step 100 [reward 386.00]
> Step 125 [reward 486.00]
> Step 150 [reward 586.00]
> Step 175 [reward 686.00]
> Step 200 [reward 786.00]
> Step 225 [reward 886.00]
> Step 250 [reward 986.00]
Rewards 986.00 / Steps 250.00
Reward stats:
 {'max': '1584.61', 'mean': '742.64', 'min': '145.85', 'std': '228.56'}
Information gain stats:
 {'max': '1.56', 'mean': '0.90', 'min': '0.28', 'std': '0.20'}
Episode time 87.57
Saved _metrics_

=== Episode 47 ===
Training on [12750/51000] data points
> Train epoch 20 [ensemble -38.10 | reward 7.53]
> Train epoch 40 [ensemble -40.59 | reward 21.27]
> Train epoch 60 [ensemble -41.85 | reward 34.54]
> Train epoch 80 [ensemble -42.68 | reward 44.54]
> Train epoch 100 [ensemble -43.29 | reward 51.01]
Ensemble loss -43.29 / Reward Loss 51.01

=== Collecting data [47] ===
> Step 25 [reward 57.00]
> Step 50 [reward 157.00]
> Step 75 [reward 257.00]
> Step 100 [reward 357.00]
> Step 125 [reward 457.00]
> Step 150 [reward 557.00]
> Step 175 [reward 657.00]
> Step 200 [reward 757.00]
> Step 225 [reward 857.00]
> Step 250 [reward 957.00]
Rewards 957.00 / Steps 250.00
Reward stats:
 {'max': '1628.43', 'mean': '788.10', 'min': '143.46', 'std': '242.52'}
Information gain stats:
 {'max': '1.61', 'mean': '0.90', 'min': '0.32', 'std': '0.20'}
Episode time 89.20
Saved _metrics_

=== Episode 48 ===
Training on [13000/52000] data points
> Train epoch 20 [ensemble -38.27 | reward 7.71]
> Train epoch 40 [ensemble -40.70 | reward 21.85]
> Train epoch 60 [ensemble -41.94 | reward 35.39]
> Train epoch 80 [ensemble -42.76 | reward 45.63]
> Train epoch 100 [ensemble -43.36 | reward 52.25]
Ensemble loss -43.36 / Reward Loss 52.25

=== Collecting data [48] ===
> Step 25 [reward 86.00]
> Step 50 [reward 186.00]
> Step 75 [reward 286.00]
> Step 100 [reward 386.00]
> Step 125 [reward 486.00]
> Step 150 [reward 586.00]
> Step 175 [reward 686.00]
> Step 200 [reward 786.00]
> Step 225 [reward 886.00]
> Step 250 [reward 986.00]
Rewards 986.00 / Steps 250.00
Reward stats:
 {'max': '1583.01', 'mean': '788.68', 'min': '152.33', 'std': '231.34'}
Information gain stats:
 {'max': '1.60', 'mean': '0.90', 'min': '0.31', 'std': '0.21'}
Episode time 90.30
Saved _metrics_

=== Episode 49 ===
Training on [13250/53000] data points
> Train epoch 20 [ensemble -38.51 | reward 8.15]
> Train epoch 40 [ensemble -40.87 | reward 23.12]
> Train epoch 60 [ensemble -42.08 | reward 37.22]
> Train epoch 80 [ensemble -42.87 | reward 47.83]
> Train epoch 100 [ensemble -43.45 | reward 54.67]
Ensemble loss -43.45 / Reward Loss 54.67

=== Collecting data [49] ===
> Step 25 [reward 58.00]
> Step 50 [reward 158.00]
> Step 75 [reward 258.00]
> Step 100 [reward 358.00]
> Step 125 [reward 458.00]
> Step 150 [reward 558.00]
> Step 175 [reward 658.00]
> Step 200 [reward 758.00]
> Step 225 [reward 858.00]
> Step 250 [reward 958.00]
Rewards 958.00 / Steps 250.00
Reward stats:
 {'max': '1681.75', 'mean': '833.61', 'min': '153.73', 'std': '245.86'}
Information gain stats:
 {'max': '1.57', 'mean': '0.89', 'min': '0.31', 'std': '0.21'}
Episode time 92.04
Saved _metrics_