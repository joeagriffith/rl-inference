20:49:51

=== Loading experiment [device: cuda] ===

{'action_noise': None,
 'action_repeat': 4,
 'batch_size': 50,
 'coverage': False,
 'ensemble_size': 10,
 'env_name': 'DeepMindCatch',
 'epsilon': 1e-08,
 'expl_scale': 0.1,
 'expl_strategy': 'information',
 'grad_clip_norm': 1000,
 'hidden_size': 200,
 'learning_rate': 0.001,
 'logdir': 'cup_catch_DQN-like',
 'max_episode_len': 1000,
 'n_candidates': 500,
 'n_episodes': 50,
 'n_seed_episodes': 5,
 'n_train_epochs': 100,
 'optimisation_iters': 5,
 'plan_horizon': 12,
 'record_every': None,
 'reward_scale': 1.0,
 'seed': 0,
 'strategy': 'information',
 'top_candidates': 50,
 'use_exploration': True,
 'use_mean': False,
 'use_reward': True}

Collected seeds: [5 episodes | 1250 frames]

=== Episode 1 ===
Training on [1250/5000] data points
> Train epoch 20 [ensemble -19.56 | reward 0.24]
> Train epoch 40 [ensemble -27.34 | reward 0.19]
> Train epoch 60 [ensemble -31.09 | reward 0.16]
> Train epoch 80 [ensemble -33.50 | reward 0.14]
> Train epoch 100 [ensemble -35.23 | reward 0.12]
Ensemble loss -35.23 / Reward Loss 0.12

=== Collecting data [1] ===
> Step 25 [reward 0.00]
> Step 50 [reward 56.00]
> Step 75 [reward 156.00]
> Step 100 [reward 256.00]
> Step 125 [reward 356.00]
> Step 150 [reward 456.00]
> Step 175 [reward 555.00]
> Step 200 [reward 654.00]
> Step 225 [reward 753.00]
> Step 250 [reward 853.00]
Rewards 853.00 / Steps 250.00
Reward stats:
 {'max': '260.03', 'mean': '42.53', 'min': '-6.95', 'std': '35.00'}
Information gain stats:
 {'max': '2.23', 'mean': '1.25', 'min': '0.54', 'std': '0.14'}
Episode time 27.02
Saved _metrics_

=== Episode 2 ===
Training on [1500/6000] data points
> Train epoch 20 [ensemble -18.58 | reward 0.46]
> Train epoch 40 [ensemble -26.19 | reward 0.44]
> Train epoch 60 [ensemble -30.04 | reward 0.47]
> Train epoch 80 [ensemble -32.53 | reward 0.48]
> Train epoch 100 [ensemble -34.34 | reward 0.48]
Ensemble loss -34.34 / Reward Loss 0.48

=== Collecting data [2] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 32.00]
> Step 150 [reward 132.00]
> Step 175 [reward 232.00]
> Step 200 [reward 332.00]
> Step 225 [reward 432.00]
> Step 250 [reward 532.00]
Rewards 532.00 / Steps 250.00
Reward stats:
 {'max': '333.32', 'mean': '134.58', 'min': '2.18', 'std': '92.37'}
Information gain stats:
 {'max': '1.88', 'mean': '0.86', 'min': '0.34', 'std': '0.22'}
Episode time 26.94
Saved _metrics_

=== Episode 3 ===
Training on [1750/7000] data points
> Train epoch 20 [ensemble -18.38 | reward 0.65]
> Train epoch 40 [ensemble -25.73 | reward 0.78]
> Train epoch 60 [ensemble -29.52 | reward 0.93]
> Train epoch 80 [ensemble -32.01 | reward 1.01]
> Train epoch 100 [ensemble -33.83 | reward 1.03]
Ensemble loss -33.83 / Reward Loss 1.03

=== Collecting data [3] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 93.00]
> Step 150 [reward 193.00]
> Step 175 [reward 293.00]
> Step 200 [reward 393.00]
> Step 225 [reward 493.00]
> Step 250 [reward 593.00]
Rewards 593.00 / Steps 250.00
Reward stats:
 {'max': '352.61', 'mean': '126.35', 'min': '-8.12', 'std': '82.15'}
Information gain stats:
 {'max': '1.69', 'mean': '0.86', 'min': '0.31', 'std': '0.23'}
Episode time 28.44
Saved _metrics_

=== Episode 4 ===
Training on [2000/8000] data points
> Train epoch 20 [ensemble -19.10 | reward 0.80]
> Train epoch 40 [ensemble -26.16 | reward 1.17]
> Train epoch 60 [ensemble -29.80 | reward 1.46]
> Train epoch 80 [ensemble -32.22 | reward 1.62]
> Train epoch 100 [ensemble -33.99 | reward 1.67]
Ensemble loss -33.99 / Reward Loss 1.67

=== Collecting data [4] ===
> Step 25 [reward 70.00]
> Step 50 [reward 170.00]
> Step 75 [reward 270.00]
> Step 100 [reward 370.00]
> Step 125 [reward 470.00]
> Step 150 [reward 570.00]
> Step 175 [reward 670.00]
> Step 200 [reward 770.00]
> Step 225 [reward 870.00]
> Step 250 [reward 970.00]
Rewards 970.00 / Steps 250.00
Reward stats:
 {'max': '352.53', 'mean': '177.99', 'min': '-11.04', 'std': '86.69'}
Information gain stats:
 {'max': '1.58', 'mean': '0.75', 'min': '0.28', 'std': '0.24'}
Episode time 30.96
Saved _metrics_

=== Episode 5 ===
Training on [2250/9000] data points
> Train epoch 20 [ensemble -20.91 | reward 0.82]
> Train epoch 40 [ensemble -27.70 | reward 1.19]
> Train epoch 60 [ensemble -31.12 | reward 1.52]
> Train epoch 80 [ensemble -33.38 | reward 1.72]
> Train epoch 100 [ensemble -35.02 | reward 1.79]
Ensemble loss -35.02 / Reward Loss 1.79

=== Collecting data [5] ===
> Step 25 [reward 90.00]
> Step 50 [reward 190.00]
> Step 75 [reward 290.00]
> Step 100 [reward 390.00]
> Step 125 [reward 490.00]
> Step 150 [reward 590.00]
> Step 175 [reward 690.00]
> Step 200 [reward 790.00]
> Step 225 [reward 890.00]
> Step 250 [reward 990.00]
Rewards 990.00 / Steps 250.00
Reward stats:
 {'max': '398.05', 'mean': '195.65', 'min': '-2.67', 'std': '89.13'}
Information gain stats:
 {'max': '1.61', 'mean': '0.78', 'min': '0.29', 'std': '0.24'}
Episode time 32.14
Saved _metrics_

=== Episode 6 ===
Training on [2500/10000] data points
> Train epoch 20 [ensemble -23.07 | reward 0.89]
> Train epoch 40 [ensemble -29.36 | reward 1.41]
> Train epoch 60 [ensemble -32.52 | reward 1.86]
> Train epoch 80 [ensemble -34.59 | reward 2.16]
> Train epoch 100 [ensemble -36.10 | reward 2.29]
Ensemble loss -36.10 / Reward Loss 2.29

=== Collecting data [6] ===
> Step 25 [reward 52.00]
> Step 50 [reward 152.00]
> Step 75 [reward 252.00]
> Step 100 [reward 352.00]
> Step 125 [reward 452.00]
> Step 150 [reward 552.00]
> Step 175 [reward 652.00]
> Step 200 [reward 752.00]
> Step 225 [reward 852.00]
> Step 250 [reward 952.00]
Rewards 952.00 / Steps 250.00
Reward stats:
 {'max': '433.44', 'mean': '219.20', 'min': '-6.56', 'std': '101.40'}
Information gain stats:
 {'max': '1.62', 'mean': '0.81', 'min': '0.29', 'std': '0.25'}
Episode time 33.65
Saved _metrics_

=== Episode 7 ===
Training on [2750/11000] data points
> Train epoch 20 [ensemble -24.32 | reward 0.95]
> Train epoch 40 [ensemble -30.34 | reward 1.64]
> Train epoch 60 [ensemble -33.30 | reward 2.27]
> Train epoch 80 [ensemble -35.23 | reward 2.70]
> Train epoch 100 [ensemble -36.64 | reward 2.93]
Ensemble loss -36.64 / Reward Loss 2.93

=== Collecting data [7] ===
> Step 25 [reward 86.00]
> Step 50 [reward 186.00]
> Step 75 [reward 286.00]
> Step 100 [reward 386.00]
> Step 125 [reward 486.00]
> Step 150 [reward 586.00]
> Step 175 [reward 686.00]
> Step 200 [reward 786.00]
> Step 225 [reward 886.00]
> Step 250 [reward 986.00]
Rewards 986.00 / Steps 250.00
Reward stats:
 {'max': '444.82', 'mean': '230.61', 'min': '-7.10', 'std': '98.48'}
Information gain stats:
 {'max': '1.65', 'mean': '0.80', 'min': '0.28', 'std': '0.23'}
Episode time 34.96
Saved _metrics_

=== Episode 8 ===
Training on [3000/12000] data points
> Train epoch 20 [ensemble -25.58 | reward 1.14]
> Train epoch 40 [ensemble -31.32 | reward 2.07]
> Train epoch 60 [ensemble -34.16 | reward 2.93]
> Train epoch 80 [ensemble -36.00 | reward 3.53]
> Train epoch 100 [ensemble -37.34 | reward 3.85]
Ensemble loss -37.34 / Reward Loss 3.85

=== Collecting data [8] ===
> Step 25 [reward 86.00]
> Step 50 [reward 186.00]
> Step 75 [reward 286.00]
> Step 100 [reward 386.00]
> Step 125 [reward 486.00]
> Step 150 [reward 586.00]
> Step 175 [reward 686.00]
> Step 200 [reward 786.00]
> Step 225 [reward 886.00]
> Step 250 [reward 986.00]
Rewards 986.00 / Steps 250.00
Reward stats:
 {'max': '506.83', 'mean': '270.97', 'min': '-6.66', 'std': '119.68'}
Information gain stats:
 {'max': '1.66', 'mean': '0.78', 'min': '0.28', 'std': '0.26'}
Episode time 35.63
Saved _metrics_

=== Episode 9 ===
Training on [3250/13000] data points
> Train epoch 20 [ensemble -26.73 | reward 1.16]
> Train epoch 40 [ensemble -32.23 | reward 2.21]
> Train epoch 60 [ensemble -34.92 | reward 3.15]
> Train epoch 80 [ensemble -36.65 | reward 3.83]
> Train epoch 100 [ensemble -37.91 | reward 4.20]
Ensemble loss -37.91 / Reward Loss 4.20

=== Collecting data [9] ===
> Step 25 [reward 36.00]
> Step 50 [reward 136.00]
> Step 75 [reward 236.00]
> Step 100 [reward 336.00]
> Step 125 [reward 436.00]
> Step 150 [reward 536.00]
> Step 175 [reward 636.00]
> Step 200 [reward 736.00]
> Step 225 [reward 836.00]
> Step 250 [reward 936.00]
Rewards 936.00 / Steps 250.00
Reward stats:
 {'max': '553.64', 'mean': '283.01', 'min': '-9.61', 'std': '131.27'}
Information gain stats:
 {'max': '1.78', 'mean': '0.80', 'min': '0.27', 'std': '0.27'}
Episode time 37.19
Saved _metrics_

=== Episode 10 ===
Training on [3500/14000] data points
> Train epoch 20 [ensemble -27.76 | reward 1.20]
> Train epoch 40 [ensemble -32.90 | reward 2.44]
> Train epoch 60 [ensemble -35.42 | reward 3.64]
> Train epoch 80 [ensemble -37.05 | reward 4.55]
> Train epoch 100 [ensemble -38.24 | reward 5.09]
Ensemble loss -38.24 / Reward Loss 5.09

=== Collecting data [10] ===
> Step 25 [reward 61.00]
> Step 50 [reward 161.00]
> Step 75 [reward 261.00]
> Step 100 [reward 361.00]
> Step 125 [reward 461.00]
> Step 150 [reward 561.00]
> Step 175 [reward 661.00]
> Step 200 [reward 761.00]
> Step 225 [reward 861.00]
> Step 250 [reward 961.00]
Rewards 961.00 / Steps 250.00
Reward stats:
 {'max': '608.16', 'mean': '322.90', 'min': '-5.80', 'std': '137.91'}
Information gain stats:
 {'max': '1.69', 'mean': '0.80', 'min': '0.30', 'std': '0.26'}
Episode time 38.70
Saved _metrics_

=== Episode 11 ===
Training on [3750/15000] data points
> Train epoch 20 [ensemble -28.29 | reward 1.26]
> Train epoch 40 [ensemble -33.36 | reward 2.54]
> Train epoch 60 [ensemble -35.83 | reward 3.83]
> Train epoch 80 [ensemble -37.42 | reward 4.84]
> Train epoch 100 [ensemble -38.58 | reward 5.45]
Ensemble loss -38.58 / Reward Loss 5.45

=== Collecting data [11] ===
> Step 25 [reward 0.00]
> Step 50 [reward 91.00]
> Step 75 [reward 191.00]
> Step 100 [reward 291.00]
> Step 125 [reward 391.00]
> Step 150 [reward 491.00]
> Step 175 [reward 591.00]
> Step 200 [reward 691.00]
> Step 225 [reward 791.00]
> Step 250 [reward 891.00]
Rewards 891.00 / Steps 250.00
Reward stats:
 {'max': '599.77', 'mean': '294.03', 'min': '-7.94', 'std': '139.02'}
Information gain stats:
 {'max': '1.77', 'mean': '0.84', 'min': '0.30', 'std': '0.25'}
Episode time 40.13
Saved _metrics_

=== Episode 12 ===
Training on [4000/16000] data points
> Train epoch 20 [ensemble -29.04 | reward 1.39]
> Train epoch 40 [ensemble -33.83 | reward 2.95]
> Train epoch 60 [ensemble -36.20 | reward 4.53]
> Train epoch 80 [ensemble -37.73 | reward 5.78]
> Train epoch 100 [ensemble -38.85 | reward 6.56]
Ensemble loss -38.85 / Reward Loss 6.56

=== Collecting data [12] ===
> Step 25 [reward 53.00]
> Step 50 [reward 153.00]
> Step 75 [reward 253.00]
> Step 100 [reward 353.00]
> Step 125 [reward 453.00]
> Step 150 [reward 553.00]
> Step 175 [reward 653.00]
> Step 200 [reward 753.00]
> Step 225 [reward 853.00]
> Step 250 [reward 953.00]
Rewards 953.00 / Steps 250.00
Reward stats:
 {'max': '673.56', 'mean': '332.57', 'min': '-11.21', 'std': '143.97'}
Information gain stats:
 {'max': '1.69', 'mean': '0.83', 'min': '0.29', 'std': '0.25'}
Episode time 41.06
Saved _metrics_

=== Episode 13 ===
Training on [4250/17000] data points
> Train epoch 20 [ensemble -29.75 | reward 1.51]
> Train epoch 40 [ensemble -34.35 | reward 3.25]
> Train epoch 60 [ensemble -36.61 | reward 5.04]
> Train epoch 80 [ensemble -38.07 | reward 6.48]
> Train epoch 100 [ensemble -39.15 | reward 7.37]
Ensemble loss -39.15 / Reward Loss 7.37

=== Collecting data [13] ===
> Step 25 [reward 51.00]
> Step 50 [reward 151.00]
> Step 75 [reward 251.00]
> Step 100 [reward 351.00]
> Step 125 [reward 451.00]
> Step 150 [reward 551.00]
> Step 175 [reward 651.00]
> Step 200 [reward 751.00]
> Step 225 [reward 851.00]
> Step 250 [reward 951.00]
Rewards 951.00 / Steps 250.00
Reward stats:
 {'max': '894.06', 'mean': '410.51', 'min': '-13.94', 'std': '181.23'}
Information gain stats:
 {'max': '1.76', 'mean': '0.87', 'min': '0.32', 'std': '0.24'}
Episode time 47.30
Saved _metrics_

=== Episode 14 ===
Training on [4500/18000] data points
> Train epoch 20 [ensemble -30.16 | reward 1.67]
> Train epoch 40 [ensemble -34.56 | reward 3.72]
> Train epoch 60 [ensemble -36.75 | reward 5.71]
> Train epoch 80 [ensemble -38.19 | reward 7.29]
> Train epoch 100 [ensemble -39.24 | reward 8.29]
Ensemble loss -39.24 / Reward Loss 8.29

=== Collecting data [14] ===
> Step 25 [reward 47.00]
> Step 50 [reward 147.00]
> Step 75 [reward 247.00]
> Step 100 [reward 347.00]
> Step 125 [reward 447.00]
> Step 150 [reward 547.00]
> Step 175 [reward 647.00]
> Step 200 [reward 747.00]
> Step 225 [reward 847.00]
> Step 250 [reward 947.00]
Rewards 947.00 / Steps 250.00
Reward stats:
 {'max': '778.08', 'mean': '401.98', 'min': '6.82', 'std': '157.88'}
Information gain stats:
 {'max': '1.74', 'mean': '0.84', 'min': '0.29', 'std': '0.25'}
Episode time 43.95
Saved _metrics_

=== Episode 15 ===
Training on [4750/19000] data points
> Train epoch 20 [ensemble -30.21 | reward 1.72]
> Train epoch 40 [ensemble -34.62 | reward 3.98]
> Train epoch 60 [ensemble -36.78 | reward 6.28]
> Train epoch 80 [ensemble -38.19 | reward 8.08]
> Train epoch 100 [ensemble -39.23 | reward 9.20]
Ensemble loss -39.23 / Reward Loss 9.20

=== Collecting data [15] ===
> Step 25 [reward 26.00]
> Step 50 [reward 126.00]
> Step 75 [reward 226.00]
> Step 100 [reward 326.00]
> Step 125 [reward 426.00]
> Step 150 [reward 526.00]
> Step 175 [reward 626.00]
> Step 200 [reward 726.00]
> Step 225 [reward 826.00]
> Step 250 [reward 926.00]
Rewards 926.00 / Steps 250.00
Reward stats:
 {'max': '751.96', 'mean': '375.68', 'min': '-9.37', 'std': '149.74'}
Information gain stats:
 {'max': '1.72', 'mean': '0.86', 'min': '0.30', 'std': '0.23'}
Episode time 50.78
Saved _metrics_

=== Episode 16 ===
Training on [5000/20000] data points
> Train epoch 20 [ensemble -30.74 | reward 1.84]
> Train epoch 40 [ensemble -35.00 | reward 4.30]
> Train epoch 60 [ensemble -37.10 | reward 6.83]
> Train epoch 80 [ensemble -38.48 | reward 8.80]
> Train epoch 100 [ensemble -39.49 | reward 10.04]
Ensemble loss -39.49 / Reward Loss 10.04

=== Collecting data [16] ===
> Step 25 [reward 0.00]
> Step 50 [reward 62.00]
> Step 75 [reward 162.00]
> Step 100 [reward 262.00]
> Step 125 [reward 362.00]
> Step 150 [reward 462.00]
> Step 175 [reward 562.00]
> Step 200 [reward 662.00]
> Step 225 [reward 762.00]
> Step 250 [reward 862.00]
Rewards 862.00 / Steps 250.00
Reward stats:
 {'max': '804.98', 'mean': '386.36', 'min': '-3.44', 'std': '165.13'}
Information gain stats:
 {'max': '1.81', 'mean': '0.87', 'min': '0.30', 'std': '0.26'}
Episode time 51.53
Saved _metrics_

=== Episode 17 ===
Training on [5250/21000] data points
> Train epoch 20 [ensemble -30.82 | reward 2.06]
> Train epoch 40 [ensemble -35.08 | reward 5.04]
> Train epoch 60 [ensemble -37.18 | reward 8.03]
> Train epoch 80 [ensemble -38.55 | reward 10.32]
> Train epoch 100 [ensemble -39.55 | reward 11.76]
Ensemble loss -39.55 / Reward Loss 11.76

=== Collecting data [17] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 39.00]
> Step 125 [reward 139.00]
> Step 150 [reward 239.00]
> Step 175 [reward 339.00]
> Step 200 [reward 439.00]
> Step 225 [reward 539.00]
> Step 250 [reward 639.00]
Rewards 639.00 / Steps 250.00
Reward stats:
 {'max': '833.20', 'mean': '371.06', 'min': '-12.84', 'std': '164.24'}
Information gain stats:
 {'max': '1.71', 'mean': '0.95', 'min': '0.26', 'std': '0.26'}
Episode time 49.64
Saved _metrics_

=== Episode 18 ===
Training on [5500/22000] data points
> Train epoch 20 [ensemble -31.54 | reward 2.15]
> Train epoch 40 [ensemble -35.57 | reward 5.37]
> Train epoch 60 [ensemble -37.56 | reward 8.59]
> Train epoch 80 [ensemble -38.87 | reward 11.08]
> Train epoch 100 [ensemble -39.83 | reward 12.66]
Ensemble loss -39.83 / Reward Loss 12.66

=== Collecting data [18] ===
> Step 25 [reward 47.00]
> Step 50 [reward 147.00]
> Step 75 [reward 247.00]
> Step 100 [reward 347.00]
> Step 125 [reward 447.00]
> Step 150 [reward 547.00]
> Step 175 [reward 647.00]
> Step 200 [reward 747.00]
> Step 225 [reward 847.00]
> Step 250 [reward 947.00]
Rewards 947.00 / Steps 250.00
Reward stats:
 {'max': '860.03', 'mean': '407.68', 'min': '13.78', 'std': '164.89'}
Information gain stats:
 {'max': '1.67', 'mean': '0.87', 'min': '0.30', 'std': '0.24'}
Episode time 50.09
Saved _metrics_

=== Episode 19 ===
Training on [5750/23000] data points
> Train epoch 20 [ensemble -31.84 | reward 2.19]
> Train epoch 40 [ensemble -35.75 | reward 5.51]
> Train epoch 60 [ensemble -37.71 | reward 8.95]
> Train epoch 80 [ensemble -39.00 | reward 11.77]
> Train epoch 100 [ensemble -39.95 | reward 13.58]
Ensemble loss -39.95 / Reward Loss 13.58

=== Collecting data [19] ===
> Step 25 [reward 57.00]
> Step 50 [reward 157.00]
> Step 75 [reward 257.00]
> Step 100 [reward 357.00]
> Step 125 [reward 457.00]
> Step 150 [reward 557.00]
> Step 175 [reward 657.00]
> Step 200 [reward 757.00]
> Step 225 [reward 857.00]
> Step 250 [reward 957.00]
Rewards 957.00 / Steps 250.00
Reward stats:
 {'max': '919.88', 'mean': '443.32', 'min': '6.77', 'std': '177.31'}
Information gain stats:
 {'max': '1.62', 'mean': '0.84', 'min': '0.28', 'std': '0.23'}
Episode time 54.50
Saved _metrics_

=== Episode 20 ===
Training on [6000/24000] data points
> Train epoch 20 [ensemble -32.39 | reward 2.39]
> Train epoch 40 [ensemble -36.20 | reward 6.14]
> Train epoch 60 [ensemble -38.11 | reward 10.04]
> Train epoch 80 [ensemble -39.34 | reward 13.12]
> Train epoch 100 [ensemble -40.25 | reward 15.09]
Ensemble loss -40.25 / Reward Loss 15.09

=== Collecting data [20] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 71.00]
> Step 150 [reward 171.00]
> Step 175 [reward 271.00]
> Step 200 [reward 371.00]
> Step 225 [reward 471.00]
> Step 250 [reward 571.00]
Rewards 571.00 / Steps 250.00
Reward stats:
 {'max': '957.90', 'mean': '385.82', 'min': '20.29', 'std': '186.47'}
Information gain stats:
 {'max': '1.75', 'mean': '0.99', 'min': '0.29', 'std': '0.26'}
Episode time 56.07
Saved _metrics_

=== Episode 21 ===
Training on [6250/25000] data points
> Train epoch 20 [ensemble -32.49 | reward 2.51]
> Train epoch 40 [ensemble -36.27 | reward 6.48]
> Train epoch 60 [ensemble -38.16 | reward 10.73]
> Train epoch 80 [ensemble -39.40 | reward 14.19]
> Train epoch 100 [ensemble -40.31 | reward 16.40]
Ensemble loss -40.31 / Reward Loss 16.40

=== Collecting data [21] ===
> Step 25 [reward 44.00]
> Step 50 [reward 144.00]
> Step 75 [reward 244.00]
> Step 100 [reward 344.00]
> Step 125 [reward 444.00]
> Step 150 [reward 544.00]
> Step 175 [reward 644.00]
> Step 200 [reward 744.00]
> Step 225 [reward 844.00]
> Step 250 [reward 944.00]
Rewards 944.00 / Steps 250.00
Reward stats:
 {'max': '962.71', 'mean': '436.56', 'min': '-8.25', 'std': '186.95'}
Information gain stats:
 {'max': '1.63', 'mean': '0.86', 'min': '0.28', 'std': '0.24'}
Episode time 56.61
Saved _metrics_

=== Episode 22 ===
Training on [6500/26000] data points
> Train epoch 20 [ensemble -32.97 | reward 2.76]
> Train epoch 40 [ensemble -36.66 | reward 7.39]
> Train epoch 60 [ensemble -38.49 | reward 12.15]
> Train epoch 80 [ensemble -39.68 | reward 15.87]
> Train epoch 100 [ensemble -40.55 | reward 18.26]
Ensemble loss -40.55 / Reward Loss 18.26

=== Collecting data [22] ===
> Step 25 [reward 0.00]
> Step 50 [reward 18.00]
> Step 75 [reward 118.00]
> Step 100 [reward 218.00]
> Step 125 [reward 318.00]
> Step 150 [reward 418.00]
> Step 175 [reward 518.00]
> Step 200 [reward 618.00]
> Step 225 [reward 718.00]
> Step 250 [reward 818.00]
Rewards 818.00 / Steps 250.00
Reward stats:
 {'max': '1028.19', 'mean': '468.92', 'min': '-24.87', 'std': '200.53'}
Information gain stats:
 {'max': '1.65', 'mean': '0.91', 'min': '0.29', 'std': '0.24'}
Episode time 55.82
Saved _metrics_

=== Episode 23 ===
Training on [6750/27000] data points
> Train epoch 20 [ensemble -32.89 | reward 2.83]
> Train epoch 40 [ensemble -36.58 | reward 7.40]
> Train epoch 60 [ensemble -38.42 | reward 12.30]
> Train epoch 80 [ensemble -39.62 | reward 16.21]
> Train epoch 100 [ensemble -40.49 | reward 18.74]
Ensemble loss -40.49 / Reward Loss 18.74

=== Collecting data [23] ===
> Step 25 [reward 8.00]
> Step 50 [reward 108.00]
> Step 75 [reward 208.00]
> Step 100 [reward 308.00]
> Step 125 [reward 408.00]
> Step 150 [reward 508.00]
> Step 175 [reward 608.00]
> Step 200 [reward 708.00]
> Step 225 [reward 808.00]
> Step 250 [reward 908.00]
Rewards 908.00 / Steps 250.00
Reward stats:
 {'max': '1047.52', 'mean': '501.52', 'min': '17.07', 'std': '207.51'}
Information gain stats:
 {'max': '1.65', 'mean': '0.87', 'min': '0.29', 'std': '0.23'}
Episode time 57.25
Saved _metrics_

=== Episode 24 ===
Training on [7000/28000] data points
> Train epoch 20 [ensemble -33.40 | reward 3.01]
> Train epoch 40 [ensemble -36.96 | reward 8.13]
> Train epoch 60 [ensemble -38.73 | reward 13.52]
> Train epoch 80 [ensemble -39.87 | reward 17.75]
> Train epoch 100 [ensemble -40.72 | reward 20.46]
Ensemble loss -40.72 / Reward Loss 20.46

=== Collecting data [24] ===
> Step 25 [reward 49.00]
> Step 50 [reward 149.00]
> Step 75 [reward 249.00]
> Step 100 [reward 349.00]
> Step 125 [reward 449.00]
> Step 150 [reward 549.00]
> Step 175 [reward 649.00]
> Step 200 [reward 749.00]
> Step 225 [reward 849.00]
> Step 250 [reward 949.00]
Rewards 949.00 / Steps 250.00
Reward stats:
 {'max': '1073.36', 'mean': '564.54', 'min': '35.27', 'std': '225.13'}
Information gain stats:
 {'max': '1.64', 'mean': '0.81', 'min': '0.27', 'std': '0.25'}
Episode time 59.50
Saved _metrics_

=== Episode 25 ===
Training on [7250/29000] data points
> Train epoch 20 [ensemble -33.71 | reward 3.23]
> Train epoch 40 [ensemble -37.20 | reward 8.68]
> Train epoch 60 [ensemble -38.94 | reward 14.38]
> Train epoch 80 [ensemble -40.07 | reward 18.91]
> Train epoch 100 [ensemble -40.91 | reward 21.83]
Ensemble loss -40.91 / Reward Loss 21.83

=== Collecting data [25] ===
> Step 25 [reward 51.00]
> Step 50 [reward 151.00]
> Step 75 [reward 251.00]
> Step 100 [reward 351.00]
> Step 125 [reward 451.00]
> Step 150 [reward 551.00]
> Step 175 [reward 651.00]
> Step 200 [reward 751.00]
> Step 225 [reward 851.00]
> Step 250 [reward 951.00]
Rewards 951.00 / Steps 250.00
Reward stats:
 {'max': '1127.03', 'mean': '561.56', 'min': '-49.36', 'std': '209.84'}
Information gain stats:
 {'max': '1.62', 'mean': '0.87', 'min': '0.31', 'std': '0.23'}
Episode time 59.68
Saved _metrics_

=== Episode 26 ===
Training on [7500/30000] data points
> Train epoch 20 [ensemble -33.95 | reward 3.35]
> Train epoch 40 [ensemble -37.42 | reward 9.13]
> Train epoch 60 [ensemble -39.13 | reward 15.14]
> Train epoch 80 [ensemble -40.24 | reward 19.89]
> Train epoch 100 [ensemble -41.06 | reward 22.97]
Ensemble loss -41.06 / Reward Loss 22.97

=== Collecting data [26] ===
> Step 25 [reward 51.00]
> Step 50 [reward 151.00]
> Step 75 [reward 251.00]
> Step 100 [reward 351.00]
> Step 125 [reward 451.00]
> Step 150 [reward 551.00]
> Step 175 [reward 651.00]
> Step 200 [reward 751.00]
> Step 225 [reward 851.00]
> Step 250 [reward 951.00]
Rewards 951.00 / Steps 250.00
Reward stats:
 {'max': '1176.35', 'mean': '578.92', 'min': '3.29', 'std': '219.83'}
Information gain stats:
 {'max': '1.63', 'mean': '0.86', 'min': '0.26', 'std': '0.23'}
Episode time 59.84
Saved _metrics_

=== Episode 27 ===
Training on [7750/31000] data points
> Train epoch 20 [ensemble -34.24 | reward 3.48]
> Train epoch 40 [ensemble -37.60 | reward 9.45]
> Train epoch 60 [ensemble -39.26 | reward 15.71]
> Train epoch 80 [ensemble -40.35 | reward 20.68]
> Train epoch 100 [ensemble -41.14 | reward 23.92]
Ensemble loss -41.14 / Reward Loss 23.92

=== Collecting data [27] ===
> Step 25 [reward 4.00]
> Step 50 [reward 104.00]
> Step 75 [reward 204.00]
> Step 100 [reward 304.00]
> Step 125 [reward 404.00]
> Step 150 [reward 504.00]
> Step 175 [reward 604.00]
> Step 200 [reward 704.00]
> Step 225 [reward 804.00]
> Step 250 [reward 904.00]
Rewards 904.00 / Steps 250.00
Reward stats:
 {'max': '1215.71', 'mean': '580.42', 'min': '12.69', 'std': '226.16'}
Information gain stats:
 {'max': '1.71', 'mean': '0.88', 'min': '0.31', 'std': '0.23'}
Episode time 61.95
Saved _metrics_

=== Episode 28 ===
Training on [8000/32000] data points
> Train epoch 20 [ensemble -34.65 | reward 3.70]
> Train epoch 40 [ensemble -37.92 | reward 10.24]
> Train epoch 60 [ensemble -39.54 | reward 17.07]
> Train epoch 80 [ensemble -40.59 | reward 22.45]
> Train epoch 100 [ensemble -41.36 | reward 25.91]
Ensemble loss -41.36 / Reward Loss 25.91

=== Collecting data [28] ===
> Step 25 [reward 7.00]
> Step 50 [reward 107.00]
> Step 75 [reward 207.00]
> Step 100 [reward 307.00]
> Step 125 [reward 407.00]
> Step 150 [reward 507.00]
> Step 175 [reward 607.00]
> Step 200 [reward 707.00]
> Step 225 [reward 807.00]
> Step 250 [reward 907.00]
Rewards 907.00 / Steps 250.00
Reward stats:
 {'max': '1255.29', 'mean': '599.36', 'min': '0.96', 'std': '219.13'}
Information gain stats:
 {'max': '1.61', 'mean': '0.88', 'min': '0.27', 'std': '0.23'}
Episode time 64.04
Saved _metrics_

=== Episode 29 ===
Training on [8250/33000] data points
> Train epoch 20 [ensemble -34.67 | reward 4.13]
> Train epoch 40 [ensemble -37.95 | reward 11.41]
> Train epoch 60 [ensemble -39.56 | reward 18.75]
> Train epoch 80 [ensemble -40.60 | reward 24.53]
> Train epoch 100 [ensemble -41.37 | reward 28.28]
Ensemble loss -41.37 / Reward Loss 28.28

=== Collecting data [29] ===
> Step 25 [reward 53.00]
> Step 50 [reward 153.00]
> Step 75 [reward 253.00]
> Step 100 [reward 353.00]
> Step 125 [reward 453.00]
> Step 150 [reward 553.00]
> Step 175 [reward 653.00]
> Step 200 [reward 753.00]
> Step 225 [reward 853.00]
> Step 250 [reward 953.00]
Rewards 953.00 / Steps 250.00
Reward stats:
 {'max': '1215.44', 'mean': '609.18', 'min': '80.74', 'std': '221.56'}
Information gain stats:
 {'max': '1.67', 'mean': '0.88', 'min': '0.29', 'std': '0.24'}
Episode time 65.70
Saved _metrics_

=== Episode 30 ===
Training on [8500/34000] data points
> Train epoch 20 [ensemble -34.95 | reward 4.06]
> Train epoch 40 [ensemble -38.16 | reward 11.18]
> Train epoch 60 [ensemble -39.73 | reward 18.66]
> Train epoch 80 [ensemble -40.76 | reward 24.64]
> Train epoch 100 [ensemble -41.51 | reward 28.56]
Ensemble loss -41.51 / Reward Loss 28.56

=== Collecting data [30] ===
> Step 25 [reward 50.00]
> Step 50 [reward 150.00]
> Step 75 [reward 250.00]
> Step 100 [reward 350.00]
> Step 125 [reward 450.00]
> Step 150 [reward 550.00]
> Step 175 [reward 650.00]
> Step 200 [reward 750.00]
> Step 225 [reward 850.00]
> Step 250 [reward 950.00]
Rewards 950.00 / Steps 250.00
Reward stats:
 {'max': '1338.90', 'mean': '654.53', 'min': '33.67', 'std': '237.46'}
Information gain stats:
 {'max': '1.66', 'mean': '0.89', 'min': '0.29', 'std': '0.22'}
Episode time 67.46
Saved _metrics_

=== Episode 31 ===
Training on [8750/35000] data points
> Train epoch 20 [ensemble -35.16 | reward 4.28]
> Train epoch 40 [ensemble -38.35 | reward 11.85]
> Train epoch 60 [ensemble -39.90 | reward 19.74]
> Train epoch 80 [ensemble -40.90 | reward 25.95]
> Train epoch 100 [ensemble -41.63 | reward 29.99]
Ensemble loss -41.63 / Reward Loss 29.99

=== Collecting data [31] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 89.00]
> Step 125 [reward 189.00]
> Step 150 [reward 289.00]
> Step 175 [reward 389.00]
> Step 200 [reward 489.00]
> Step 225 [reward 589.00]
> Step 250 [reward 689.00]
Rewards 689.00 / Steps 250.00
Reward stats:
 {'max': '1336.82', 'mean': '595.18', 'min': '39.54', 'std': '242.53'}
Information gain stats:
 {'max': '1.67', 'mean': '0.96', 'min': '0.32', 'std': '0.22'}
Episode time 69.28
Saved _metrics_

=== Episode 32 ===
Training on [9000/36000] data points
> Train epoch 20 [ensemble -35.26 | reward 4.52]
> Train epoch 40 [ensemble -38.38 | reward 12.66]
> Train epoch 60 [ensemble -39.92 | reward 21.19]
> Train epoch 80 [ensemble -40.92 | reward 27.97]
> Train epoch 100 [ensemble -41.66 | reward 32.44]
Ensemble loss -41.66 / Reward Loss 32.44

=== Collecting data [32] ===
> Step 25 [reward 0.00]
> Step 50 [reward 93.00]
> Step 75 [reward 193.00]
> Step 100 [reward 293.00]
> Step 125 [reward 393.00]
> Step 150 [reward 493.00]
> Step 175 [reward 593.00]
> Step 200 [reward 693.00]
> Step 225 [reward 793.00]
> Step 250 [reward 893.00]
Rewards 893.00 / Steps 250.00
Reward stats:
 {'max': '1335.98', 'mean': '663.76', 'min': '84.74', 'std': '233.26'}
Information gain stats:
 {'max': '1.67', 'mean': '0.91', 'min': '0.32', 'std': '0.22'}
Episode time 68.98
Saved _metrics_

=== Episode 33 ===
Training on [9250/37000] data points
> Train epoch 20 [ensemble -35.39 | reward 4.68]
> Train epoch 40 [ensemble -38.49 | reward 12.96]
> Train epoch 60 [ensemble -40.01 | reward 21.56]
> Train epoch 80 [ensemble -41.00 | reward 28.44]
> Train epoch 100 [ensemble -41.72 | reward 32.99]
Ensemble loss -41.72 / Reward Loss 32.99

=== Collecting data [33] ===
> Step 25 [reward 0.00]
> Step 50 [reward 92.00]
> Step 75 [reward 192.00]
> Step 100 [reward 292.00]
> Step 125 [reward 392.00]
> Step 150 [reward 492.00]
> Step 175 [reward 592.00]
> Step 200 [reward 692.00]
> Step 225 [reward 792.00]
> Step 250 [reward 892.00]
Rewards 892.00 / Steps 250.00
Reward stats:
 {'max': '1376.13', 'mean': '671.42', 'min': '66.77', 'std': '239.35'}
Information gain stats:
 {'max': '1.64', 'mean': '0.91', 'min': '0.29', 'std': '0.22'}
Episode time 70.32
Saved _metrics_

=== Episode 34 ===
Training on [9500/38000] data points
> Train epoch 20 [ensemble -35.69 | reward 5.12]
> Train epoch 40 [ensemble -38.70 | reward 14.21]
> Train epoch 60 [ensemble -40.18 | reward 23.35]
> Train epoch 80 [ensemble -41.14 | reward 30.49]
> Train epoch 100 [ensemble -41.85 | reward 35.19]
Ensemble loss -41.85 / Reward Loss 35.19

=== Collecting data [34] ===
> Step 25 [reward 91.00]
> Step 50 [reward 191.00]
> Step 75 [reward 291.00]
> Step 100 [reward 391.00]
> Step 125 [reward 491.00]
> Step 150 [reward 591.00]
> Step 175 [reward 691.00]
> Step 200 [reward 791.00]
> Step 225 [reward 891.00]
> Step 250 [reward 991.00]
Rewards 991.00 / Steps 250.00
Reward stats:
 {'max': '1399.05', 'mean': '713.71', 'min': '117.25', 'std': '234.35'}
Information gain stats:
 {'max': '1.65', 'mean': '0.88', 'min': '0.29', 'std': '0.23'}
Episode time 72.56
Saved _metrics_

=== Episode 35 ===
Training on [9750/39000] data points
> Train epoch 20 [ensemble -35.92 | reward 5.33]
> Train epoch 40 [ensemble -38.88 | reward 14.73]
> Train epoch 60 [ensemble -40.33 | reward 24.22]
> Train epoch 80 [ensemble -41.27 | reward 31.67]
> Train epoch 100 [ensemble -41.95 | reward 36.54]
Ensemble loss -41.95 / Reward Loss 36.54

=== Collecting data [35] ===
> Step 25 [reward 45.00]
> Step 50 [reward 145.00]
> Step 75 [reward 245.00]
> Step 100 [reward 345.00]
> Step 125 [reward 445.00]
> Step 150 [reward 545.00]
> Step 175 [reward 645.00]
> Step 200 [reward 745.00]
> Step 225 [reward 845.00]
> Step 250 [reward 945.00]
Rewards 945.00 / Steps 250.00
Reward stats:
 {'max': '1394.58', 'mean': '733.45', 'min': '143.35', 'std': '219.95'}
Information gain stats:
 {'max': '1.64', 'mean': '0.89', 'min': '0.31', 'std': '0.22'}
Episode time 72.46
Saved _metrics_

=== Episode 36 ===
Training on [10000/40000] data points
> Train epoch 20 [ensemble -36.06 | reward 5.47]
> Train epoch 40 [ensemble -39.00 | reward 15.19]
> Train epoch 60 [ensemble -40.43 | reward 25.14]
> Train epoch 80 [ensemble -41.37 | reward 32.97]
> Train epoch 100 [ensemble -42.05 | reward 38.10]
Ensemble loss -42.05 / Reward Loss 38.10

=== Collecting data [36] ===
> Step 25 [reward 89.00]
> Step 50 [reward 189.00]
> Step 75 [reward 289.00]
> Step 100 [reward 389.00]
> Step 125 [reward 489.00]
> Step 150 [reward 589.00]
> Step 175 [reward 689.00]
> Step 200 [reward 789.00]
> Step 225 [reward 889.00]
> Step 250 [reward 989.00]
Rewards 989.00 / Steps 250.00
Reward stats:
 {'max': '1440.69', 'mean': '766.36', 'min': '117.20', 'std': '235.90'}
Information gain stats:
 {'max': '1.73', 'mean': '0.88', 'min': '0.29', 'std': '0.23'}
Episode time 75.61
Saved _metrics_

=== Episode 37 ===
Training on [10250/41000] data points
> Train epoch 20 [ensemble -36.20 | reward 5.45]
> Train epoch 40 [ensemble -39.11 | reward 15.53]
> Train epoch 60 [ensemble -40.54 | reward 25.90]
> Train epoch 80 [ensemble -41.47 | reward 34.04]
> Train epoch 100 [ensemble -42.16 | reward 39.33]
Ensemble loss -42.16 / Reward Loss 39.33

=== Collecting data [37] ===
> Step 25 [reward 92.00]
> Step 50 [reward 192.00]
> Step 75 [reward 292.00]
> Step 100 [reward 392.00]
> Step 125 [reward 492.00]
> Step 150 [reward 592.00]
> Step 175 [reward 692.00]
> Step 200 [reward 792.00]
> Step 225 [reward 892.00]
> Step 250 [reward 992.00]
Rewards 992.00 / Steps 250.00
Reward stats:
 {'max': '1470.18', 'mean': '797.64', 'min': '149.92', 'std': '228.49'}
Information gain stats:
 {'max': '1.63', 'mean': '0.91', 'min': '0.30', 'std': '0.22'}
Episode time 75.08
Saved _metrics_

=== Episode 38 ===
Training on [10500/42000] data points
> Train epoch 20 [ensemble -36.59 | reward 5.81]
> Train epoch 40 [ensemble -39.39 | reward 16.41]
> Train epoch 60 [ensemble -40.76 | reward 27.15]
> Train epoch 80 [ensemble -41.65 | reward 35.55]
> Train epoch 100 [ensemble -42.31 | reward 41.06]
Ensemble loss -42.31 / Reward Loss 41.06

=== Collecting data [38] ===
> Step 25 [reward 24.00]
> Step 50 [reward 124.00]
> Step 75 [reward 224.00]
> Step 100 [reward 324.00]
> Step 125 [reward 424.00]
> Step 150 [reward 524.00]
> Step 175 [reward 624.00]
> Step 200 [reward 724.00]
> Step 225 [reward 824.00]
> Step 250 [reward 924.00]
Rewards 924.00 / Steps 250.00
Reward stats:
 {'max': '1536.54', 'mean': '802.17', 'min': '139.41', 'std': '244.03'}
Information gain stats:
 {'max': '1.69', 'mean': '0.93', 'min': '0.32', 'std': '0.21'}
Episode time 76.26
Saved _metrics_

=== Episode 39 ===
Training on [10750/43000] data points
> Train epoch 20 [ensemble -36.73 | reward 6.01]
> Train epoch 40 [ensemble -39.49 | reward 17.04]
> Train epoch 60 [ensemble -40.83 | reward 28.35]
> Train epoch 80 [ensemble -41.70 | reward 37.27]
> Train epoch 100 [ensemble -42.34 | reward 43.18]
Ensemble loss -42.34 / Reward Loss 43.18

=== Collecting data [39] ===
> Step 25 [reward 14.00]
> Step 50 [reward 114.00]
> Step 75 [reward 214.00]
> Step 100 [reward 314.00]
> Step 125 [reward 414.00]
> Step 150 [reward 514.00]
> Step 175 [reward 614.00]
> Step 200 [reward 714.00]
> Step 225 [reward 814.00]
> Step 250 [reward 914.00]
Rewards 914.00 / Steps 250.00
Reward stats:
 {'max': '1575.64', 'mean': '812.87', 'min': '113.30', 'std': '253.95'}
Information gain stats:
 {'max': '1.72', 'mean': '0.94', 'min': '0.33', 'std': '0.21'}
Episode time 78.04
Saved _metrics_

=== Episode 40 ===
Training on [11000/44000] data points
> Train epoch 20 [ensemble -36.75 | reward 6.02]
> Train epoch 40 [ensemble -39.51 | reward 17.27]
> Train epoch 60 [ensemble -40.86 | reward 28.85]
> Train epoch 80 [ensemble -41.74 | reward 37.99]
> Train epoch 100 [ensemble -42.38 | reward 43.98]
Ensemble loss -42.38 / Reward Loss 43.98

=== Collecting data [40] ===
> Step 25 [reward 53.00]
> Step 50 [reward 153.00]
> Step 75 [reward 253.00]
> Step 100 [reward 353.00]
> Step 125 [reward 453.00]
> Step 150 [reward 553.00]
> Step 175 [reward 653.00]
> Step 200 [reward 753.00]
> Step 225 [reward 853.00]
> Step 250 [reward 953.00]
Rewards 953.00 / Steps 250.00
Reward stats:
 {'max': '1585.42', 'mean': '854.90', 'min': '136.15', 'std': '255.57'}
Information gain stats:
 {'max': '1.69', 'mean': '0.91', 'min': '0.33', 'std': '0.22'}
Episode time 81.47
Saved _metrics_

=== Episode 41 ===
Training on [11250/45000] data points
> Train epoch 20 [ensemble -36.98 | reward 6.59]
> Train epoch 40 [ensemble -39.68 | reward 18.54]
> Train epoch 60 [ensemble -41.00 | reward 30.50]
> Train epoch 80 [ensemble -41.86 | reward 39.73]
> Train epoch 100 [ensemble -42.49 | reward 45.78]
Ensemble loss -42.49 / Reward Loss 45.78

=== Collecting data [41] ===
> Step 25 [reward 45.00]
> Step 50 [reward 145.00]
> Step 75 [reward 245.00]
> Step 100 [reward 345.00]
> Step 125 [reward 445.00]
> Step 150 [reward 545.00]
> Step 175 [reward 645.00]
> Step 200 [reward 745.00]
> Step 225 [reward 845.00]
> Step 250 [reward 945.00]
Rewards 945.00 / Steps 250.00
Reward stats:
 {'max': '1563.00', 'mean': '826.59', 'min': '131.65', 'std': '254.41'}
Information gain stats:
 {'max': '1.65', 'mean': '0.96', 'min': '0.34', 'std': '0.21'}
Episode time 81.73
Saved _metrics_

=== Episode 42 ===
Training on [11500/46000] data points
> Train epoch 20 [ensemble -37.13 | reward 6.83]
> Train epoch 40 [ensemble -39.79 | reward 19.17]
> Train epoch 60 [ensemble -41.09 | reward 31.65]
> Train epoch 80 [ensemble -41.94 | reward 41.39]
> Train epoch 100 [ensemble -42.57 | reward 47.76]
Ensemble loss -42.57 / Reward Loss 47.76

=== Collecting data [42] ===
> Step 25 [reward 0.00]
> Step 50 [reward 86.00]
> Step 75 [reward 186.00]
> Step 100 [reward 286.00]
> Step 125 [reward 386.00]
> Step 150 [reward 486.00]
> Step 175 [reward 586.00]
> Step 200 [reward 686.00]
> Step 225 [reward 786.00]
> Step 250 [reward 886.00]
Rewards 886.00 / Steps 250.00
Reward stats:
 {'max': '1576.32', 'mean': '846.36', 'min': '185.23', 'std': '237.17'}
Information gain stats:
 {'max': '1.72', 'mean': '0.96', 'min': '0.32', 'std': '0.21'}
Episode time 83.36
Saved _metrics_

=== Episode 43 ===
Training on [11750/47000] data points
> Train epoch 20 [ensemble -37.09 | reward 6.99]
> Train epoch 40 [ensemble -39.76 | reward 19.81]
> Train epoch 60 [ensemble -41.06 | reward 32.71]
> Train epoch 80 [ensemble -41.91 | reward 42.74]
> Train epoch 100 [ensemble -42.54 | reward 49.31]
Ensemble loss -42.54 / Reward Loss 49.31

=== Collecting data [43] ===
> Step 25 [reward 0.00]
> Step 50 [reward 75.00]
> Step 75 [reward 175.00]
> Step 100 [reward 275.00]
> Step 125 [reward 375.00]
> Step 150 [reward 475.00]
> Step 175 [reward 575.00]
> Step 200 [reward 675.00]
> Step 225 [reward 775.00]
> Step 250 [reward 875.00]
Rewards 875.00 / Steps 250.00
Reward stats:
 {'max': '1627.37', 'mean': '824.38', 'min': '174.70', 'std': '243.70'}
Information gain stats:
 {'max': '1.68', 'mean': '0.95', 'min': '0.31', 'std': '0.21'}
Episode time 84.21
Saved _metrics_

=== Episode 44 ===
Training on [12000/48000] data points
> Train epoch 20 [ensemble -37.26 | reward 7.66]
> Train epoch 40 [ensemble -39.91 | reward 21.51]
> Train epoch 60 [ensemble -41.20 | reward 34.74]
> Train epoch 80 [ensemble -42.04 | reward 44.94]
> Train epoch 100 [ensemble -42.66 | reward 51.65]
Ensemble loss -42.66 / Reward Loss 51.65

=== Collecting data [44] ===
> Step 25 [reward 49.00]
> Step 50 [reward 149.00]
> Step 75 [reward 249.00]
> Step 100 [reward 349.00]
> Step 125 [reward 449.00]
> Step 150 [reward 549.00]
> Step 175 [reward 649.00]
> Step 200 [reward 749.00]
> Step 225 [reward 849.00]
> Step 250 [reward 949.00]
Rewards 949.00 / Steps 250.00
Reward stats:
 {'max': '1591.44', 'mean': '885.21', 'min': '191.83', 'std': '222.62'}
Information gain stats:
 {'max': '1.67', 'mean': '0.96', 'min': '0.34', 'std': '0.20'}
Episode time 87.83
Saved _metrics_

=== Episode 45 ===
Training on [12250/49000] data points
> Train epoch 20 [ensemble -37.41 | reward 7.72]
> Train epoch 40 [ensemble -40.01 | reward 21.61]
> Train epoch 60 [ensemble -41.29 | reward 35.21]
> Train epoch 80 [ensemble -42.12 | reward 45.63]
> Train epoch 100 [ensemble -42.74 | reward 52.41]
Ensemble loss -42.74 / Reward Loss 52.41

=== Collecting data [45] ===
> Step 25 [reward 7.00]
> Step 50 [reward 107.00]
> Step 75 [reward 207.00]
> Step 100 [reward 307.00]
> Step 125 [reward 407.00]
> Step 150 [reward 507.00]
> Step 175 [reward 607.00]
> Step 200 [reward 707.00]
> Step 225 [reward 807.00]
> Step 250 [reward 907.00]
Rewards 907.00 / Steps 250.00
Reward stats:
 {'max': '1668.02', 'mean': '932.90', 'min': '203.00', 'std': '248.89'}
Information gain stats:
 {'max': '1.66', 'mean': '0.93', 'min': '0.34', 'std': '0.22'}
Episode time 87.47
Saved _metrics_

=== Episode 46 ===
Training on [12500/50000] data points
> Train epoch 20 [ensemble -37.58 | reward 7.78]
> Train epoch 40 [ensemble -40.14 | reward 21.84]
> Train epoch 60 [ensemble -41.39 | reward 35.82]
> Train epoch 80 [ensemble -42.22 | reward 46.63]
> Train epoch 100 [ensemble -42.82 | reward 53.69]
Ensemble loss -42.82 / Reward Loss 53.69

=== Collecting data [46] ===
> Step 25 [reward 51.00]
> Step 50 [reward 151.00]
> Step 75 [reward 251.00]
> Step 100 [reward 351.00]
> Step 125 [reward 451.00]
> Step 150 [reward 551.00]
> Step 175 [reward 651.00]
> Step 200 [reward 751.00]
> Step 225 [reward 851.00]
> Step 250 [reward 951.00]
Rewards 951.00 / Steps 250.00
Reward stats:
 {'max': '1753.64', 'mean': '972.73', 'min': '213.19', 'std': '252.38'}
Information gain stats:
 {'max': '1.66', 'mean': '0.96', 'min': '0.33', 'std': '0.20'}
Episode time 89.08
Saved _metrics_

=== Episode 47 ===
Training on [12750/51000] data points
> Train epoch 20 [ensemble -37.60 | reward 8.05]
> Train epoch 40 [ensemble -40.15 | reward 22.64]
> Train epoch 60 [ensemble -41.40 | reward 37.06]
> Train epoch 80 [ensemble -42.21 | reward 48.22]
> Train epoch 100 [ensemble -42.82 | reward 55.53]
Ensemble loss -42.82 / Reward Loss 55.53

=== Collecting data [47] ===
> Step 25 [reward 8.00]
> Step 50 [reward 108.00]
> Step 75 [reward 208.00]
> Step 100 [reward 308.00]
> Step 125 [reward 408.00]
> Step 150 [reward 508.00]
> Step 175 [reward 608.00]
> Step 200 [reward 708.00]
> Step 225 [reward 808.00]
> Step 250 [reward 908.00]
Rewards 908.00 / Steps 250.00
Reward stats:
 {'max': '1690.49', 'mean': '928.44', 'min': '184.23', 'std': '252.93'}
Information gain stats:
 {'max': '1.71', 'mean': '0.93', 'min': '0.33', 'std': '0.21'}
Episode time 90.83
Saved _metrics_

=== Episode 48 ===
Training on [13000/52000] data points
> Train epoch 20 [ensemble -37.81 | reward 8.83]
> Train epoch 40 [ensemble -40.31 | reward 24.42]
> Train epoch 60 [ensemble -41.54 | reward 39.18]
> Train epoch 80 [ensemble -42.35 | reward 50.45]
> Train epoch 100 [ensemble -42.94 | reward 57.89]
Ensemble loss -42.94 / Reward Loss 57.89

=== Collecting data [48] ===
> Step 25 [reward 85.00]
> Step 50 [reward 185.00]
> Step 75 [reward 285.00]
> Step 100 [reward 385.00]
> Step 125 [reward 485.00]
> Step 150 [reward 585.00]
> Step 175 [reward 685.00]
> Step 200 [reward 785.00]
> Step 225 [reward 885.00]
> Step 250 [reward 985.00]
Rewards 985.00 / Steps 250.00
Reward stats:
 {'max': '1745.80', 'mean': '1028.52', 'min': '308.68', 'std': '248.27'}
Information gain stats:
 {'max': '1.68', 'mean': '0.95', 'min': '0.30', 'std': '0.21'}
Episode time 91.89
Saved _metrics_

=== Episode 49 ===
Training on [13250/53000] data points
> Train epoch 20 [ensemble -38.03 | reward 8.97]
> Train epoch 40 [ensemble -40.48 | reward 24.80]
> Train epoch 60 [ensemble -41.68 | reward 39.92]
> Train epoch 80 [ensemble -42.46 | reward 51.46]
> Train epoch 100 [ensemble -43.04 | reward 59.09]
Ensemble loss -43.04 / Reward Loss 59.09

=== Collecting data [49] ===
> Step 25 [reward 33.00]
> Step 50 [reward 133.00]
> Step 75 [reward 233.00]
> Step 100 [reward 333.00]
> Step 125 [reward 433.00]
> Step 150 [reward 533.00]
> Step 175 [reward 633.00]
> Step 200 [reward 733.00]
> Step 225 [reward 833.00]
> Step 250 [reward 933.00]
Rewards 933.00 / Steps 250.00
Reward stats:
 {'max': '1818.48', 'mean': '976.23', 'min': '239.32', 'std': '261.98'}
Information gain stats:
 {'max': '1.75', 'mean': '0.99', 'min': '0.39', 'std': '0.18'}
Episode time 92.22
Saved _metrics_