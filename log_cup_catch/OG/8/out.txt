13:12:56

=== Loading experiment [device: cuda] ===

{'action_noise': None,
 'action_repeat': 4,
 'batch_size': 50,
 'coverage': False,
 'ensemble_size': 10,
 'env_name': 'DeepMindCatch',
 'epsilon': 1e-08,
 'expl_scale': 0.1,
 'expl_strategy': 'information',
 'grad_clip_norm': 1000,
 'hidden_size': 200,
 'learning_rate': 0.001,
 'logdir': 'cup_catch_OG',
 'max_episode_len': 1000,
 'n_candidates': 500,
 'n_episodes': 50,
 'n_seed_episodes': 5,
 'n_train_epochs': 100,
 'optimisation_iters': 5,
 'plan_horizon': 12,
 'record_every': None,
 'reward_scale': 1.0,
 'seed': 8,
 'strategy': 'information',
 'top_candidates': 50,
 'use_exploration': True,
 'use_mean': False,
 'use_reward': True}

Collected seeds: [5 episodes | 1250 frames]

=== Episode 1 ===
Training on [1250/5000] data points
> Train epoch 20 [ensemble -20.38 | reward 0.10]
> Train epoch 40 [ensemble -28.08 | reward 0.05]
> Train epoch 60 [ensemble -31.84 | reward 0.03]
> Train epoch 80 [ensemble -34.23 | reward 0.02]
> Train epoch 100 [ensemble -35.95 | reward 0.02]
Ensemble loss -35.95 / Reward Loss 0.02

=== Collecting data [1] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '22.84', 'mean': '6.11', 'min': '-1.69', 'std': '4.19'}
Information gain stats:
 {'max': '2.53', 'mean': '1.54', 'min': '0.60', 'std': '0.22'}
Episode time 22.61
Saved _metrics_

=== Episode 2 ===
Training on [1500/6000] data points
> Train epoch 20 [ensemble -22.78 | reward 0.08]
> Train epoch 40 [ensemble -30.04 | reward 0.04]
> Train epoch 60 [ensemble -33.47 | reward 0.03]
> Train epoch 80 [ensemble -35.61 | reward 0.02]
> Train epoch 100 [ensemble -37.13 | reward 0.02]
Ensemble loss -37.13 / Reward Loss 0.02

=== Collecting data [2] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 67.00]
> Step 125 [reward 167.00]
> Step 150 [reward 267.00]
> Step 175 [reward 367.00]
> Step 200 [reward 467.00]
> Step 225 [reward 567.00]
> Step 250 [reward 661.00]
Rewards 661.00 / Steps 250.00
Reward stats:
 {'max': '7.86', 'mean': '1.01', 'min': '-1.38', 'std': '0.91'}
Information gain stats:
 {'max': '1.50', 'mean': '0.98', 'min': '0.48', 'std': '0.11'}
Episode time 23.62
Saved _metrics_

=== Episode 3 ===
Training on [1750/7000] data points
> Train epoch 20 [ensemble -22.73 | reward 0.17]
> Train epoch 40 [ensemble -29.73 | reward 0.09]
> Train epoch 60 [ensemble -33.13 | reward 0.06]
> Train epoch 80 [ensemble -35.27 | reward 0.04]
> Train epoch 100 [ensemble -36.81 | reward 0.04]
Ensemble loss -36.81 / Reward Loss 0.04

=== Collecting data [3] ===
> Step 25 [reward 49.00]
> Step 50 [reward 149.00]
> Step 75 [reward 249.00]
> Step 100 [reward 349.00]
> Step 125 [reward 449.00]
> Step 150 [reward 549.00]
> Step 175 [reward 642.00]
> Step 200 [reward 730.00]
> Step 225 [reward 797.00]
> Step 250 [reward 896.00]
Rewards 896.00 / Steps 250.00
Reward stats:
 {'max': '47.02', 'mean': '10.61', 'min': '-1.22', 'std': '8.06'}
Information gain stats:
 {'max': '1.54', 'mean': '0.83', 'min': '0.36', 'std': '0.19'}
Episode time 24.72
Saved _metrics_

=== Episode 4 ===
Training on [2000/8000] data points
> Train epoch 20 [ensemble -23.61 | reward 0.23]
> Train epoch 40 [ensemble -30.13 | reward 0.13]
> Train epoch 60 [ensemble -33.30 | reward 0.09]
> Train epoch 80 [ensemble -35.34 | reward 0.06]
> Train epoch 100 [ensemble -36.81 | reward 0.05]
Ensemble loss -36.81 / Reward Loss 0.05

=== Collecting data [4] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '31.90', 'mean': '3.91', 'min': '-1.49', 'std': '4.49'}
Information gain stats:
 {'max': '1.55', 'mean': '0.78', 'min': '0.36', 'std': '0.13'}
Episode time 25.77
Saved _metrics_

=== Episode 5 ===
Training on [2250/9000] data points
> Train epoch 20 [ensemble -23.79 | reward 0.21]
> Train epoch 40 [ensemble -30.33 | reward 0.11]
> Train epoch 60 [ensemble -33.55 | reward 0.08]
> Train epoch 80 [ensemble -35.61 | reward 0.06]
> Train epoch 100 [ensemble -37.11 | reward 0.05]
Ensemble loss -37.11 / Reward Loss 0.05

=== Collecting data [5] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 89.00]
> Step 100 [reward 189.00]
> Step 125 [reward 289.00]
> Step 150 [reward 389.00]
> Step 175 [reward 489.00]
> Step 200 [reward 589.00]
> Step 225 [reward 689.00]
> Step 250 [reward 789.00]
Rewards 789.00 / Steps 250.00
Reward stats:
 {'max': '30.16', 'mean': '7.02', 'min': '-0.97', 'std': '5.05'}
Information gain stats:
 {'max': '1.65', 'mean': '0.91', 'min': '0.38', 'std': '0.18'}
Episode time 26.84
Saved _metrics_

=== Episode 6 ===
Training on [2500/10000] data points
> Train epoch 20 [ensemble -24.55 | reward 0.25]
> Train epoch 40 [ensemble -30.81 | reward 0.13]
> Train epoch 60 [ensemble -33.93 | reward 0.09]
> Train epoch 80 [ensemble -35.93 | reward 0.07]
> Train epoch 100 [ensemble -37.37 | reward 0.05]
Ensemble loss -37.37 / Reward Loss 0.05

=== Collecting data [6] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 87.00]
> Step 100 [reward 187.00]
> Step 125 [reward 287.00]
> Step 150 [reward 387.00]
> Step 175 [reward 487.00]
> Step 200 [reward 587.00]
> Step 225 [reward 687.00]
> Step 250 [reward 787.00]
Rewards 787.00 / Steps 250.00
Reward stats:
 {'max': '28.39', 'mean': '6.42', 'min': '-2.39', 'std': '5.07'}
Information gain stats:
 {'max': '1.76', 'mean': '0.95', 'min': '0.42', 'std': '0.16'}
Episode time 27.92
Saved _metrics_

=== Episode 7 ===
Training on [2750/11000] data points
> Train epoch 20 [ensemble -25.27 | reward 0.24]
> Train epoch 40 [ensemble -31.29 | reward 0.13]
> Train epoch 60 [ensemble -34.25 | reward 0.09]
> Train epoch 80 [ensemble -36.18 | reward 0.07]
> Train epoch 100 [ensemble -37.60 | reward 0.05]
Ensemble loss -37.60 / Reward Loss 0.05

=== Collecting data [7] ===
> Step 25 [reward 0.00]
> Step 50 [reward 14.00]
> Step 75 [reward 114.00]
> Step 100 [reward 214.00]
> Step 125 [reward 314.00]
> Step 150 [reward 414.00]
> Step 175 [reward 514.00]
> Step 200 [reward 614.00]
> Step 225 [reward 714.00]
> Step 250 [reward 814.00]
Rewards 814.00 / Steps 250.00
Reward stats:
 {'max': '27.31', 'mean': '4.97', 'min': '-1.32', 'std': '4.51'}
Information gain stats:
 {'max': '1.75', 'mean': '0.94', 'min': '0.37', 'std': '0.17'}
Episode time 28.99
Saved _metrics_

=== Episode 8 ===
Training on [3000/12000] data points
> Train epoch 20 [ensemble -26.04 | reward 0.23]
> Train epoch 40 [ensemble -31.85 | reward 0.13]
> Train epoch 60 [ensemble -34.70 | reward 0.09]
> Train epoch 80 [ensemble -36.54 | reward 0.06]
> Train epoch 100 [ensemble -37.89 | reward 0.05]
Ensemble loss -37.89 / Reward Loss 0.05

=== Collecting data [8] ===
> Step 25 [reward 0.00]
> Step 50 [reward 22.00]
> Step 75 [reward 122.00]
> Step 100 [reward 222.00]
> Step 125 [reward 322.00]
> Step 150 [reward 422.00]
> Step 175 [reward 522.00]
> Step 200 [reward 622.00]
> Step 225 [reward 722.00]
> Step 250 [reward 822.00]
Rewards 822.00 / Steps 250.00
Reward stats:
 {'max': '28.00', 'mean': '6.03', 'min': '-1.51', 'std': '4.87'}
Information gain stats:
 {'max': '1.65', 'mean': '0.94', 'min': '0.42', 'std': '0.16'}
Episode time 30.17
Saved _metrics_

=== Episode 9 ===
Training on [3250/13000] data points
> Train epoch 20 [ensemble -26.79 | reward 0.23]
> Train epoch 40 [ensemble -32.34 | reward 0.13]
> Train epoch 60 [ensemble -35.07 | reward 0.09]
> Train epoch 80 [ensemble -36.87 | reward 0.07]
> Train epoch 100 [ensemble -38.19 | reward 0.05]
Ensemble loss -38.19 / Reward Loss 0.05

=== Collecting data [9] ===
> Step 25 [reward 47.00]
> Step 50 [reward 147.00]
> Step 75 [reward 247.00]
> Step 100 [reward 347.00]
> Step 125 [reward 447.00]
> Step 150 [reward 547.00]
> Step 175 [reward 647.00]
> Step 200 [reward 747.00]
> Step 225 [reward 847.00]
> Step 250 [reward 947.00]
Rewards 947.00 / Steps 250.00
Reward stats:
 {'max': '29.47', 'mean': '7.13', 'min': '-1.35', 'std': '5.37'}
Information gain stats:
 {'max': '1.62', 'mean': '0.91', 'min': '0.39', 'std': '0.16'}
Episode time 31.11
Saved _metrics_

=== Episode 10 ===
Training on [3500/14000] data points
> Train epoch 20 [ensemble -27.68 | reward 0.24]
> Train epoch 40 [ensemble -32.99 | reward 0.13]
> Train epoch 60 [ensemble -35.63 | reward 0.09]
> Train epoch 80 [ensemble -37.35 | reward 0.07]
> Train epoch 100 [ensemble -38.63 | reward 0.06]
Ensemble loss -38.63 / Reward Loss 0.06

=== Collecting data [10] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 69.00]
> Step 100 [reward 169.00]
> Step 125 [reward 269.00]
> Step 150 [reward 369.00]
> Step 175 [reward 469.00]
> Step 200 [reward 569.00]
> Step 225 [reward 669.00]
> Step 250 [reward 769.00]
Rewards 769.00 / Steps 250.00
Reward stats:
 {'max': '30.89', 'mean': '5.87', 'min': '-2.97', 'std': '5.51'}
Information gain stats:
 {'max': '1.75', 'mean': '0.96', 'min': '0.38', 'std': '0.16'}
Episode time 32.18
Saved _metrics_

=== Episode 11 ===
Training on [3750/15000] data points
> Train epoch 20 [ensemble -28.11 | reward 0.19]
> Train epoch 40 [ensemble -33.31 | reward 0.10]
> Train epoch 60 [ensemble -35.91 | reward 0.07]
> Train epoch 80 [ensemble -37.59 | reward 0.05]
> Train epoch 100 [ensemble -38.84 | reward 0.04]
Ensemble loss -38.84 / Reward Loss 0.04

=== Collecting data [11] ===
> Step 25 [reward 53.00]
> Step 50 [reward 153.00]
> Step 75 [reward 253.00]
> Step 100 [reward 353.00]
> Step 125 [reward 453.00]
> Step 150 [reward 553.00]
> Step 175 [reward 653.00]
> Step 200 [reward 753.00]
> Step 225 [reward 853.00]
> Step 250 [reward 953.00]
Rewards 953.00 / Steps 250.00
Reward stats:
 {'max': '31.13', 'mean': '7.39', 'min': '-1.22', 'std': '5.14'}
Information gain stats:
 {'max': '1.67', 'mean': '0.94', 'min': '0.41', 'std': '0.15'}
Episode time 33.24
Saved _metrics_

=== Episode 12 ===
Training on [4000/16000] data points
> Train epoch 20 [ensemble -28.49 | reward 0.21]
> Train epoch 40 [ensemble -33.62 | reward 0.12]
> Train epoch 60 [ensemble -36.18 | reward 0.08]
> Train epoch 80 [ensemble -37.86 | reward 0.06]
> Train epoch 100 [ensemble -39.09 | reward 0.05]
Ensemble loss -39.09 / Reward Loss 0.05

=== Collecting data [12] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '17.80', 'mean': '1.23', 'min': '-3.36', 'std': '1.52'}
Information gain stats:
 {'max': '1.76', 'mean': '1.07', 'min': '0.56', 'std': '0.13'}
Episode time 34.30
Saved _metrics_

=== Episode 13 ===
Training on [4250/17000] data points
> Train epoch 20 [ensemble -28.72 | reward 0.21]
> Train epoch 40 [ensemble -33.75 | reward 0.12]
> Train epoch 60 [ensemble -36.24 | reward 0.08]
> Train epoch 80 [ensemble -37.87 | reward 0.06]
> Train epoch 100 [ensemble -39.06 | reward 0.05]
Ensemble loss -39.06 / Reward Loss 0.05

=== Collecting data [13] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 39.00]
> Step 100 [reward 139.00]
> Step 125 [reward 239.00]
> Step 150 [reward 339.00]
> Step 175 [reward 439.00]
> Step 200 [reward 539.00]
> Step 225 [reward 639.00]
> Step 250 [reward 739.00]
Rewards 739.00 / Steps 250.00
Reward stats:
 {'max': '32.50', 'mean': '6.27', 'min': '-3.34', 'std': '6.12'}
Information gain stats:
 {'max': '1.61', 'mean': '0.94', 'min': '0.35', 'std': '0.16'}
Episode time 35.44
Saved _metrics_

=== Episode 14 ===
Training on [4500/18000] data points
> Train epoch 20 [ensemble -29.05 | reward 0.19]
> Train epoch 40 [ensemble -34.04 | reward 0.10]
> Train epoch 60 [ensemble -36.52 | reward 0.07]
> Train epoch 80 [ensemble -38.15 | reward 0.05]
> Train epoch 100 [ensemble -39.33 | reward 0.04]
Ensemble loss -39.33 / Reward Loss 0.04

=== Collecting data [14] ===
> Step 25 [reward 46.00]
> Step 50 [reward 146.00]
> Step 75 [reward 246.00]
> Step 100 [reward 346.00]
> Step 125 [reward 446.00]
> Step 150 [reward 546.00]
> Step 175 [reward 646.00]
> Step 200 [reward 746.00]
> Step 225 [reward 846.00]
> Step 250 [reward 946.00]
Rewards 946.00 / Steps 250.00
Reward stats:
 {'max': '31.73', 'mean': '5.93', 'min': '-2.32', 'std': '5.13'}
Information gain stats:
 {'max': '1.78', 'mean': '0.95', 'min': '0.34', 'std': '0.18'}
Episode time 36.54
Saved _metrics_

=== Episode 15 ===
Training on [4750/19000] data points
> Train epoch 20 [ensemble -29.46 | reward 0.19]
> Train epoch 40 [ensemble -34.30 | reward 0.10]
> Train epoch 60 [ensemble -36.74 | reward 0.07]
> Train epoch 80 [ensemble -38.33 | reward 0.05]
> Train epoch 100 [ensemble -39.50 | reward 0.04]
Ensemble loss -39.50 / Reward Loss 0.04

=== Collecting data [15] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 74.00]
> Step 100 [reward 174.00]
> Step 125 [reward 274.00]
> Step 150 [reward 374.00]
> Step 175 [reward 474.00]
> Step 200 [reward 574.00]
> Step 225 [reward 674.00]
> Step 250 [reward 774.00]
Rewards 774.00 / Steps 250.00
Reward stats:
 {'max': '32.83', 'mean': '6.72', 'min': '-1.97', 'std': '5.31'}
Information gain stats:
 {'max': '1.61', 'mean': '0.95', 'min': '0.38', 'std': '0.18'}
Episode time 37.55
Saved _metrics_

=== Episode 16 ===
Training on [5000/20000] data points
> Train epoch 20 [ensemble -29.89 | reward 0.18]
> Train epoch 40 [ensemble -34.60 | reward 0.10]
> Train epoch 60 [ensemble -36.98 | reward 0.07]
> Train epoch 80 [ensemble -38.53 | reward 0.05]
> Train epoch 100 [ensemble -39.66 | reward 0.04]
Ensemble loss -39.66 / Reward Loss 0.04

=== Collecting data [16] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 55.00]
> Step 200 [reward 155.00]
> Step 225 [reward 255.00]
> Step 250 [reward 355.00]
Rewards 355.00 / Steps 250.00
Reward stats:
 {'max': '33.93', 'mean': '4.54', 'min': '-3.05', 'std': '5.53'}
Information gain stats:
 {'max': '1.64', 'mean': '1.01', 'min': '0.36', 'std': '0.16'}
Episode time 38.60
Saved _metrics_

=== Episode 17 ===
Training on [5250/21000] data points
> Train epoch 20 [ensemble -29.99 | reward 0.22]
> Train epoch 40 [ensemble -34.65 | reward 0.11]
> Train epoch 60 [ensemble -36.99 | reward 0.08]
> Train epoch 80 [ensemble -38.52 | reward 0.06]
> Train epoch 100 [ensemble -39.64 | reward 0.05]
Ensemble loss -39.64 / Reward Loss 0.05

=== Collecting data [17] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '9.08', 'mean': '1.62', 'min': '-4.09', 'std': '1.30'}
Information gain stats:
 {'max': '1.70', 'mean': '1.14', 'min': '0.60', 'std': '0.11'}
Episode time 39.70
Saved _metrics_

=== Episode 18 ===
Training on [5500/22000] data points
> Train epoch 20 [ensemble -31.06 | reward 0.20]
> Train epoch 40 [ensemble -35.59 | reward 0.11]
> Train epoch 60 [ensemble -37.83 | reward 0.07]
> Train epoch 80 [ensemble -39.30 | reward 0.05]
> Train epoch 100 [ensemble -40.36 | reward 0.04]
Ensemble loss -40.36 / Reward Loss 0.04

=== Collecting data [18] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 69.00]
> Step 150 [reward 169.00]
> Step 175 [reward 269.00]
> Step 200 [reward 369.00]
> Step 225 [reward 469.00]
> Step 250 [reward 569.00]
Rewards 569.00 / Steps 250.00
Reward stats:
 {'max': '27.60', 'mean': '4.39', 'min': '-3.06', 'std': '5.07'}
Information gain stats:
 {'max': '1.62', 'mean': '0.97', 'min': '0.37', 'std': '0.15'}
Episode time 40.72
Saved _metrics_

=== Episode 19 ===
Training on [5750/23000] data points
> Train epoch 20 [ensemble -31.11 | reward 0.19]
> Train epoch 40 [ensemble -35.60 | reward 0.10]
> Train epoch 60 [ensemble -37.82 | reward 0.07]
> Train epoch 80 [ensemble -39.27 | reward 0.05]
> Train epoch 100 [ensemble -40.33 | reward 0.04]
Ensemble loss -40.33 / Reward Loss 0.04

=== Collecting data [19] ===
> Step 25 [reward 90.00]
> Step 50 [reward 190.00]
> Step 75 [reward 290.00]
> Step 100 [reward 390.00]
> Step 125 [reward 490.00]
> Step 150 [reward 590.00]
> Step 175 [reward 690.00]
> Step 200 [reward 790.00]
> Step 225 [reward 890.00]
> Step 250 [reward 990.00]
Rewards 990.00 / Steps 250.00
Reward stats:
 {'max': '32.20', 'mean': '7.27', 'min': '-1.58', 'std': '5.47'}
Information gain stats:
 {'max': '1.51', 'mean': '0.92', 'min': '0.37', 'std': '0.16'}
Episode time 41.81
Saved _metrics_

=== Episode 20 ===
Training on [6000/24000] data points
> Train epoch 20 [ensemble -31.56 | reward 0.20]
> Train epoch 40 [ensemble -35.90 | reward 0.11]
> Train epoch 60 [ensemble -38.05 | reward 0.07]
> Train epoch 80 [ensemble -39.46 | reward 0.06]
> Train epoch 100 [ensemble -40.49 | reward 0.04]
Ensemble loss -40.49 / Reward Loss 0.04

=== Collecting data [20] ===
> Step 25 [reward 4.00]
> Step 50 [reward 104.00]
> Step 75 [reward 204.00]
> Step 100 [reward 304.00]
> Step 125 [reward 404.00]
> Step 150 [reward 504.00]
> Step 175 [reward 604.00]
> Step 200 [reward 704.00]
> Step 225 [reward 804.00]
> Step 250 [reward 904.00]
Rewards 904.00 / Steps 250.00
Reward stats:
 {'max': '29.27', 'mean': '6.31', 'min': '-0.81', 'std': '4.76'}
Information gain stats:
 {'max': '1.57', 'mean': '0.96', 'min': '0.36', 'std': '0.15'}
Episode time 42.85
Saved _metrics_

=== Episode 21 ===
Training on [6250/25000] data points
> Train epoch 20 [ensemble -31.83 | reward 0.19]
> Train epoch 40 [ensemble -36.10 | reward 0.10]
> Train epoch 60 [ensemble -38.22 | reward 0.07]
> Train epoch 80 [ensemble -39.60 | reward 0.05]
> Train epoch 100 [ensemble -40.61 | reward 0.04]
Ensemble loss -40.61 / Reward Loss 0.04

=== Collecting data [21] ===
> Step 25 [reward 100.00]
> Step 50 [reward 200.00]
> Step 75 [reward 300.00]
> Step 100 [reward 400.00]
> Step 125 [reward 500.00]
> Step 150 [reward 600.00]
> Step 175 [reward 700.00]
> Step 200 [reward 800.00]
> Step 225 [reward 900.00]
> Step 250 [reward 1000.00]
Rewards 1000.00 / Steps 250.00
Reward stats:
 {'max': '32.32', 'mean': '8.93', 'min': '-0.87', 'std': '5.72'}
Information gain stats:
 {'max': '1.60', 'mean': '0.92', 'min': '0.40', 'std': '0.16'}
Episode time 43.89
Saved _metrics_

=== Episode 22 ===
Training on [6500/26000] data points
> Train epoch 20 [ensemble -32.45 | reward 0.19]
> Train epoch 40 [ensemble -36.55 | reward 0.10]
> Train epoch 60 [ensemble -38.61 | reward 0.07]
> Train epoch 80 [ensemble -39.94 | reward 0.05]
> Train epoch 100 [ensemble -40.91 | reward 0.04]
Ensemble loss -40.91 / Reward Loss 0.04

=== Collecting data [22] ===
> Step 25 [reward 5.00]
> Step 50 [reward 105.00]
> Step 75 [reward 205.00]
> Step 100 [reward 305.00]
> Step 125 [reward 405.00]
> Step 150 [reward 505.00]
> Step 175 [reward 605.00]
> Step 200 [reward 705.00]
> Step 225 [reward 805.00]
> Step 250 [reward 905.00]
Rewards 905.00 / Steps 250.00
Reward stats:
 {'max': '30.83', 'mean': '7.13', 'min': '-3.05', 'std': '5.39'}
Information gain stats:
 {'max': '1.59', 'mean': '0.94', 'min': '0.38', 'std': '0.16'}
Episode time 45.12
Saved _metrics_

=== Episode 23 ===
Training on [6750/27000] data points
> Train epoch 20 [ensemble -32.72 | reward 0.18]
> Train epoch 40 [ensemble -36.72 | reward 0.09]
> Train epoch 60 [ensemble -38.72 | reward 0.06]
> Train epoch 80 [ensemble -40.03 | reward 0.05]
> Train epoch 100 [ensemble -40.99 | reward 0.04]
Ensemble loss -40.99 / Reward Loss 0.04

=== Collecting data [23] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 80.00]
> Step 125 [reward 180.00]
> Step 150 [reward 280.00]
> Step 175 [reward 380.00]
> Step 200 [reward 480.00]
> Step 225 [reward 580.00]
> Step 250 [reward 680.00]
Rewards 680.00 / Steps 250.00
Reward stats:
 {'max': '28.98', 'mean': '4.76', 'min': '-3.19', 'std': '4.63'}
Information gain stats:
 {'max': '1.64', 'mean': '1.00', 'min': '0.40', 'std': '0.16'}
Episode time 46.26
Saved _metrics_

=== Episode 24 ===
Training on [7000/28000] data points
> Train epoch 20 [ensemble -32.81 | reward 0.17]
> Train epoch 40 [ensemble -36.77 | reward 0.09]
> Train epoch 60 [ensemble -38.77 | reward 0.06]
> Train epoch 80 [ensemble -40.08 | reward 0.05]
> Train epoch 100 [ensemble -41.04 | reward 0.04]
Ensemble loss -41.04 / Reward Loss 0.04

=== Collecting data [24] ===
> Step 25 [reward 89.00]
> Step 50 [reward 189.00]
> Step 75 [reward 289.00]
> Step 100 [reward 389.00]
> Step 125 [reward 489.00]
> Step 150 [reward 589.00]
> Step 175 [reward 689.00]
> Step 200 [reward 789.00]
> Step 225 [reward 889.00]
> Step 250 [reward 989.00]
Rewards 989.00 / Steps 250.00
Reward stats:
 {'max': '32.22', 'mean': '7.12', 'min': '-1.08', 'std': '5.26'}
Information gain stats:
 {'max': '1.58', 'mean': '0.94', 'min': '0.36', 'std': '0.16'}
Episode time 47.39
Saved _metrics_

=== Episode 25 ===
Training on [7250/29000] data points
> Train epoch 20 [ensemble -33.21 | reward 0.17]
> Train epoch 40 [ensemble -37.07 | reward 0.09]
> Train epoch 60 [ensemble -39.01 | reward 0.06]
> Train epoch 80 [ensemble -40.28 | reward 0.05]
> Train epoch 100 [ensemble -41.21 | reward 0.04]
Ensemble loss -41.21 / Reward Loss 0.04

=== Collecting data [25] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 94.00]
> Step 125 [reward 194.00]
> Step 150 [reward 294.00]
> Step 175 [reward 394.00]
> Step 200 [reward 494.00]
> Step 225 [reward 594.00]
> Step 250 [reward 694.00]
Rewards 694.00 / Steps 250.00
Reward stats:
 {'max': '34.77', 'mean': '5.46', 'min': '-2.32', 'std': '5.47'}
Information gain stats:
 {'max': '1.78', 'mean': '0.97', 'min': '0.36', 'std': '0.16'}
Episode time 48.31
Saved _metrics_

=== Episode 26 ===
Training on [7500/30000] data points
> Train epoch 20 [ensemble -33.50 | reward 0.17]
> Train epoch 40 [ensemble -37.30 | reward 0.09]
> Train epoch 60 [ensemble -39.21 | reward 0.06]
> Train epoch 80 [ensemble -40.46 | reward 0.05]
> Train epoch 100 [ensemble -41.36 | reward 0.04]
Ensemble loss -41.36 / Reward Loss 0.04

=== Collecting data [26] ===
> Step 25 [reward 44.00]
> Step 50 [reward 144.00]
> Step 75 [reward 244.00]
> Step 100 [reward 344.00]
> Step 125 [reward 444.00]
> Step 150 [reward 544.00]
> Step 175 [reward 644.00]
> Step 200 [reward 744.00]
> Step 225 [reward 844.00]
> Step 250 [reward 944.00]
Rewards 944.00 / Steps 250.00
Reward stats:
 {'max': '31.49', 'mean': '7.15', 'min': '-0.86', 'std': '5.59'}
Information gain stats:
 {'max': '1.67', 'mean': '0.95', 'min': '0.38', 'std': '0.16'}
Episode time 49.33
Saved _metrics_

=== Episode 27 ===
Training on [7750/31000] data points
> Train epoch 20 [ensemble -33.64 | reward 0.16]
> Train epoch 40 [ensemble -37.41 | reward 0.09]
> Train epoch 60 [ensemble -39.30 | reward 0.06]
> Train epoch 80 [ensemble -40.53 | reward 0.04]
> Train epoch 100 [ensemble -41.43 | reward 0.04]
Ensemble loss -41.43 / Reward Loss 0.04

=== Collecting data [27] ===
> Step 25 [reward 95.00]
> Step 50 [reward 195.00]
> Step 75 [reward 295.00]
> Step 100 [reward 395.00]
> Step 125 [reward 495.00]
> Step 150 [reward 595.00]
> Step 175 [reward 695.00]
> Step 200 [reward 795.00]
> Step 225 [reward 895.00]
> Step 250 [reward 995.00]
Rewards 995.00 / Steps 250.00
Reward stats:
 {'max': '32.88', 'mean': '7.31', 'min': '-1.39', 'std': '5.48'}
Information gain stats:
 {'max': '1.64', 'mean': '0.94', 'min': '0.36', 'std': '0.16'}
Episode time 50.40
Saved _metrics_

=== Episode 28 ===
Training on [8000/32000] data points
> Train epoch 20 [ensemble -34.22 | reward 0.16]
> Train epoch 40 [ensemble -37.80 | reward 0.08]
> Train epoch 60 [ensemble -39.61 | reward 0.06]
> Train epoch 80 [ensemble -40.80 | reward 0.04]
> Train epoch 100 [ensemble -41.66 | reward 0.03]
Ensemble loss -41.66 / Reward Loss 0.03

=== Collecting data [28] ===
> Step 25 [reward 0.00]
> Step 50 [reward 80.00]
> Step 75 [reward 180.00]
> Step 100 [reward 280.00]
> Step 125 [reward 380.00]
> Step 150 [reward 480.00]
> Step 175 [reward 580.00]
> Step 200 [reward 680.00]
> Step 225 [reward 780.00]
> Step 250 [reward 880.00]
Rewards 880.00 / Steps 250.00
Reward stats:
 {'max': '33.81', 'mean': '6.71', 'min': '-2.95', 'std': '5.50'}
Information gain stats:
 {'max': '1.67', 'mean': '0.97', 'min': '0.38', 'std': '0.16'}
Episode time 51.40
Saved _metrics_

=== Episode 29 ===
Training on [8250/33000] data points
> Train epoch 20 [ensemble -34.43 | reward 0.16]
> Train epoch 40 [ensemble -37.97 | reward 0.09]
> Train epoch 60 [ensemble -39.75 | reward 0.06]
> Train epoch 80 [ensemble -40.91 | reward 0.04]
> Train epoch 100 [ensemble -41.76 | reward 0.04]
Ensemble loss -41.76 / Reward Loss 0.04

=== Collecting data [29] ===
> Step 25 [reward 88.00]
> Step 50 [reward 188.00]
> Step 75 [reward 288.00]
> Step 100 [reward 388.00]
> Step 125 [reward 488.00]
> Step 150 [reward 588.00]
> Step 175 [reward 688.00]
> Step 200 [reward 788.00]
> Step 225 [reward 888.00]
> Step 250 [reward 988.00]
Rewards 988.00 / Steps 250.00
Reward stats:
 {'max': '33.39', 'mean': '8.79', 'min': '-1.35', 'std': '5.98'}
Information gain stats:
 {'max': '1.62', 'mean': '0.98', 'min': '0.37', 'std': '0.18'}
Episode time 52.57
Saved _metrics_

=== Episode 30 ===
Training on [8500/34000] data points
> Train epoch 20 [ensemble -34.64 | reward 0.15]
> Train epoch 40 [ensemble -38.14 | reward 0.08]
> Train epoch 60 [ensemble -39.90 | reward 0.05]
> Train epoch 80 [ensemble -41.05 | reward 0.04]
> Train epoch 100 [ensemble -41.88 | reward 0.03]
Ensemble loss -41.88 / Reward Loss 0.03

=== Collecting data [30] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 10.00]
> Step 250 [reward 110.00]
Rewards 110.00 / Steps 250.00
Reward stats:
 {'max': '32.99', 'mean': '2.40', 'min': '-1.28', 'std': '3.60'}
Information gain stats:
 {'max': '1.76', 'mean': '1.06', 'min': '0.39', 'std': '0.13'}
Episode time 53.70
Saved _metrics_

=== Episode 31 ===
Training on [8750/35000] data points
> Train epoch 20 [ensemble -34.57 | reward 0.14]
> Train epoch 40 [ensemble -38.03 | reward 0.08]
> Train epoch 60 [ensemble -39.77 | reward 0.05]
> Train epoch 80 [ensemble -40.90 | reward 0.04]
> Train epoch 100 [ensemble -41.73 | reward 0.03]
Ensemble loss -41.73 / Reward Loss 0.03

=== Collecting data [31] ===
> Step 25 [reward 91.00]
> Step 50 [reward 191.00]
> Step 75 [reward 291.00]
> Step 100 [reward 391.00]
> Step 125 [reward 491.00]
> Step 150 [reward 591.00]
> Step 175 [reward 691.00]
> Step 200 [reward 791.00]
> Step 225 [reward 891.00]
> Step 250 [reward 991.00]
Rewards 991.00 / Steps 250.00
Reward stats:
 {'max': '17.84', 'mean': '3.29', 'min': '-1.86', 'std': '2.31'}
Information gain stats:
 {'max': '1.61', 'mean': '1.03', 'min': '0.57', 'std': '0.12'}
Episode time 54.68
Saved _metrics_

=== Episode 32 ===
Training on [9000/36000] data points
> Train epoch 20 [ensemble -35.09 | reward 0.15]
> Train epoch 40 [ensemble -38.36 | reward 0.08]
> Train epoch 60 [ensemble -40.01 | reward 0.06]
> Train epoch 80 [ensemble -41.10 | reward 0.04]
> Train epoch 100 [ensemble -41.89 | reward 0.03]
Ensemble loss -41.89 / Reward Loss 0.03

=== Collecting data [32] ===
> Step 25 [reward 0.00]
> Step 50 [reward 61.00]
> Step 75 [reward 161.00]
> Step 100 [reward 261.00]
> Step 125 [reward 361.00]
> Step 150 [reward 461.00]
> Step 175 [reward 561.00]
> Step 200 [reward 661.00]
> Step 225 [reward 761.00]
> Step 250 [reward 861.00]
Rewards 861.00 / Steps 250.00
Reward stats:
 {'max': '32.94', 'mean': '7.53', 'min': '-1.97', 'std': '6.01'}
Information gain stats:
 {'max': '1.63', 'mean': '0.97', 'min': '0.37', 'std': '0.16'}
Episode time 55.78
Saved _metrics_

=== Episode 33 ===
Training on [9250/37000] data points
> Train epoch 20 [ensemble -35.38 | reward 0.16]
> Train epoch 40 [ensemble -38.57 | reward 0.08]
> Train epoch 60 [ensemble -40.19 | reward 0.06]
> Train epoch 80 [ensemble -41.25 | reward 0.04]
> Train epoch 100 [ensemble -42.02 | reward 0.03]
Ensemble loss -42.02 / Reward Loss 0.03

=== Collecting data [33] ===
> Step 25 [reward 0.00]
> Step 50 [reward 88.00]
> Step 75 [reward 188.00]
> Step 100 [reward 288.00]
> Step 125 [reward 388.00]
> Step 150 [reward 488.00]
> Step 175 [reward 588.00]
> Step 200 [reward 688.00]
> Step 225 [reward 788.00]
> Step 250 [reward 888.00]
Rewards 888.00 / Steps 250.00
Reward stats:
 {'max': '34.98', 'mean': '8.34', 'min': '-0.62', 'std': '6.19'}
Information gain stats:
 {'max': '1.73', 'mean': '0.96', 'min': '0.34', 'std': '0.17'}
Episode time 56.99
Saved _metrics_

=== Episode 34 ===
Training on [9500/38000] data points
> Train epoch 20 [ensemble -35.59 | reward 0.15]
> Train epoch 40 [ensemble -38.71 | reward 0.08]
> Train epoch 60 [ensemble -40.28 | reward 0.05]
> Train epoch 80 [ensemble -41.32 | reward 0.04]
> Train epoch 100 [ensemble -42.09 | reward 0.03]
Ensemble loss -42.09 / Reward Loss 0.03

=== Collecting data [34] ===
> Step 25 [reward 20.00]
> Step 50 [reward 120.00]
> Step 75 [reward 220.00]
> Step 100 [reward 320.00]
> Step 125 [reward 420.00]
> Step 150 [reward 520.00]
> Step 175 [reward 620.00]
> Step 200 [reward 720.00]
> Step 225 [reward 820.00]
> Step 250 [reward 920.00]
Rewards 920.00 / Steps 250.00
Reward stats:
 {'max': '31.47', 'mean': '7.25', 'min': '-1.95', 'std': '5.35'}
Information gain stats:
 {'max': '1.58', 'mean': '0.96', 'min': '0.39', 'std': '0.14'}
Episode time 57.79
Saved _metrics_

=== Episode 35 ===
Training on [9750/39000] data points
> Train epoch 20 [ensemble -35.90 | reward 0.14]
> Train epoch 40 [ensemble -38.93 | reward 0.07]
> Train epoch 60 [ensemble -40.46 | reward 0.05]
> Train epoch 80 [ensemble -41.47 | reward 0.04]
> Train epoch 100 [ensemble -42.21 | reward 0.03]
Ensemble loss -42.21 / Reward Loss 0.03

=== Collecting data [35] ===
> Step 25 [reward 90.00]
> Step 50 [reward 190.00]
> Step 75 [reward 290.00]
> Step 100 [reward 390.00]
> Step 125 [reward 490.00]
> Step 150 [reward 590.00]
> Step 175 [reward 690.00]
> Step 200 [reward 790.00]
> Step 225 [reward 890.00]
> Step 250 [reward 990.00]
Rewards 990.00 / Steps 250.00
Reward stats:
 {'max': '29.24', 'mean': '7.36', 'min': '-0.84', 'std': '4.92'}
Information gain stats:
 {'max': '1.54', 'mean': '0.95', 'min': '0.42', 'std': '0.15'}
Episode time 59.06
Saved _metrics_

=== Episode 36 ===
Training on [10000/40000] data points
> Train epoch 20 [ensemble -36.02 | reward 0.16]
> Train epoch 40 [ensemble -39.02 | reward 0.08]
> Train epoch 60 [ensemble -40.54 | reward 0.06]
> Train epoch 80 [ensemble -41.54 | reward 0.04]
> Train epoch 100 [ensemble -42.27 | reward 0.03]
Ensemble loss -42.27 / Reward Loss 0.03

=== Collecting data [36] ===
> Step 25 [reward 51.00]
> Step 50 [reward 151.00]
> Step 75 [reward 251.00]
> Step 100 [reward 351.00]
> Step 125 [reward 451.00]
> Step 150 [reward 551.00]
> Step 175 [reward 651.00]
> Step 200 [reward 751.00]
> Step 225 [reward 851.00]
> Step 250 [reward 951.00]
Rewards 951.00 / Steps 250.00
Reward stats:
 {'max': '37.09', 'mean': '9.06', 'min': '-1.59', 'std': '6.45'}
Information gain stats:
 {'max': '1.59', 'mean': '0.96', 'min': '0.34', 'std': '0.17'}
Episode time 60.14
Saved _metrics_

=== Episode 37 ===
Training on [10250/41000] data points
> Train epoch 20 [ensemble -36.38 | reward 0.14]
> Train epoch 40 [ensemble -39.29 | reward 0.08]
> Train epoch 60 [ensemble -40.77 | reward 0.05]
> Train epoch 80 [ensemble -41.74 | reward 0.04]
> Train epoch 100 [ensemble -42.45 | reward 0.03]
Ensemble loss -42.45 / Reward Loss 0.03

=== Collecting data [37] ===
> Step 25 [reward 86.00]
> Step 50 [reward 186.00]
> Step 75 [reward 286.00]
> Step 100 [reward 386.00]
> Step 125 [reward 486.00]
> Step 150 [reward 586.00]
> Step 175 [reward 686.00]
> Step 200 [reward 786.00]
> Step 225 [reward 886.00]
> Step 250 [reward 986.00]
Rewards 986.00 / Steps 250.00
Reward stats:
 {'max': '31.84', 'mean': '7.56', 'min': '-0.58', 'std': '4.87'}
Information gain stats:
 {'max': '1.54', 'mean': '0.97', 'min': '0.43', 'std': '0.14'}
Episode time 61.23
Saved _metrics_

=== Episode 38 ===
Training on [10500/42000] data points
> Train epoch 20 [ensemble -36.53 | reward 0.15]
> Train epoch 40 [ensemble -39.38 | reward 0.08]
> Train epoch 60 [ensemble -40.82 | reward 0.05]
> Train epoch 80 [ensemble -41.78 | reward 0.04]
> Train epoch 100 [ensemble -42.48 | reward 0.03]
Ensemble loss -42.48 / Reward Loss 0.03

=== Collecting data [38] ===
> Step 25 [reward 23.00]
> Step 50 [reward 123.00]
> Step 75 [reward 223.00]
> Step 100 [reward 323.00]
> Step 125 [reward 423.00]
> Step 150 [reward 523.00]
> Step 175 [reward 623.00]
> Step 200 [reward 723.00]
> Step 225 [reward 823.00]
> Step 250 [reward 923.00]
Rewards 923.00 / Steps 250.00
Reward stats:
 {'max': '33.63', 'mean': '7.56', 'min': '-0.78', 'std': '5.44'}
Information gain stats:
 {'max': '1.63', 'mean': '0.98', 'min': '0.43', 'std': '0.14'}
Episode time 62.45
Saved _metrics_

=== Episode 39 ===
Training on [10750/43000] data points
> Train epoch 20 [ensemble -36.64 | reward 0.14]
> Train epoch 40 [ensemble -39.50 | reward 0.07]
> Train epoch 60 [ensemble -40.94 | reward 0.05]
> Train epoch 80 [ensemble -41.90 | reward 0.04]
> Train epoch 100 [ensemble -42.60 | reward 0.03]
Ensemble loss -42.60 / Reward Loss 0.03

=== Collecting data [39] ===
> Step 25 [reward 89.00]
> Step 50 [reward 189.00]
> Step 75 [reward 289.00]
> Step 100 [reward 389.00]
> Step 125 [reward 489.00]
> Step 150 [reward 589.00]
> Step 175 [reward 689.00]
> Step 200 [reward 789.00]
> Step 225 [reward 889.00]
> Step 250 [reward 989.00]
Rewards 989.00 / Steps 250.00
Reward stats:
 {'max': '35.10', 'mean': '7.14', 'min': '-0.61', 'std': '5.24'}
Information gain stats:
 {'max': '1.65', 'mean': '1.00', 'min': '0.39', 'std': '0.15'}
Episode time 64.07
Saved _metrics_

=== Episode 40 ===
Training on [11000/44000] data points
> Train epoch 20 [ensemble -36.84 | reward 0.14]
> Train epoch 40 [ensemble -39.64 | reward 0.07]
> Train epoch 60 [ensemble -41.06 | reward 0.05]
> Train epoch 80 [ensemble -42.00 | reward 0.04]
> Train epoch 100 [ensemble -42.69 | reward 0.03]
Ensemble loss -42.69 / Reward Loss 0.03

=== Collecting data [40] ===
> Step 25 [reward 8.00]
> Step 50 [reward 108.00]
> Step 75 [reward 208.00]
> Step 100 [reward 308.00]
> Step 125 [reward 408.00]
> Step 150 [reward 508.00]
> Step 175 [reward 608.00]
> Step 200 [reward 708.00]
> Step 225 [reward 808.00]
> Step 250 [reward 908.00]
Rewards 908.00 / Steps 250.00
Reward stats:
 {'max': '33.34', 'mean': '6.53', 'min': '-0.69', 'std': '4.99'}
Information gain stats:
 {'max': '1.61', 'mean': '1.01', 'min': '0.46', 'std': '0.15'}
Episode time 64.90
Saved _metrics_

=== Episode 41 ===
Training on [11250/45000] data points
> Train epoch 20 [ensemble -36.94 | reward 0.13]
> Train epoch 40 [ensemble -39.71 | reward 0.07]
> Train epoch 60 [ensemble -41.11 | reward 0.05]
> Train epoch 80 [ensemble -42.03 | reward 0.04]
> Train epoch 100 [ensemble -42.71 | reward 0.03]
Ensemble loss -42.71 / Reward Loss 0.03

=== Collecting data [41] ===
> Step 25 [reward 0.00]
> Step 50 [reward 84.00]
> Step 75 [reward 184.00]
> Step 100 [reward 284.00]
> Step 125 [reward 384.00]
> Step 150 [reward 484.00]
> Step 175 [reward 584.00]
> Step 200 [reward 684.00]
> Step 225 [reward 784.00]
> Step 250 [reward 884.00]
Rewards 884.00 / Steps 250.00
Reward stats:
 {'max': '32.50', 'mean': '8.79', 'min': '-0.93', 'std': '6.14'}
Information gain stats:
 {'max': '1.63', 'mean': '1.01', 'min': '0.40', 'std': '0.16'}
Episode time 65.86
Saved _metrics_

=== Episode 42 ===
Training on [11500/46000] data points
> Train epoch 20 [ensemble -37.12 | reward 0.15]
> Train epoch 40 [ensemble -39.86 | reward 0.08]
> Train epoch 60 [ensemble -41.24 | reward 0.05]
> Train epoch 80 [ensemble -42.15 | reward 0.04]
> Train epoch 100 [ensemble -42.82 | reward 0.03]
Ensemble loss -42.82 / Reward Loss 0.03

=== Collecting data [42] ===
> Step 25 [reward 87.00]
> Step 50 [reward 187.00]
> Step 75 [reward 287.00]
> Step 100 [reward 387.00]
> Step 125 [reward 487.00]
> Step 150 [reward 587.00]
> Step 175 [reward 687.00]
> Step 200 [reward 787.00]
> Step 225 [reward 887.00]
> Step 250 [reward 987.00]
Rewards 987.00 / Steps 250.00
Reward stats:
 {'max': '35.15', 'mean': '9.12', 'min': '-0.59', 'std': '6.06'}
Information gain stats:
 {'max': '1.65', 'mean': '0.98', 'min': '0.36', 'std': '0.17'}
Episode time 66.81
Saved _metrics_

=== Episode 43 ===
Training on [11750/47000] data points
> Train epoch 20 [ensemble -37.35 | reward 0.13]
> Train epoch 40 [ensemble -40.02 | reward 0.07]
> Train epoch 60 [ensemble -41.38 | reward 0.05]
> Train epoch 80 [ensemble -42.27 | reward 0.04]
> Train epoch 100 [ensemble -42.93 | reward 0.03]
Ensemble loss -42.93 / Reward Loss 0.03

=== Collecting data [43] ===
> Step 25 [reward 21.00]
> Step 50 [reward 121.00]
> Step 75 [reward 221.00]
> Step 100 [reward 321.00]
> Step 125 [reward 421.00]
> Step 150 [reward 521.00]
> Step 175 [reward 621.00]
> Step 200 [reward 721.00]
> Step 225 [reward 821.00]
> Step 250 [reward 921.00]
Rewards 921.00 / Steps 250.00
Reward stats:
 {'max': '35.36', 'mean': '8.86', 'min': '-0.84', 'std': '6.14'}
Information gain stats:
 {'max': '1.70', 'mean': '1.01', 'min': '0.40', 'std': '0.19'}
Episode time 67.77
Saved _metrics_

=== Episode 44 ===
Training on [12000/48000] data points
> Train epoch 20 [ensemble -37.42 | reward 0.14]
> Train epoch 40 [ensemble -40.08 | reward 0.07]
> Train epoch 60 [ensemble -41.42 | reward 0.05]
> Train epoch 80 [ensemble -42.31 | reward 0.04]
> Train epoch 100 [ensemble -42.96 | reward 0.03]
Ensemble loss -42.96 / Reward Loss 0.03

=== Collecting data [44] ===
> Step 25 [reward 100.00]
> Step 50 [reward 200.00]
> Step 75 [reward 300.00]
> Step 100 [reward 400.00]
> Step 125 [reward 500.00]
> Step 150 [reward 600.00]
> Step 175 [reward 700.00]
> Step 200 [reward 800.00]
> Step 225 [reward 900.00]
> Step 250 [reward 1000.00]
Rewards 1000.00 / Steps 250.00
Reward stats:
 {'max': '35.51', 'mean': '9.52', 'min': '-0.81', 'std': '6.19'}
Information gain stats:
 {'max': '1.66', 'mean': '1.00', 'min': '0.39', 'std': '0.18'}
Episode time 68.65
Saved _metrics_

=== Episode 45 ===
Training on [12250/49000] data points
> Train epoch 20 [ensemble -37.57 | reward 0.12]
> Train epoch 40 [ensemble -40.18 | reward 0.06]
> Train epoch 60 [ensemble -41.50 | reward 0.04]
> Train epoch 80 [ensemble -42.39 | reward 0.03]
> Train epoch 100 [ensemble -43.03 | reward 0.03]
Ensemble loss -43.03 / Reward Loss 0.03

=== Collecting data [45] ===
> Step 25 [reward 0.00]
> Step 50 [reward 12.00]
> Step 75 [reward 112.00]
> Step 100 [reward 212.00]
> Step 125 [reward 312.00]
> Step 150 [reward 412.00]
> Step 175 [reward 512.00]
> Step 200 [reward 612.00]
> Step 225 [reward 712.00]
> Step 250 [reward 812.00]
Rewards 812.00 / Steps 250.00
Reward stats:
 {'max': '38.66', 'mean': '8.75', 'min': '-0.42', 'std': '7.16'}
Information gain stats:
 {'max': '1.64', 'mean': '1.02', 'min': '0.39', 'std': '0.16'}
Episode time 69.70
Saved _metrics_

=== Episode 46 ===
Training on [12500/50000] data points
> Train epoch 20 [ensemble -37.65 | reward 0.12]
> Train epoch 40 [ensemble -40.25 | reward 0.06]
> Train epoch 60 [ensemble -41.57 | reward 0.04]
> Train epoch 80 [ensemble -42.44 | reward 0.03]
> Train epoch 100 [ensemble -43.08 | reward 0.03]
Ensemble loss -43.08 / Reward Loss 0.03

=== Collecting data [46] ===
> Step 25 [reward 55.00]
> Step 50 [reward 155.00]
> Step 75 [reward 255.00]
> Step 100 [reward 355.00]
> Step 125 [reward 455.00]
> Step 150 [reward 555.00]
> Step 175 [reward 655.00]
> Step 200 [reward 755.00]
> Step 225 [reward 855.00]
> Step 250 [reward 955.00]
Rewards 955.00 / Steps 250.00
Reward stats:
 {'max': '39.94', 'mean': '10.20', 'min': '-0.87', 'std': '7.12'}
Information gain stats:
 {'max': '1.64', 'mean': '1.00', 'min': '0.40', 'std': '0.18'}
Episode time 70.84
Saved _metrics_

=== Episode 47 ===
Training on [12750/51000] data points
> Train epoch 20 [ensemble -37.80 | reward 0.13]
> Train epoch 40 [ensemble -40.36 | reward 0.07]
> Train epoch 60 [ensemble -41.66 | reward 0.05]
> Train epoch 80 [ensemble -42.53 | reward 0.03]
> Train epoch 100 [ensemble -43.17 | reward 0.03]
Ensemble loss -43.17 / Reward Loss 0.03

=== Collecting data [47] ===
> Step 25 [reward 91.00]
> Step 50 [reward 191.00]
> Step 75 [reward 291.00]
> Step 100 [reward 391.00]
> Step 125 [reward 491.00]
> Step 150 [reward 591.00]
> Step 175 [reward 691.00]
> Step 200 [reward 791.00]
> Step 225 [reward 891.00]
> Step 250 [reward 991.00]
Rewards 991.00 / Steps 250.00
Reward stats:
 {'max': '35.67', 'mean': '9.82', 'min': '-0.76', 'std': '6.31'}
Information gain stats:
 {'max': '1.67', 'mean': '1.03', 'min': '0.39', 'std': '0.19'}
Episode time 71.91
Saved _metrics_

=== Episode 48 ===
Training on [13000/52000] data points
> Train epoch 20 [ensemble -37.99 | reward 0.12]
> Train epoch 40 [ensemble -40.48 | reward 0.07]
> Train epoch 60 [ensemble -41.75 | reward 0.04]
> Train epoch 80 [ensemble -42.60 | reward 0.03]
> Train epoch 100 [ensemble -43.22 | reward 0.03]
Ensemble loss -43.22 / Reward Loss 0.03

=== Collecting data [48] ===
> Step 25 [reward 56.00]
> Step 50 [reward 156.00]
> Step 75 [reward 256.00]
> Step 100 [reward 356.00]
> Step 125 [reward 456.00]
> Step 150 [reward 556.00]
> Step 175 [reward 656.00]
> Step 200 [reward 756.00]
> Step 225 [reward 856.00]
> Step 250 [reward 956.00]
Rewards 956.00 / Steps 250.00
Reward stats:
 {'max': '37.11', 'mean': '9.34', 'min': '-0.28', 'std': '6.56'}
Information gain stats:
 {'max': '1.75', 'mean': '1.00', 'min': '0.39', 'std': '0.18'}
Episode time 72.88
Saved _metrics_

=== Episode 49 ===
Training on [13250/53000] data points
> Train epoch 20 [ensemble -38.10 | reward 0.11]
> Train epoch 40 [ensemble -40.59 | reward 0.06]
> Train epoch 60 [ensemble -41.85 | reward 0.04]
> Train epoch 80 [ensemble -42.69 | reward 0.03]
> Train epoch 100 [ensemble -43.31 | reward 0.02]
Ensemble loss -43.31 / Reward Loss 0.02

=== Collecting data [49] ===
> Step 25 [reward 56.00]
> Step 50 [reward 156.00]
> Step 75 [reward 256.00]
> Step 100 [reward 356.00]
> Step 125 [reward 456.00]
> Step 150 [reward 556.00]
> Step 175 [reward 656.00]
> Step 200 [reward 756.00]
> Step 225 [reward 856.00]
> Step 250 [reward 956.00]
Rewards 956.00 / Steps 250.00
Reward stats:
 {'max': '36.19', 'mean': '8.92', 'min': '-0.35', 'std': '6.10'}
Information gain stats:
 {'max': '1.64', 'mean': '1.03', 'min': '0.41', 'std': '0.16'}
Episode time 74.13
Saved _metrics_