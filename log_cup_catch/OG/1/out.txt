07:51:08

=== Loading experiment [device: cuda] ===

{'action_noise': None,
 'action_repeat': 4,
 'batch_size': 50,
 'coverage': False,
 'ensemble_size': 10,
 'env_name': 'DeepMindCatch',
 'epsilon': 1e-08,
 'expl_scale': 0.1,
 'expl_strategy': 'information',
 'grad_clip_norm': 1000,
 'hidden_size': 200,
 'learning_rate': 0.001,
 'logdir': 'cup_catch_OG',
 'max_episode_len': 1000,
 'n_candidates': 500,
 'n_episodes': 50,
 'n_seed_episodes': 5,
 'n_train_epochs': 100,
 'optimisation_iters': 5,
 'plan_horizon': 12,
 'record_every': None,
 'reward_scale': 1.0,
 'seed': 1,
 'strategy': 'information',
 'top_candidates': 50,
 'use_exploration': True,
 'use_mean': False,
 'use_reward': True}

Collected seeds: [5 episodes | 1250 frames]

=== Episode 1 ===
Training on [1250/5000] data points
> Train epoch 20 [ensemble -22.23 | reward 0.00]
> Train epoch 40 [ensemble -30.09 | reward 0.00]
> Train epoch 60 [ensemble -33.76 | reward 0.00]
> Train epoch 80 [ensemble -36.07 | reward 0.00]
> Train epoch 100 [ensemble -37.72 | reward 0.00]
Ensemble loss -37.72 / Reward Loss 0.00

=== Collecting data [1] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '0.49', 'mean': '-0.01', 'min': '-0.41', 'std': '0.07'}
Information gain stats:
 {'max': '3.00', 'mean': '1.61', 'min': '0.52', 'std': '0.32'}
Episode time 23.39
Saved _metrics_

=== Episode 2 ===
Training on [1500/6000] data points
> Train epoch 20 [ensemble -19.70 | reward 0.00]
> Train epoch 40 [ensemble -28.16 | reward 0.00]
> Train epoch 60 [ensemble -31.91 | reward 0.00]
> Train epoch 80 [ensemble -34.22 | reward 0.00]
> Train epoch 100 [ensemble -35.85 | reward 0.00]
Ensemble loss -35.85 / Reward Loss 0.00

=== Collecting data [2] ===
> Step 25 [reward 83.00]
> Step 50 [reward 183.00]
> Step 75 [reward 283.00]
> Step 100 [reward 383.00]
> Step 125 [reward 483.00]
> Step 150 [reward 583.00]
> Step 175 [reward 683.00]
> Step 200 [reward 772.00]
> Step 225 [reward 864.00]
> Step 250 [reward 954.00]
Rewards 954.00 / Steps 250.00
Reward stats:
 {'max': '0.05', 'mean': '-0.01', 'min': '-0.09', 'std': '0.01'}
Information gain stats:
 {'max': '1.63', 'mean': '0.96', 'min': '0.44', 'std': '0.22'}
Episode time 23.47
Saved _metrics_

=== Episode 3 ===
Training on [1750/7000] data points
> Train epoch 20 [ensemble -17.09 | reward 0.06]
> Train epoch 40 [ensemble -26.49 | reward 0.03]
> Train epoch 60 [ensemble -30.71 | reward 0.02]
> Train epoch 80 [ensemble -33.27 | reward 0.02]
> Train epoch 100 [ensemble -35.06 | reward 0.01]
Ensemble loss -35.06 / Reward Loss 0.01

=== Collecting data [3] ===
> Step 25 [reward 86.00]
> Step 50 [reward 186.00]
> Step 75 [reward 286.00]
> Step 100 [reward 386.00]
> Step 125 [reward 486.00]
> Step 150 [reward 586.00]
> Step 175 [reward 686.00]
> Step 200 [reward 786.00]
> Step 225 [reward 886.00]
> Step 250 [reward 986.00]
Rewards 986.00 / Steps 250.00
Reward stats:
 {'max': '55.06', 'mean': '15.25', 'min': '-0.36', 'std': '13.18'}
Information gain stats:
 {'max': '1.30', 'mean': '0.75', 'min': '0.32', 'std': '0.14'}
Episode time 24.66
Saved _metrics_

=== Episode 4 ===
Training on [2000/8000] data points
> Train epoch 20 [ensemble -18.07 | reward 0.09]
> Train epoch 40 [ensemble -27.16 | reward 0.05]
> Train epoch 60 [ensemble -31.27 | reward 0.03]
> Train epoch 80 [ensemble -33.74 | reward 0.02]
> Train epoch 100 [ensemble -35.46 | reward 0.02]
Ensemble loss -35.46 / Reward Loss 0.02

=== Collecting data [4] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '47.27', 'mean': '12.61', 'min': '-0.31', 'std': '11.90'}
Information gain stats:
 {'max': '1.23', 'mean': '0.74', 'min': '0.40', 'std': '0.10'}
Episode time 25.53
Saved _metrics_

=== Episode 5 ===
Training on [2250/9000] data points
> Train epoch 20 [ensemble -19.77 | reward 0.13]
> Train epoch 40 [ensemble -28.30 | reward 0.07]
> Train epoch 60 [ensemble -32.18 | reward 0.04]
> Train epoch 80 [ensemble -34.51 | reward 0.03]
> Train epoch 100 [ensemble -36.14 | reward 0.03]
Ensemble loss -36.14 / Reward Loss 0.03

=== Collecting data [5] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '48.40', 'mean': '7.23', 'min': '-1.03', 'std': '7.40'}
Information gain stats:
 {'max': '1.34', 'mean': '0.75', 'min': '0.35', 'std': '0.13'}
Episode time 26.77
Saved _metrics_

=== Episode 6 ===
Training on [2500/10000] data points
> Train epoch 20 [ensemble -21.31 | reward 0.13]
> Train epoch 40 [ensemble -29.27 | reward 0.06]
> Train epoch 60 [ensemble -32.93 | reward 0.04]
> Train epoch 80 [ensemble -35.13 | reward 0.03]
> Train epoch 100 [ensemble -36.68 | reward 0.03]
Ensemble loss -36.68 / Reward Loss 0.03

=== Collecting data [6] ===
> Step 25 [reward 55.00]
> Step 50 [reward 155.00]
> Step 75 [reward 255.00]
> Step 100 [reward 355.00]
> Step 125 [reward 455.00]
> Step 150 [reward 555.00]
> Step 175 [reward 655.00]
> Step 200 [reward 755.00]
> Step 225 [reward 855.00]
> Step 250 [reward 955.00]
Rewards 955.00 / Steps 250.00
Reward stats:
 {'max': '56.94', 'mean': '10.72', 'min': '-1.46', 'std': '9.59'}
Information gain stats:
 {'max': '1.37', 'mean': '0.75', 'min': '0.25', 'std': '0.16'}
Episode time 27.88
Saved _metrics_

=== Episode 7 ===
Training on [2750/11000] data points
> Train epoch 20 [ensemble -22.77 | reward 0.13]
> Train epoch 40 [ensemble -30.21 | reward 0.07]
> Train epoch 60 [ensemble -33.68 | reward 0.05]
> Train epoch 80 [ensemble -35.79 | reward 0.03]
> Train epoch 100 [ensemble -37.26 | reward 0.03]
Ensemble loss -37.26 / Reward Loss 0.03

=== Collecting data [7] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '38.40', 'mean': '2.71', 'min': '-2.16', 'std': '3.59'}
Information gain stats:
 {'max': '1.43', 'mean': '0.83', 'min': '0.35', 'std': '0.13'}
Episode time 28.77
Saved _metrics_

=== Episode 8 ===
Training on [3000/12000] data points
> Train epoch 20 [ensemble -21.90 | reward 0.15]
> Train epoch 40 [ensemble -29.48 | reward 0.08]
> Train epoch 60 [ensemble -32.96 | reward 0.05]
> Train epoch 80 [ensemble -35.09 | reward 0.04]
> Train epoch 100 [ensemble -36.59 | reward 0.03]
Ensemble loss -36.59 / Reward Loss 0.03

=== Collecting data [8] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 51.00]
> Step 125 [reward 151.00]
> Step 150 [reward 251.00]
> Step 175 [reward 351.00]
> Step 200 [reward 451.00]
> Step 225 [reward 551.00]
> Step 250 [reward 651.00]
Rewards 651.00 / Steps 250.00
Reward stats:
 {'max': '31.37', 'mean': '3.88', 'min': '-3.01', 'std': '4.52'}
Information gain stats:
 {'max': '1.51', 'mean': '0.89', 'min': '0.43', 'std': '0.14'}
Episode time 29.72
Saved _metrics_

=== Episode 9 ===
Training on [3250/13000] data points
> Train epoch 20 [ensemble -23.29 | reward 0.15]
> Train epoch 40 [ensemble -30.35 | reward 0.08]
> Train epoch 60 [ensemble -33.57 | reward 0.05]
> Train epoch 80 [ensemble -35.56 | reward 0.04]
> Train epoch 100 [ensemble -36.98 | reward 0.03]
Ensemble loss -36.98 / Reward Loss 0.03

=== Collecting data [9] ===
> Step 25 [reward 25.00]
> Step 50 [reward 25.00]
> Step 75 [reward 25.00]
> Step 100 [reward 25.00]
> Step 125 [reward 25.00]
> Step 150 [reward 25.00]
> Step 175 [reward 25.00]
> Step 200 [reward 25.00]
> Step 225 [reward 25.00]
> Step 250 [reward 25.00]
Rewards 25.00 / Steps 250.00
Reward stats:
 {'max': '12.64', 'mean': '0.53', 'min': '-1.63', 'std': '0.66'}
Information gain stats:
 {'max': '1.47', 'mean': '0.97', 'min': '0.51', 'std': '0.11'}
Episode time 30.74
Saved _metrics_

=== Episode 10 ===
Training on [3500/14000] data points
> Train epoch 20 [ensemble -23.11 | reward 0.15]
> Train epoch 40 [ensemble -29.96 | reward 0.08]
> Train epoch 60 [ensemble -33.10 | reward 0.06]
> Train epoch 80 [ensemble -35.07 | reward 0.04]
> Train epoch 100 [ensemble -36.50 | reward 0.03]
Ensemble loss -36.50 / Reward Loss 0.03

=== Collecting data [10] ===
> Step 25 [reward 0.00]
> Step 50 [reward 61.00]
> Step 75 [reward 161.00]
> Step 100 [reward 261.00]
> Step 125 [reward 361.00]
> Step 150 [reward 461.00]
> Step 175 [reward 561.00]
> Step 200 [reward 661.00]
> Step 225 [reward 761.00]
> Step 250 [reward 861.00]
Rewards 861.00 / Steps 250.00
Reward stats:
 {'max': '25.88', 'mean': '4.06', 'min': '-1.46', 'std': '3.47'}
Information gain stats:
 {'max': '1.50', 'mean': '0.92', 'min': '0.42', 'std': '0.14'}
Episode time 31.88
Saved _metrics_

=== Episode 11 ===
Training on [3750/15000] data points
> Train epoch 20 [ensemble -23.77 | reward 0.16]
> Train epoch 40 [ensemble -30.40 | reward 0.09]
> Train epoch 60 [ensemble -33.43 | reward 0.06]
> Train epoch 80 [ensemble -35.33 | reward 0.04]
> Train epoch 100 [ensemble -36.71 | reward 0.04]
Ensemble loss -36.71 / Reward Loss 0.04

=== Collecting data [11] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '12.58', 'mean': '2.05', 'min': '-1.35', 'std': '1.91'}
Information gain stats:
 {'max': '1.50', 'mean': '1.08', 'min': '0.57', 'std': '0.10'}
Episode time 32.96
Saved _metrics_

=== Episode 12 ===
Training on [4000/16000] data points
> Train epoch 20 [ensemble -25.01 | reward 0.15]
> Train epoch 40 [ensemble -31.26 | reward 0.08]
> Train epoch 60 [ensemble -34.15 | reward 0.06]
> Train epoch 80 [ensemble -35.98 | reward 0.04]
> Train epoch 100 [ensemble -37.31 | reward 0.03]
Ensemble loss -37.31 / Reward Loss 0.03

=== Collecting data [12] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '7.01', 'mean': '0.42', 'min': '-3.53', 'std': '0.73'}
Information gain stats:
 {'max': '1.49', 'mean': '0.93', 'min': '0.47', 'std': '0.12'}
Episode time 33.92
Saved _metrics_

=== Episode 13 ===
Training on [4250/17000] data points
> Train epoch 20 [ensemble -25.66 | reward 0.15]
> Train epoch 40 [ensemble -31.54 | reward 0.09]
> Train epoch 60 [ensemble -34.32 | reward 0.06]
> Train epoch 80 [ensemble -36.11 | reward 0.04]
> Train epoch 100 [ensemble -37.41 | reward 0.04]
Ensemble loss -37.41 / Reward Loss 0.04

=== Collecting data [13] ===
> Step 25 [reward 0.00]
> Step 50 [reward 20.00]
> Step 75 [reward 120.00]
> Step 100 [reward 220.00]
> Step 125 [reward 320.00]
> Step 150 [reward 420.00]
> Step 175 [reward 520.00]
> Step 200 [reward 620.00]
> Step 225 [reward 720.00]
> Step 250 [reward 820.00]
Rewards 820.00 / Steps 250.00
Reward stats:
 {'max': '26.35', 'mean': '3.60', 'min': '-2.63', 'std': '3.60'}
Information gain stats:
 {'max': '1.49', 'mean': '0.89', 'min': '0.44', 'std': '0.13'}
Episode time 35.05
Saved _metrics_

=== Episode 14 ===
Training on [4500/18000] data points
> Train epoch 20 [ensemble -26.21 | reward 0.14]
> Train epoch 40 [ensemble -31.90 | reward 0.08]
> Train epoch 60 [ensemble -34.59 | reward 0.06]
> Train epoch 80 [ensemble -36.34 | reward 0.04]
> Train epoch 100 [ensemble -37.61 | reward 0.03]
Ensemble loss -37.61 / Reward Loss 0.03

=== Collecting data [14] ===
> Step 25 [reward 0.00]
> Step 50 [reward 4.00]
> Step 75 [reward 73.00]
> Step 100 [reward 173.00]
> Step 125 [reward 273.00]
> Step 150 [reward 373.00]
> Step 175 [reward 473.00]
> Step 200 [reward 573.00]
> Step 225 [reward 673.00]
> Step 250 [reward 773.00]
Rewards 773.00 / Steps 250.00
Reward stats:
 {'max': '28.40', 'mean': '3.84', 'min': '-1.31', 'std': '3.94'}
Information gain stats:
 {'max': '1.53', 'mean': '0.89', 'min': '0.37', 'std': '0.14'}
Episode time 36.80
Saved _metrics_

=== Episode 15 ===
Training on [4750/19000] data points
> Train epoch 20 [ensemble -26.70 | reward 0.14]
> Train epoch 40 [ensemble -32.22 | reward 0.08]
> Train epoch 60 [ensemble -34.84 | reward 0.05]
> Train epoch 80 [ensemble -36.54 | reward 0.04]
> Train epoch 100 [ensemble -37.79 | reward 0.03]
Ensemble loss -37.79 / Reward Loss 0.03

=== Collecting data [15] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '3.91', 'mean': '0.83', 'min': '-1.47', 'std': '0.66'}
Information gain stats:
 {'max': '1.44', 'mean': '1.04', 'min': '0.54', 'std': '0.09'}
Episode time 39.57
Saved _metrics_

=== Episode 16 ===
Training on [5000/20000] data points
> Train epoch 20 [ensemble -27.27 | reward 0.14]
> Train epoch 40 [ensemble -32.81 | reward 0.08]
> Train epoch 60 [ensemble -35.43 | reward 0.06]
> Train epoch 80 [ensemble -37.12 | reward 0.04]
> Train epoch 100 [ensemble -38.35 | reward 0.03]
Ensemble loss -38.35 / Reward Loss 0.03

=== Collecting data [16] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 93.00]
> Step 100 [reward 193.00]
> Step 125 [reward 293.00]
> Step 150 [reward 393.00]
> Step 175 [reward 493.00]
> Step 200 [reward 593.00]
> Step 225 [reward 693.00]
> Step 250 [reward 793.00]
Rewards 793.00 / Steps 250.00
Reward stats:
 {'max': '31.92', 'mean': '4.38', 'min': '-2.09', 'std': '4.44'}
Information gain stats:
 {'max': '1.50', 'mean': '0.83', 'min': '0.38', 'std': '0.13'}
Episode time 39.36
Saved _metrics_

=== Episode 17 ===
Training on [5250/21000] data points
> Train epoch 20 [ensemble -27.79 | reward 0.15]
> Train epoch 40 [ensemble -33.12 | reward 0.08]
> Train epoch 60 [ensemble -35.64 | reward 0.06]
> Train epoch 80 [ensemble -37.26 | reward 0.04]
> Train epoch 100 [ensemble -38.45 | reward 0.03]
Ensemble loss -38.45 / Reward Loss 0.03

=== Collecting data [17] ===
> Step 25 [reward 0.00]
> Step 50 [reward 58.00]
> Step 75 [reward 158.00]
> Step 100 [reward 258.00]
> Step 125 [reward 358.00]
> Step 150 [reward 458.00]
> Step 175 [reward 558.00]
> Step 200 [reward 658.00]
> Step 225 [reward 758.00]
> Step 250 [reward 858.00]
Rewards 858.00 / Steps 250.00
Reward stats:
 {'max': '23.41', 'mean': '3.34', 'min': '-1.77', 'std': '3.21'}
Information gain stats:
 {'max': '1.49', 'mean': '0.87', 'min': '0.41', 'std': '0.13'}
Episode time 41.94
Saved _metrics_

=== Episode 18 ===
Training on [5500/22000] data points
> Train epoch 20 [ensemble -28.36 | reward 0.14]
> Train epoch 40 [ensemble -33.51 | reward 0.08]
> Train epoch 60 [ensemble -35.97 | reward 0.05]
> Train epoch 80 [ensemble -37.56 | reward 0.04]
> Train epoch 100 [ensemble -38.72 | reward 0.03]
Ensemble loss -38.72 / Reward Loss 0.03

=== Collecting data [18] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 63.00]
> Step 125 [reward 163.00]
> Step 150 [reward 263.00]
> Step 175 [reward 363.00]
> Step 200 [reward 463.00]
> Step 225 [reward 563.00]
> Step 250 [reward 663.00]
Rewards 663.00 / Steps 250.00
Reward stats:
 {'max': '23.36', 'mean': '2.62', 'min': '-3.49', 'std': '2.87'}
Information gain stats:
 {'max': '1.47', 'mean': '0.89', 'min': '0.46', 'std': '0.13'}
Episode time 42.38
Saved _metrics_

=== Episode 19 ===
Training on [5750/23000] data points
> Train epoch 20 [ensemble -28.77 | reward 0.14]
> Train epoch 40 [ensemble -33.77 | reward 0.08]
> Train epoch 60 [ensemble -36.18 | reward 0.06]
> Train epoch 80 [ensemble -37.73 | reward 0.04]
> Train epoch 100 [ensemble -38.88 | reward 0.04]
Ensemble loss -38.88 / Reward Loss 0.04

=== Collecting data [19] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 92.00]
> Step 175 [reward 192.00]
> Step 200 [reward 292.00]
> Step 225 [reward 392.00]
> Step 250 [reward 492.00]
Rewards 492.00 / Steps 250.00
Reward stats:
 {'max': '21.55', 'mean': '1.66', 'min': '-2.89', 'std': '2.40'}
Information gain stats:
 {'max': '1.58', 'mean': '0.90', 'min': '0.41', 'std': '0.14'}
Episode time 42.93
Saved _metrics_

=== Episode 20 ===
Training on [6000/24000] data points
> Train epoch 20 [ensemble -28.92 | reward 0.15]
> Train epoch 40 [ensemble -33.88 | reward 0.09]
> Train epoch 60 [ensemble -36.27 | reward 0.06]
> Train epoch 80 [ensemble -37.83 | reward 0.04]
> Train epoch 100 [ensemble -38.97 | reward 0.04]
Ensemble loss -38.97 / Reward Loss 0.04

=== Collecting data [20] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 56.00]
> Step 100 [reward 156.00]
> Step 125 [reward 256.00]
> Step 150 [reward 356.00]
> Step 175 [reward 456.00]
> Step 200 [reward 556.00]
> Step 225 [reward 656.00]
> Step 250 [reward 756.00]
Rewards 756.00 / Steps 250.00
Reward stats:
 {'max': '26.11', 'mean': '2.71', 'min': '-2.12', 'std': '2.92'}
Information gain stats:
 {'max': '1.46', 'mean': '0.86', 'min': '0.34', 'std': '0.13'}
Episode time 44.18
Saved _metrics_

=== Episode 21 ===
Training on [6250/25000] data points
> Train epoch 20 [ensemble -29.59 | reward 0.15]
> Train epoch 40 [ensemble -34.36 | reward 0.08]
> Train epoch 60 [ensemble -36.64 | reward 0.06]
> Train epoch 80 [ensemble -38.12 | reward 0.04]
> Train epoch 100 [ensemble -39.21 | reward 0.04]
Ensemble loss -39.21 / Reward Loss 0.04

=== Collecting data [21] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '10.06', 'mean': '1.91', 'min': '-1.84', 'std': '1.52'}
Information gain stats:
 {'max': '1.49', 'mean': '0.97', 'min': '0.52', 'std': '0.10'}
Episode time 44.67
Saved _metrics_

=== Episode 22 ===
Training on [6500/26000] data points
> Train epoch 20 [ensemble -29.69 | reward 0.14]
> Train epoch 40 [ensemble -34.48 | reward 0.08]
> Train epoch 60 [ensemble -36.79 | reward 0.06]
> Train epoch 80 [ensemble -38.29 | reward 0.04]
> Train epoch 100 [ensemble -39.40 | reward 0.03]
Ensemble loss -39.40 / Reward Loss 0.03

=== Collecting data [22] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 19.00]
> Step 100 [reward 119.00]
> Step 125 [reward 219.00]
> Step 150 [reward 319.00]
> Step 175 [reward 419.00]
> Step 200 [reward 519.00]
> Step 225 [reward 619.00]
> Step 250 [reward 719.00]
Rewards 719.00 / Steps 250.00
Reward stats:
 {'max': '21.54', 'mean': '2.82', 'min': '-1.54', 'std': '3.05'}
Information gain stats:
 {'max': '1.45', 'mean': '0.83', 'min': '0.38', 'std': '0.13'}
Episode time 45.28
Saved _metrics_

=== Episode 23 ===
Training on [6750/27000] data points
> Train epoch 20 [ensemble -30.02 | reward 0.14]
> Train epoch 40 [ensemble -34.69 | reward 0.08]
> Train epoch 60 [ensemble -36.95 | reward 0.05]
> Train epoch 80 [ensemble -38.43 | reward 0.04]
> Train epoch 100 [ensemble -39.51 | reward 0.03]
Ensemble loss -39.51 / Reward Loss 0.03

=== Collecting data [23] ===
> Step 25 [reward 55.00]
> Step 50 [reward 155.00]
> Step 75 [reward 255.00]
> Step 100 [reward 355.00]
> Step 125 [reward 455.00]
> Step 150 [reward 555.00]
> Step 175 [reward 655.00]
> Step 200 [reward 755.00]
> Step 225 [reward 855.00]
> Step 250 [reward 955.00]
Rewards 955.00 / Steps 250.00
Reward stats:
 {'max': '24.13', 'mean': '3.16', 'min': '-1.03', 'std': '2.85'}
Information gain stats:
 {'max': '1.46', 'mean': '0.84', 'min': '0.43', 'std': '0.12'}
Episode time 49.10
Saved _metrics_

=== Episode 24 ===
Training on [7000/28000] data points
> Train epoch 20 [ensemble -30.46 | reward 0.14]
> Train epoch 40 [ensemble -35.03 | reward 0.08]
> Train epoch 60 [ensemble -37.25 | reward 0.06]
> Train epoch 80 [ensemble -38.70 | reward 0.04]
> Train epoch 100 [ensemble -39.77 | reward 0.04]
Ensemble loss -39.77 / Reward Loss 0.04

=== Collecting data [24] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '6.07', 'mean': '0.66', 'min': '-2.96', 'std': '0.81'}
Information gain stats:
 {'max': '1.50', 'mean': '0.91', 'min': '0.47', 'std': '0.12'}
Episode time 48.77
Saved _metrics_

=== Episode 25 ===
Training on [7250/29000] data points
> Train epoch 20 [ensemble -30.51 | reward 0.12]
> Train epoch 40 [ensemble -35.04 | reward 0.07]
> Train epoch 60 [ensemble -37.24 | reward 0.05]
> Train epoch 80 [ensemble -38.69 | reward 0.04]
> Train epoch 100 [ensemble -39.76 | reward 0.03]
Ensemble loss -39.76 / Reward Loss 0.03

=== Collecting data [25] ===
> Step 25 [reward 21.00]
> Step 50 [reward 121.00]
> Step 75 [reward 221.00]
> Step 100 [reward 321.00]
> Step 125 [reward 421.00]
> Step 150 [reward 521.00]
> Step 175 [reward 621.00]
> Step 200 [reward 721.00]
> Step 225 [reward 821.00]
> Step 250 [reward 921.00]
Rewards 921.00 / Steps 250.00
Reward stats:
 {'max': '19.11', 'mean': '3.70', 'min': '-1.64', 'std': '3.15'}
Information gain stats:
 {'max': '1.50', 'mean': '0.84', 'min': '0.48', 'std': '0.12'}
Episode time 49.64
Saved _metrics_

=== Episode 26 ===
Training on [7500/30000] data points
> Train epoch 20 [ensemble -30.74 | reward 0.13]
> Train epoch 40 [ensemble -35.22 | reward 0.07]
> Train epoch 60 [ensemble -37.42 | reward 0.05]
> Train epoch 80 [ensemble -38.86 | reward 0.04]
> Train epoch 100 [ensemble -39.91 | reward 0.03]
Ensemble loss -39.91 / Reward Loss 0.03

=== Collecting data [26] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 37.00]
> Step 150 [reward 137.00]
> Step 175 [reward 237.00]
> Step 200 [reward 337.00]
> Step 225 [reward 437.00]
> Step 250 [reward 537.00]
Rewards 537.00 / Steps 250.00
Reward stats:
 {'max': '21.46', 'mean': '2.28', 'min': '-1.74', 'std': '2.72'}
Information gain stats:
 {'max': '1.45', 'mean': '0.87', 'min': '0.44', 'std': '0.13'}
Episode time 50.62
Saved _metrics_

=== Episode 27 ===
Training on [7750/31000] data points
> Train epoch 20 [ensemble -31.07 | reward 0.14]
> Train epoch 40 [ensemble -35.41 | reward 0.08]
> Train epoch 60 [ensemble -37.55 | reward 0.06]
> Train epoch 80 [ensemble -38.96 | reward 0.04]
> Train epoch 100 [ensemble -40.01 | reward 0.04]
Ensemble loss -40.01 / Reward Loss 0.04

=== Collecting data [27] ===
> Step 25 [reward 91.00]
> Step 50 [reward 191.00]
> Step 75 [reward 291.00]
> Step 100 [reward 391.00]
> Step 125 [reward 491.00]
> Step 150 [reward 591.00]
> Step 175 [reward 691.00]
> Step 200 [reward 791.00]
> Step 225 [reward 891.00]
> Step 250 [reward 991.00]
Rewards 991.00 / Steps 250.00
Reward stats:
 {'max': '8.19', 'mean': '1.62', 'min': '-2.50', 'std': '1.25'}
Information gain stats:
 {'max': '1.49', 'mean': '0.95', 'min': '0.57', 'std': '0.09'}
Episode time 51.77
Saved _metrics_

=== Episode 28 ===
Training on [8000/32000] data points
> Train epoch 20 [ensemble -31.13 | reward 0.15]
> Train epoch 40 [ensemble -35.47 | reward 0.08]
> Train epoch 60 [ensemble -37.60 | reward 0.06]
> Train epoch 80 [ensemble -39.02 | reward 0.04]
> Train epoch 100 [ensemble -40.06 | reward 0.03]
Ensemble loss -40.06 / Reward Loss 0.03

=== Collecting data [28] ===
> Step 25 [reward 90.00]
> Step 50 [reward 190.00]
> Step 75 [reward 290.00]
> Step 100 [reward 390.00]
> Step 125 [reward 490.00]
> Step 150 [reward 590.00]
> Step 175 [reward 690.00]
> Step 200 [reward 790.00]
> Step 225 [reward 890.00]
> Step 250 [reward 990.00]
Rewards 990.00 / Steps 250.00
Reward stats:
 {'max': '15.71', 'mean': '3.37', 'min': '-1.21', 'std': '2.69'}
Information gain stats:
 {'max': '1.48', 'mean': '0.93', 'min': '0.56', 'std': '0.09'}
Episode time 52.79
Saved _metrics_

=== Episode 29 ===
Training on [8250/33000] data points
> Train epoch 20 [ensemble -31.51 | reward 0.15]
> Train epoch 40 [ensemble -35.74 | reward 0.08]
> Train epoch 60 [ensemble -37.82 | reward 0.06]
> Train epoch 80 [ensemble -39.20 | reward 0.04]
> Train epoch 100 [ensemble -40.22 | reward 0.04]
Ensemble loss -40.22 / Reward Loss 0.04

=== Collecting data [29] ===
> Step 25 [reward 60.00]
> Step 50 [reward 160.00]
> Step 75 [reward 260.00]
> Step 100 [reward 360.00]
> Step 125 [reward 460.00]
> Step 150 [reward 560.00]
> Step 175 [reward 660.00]
> Step 200 [reward 760.00]
> Step 225 [reward 860.00]
> Step 250 [reward 960.00]
Rewards 960.00 / Steps 250.00
Reward stats:
 {'max': '19.25', 'mean': '3.94', 'min': '-2.40', 'std': '3.24'}
Information gain stats:
 {'max': '1.53', 'mean': '0.91', 'min': '0.53', 'std': '0.10'}
Episode time 53.91
Saved _metrics_

=== Episode 30 ===
Training on [8500/34000] data points
> Train epoch 20 [ensemble -31.83 | reward 0.14]
> Train epoch 40 [ensemble -35.90 | reward 0.08]
> Train epoch 60 [ensemble -37.90 | reward 0.05]
> Train epoch 80 [ensemble -39.23 | reward 0.04]
> Train epoch 100 [ensemble -40.22 | reward 0.03]
Ensemble loss -40.22 / Reward Loss 0.03

=== Collecting data [30] ===
> Step 25 [reward 15.00]
> Step 50 [reward 115.00]
> Step 75 [reward 215.00]
> Step 100 [reward 315.00]
> Step 125 [reward 415.00]
> Step 150 [reward 515.00]
> Step 175 [reward 615.00]
> Step 200 [reward 715.00]
> Step 225 [reward 815.00]
> Step 250 [reward 915.00]
Rewards 915.00 / Steps 250.00
Reward stats:
 {'max': '22.12', 'mean': '3.79', 'min': '-2.46', 'std': '3.46'}
Information gain stats:
 {'max': '1.55', 'mean': '0.91', 'min': '0.54', 'std': '0.11'}
Episode time 55.14
Saved _metrics_

=== Episode 31 ===
Training on [8750/35000] data points
> Train epoch 20 [ensemble -31.87 | reward 0.14]
> Train epoch 40 [ensemble -35.95 | reward 0.08]
> Train epoch 60 [ensemble -37.96 | reward 0.06]
> Train epoch 80 [ensemble -39.29 | reward 0.04]
> Train epoch 100 [ensemble -40.29 | reward 0.03]
Ensemble loss -40.29 / Reward Loss 0.03

=== Collecting data [31] ===
> Step 25 [reward 0.00]
> Step 50 [reward 71.00]
> Step 75 [reward 171.00]
> Step 100 [reward 271.00]
> Step 125 [reward 371.00]
> Step 150 [reward 471.00]
> Step 175 [reward 571.00]
> Step 200 [reward 671.00]
> Step 225 [reward 771.00]
> Step 250 [reward 871.00]
Rewards 871.00 / Steps 250.00
Reward stats:
 {'max': '19.30', 'mean': '3.19', 'min': '-1.89', 'std': '3.12'}
Information gain stats:
 {'max': '1.52', 'mean': '0.93', 'min': '0.47', 'std': '0.11'}
Episode time 58.87
Saved _metrics_

=== Episode 32 ===
Training on [9000/36000] data points
> Train epoch 20 [ensemble -32.06 | reward 0.15]
> Train epoch 40 [ensemble -36.06 | reward 0.08]
> Train epoch 60 [ensemble -38.03 | reward 0.06]
> Train epoch 80 [ensemble -39.35 | reward 0.04]
> Train epoch 100 [ensemble -40.34 | reward 0.04]
Ensemble loss -40.34 / Reward Loss 0.04

=== Collecting data [32] ===
> Step 25 [reward 0.00]
> Step 50 [reward 90.00]
> Step 75 [reward 190.00]
> Step 100 [reward 290.00]
> Step 125 [reward 390.00]
> Step 150 [reward 490.00]
> Step 175 [reward 590.00]
> Step 200 [reward 690.00]
> Step 225 [reward 790.00]
> Step 250 [reward 890.00]
Rewards 890.00 / Steps 250.00
Reward stats:
 {'max': '21.85', 'mean': '3.29', 'min': '-3.08', 'std': '3.30'}
Information gain stats:
 {'max': '1.51', 'mean': '0.92', 'min': '0.52', 'std': '0.12'}
Episode time 57.91
Saved _metrics_

=== Episode 33 ===
Training on [9250/37000] data points
> Train epoch 20 [ensemble -32.19 | reward 0.14]
> Train epoch 40 [ensemble -36.17 | reward 0.08]
> Train epoch 60 [ensemble -38.13 | reward 0.05]
> Train epoch 80 [ensemble -39.46 | reward 0.04]
> Train epoch 100 [ensemble -40.46 | reward 0.03]
Ensemble loss -40.46 / Reward Loss 0.03

=== Collecting data [33] ===
> Step 25 [reward 56.00]
> Step 50 [reward 156.00]
> Step 75 [reward 256.00]
> Step 100 [reward 356.00]
> Step 125 [reward 456.00]
> Step 150 [reward 556.00]
> Step 175 [reward 656.00]
> Step 200 [reward 756.00]
> Step 225 [reward 856.00]
> Step 250 [reward 956.00]
Rewards 956.00 / Steps 250.00
Reward stats:
 {'max': '26.68', 'mean': '3.88', 'min': '-1.43', 'std': '3.74'}
Information gain stats:
 {'max': '1.56', 'mean': '0.93', 'min': '0.57', 'std': '0.11'}
Episode time 62.00
Saved _metrics_

=== Episode 34 ===
Training on [9500/38000] data points
> Train epoch 20 [ensemble -32.32 | reward 0.15]
> Train epoch 40 [ensemble -36.22 | reward 0.08]
> Train epoch 60 [ensemble -38.15 | reward 0.06]
> Train epoch 80 [ensemble -39.46 | reward 0.04]
> Train epoch 100 [ensemble -40.44 | reward 0.04]
Ensemble loss -40.44 / Reward Loss 0.04

=== Collecting data [34] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 16.00]
> Step 100 [reward 116.00]
> Step 125 [reward 216.00]
> Step 150 [reward 316.00]
> Step 175 [reward 416.00]
> Step 200 [reward 516.00]
> Step 225 [reward 616.00]
> Step 250 [reward 716.00]
Rewards 716.00 / Steps 250.00
Reward stats:
 {'max': '25.14', 'mean': '2.81', 'min': '-1.85', 'std': '3.48'}
Information gain stats:
 {'max': '1.59', 'mean': '0.93', 'min': '0.48', 'std': '0.12'}
Episode time 61.17
Saved _metrics_

=== Episode 35 ===
Training on [9750/39000] data points
> Train epoch 20 [ensemble -32.45 | reward 0.14]
> Train epoch 40 [ensemble -36.33 | reward 0.08]
> Train epoch 60 [ensemble -38.27 | reward 0.05]
> Train epoch 80 [ensemble -39.59 | reward 0.04]
> Train epoch 100 [ensemble -40.56 | reward 0.03]
Ensemble loss -40.56 / Reward Loss 0.03

=== Collecting data [35] ===
> Step 25 [reward 57.00]
> Step 50 [reward 157.00]
> Step 75 [reward 257.00]
> Step 100 [reward 357.00]
> Step 125 [reward 457.00]
> Step 150 [reward 557.00]
> Step 175 [reward 657.00]
> Step 200 [reward 757.00]
> Step 225 [reward 857.00]
> Step 250 [reward 957.00]
Rewards 957.00 / Steps 250.00
Reward stats:
 {'max': '23.22', 'mean': '3.45', 'min': '-1.73', 'std': '3.15'}
Information gain stats:
 {'max': '1.53', 'mean': '0.94', 'min': '0.52', 'std': '0.11'}
Episode time 61.67
Saved _metrics_

=== Episode 36 ===
Training on [10000/40000] data points
> Train epoch 20 [ensemble -32.66 | reward 0.15]
> Train epoch 40 [ensemble -36.47 | reward 0.08]
> Train epoch 60 [ensemble -38.38 | reward 0.06]
> Train epoch 80 [ensemble -39.68 | reward 0.04]
> Train epoch 100 [ensemble -40.64 | reward 0.04]
Ensemble loss -40.64 / Reward Loss 0.04

=== Collecting data [36] ===
> Step 25 [reward 9.00]
> Step 50 [reward 109.00]
> Step 75 [reward 209.00]
> Step 100 [reward 309.00]
> Step 125 [reward 409.00]
> Step 150 [reward 509.00]
> Step 175 [reward 609.00]
> Step 200 [reward 709.00]
> Step 225 [reward 809.00]
> Step 250 [reward 909.00]
Rewards 909.00 / Steps 250.00
Reward stats:
 {'max': '21.91', 'mean': '3.78', 'min': '-2.12', 'std': '3.27'}
Information gain stats:
 {'max': '1.58', 'mean': '0.92', 'min': '0.51', 'std': '0.12'}
Episode time 62.94
Saved _metrics_

=== Episode 37 ===
Training on [10250/41000] data points
> Train epoch 20 [ensemble -32.88 | reward 0.14]
> Train epoch 40 [ensemble -36.65 | reward 0.08]
> Train epoch 60 [ensemble -38.52 | reward 0.05]
> Train epoch 80 [ensemble -39.79 | reward 0.04]
> Train epoch 100 [ensemble -40.73 | reward 0.03]
Ensemble loss -40.73 / Reward Loss 0.03

=== Collecting data [37] ===
> Step 25 [reward 25.00]
> Step 50 [reward 125.00]
> Step 75 [reward 225.00]
> Step 100 [reward 325.00]
> Step 125 [reward 425.00]
> Step 150 [reward 525.00]
> Step 175 [reward 625.00]
> Step 200 [reward 725.00]
> Step 225 [reward 825.00]
> Step 250 [reward 925.00]
Rewards 925.00 / Steps 250.00
Reward stats:
 {'max': '27.74', 'mean': '5.27', 'min': '-1.33', 'std': '4.47'}
Information gain stats:
 {'max': '1.58', 'mean': '0.92', 'min': '0.51', 'std': '0.12'}
Episode time 63.42
Saved _metrics_

=== Episode 38 ===
Training on [10500/42000] data points
> Train epoch 20 [ensemble -33.06 | reward 0.14]
> Train epoch 40 [ensemble -36.75 | reward 0.08]
> Train epoch 60 [ensemble -38.60 | reward 0.05]
> Train epoch 80 [ensemble -39.85 | reward 0.04]
> Train epoch 100 [ensemble -40.78 | reward 0.03]
Ensemble loss -40.78 / Reward Loss 0.03

=== Collecting data [38] ===
> Step 25 [reward 17.00]
> Step 50 [reward 117.00]
> Step 75 [reward 217.00]
> Step 100 [reward 317.00]
> Step 125 [reward 417.00]
> Step 150 [reward 517.00]
> Step 175 [reward 617.00]
> Step 200 [reward 717.00]
> Step 225 [reward 817.00]
> Step 250 [reward 917.00]
Rewards 917.00 / Steps 250.00
Reward stats:
 {'max': '23.83', 'mean': '3.93', 'min': '-1.81', 'std': '3.55'}
Information gain stats:
 {'max': '1.52', 'mean': '0.92', 'min': '0.52', 'std': '0.12'}
Episode time 64.29
Saved _metrics_

=== Episode 39 ===
Training on [10750/43000] data points
> Train epoch 20 [ensemble -33.21 | reward 0.14]
> Train epoch 40 [ensemble -36.86 | reward 0.08]
> Train epoch 60 [ensemble -38.69 | reward 0.05]
> Train epoch 80 [ensemble -39.93 | reward 0.04]
> Train epoch 100 [ensemble -40.84 | reward 0.03]
Ensemble loss -40.84 / Reward Loss 0.03

=== Collecting data [39] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 8.00]
> Step 100 [reward 108.00]
> Step 125 [reward 208.00]
> Step 150 [reward 308.00]
> Step 175 [reward 408.00]
> Step 200 [reward 508.00]
> Step 225 [reward 608.00]
> Step 250 [reward 708.00]
Rewards 708.00 / Steps 250.00
Reward stats:
 {'max': '25.20', 'mean': '3.57', 'min': '-1.92', 'std': '3.89'}
Information gain stats:
 {'max': '1.60', 'mean': '0.94', 'min': '0.45', 'std': '0.13'}
Episode time 66.18
Saved _metrics_

=== Episode 40 ===
Training on [11000/44000] data points
> Train epoch 20 [ensemble -33.39 | reward 0.14]
> Train epoch 40 [ensemble -36.97 | reward 0.08]
> Train epoch 60 [ensemble -38.79 | reward 0.06]
> Train epoch 80 [ensemble -40.02 | reward 0.04]
> Train epoch 100 [ensemble -40.93 | reward 0.03]
Ensemble loss -40.93 / Reward Loss 0.03

=== Collecting data [40] ===
> Step 25 [reward 0.00]
> Step 50 [reward 85.00]
> Step 75 [reward 185.00]
> Step 100 [reward 285.00]
> Step 125 [reward 385.00]
> Step 150 [reward 485.00]
> Step 175 [reward 585.00]
> Step 200 [reward 685.00]
> Step 225 [reward 785.00]
> Step 250 [reward 885.00]
Rewards 885.00 / Steps 250.00
Reward stats:
 {'max': '25.56', 'mean': '4.37', 'min': '-2.07', 'std': '3.85'}
Information gain stats:
 {'max': '1.50', 'mean': '0.95', 'min': '0.46', 'std': '0.12'}
Episode time 66.63
Saved _metrics_

=== Episode 41 ===
Training on [11250/45000] data points
> Train epoch 20 [ensemble -33.49 | reward 0.13]
> Train epoch 40 [ensemble -37.08 | reward 0.07]
> Train epoch 60 [ensemble -38.92 | reward 0.05]
> Train epoch 80 [ensemble -40.16 | reward 0.04]
> Train epoch 100 [ensemble -41.07 | reward 0.03]
Ensemble loss -41.07 / Reward Loss 0.03

=== Collecting data [41] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 81.00]
> Step 100 [reward 181.00]
> Step 125 [reward 281.00]
> Step 150 [reward 381.00]
> Step 175 [reward 481.00]
> Step 200 [reward 581.00]
> Step 225 [reward 681.00]
> Step 250 [reward 781.00]
Rewards 781.00 / Steps 250.00
Reward stats:
 {'max': '26.92', 'mean': '3.27', 'min': '-1.16', 'std': '3.73'}
Information gain stats:
 {'max': '1.57', 'mean': '0.95', 'min': '0.40', 'std': '0.13'}
Episode time 68.49
Saved _metrics_

=== Episode 42 ===
Training on [11500/46000] data points
> Train epoch 20 [ensemble -33.56 | reward 0.14]
> Train epoch 40 [ensemble -37.12 | reward 0.08]
> Train epoch 60 [ensemble -38.93 | reward 0.05]
> Train epoch 80 [ensemble -40.15 | reward 0.04]
> Train epoch 100 [ensemble -41.05 | reward 0.03]
Ensemble loss -41.05 / Reward Loss 0.03

=== Collecting data [42] ===
> Step 25 [reward 90.00]
> Step 50 [reward 190.00]
> Step 75 [reward 290.00]
> Step 100 [reward 390.00]
> Step 125 [reward 490.00]
> Step 150 [reward 590.00]
> Step 175 [reward 690.00]
> Step 200 [reward 790.00]
> Step 225 [reward 890.00]
> Step 250 [reward 990.00]
Rewards 990.00 / Steps 250.00
Reward stats:
 {'max': '31.51', 'mean': '6.10', 'min': '-1.05', 'std': '5.08'}
Information gain stats:
 {'max': '1.55', 'mean': '0.91', 'min': '0.38', 'std': '0.13'}
Episode time 66.71
Saved _metrics_

=== Episode 43 ===
Training on [11750/47000] data points
> Train epoch 20 [ensemble -33.76 | reward 0.14]
> Train epoch 40 [ensemble -37.27 | reward 0.08]
> Train epoch 60 [ensemble -39.06 | reward 0.05]
> Train epoch 80 [ensemble -40.27 | reward 0.04]
> Train epoch 100 [ensemble -41.15 | reward 0.03]
Ensemble loss -41.15 / Reward Loss 0.03

=== Collecting data [43] ===
> Step 25 [reward 57.00]
> Step 50 [reward 157.00]
> Step 75 [reward 257.00]
> Step 100 [reward 357.00]
> Step 125 [reward 457.00]
> Step 150 [reward 557.00]
> Step 175 [reward 657.00]
> Step 200 [reward 757.00]
> Step 225 [reward 857.00]
> Step 250 [reward 957.00]
Rewards 957.00 / Steps 250.00
Reward stats:
 {'max': '29.12', 'mean': '5.18', 'min': '-1.04', 'std': '4.34'}
Information gain stats:
 {'max': '1.60', 'mean': '0.93', 'min': '0.36', 'std': '0.14'}
Episode time 67.44
Saved _metrics_

=== Episode 44 ===
Training on [12000/48000] data points
> Train epoch 20 [ensemble -34.10 | reward 0.14]
> Train epoch 40 [ensemble -37.53 | reward 0.08]
> Train epoch 60 [ensemble -39.29 | reward 0.05]
> Train epoch 80 [ensemble -40.47 | reward 0.04]
> Train epoch 100 [ensemble -41.34 | reward 0.03]
Ensemble loss -41.34 / Reward Loss 0.03

=== Collecting data [44] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 51.00]
> Step 100 [reward 151.00]
> Step 125 [reward 251.00]
> Step 150 [reward 351.00]
> Step 175 [reward 451.00]
> Step 200 [reward 551.00]
> Step 225 [reward 651.00]
> Step 250 [reward 751.00]
Rewards 751.00 / Steps 250.00
Reward stats:
 {'max': '29.22', 'mean': '4.09', 'min': '-2.19', 'std': '4.42'}
Information gain stats:
 {'max': '1.61', 'mean': '0.95', 'min': '0.40', 'std': '0.14'}
Episode time 68.64
Saved _metrics_

=== Episode 45 ===
Training on [12250/49000] data points
> Train epoch 20 [ensemble -34.19 | reward 0.13]
> Train epoch 40 [ensemble -37.57 | reward 0.07]
> Train epoch 60 [ensemble -39.31 | reward 0.05]
> Train epoch 80 [ensemble -40.48 | reward 0.04]
> Train epoch 100 [ensemble -41.34 | reward 0.03]
Ensemble loss -41.34 / Reward Loss 0.03

=== Collecting data [45] ===
> Step 25 [reward 23.00]
> Step 50 [reward 123.00]
> Step 75 [reward 223.00]
> Step 100 [reward 323.00]
> Step 125 [reward 423.00]
> Step 150 [reward 523.00]
> Step 175 [reward 623.00]
> Step 200 [reward 723.00]
> Step 225 [reward 823.00]
> Step 250 [reward 923.00]
Rewards 923.00 / Steps 250.00
Reward stats:
 {'max': '27.22', 'mean': '3.53', 'min': '-1.90', 'std': '3.84'}
Information gain stats:
 {'max': '1.54', 'mean': '0.95', 'min': '0.45', 'std': '0.13'}
Episode time 69.99
Saved _metrics_

=== Episode 46 ===
Training on [12500/50000] data points
> Train epoch 20 [ensemble -34.31 | reward 0.13]
> Train epoch 40 [ensemble -37.65 | reward 0.07]
> Train epoch 60 [ensemble -39.37 | reward 0.05]
> Train epoch 80 [ensemble -40.54 | reward 0.04]
> Train epoch 100 [ensemble -41.39 | reward 0.03]
Ensemble loss -41.39 / Reward Loss 0.03

=== Collecting data [46] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 16.00]
> Step 100 [reward 116.00]
> Step 125 [reward 216.00]
> Step 150 [reward 316.00]
> Step 175 [reward 416.00]
> Step 200 [reward 516.00]
> Step 225 [reward 616.00]
> Step 250 [reward 716.00]
Rewards 716.00 / Steps 250.00
Reward stats:
 {'max': '25.58', 'mean': '3.61', 'min': '-1.85', 'std': '3.57'}
Information gain stats:
 {'max': '1.58', 'mean': '0.95', 'min': '0.40', 'std': '0.13'}
Episode time 70.82
Saved _metrics_

=== Episode 47 ===
Training on [12750/51000] data points
> Train epoch 20 [ensemble -34.52 | reward 0.13]
> Train epoch 40 [ensemble -37.79 | reward 0.07]
> Train epoch 60 [ensemble -39.50 | reward 0.05]
> Train epoch 80 [ensemble -40.65 | reward 0.04]
> Train epoch 100 [ensemble -41.50 | reward 0.03]
Ensemble loss -41.50 / Reward Loss 0.03

=== Collecting data [47] ===
> Step 25 [reward 45.00]
> Step 50 [reward 145.00]
> Step 75 [reward 245.00]
> Step 100 [reward 345.00]
> Step 125 [reward 445.00]
> Step 150 [reward 545.00]
> Step 175 [reward 645.00]
> Step 200 [reward 745.00]
> Step 225 [reward 845.00]
> Step 250 [reward 945.00]
Rewards 945.00 / Steps 250.00
Reward stats:
 {'max': '23.43', 'mean': '4.02', 'min': '-1.71', 'std': '3.76'}
Information gain stats:
 {'max': '1.61', 'mean': '0.94', 'min': '0.48', 'std': '0.12'}
Episode time 71.94
Saved _metrics_

=== Episode 48 ===
Training on [13000/52000] data points
> Train epoch 20 [ensemble -34.65 | reward 0.12]
> Train epoch 40 [ensemble -37.92 | reward 0.07]
> Train epoch 60 [ensemble -39.61 | reward 0.05]
> Train epoch 80 [ensemble -40.74 | reward 0.04]
> Train epoch 100 [ensemble -41.58 | reward 0.03]
Ensemble loss -41.58 / Reward Loss 0.03

=== Collecting data [48] ===
> Step 25 [reward 8.00]
> Step 50 [reward 108.00]
> Step 75 [reward 208.00]
> Step 100 [reward 308.00]
> Step 125 [reward 408.00]
> Step 150 [reward 508.00]
> Step 175 [reward 608.00]
> Step 200 [reward 708.00]
> Step 225 [reward 808.00]
> Step 250 [reward 908.00]
Rewards 908.00 / Steps 250.00
Reward stats:
 {'max': '24.05', 'mean': '2.66', 'min': '-1.20', 'std': '2.91'}
Information gain stats:
 {'max': '1.64', 'mean': '0.95', 'min': '0.43', 'std': '0.12'}
Episode time 72.95
Saved _metrics_

=== Episode 49 ===
Training on [13250/53000] data points
> Train epoch 20 [ensemble -34.81 | reward 0.12]
> Train epoch 40 [ensemble -38.02 | reward 0.07]
> Train epoch 60 [ensemble -39.68 | reward 0.05]
> Train epoch 80 [ensemble -40.80 | reward 0.04]
> Train epoch 100 [ensemble -41.62 | reward 0.03]
Ensemble loss -41.62 / Reward Loss 0.03

=== Collecting data [49] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 44.00]
> Step 100 [reward 144.00]
> Step 125 [reward 244.00]
> Step 150 [reward 344.00]
> Step 175 [reward 444.00]
> Step 200 [reward 544.00]
> Step 225 [reward 644.00]
> Step 250 [reward 744.00]
Rewards 744.00 / Steps 250.00
Reward stats:
 {'max': '27.71', 'mean': '4.51', 'min': '-1.55', 'std': '4.52'}
Information gain stats:
 {'max': '1.69', 'mean': '1.00', 'min': '0.43', 'std': '0.15'}
Episode time 74.25
Saved _metrics_