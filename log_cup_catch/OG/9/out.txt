13:52:25

=== Loading experiment [device: cuda] ===

{'action_noise': None,
 'action_repeat': 4,
 'batch_size': 50,
 'coverage': False,
 'ensemble_size': 10,
 'env_name': 'DeepMindCatch',
 'epsilon': 1e-08,
 'expl_scale': 0.1,
 'expl_strategy': 'information',
 'grad_clip_norm': 1000,
 'hidden_size': 200,
 'learning_rate': 0.001,
 'logdir': 'cup_catch_OG',
 'max_episode_len': 1000,
 'n_candidates': 500,
 'n_episodes': 50,
 'n_seed_episodes': 5,
 'n_train_epochs': 100,
 'optimisation_iters': 5,
 'plan_horizon': 12,
 'record_every': None,
 'reward_scale': 1.0,
 'seed': 9,
 'strategy': 'information',
 'top_candidates': 50,
 'use_exploration': True,
 'use_mean': False,
 'use_reward': True}

Collected seeds: [5 episodes | 1250 frames]

=== Episode 1 ===
Training on [1250/5000] data points
> Train epoch 20 [ensemble -19.70 | reward 0.02]
> Train epoch 40 [ensemble -27.65 | reward 0.01]
> Train epoch 60 [ensemble -31.54 | reward 0.01]
> Train epoch 80 [ensemble -34.00 | reward 0.01]
> Train epoch 100 [ensemble -35.77 | reward 0.00]
Ensemble loss -35.77 / Reward Loss 0.00

=== Collecting data [1] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '26.41', 'mean': '6.05', 'min': '-2.27', 'std': '4.46'}
Information gain stats:
 {'max': '2.13', 'mean': '1.31', 'min': '0.51', 'std': '0.17'}
Episode time 22.66
Saved _metrics_

=== Episode 2 ===
Training on [1500/6000] data points
> Train epoch 20 [ensemble -21.06 | reward 0.02]
> Train epoch 40 [ensemble -28.55 | reward 0.01]
> Train epoch 60 [ensemble -32.10 | reward 0.01]
> Train epoch 80 [ensemble -34.33 | reward 0.00]
> Train epoch 100 [ensemble -35.95 | reward 0.00]
Ensemble loss -35.95 / Reward Loss 0.00

=== Collecting data [2] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 29.00]
> Step 175 [reward 113.00]
> Step 200 [reward 196.00]
> Step 225 [reward 267.00]
> Step 250 [reward 354.00]
Rewards 354.00 / Steps 250.00
Reward stats:
 {'max': '12.44', 'mean': '2.08', 'min': '-0.76', 'std': '1.95'}
Information gain stats:
 {'max': '1.58', 'mean': '0.96', 'min': '0.47', 'std': '0.11'}
Episode time 23.67
Saved _metrics_

=== Episode 3 ===
Training on [1750/7000] data points
> Train epoch 20 [ensemble -20.34 | reward 0.16]
> Train epoch 40 [ensemble -27.60 | reward 0.09]
> Train epoch 60 [ensemble -31.13 | reward 0.06]
> Train epoch 80 [ensemble -33.35 | reward 0.05]
> Train epoch 100 [ensemble -34.96 | reward 0.04]
Ensemble loss -34.96 / Reward Loss 0.04

=== Collecting data [3] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '37.22', 'mean': '7.09', 'min': '-1.81', 'std': '6.05'}
Information gain stats:
 {'max': '1.48', 'mean': '0.84', 'min': '0.40', 'std': '0.12'}
Episode time 24.71
Saved _metrics_

=== Episode 4 ===
Training on [2000/8000] data points
> Train epoch 20 [ensemble -20.10 | reward 0.12]
> Train epoch 40 [ensemble -27.39 | reward 0.07]
> Train epoch 60 [ensemble -30.93 | reward 0.05]
> Train epoch 80 [ensemble -33.18 | reward 0.03]
> Train epoch 100 [ensemble -34.80 | reward 0.03]
Ensemble loss -34.80 / Reward Loss 0.03

=== Collecting data [4] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '16.93', 'mean': '1.53', 'min': '-0.62', 'std': '1.48'}
Information gain stats:
 {'max': '1.47', 'mean': '0.85', 'min': '0.42', 'std': '0.13'}
Episode time 25.81
Saved _metrics_

=== Episode 5 ===
Training on [2250/9000] data points
> Train epoch 20 [ensemble -20.44 | reward 0.13]
> Train epoch 40 [ensemble -27.71 | reward 0.07]
> Train epoch 60 [ensemble -31.22 | reward 0.05]
> Train epoch 80 [ensemble -33.47 | reward 0.04]
> Train epoch 100 [ensemble -35.09 | reward 0.03]
Ensemble loss -35.09 / Reward Loss 0.03

=== Collecting data [5] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 83.00]
> Step 200 [reward 164.00]
> Step 225 [reward 264.00]
> Step 250 [reward 356.00]
Rewards 356.00 / Steps 250.00
Reward stats:
 {'max': '10.70', 'mean': '1.95', 'min': '-1.41', 'std': '1.47'}
Information gain stats:
 {'max': '1.61', 'mean': '1.06', 'min': '0.54', 'std': '0.12'}
Episode time 26.90
Saved _metrics_

=== Episode 6 ===
Training on [2500/10000] data points
> Train epoch 20 [ensemble -21.28 | reward 0.22]
> Train epoch 40 [ensemble -28.06 | reward 0.13]
> Train epoch 60 [ensemble -31.37 | reward 0.09]
> Train epoch 80 [ensemble -33.53 | reward 0.07]
> Train epoch 100 [ensemble -35.11 | reward 0.06]
Ensemble loss -35.11 / Reward Loss 0.06

=== Collecting data [6] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '11.82', 'mean': '0.99', 'min': '-1.97', 'std': '1.17'}
Information gain stats:
 {'max': '1.81', 'mean': '0.93', 'min': '0.45', 'std': '0.13'}
Episode time 27.87
Saved _metrics_

=== Episode 7 ===
Training on [2750/11000] data points
> Train epoch 20 [ensemble -21.38 | reward 0.18]
> Train epoch 40 [ensemble -28.03 | reward 0.10]
> Train epoch 60 [ensemble -31.26 | reward 0.07]
> Train epoch 80 [ensemble -33.37 | reward 0.05]
> Train epoch 100 [ensemble -34.91 | reward 0.04]
Ensemble loss -34.91 / Reward Loss 0.04

=== Collecting data [7] ===
> Step 25 [reward 95.00]
> Step 50 [reward 187.00]
> Step 75 [reward 286.00]
> Step 100 [reward 386.00]
> Step 125 [reward 462.00]
> Step 150 [reward 554.00]
> Step 175 [reward 644.00]
> Step 200 [reward 736.00]
> Step 225 [reward 821.00]
> Step 250 [reward 912.00]
Rewards 912.00 / Steps 250.00
Reward stats:
 {'max': '9.54', 'mean': '1.52', 'min': '-0.67', 'std': '1.28'}
Information gain stats:
 {'max': '1.53', 'mean': '1.03', 'min': '0.56', 'std': '0.12'}
Episode time 29.00
Saved _metrics_

=== Episode 8 ===
Training on [3000/12000] data points
> Train epoch 20 [ensemble -22.15 | reward 0.27]
> Train epoch 40 [ensemble -28.39 | reward 0.16]
> Train epoch 60 [ensemble -31.49 | reward 0.12]
> Train epoch 80 [ensemble -33.56 | reward 0.09]
> Train epoch 100 [ensemble -35.10 | reward 0.08]
Ensemble loss -35.10 / Reward Loss 0.08

=== Collecting data [8] ===
> Step 25 [reward 26.00]
> Step 50 [reward 122.00]
> Step 75 [reward 217.00]
> Step 100 [reward 317.00]
> Step 125 [reward 416.00]
> Step 150 [reward 514.00]
> Step 175 [reward 610.00]
> Step 200 [reward 710.00]
> Step 225 [reward 806.00]
> Step 250 [reward 905.00]
Rewards 905.00 / Steps 250.00
Reward stats:
 {'max': '18.43', 'mean': '3.01', 'min': '-3.64', 'std': '2.38'}
Information gain stats:
 {'max': '1.56', 'mean': '0.95', 'min': '0.46', 'std': '0.12'}
Episode time 30.12
Saved _metrics_

=== Episode 9 ===
Training on [3250/13000] data points
> Train epoch 20 [ensemble -22.98 | reward 0.30]
> Train epoch 40 [ensemble -28.94 | reward 0.18]
> Train epoch 60 [ensemble -31.98 | reward 0.13]
> Train epoch 80 [ensemble -34.02 | reward 0.10]
> Train epoch 100 [ensemble -35.56 | reward 0.08]
Ensemble loss -35.56 / Reward Loss 0.08

=== Collecting data [9] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 26.00]
> Step 225 [reward 126.00]
> Step 250 [reward 224.00]
Rewards 224.00 / Steps 250.00
Reward stats:
 {'max': '18.55', 'mean': '1.49', 'min': '-3.31', 'std': '2.00'}
Information gain stats:
 {'max': '1.53', 'mean': '0.94', 'min': '0.48', 'std': '0.13'}
Episode time 31.26
Saved _metrics_

=== Episode 10 ===
Training on [3500/14000] data points
> Train epoch 20 [ensemble -23.47 | reward 0.30]
> Train epoch 40 [ensemble -29.24 | reward 0.18]
> Train epoch 60 [ensemble -32.18 | reward 0.13]
> Train epoch 80 [ensemble -34.16 | reward 0.10]
> Train epoch 100 [ensemble -35.63 | reward 0.08]
Ensemble loss -35.63 / Reward Loss 0.08

=== Collecting data [10] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 64.00]
> Step 125 [reward 162.00]
> Step 150 [reward 262.00]
> Step 175 [reward 362.00]
> Step 200 [reward 461.00]
> Step 225 [reward 561.00]
> Step 250 [reward 660.00]
Rewards 660.00 / Steps 250.00
Reward stats:
 {'max': '19.40', 'mean': '2.84', 'min': '-3.70', 'std': '2.50'}
Information gain stats:
 {'max': '1.50', 'mean': '0.94', 'min': '0.41', 'std': '0.12'}
Episode time 32.24
Saved _metrics_

=== Episode 11 ===
Training on [3750/15000] data points
> Train epoch 20 [ensemble -24.10 | reward 0.34]
> Train epoch 40 [ensemble -29.64 | reward 0.20]
> Train epoch 60 [ensemble -32.50 | reward 0.14]
> Train epoch 80 [ensemble -34.45 | reward 0.11]
> Train epoch 100 [ensemble -35.92 | reward 0.09]
Ensemble loss -35.92 / Reward Loss 0.09

=== Collecting data [11] ===
> Step 25 [reward 12.00]
> Step 50 [reward 112.00]
> Step 75 [reward 211.00]
> Step 100 [reward 311.00]
> Step 125 [reward 411.00]
> Step 150 [reward 511.00]
> Step 175 [reward 611.00]
> Step 200 [reward 711.00]
> Step 225 [reward 809.00]
> Step 250 [reward 909.00]
Rewards 909.00 / Steps 250.00
Reward stats:
 {'max': '19.95', 'mean': '3.61', 'min': '-2.07', 'std': '2.82'}
Information gain stats:
 {'max': '1.51', 'mean': '0.95', 'min': '0.48', 'std': '0.12'}
Episode time 33.21
Saved _metrics_

=== Episode 12 ===
Training on [4000/16000] data points
> Train epoch 20 [ensemble -24.74 | reward 0.34]
> Train epoch 40 [ensemble -30.15 | reward 0.20]
> Train epoch 60 [ensemble -32.98 | reward 0.14]
> Train epoch 80 [ensemble -34.91 | reward 0.11]
> Train epoch 100 [ensemble -36.35 | reward 0.09]
Ensemble loss -36.35 / Reward Loss 0.09

=== Collecting data [12] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 53.00]
> Step 175 [reward 153.00]
> Step 200 [reward 253.00]
> Step 225 [reward 353.00]
> Step 250 [reward 453.00]
Rewards 453.00 / Steps 250.00
Reward stats:
 {'max': '21.09', 'mean': '2.50', 'min': '-3.15', 'std': '2.98'}
Information gain stats:
 {'max': '1.60', 'mean': '1.00', 'min': '0.45', 'std': '0.14'}
Episode time 34.36
Saved _metrics_

=== Episode 13 ===
Training on [4250/17000] data points
> Train epoch 20 [ensemble -25.20 | reward 0.34]
> Train epoch 40 [ensemble -30.51 | reward 0.20]
> Train epoch 60 [ensemble -33.28 | reward 0.14]
> Train epoch 80 [ensemble -35.17 | reward 0.11]
> Train epoch 100 [ensemble -36.59 | reward 0.09]
Ensemble loss -36.59 / Reward Loss 0.09

=== Collecting data [13] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 0.00]
Rewards 0.00 / Steps 250.00
Reward stats:
 {'max': '16.25', 'mean': '0.92', 'min': '-3.94', 'std': '1.55'}
Information gain stats:
 {'max': '1.53', 'mean': '0.95', 'min': '0.47', 'std': '0.12'}
Episode time 35.48
Saved _metrics_

=== Episode 14 ===
Training on [4500/18000] data points
> Train epoch 20 [ensemble -25.20 | reward 0.33]
> Train epoch 40 [ensemble -30.51 | reward 0.20]
> Train epoch 60 [ensemble -33.31 | reward 0.14]
> Train epoch 80 [ensemble -35.21 | reward 0.11]
> Train epoch 100 [ensemble -36.63 | reward 0.09]
Ensemble loss -36.63 / Reward Loss 0.09

=== Collecting data [14] ===
> Step 25 [reward 24.00]
> Step 50 [reward 124.00]
> Step 75 [reward 224.00]
> Step 100 [reward 324.00]
> Step 125 [reward 424.00]
> Step 150 [reward 524.00]
> Step 175 [reward 624.00]
> Step 200 [reward 724.00]
> Step 225 [reward 824.00]
> Step 250 [reward 924.00]
Rewards 924.00 / Steps 250.00
Reward stats:
 {'max': '19.44', 'mean': '3.96', 'min': '-3.09', 'std': '3.10'}
Information gain stats:
 {'max': '1.54', 'mean': '0.93', 'min': '0.47', 'std': '0.12'}
Episode time 36.54
Saved _metrics_

=== Episode 15 ===
Training on [4750/19000] data points
> Train epoch 20 [ensemble -25.92 | reward 0.33]
> Train epoch 40 [ensemble -31.12 | reward 0.20]
> Train epoch 60 [ensemble -33.90 | reward 0.14]
> Train epoch 80 [ensemble -35.76 | reward 0.11]
> Train epoch 100 [ensemble -37.14 | reward 0.09]
Ensemble loss -37.14 / Reward Loss 0.09

=== Collecting data [15] ===
> Step 25 [reward 59.00]
> Step 50 [reward 159.00]
> Step 75 [reward 259.00]
> Step 100 [reward 359.00]
> Step 125 [reward 459.00]
> Step 150 [reward 559.00]
> Step 175 [reward 659.00]
> Step 200 [reward 759.00]
> Step 225 [reward 859.00]
> Step 250 [reward 959.00]
Rewards 959.00 / Steps 250.00
Reward stats:
 {'max': '22.61', 'mean': '4.62', 'min': '-1.98', 'std': '3.14'}
Information gain stats:
 {'max': '1.51', 'mean': '0.91', 'min': '0.44', 'std': '0.12'}
Episode time 37.60
Saved _metrics_

=== Episode 16 ===
Training on [5000/20000] data points
> Train epoch 20 [ensemble -26.58 | reward 0.33]
> Train epoch 40 [ensemble -31.69 | reward 0.20]
> Train epoch 60 [ensemble -34.39 | reward 0.14]
> Train epoch 80 [ensemble -36.22 | reward 0.11]
> Train epoch 100 [ensemble -37.56 | reward 0.09]
Ensemble loss -37.56 / Reward Loss 0.09

=== Collecting data [16] ===
> Step 25 [reward 18.00]
> Step 50 [reward 118.00]
> Step 75 [reward 218.00]
> Step 100 [reward 318.00]
> Step 125 [reward 418.00]
> Step 150 [reward 518.00]
> Step 175 [reward 618.00]
> Step 200 [reward 718.00]
> Step 225 [reward 818.00]
> Step 250 [reward 918.00]
Rewards 918.00 / Steps 250.00
Reward stats:
 {'max': '20.80', 'mean': '4.17', 'min': '-2.58', 'std': '3.05'}
Information gain stats:
 {'max': '1.52', 'mean': '0.92', 'min': '0.45', 'std': '0.12'}
Episode time 38.64
Saved _metrics_

=== Episode 17 ===
Training on [5250/21000] data points
> Train epoch 20 [ensemble -27.19 | reward 0.32]
> Train epoch 40 [ensemble -32.12 | reward 0.19]
> Train epoch 60 [ensemble -34.73 | reward 0.13]
> Train epoch 80 [ensemble -36.49 | reward 0.10]
> Train epoch 100 [ensemble -37.80 | reward 0.08]
Ensemble loss -37.80 / Reward Loss 0.08

=== Collecting data [17] ===
> Step 25 [reward 95.00]
> Step 50 [reward 195.00]
> Step 75 [reward 295.00]
> Step 100 [reward 395.00]
> Step 125 [reward 495.00]
> Step 150 [reward 595.00]
> Step 175 [reward 695.00]
> Step 200 [reward 795.00]
> Step 225 [reward 895.00]
> Step 250 [reward 995.00]
Rewards 995.00 / Steps 250.00
Reward stats:
 {'max': '24.65', 'mean': '5.31', 'min': '-2.06', 'std': '3.59'}
Information gain stats:
 {'max': '1.56', 'mean': '0.93', 'min': '0.37', 'std': '0.14'}
Episode time 39.77
Saved _metrics_

=== Episode 18 ===
Training on [5500/22000] data points
> Train epoch 20 [ensemble -27.78 | reward 0.32]
> Train epoch 40 [ensemble -32.62 | reward 0.19]
> Train epoch 60 [ensemble -35.16 | reward 0.14]
> Train epoch 80 [ensemble -36.88 | reward 0.10]
> Train epoch 100 [ensemble -38.16 | reward 0.09]
Ensemble loss -38.16 / Reward Loss 0.09

=== Collecting data [18] ===
> Step 25 [reward 10.00]
> Step 50 [reward 110.00]
> Step 75 [reward 210.00]
> Step 100 [reward 310.00]
> Step 125 [reward 410.00]
> Step 150 [reward 510.00]
> Step 175 [reward 610.00]
> Step 200 [reward 710.00]
> Step 225 [reward 810.00]
> Step 250 [reward 910.00]
Rewards 910.00 / Steps 250.00
Reward stats:
 {'max': '23.63', 'mean': '5.79', 'min': '-2.33', 'std': '3.91'}
Information gain stats:
 {'max': '1.54', 'mean': '0.94', 'min': '0.40', 'std': '0.13'}
Episode time 40.77
Saved _metrics_

=== Episode 19 ===
Training on [5750/23000] data points
> Train epoch 20 [ensemble -28.33 | reward 0.29]
> Train epoch 40 [ensemble -33.00 | reward 0.17]
> Train epoch 60 [ensemble -35.50 | reward 0.12]
> Train epoch 80 [ensemble -37.19 | reward 0.09]
> Train epoch 100 [ensemble -38.44 | reward 0.07]
Ensemble loss -38.44 / Reward Loss 0.07

=== Collecting data [19] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 0.00]
> Step 100 [reward 0.00]
> Step 125 [reward 0.00]
> Step 150 [reward 0.00]
> Step 175 [reward 0.00]
> Step 200 [reward 0.00]
> Step 225 [reward 0.00]
> Step 250 [reward 2.00]
Rewards 2.00 / Steps 250.00
Reward stats:
 {'max': '18.48', 'mean': '1.10', 'min': '-3.57', 'std': '1.48'}
Information gain stats:
 {'max': '1.60', 'mean': '0.99', 'min': '0.53', 'std': '0.13'}
Episode time 41.80
Saved _metrics_

=== Episode 20 ===
Training on [6000/24000] data points
> Train epoch 20 [ensemble -28.34 | reward 0.29]
> Train epoch 40 [ensemble -33.11 | reward 0.17]
> Train epoch 60 [ensemble -35.62 | reward 0.12]
> Train epoch 80 [ensemble -37.30 | reward 0.09]
> Train epoch 100 [ensemble -38.54 | reward 0.08]
Ensemble loss -38.54 / Reward Loss 0.08

=== Collecting data [20] ===
> Step 25 [reward 55.00]
> Step 50 [reward 155.00]
> Step 75 [reward 255.00]
> Step 100 [reward 355.00]
> Step 125 [reward 455.00]
> Step 150 [reward 555.00]
> Step 175 [reward 655.00]
> Step 200 [reward 755.00]
> Step 225 [reward 855.00]
> Step 250 [reward 955.00]
Rewards 955.00 / Steps 250.00
Reward stats:
 {'max': '26.99', 'mean': '5.21', 'min': '-1.85', 'std': '3.80'}
Information gain stats:
 {'max': '1.54', 'mean': '0.95', 'min': '0.43', 'std': '0.13'}
Episode time 42.86
Saved _metrics_

=== Episode 21 ===
Training on [6250/25000] data points
> Train epoch 20 [ensemble -28.86 | reward 0.27]
> Train epoch 40 [ensemble -33.49 | reward 0.16]
> Train epoch 60 [ensemble -35.93 | reward 0.11]
> Train epoch 80 [ensemble -37.58 | reward 0.09]
> Train epoch 100 [ensemble -38.79 | reward 0.07]
Ensemble loss -38.79 / Reward Loss 0.07

=== Collecting data [21] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 89.00]
> Step 100 [reward 189.00]
> Step 125 [reward 289.00]
> Step 150 [reward 389.00]
> Step 175 [reward 489.00]
> Step 200 [reward 589.00]
> Step 225 [reward 689.00]
> Step 250 [reward 789.00]
Rewards 789.00 / Steps 250.00
Reward stats:
 {'max': '28.71', 'mean': '5.21', 'min': '-3.14', 'std': '4.71'}
Information gain stats:
 {'max': '1.56', 'mean': '0.95', 'min': '0.38', 'std': '0.15'}
Episode time 44.06
Saved _metrics_

=== Episode 22 ===
Training on [6500/26000] data points
> Train epoch 20 [ensemble -29.22 | reward 0.27]
> Train epoch 40 [ensemble -33.72 | reward 0.16]
> Train epoch 60 [ensemble -36.12 | reward 0.12]
> Train epoch 80 [ensemble -37.74 | reward 0.09]
> Train epoch 100 [ensemble -38.93 | reward 0.07]
Ensemble loss -38.93 / Reward Loss 0.07

=== Collecting data [22] ===
> Step 25 [reward 79.00]
> Step 50 [reward 179.00]
> Step 75 [reward 279.00]
> Step 100 [reward 379.00]
> Step 125 [reward 479.00]
> Step 150 [reward 579.00]
> Step 175 [reward 679.00]
> Step 200 [reward 779.00]
> Step 225 [reward 879.00]
> Step 250 [reward 979.00]
Rewards 979.00 / Steps 250.00
Reward stats:
 {'max': '24.57', 'mean': '5.77', 'min': '-2.74', 'std': '4.00'}
Information gain stats:
 {'max': '1.53', 'mean': '0.93', 'min': '0.39', 'std': '0.14'}
Episode time 45.15
Saved _metrics_

=== Episode 23 ===
Training on [6750/27000] data points
> Train epoch 20 [ensemble -29.81 | reward 0.25]
> Train epoch 40 [ensemble -34.19 | reward 0.15]
> Train epoch 60 [ensemble -36.54 | reward 0.10]
> Train epoch 80 [ensemble -38.11 | reward 0.08]
> Train epoch 100 [ensemble -39.26 | reward 0.07]
Ensemble loss -39.26 / Reward Loss 0.07

=== Collecting data [23] ===
> Step 25 [reward 53.00]
> Step 50 [reward 153.00]
> Step 75 [reward 253.00]
> Step 100 [reward 353.00]
> Step 125 [reward 453.00]
> Step 150 [reward 553.00]
> Step 175 [reward 653.00]
> Step 200 [reward 753.00]
> Step 225 [reward 853.00]
> Step 250 [reward 953.00]
Rewards 953.00 / Steps 250.00
Reward stats:
 {'max': '33.60', 'mean': '8.20', 'min': '-3.64', 'std': '5.42'}
Information gain stats:
 {'max': '1.54', 'mean': '0.92', 'min': '0.36', 'std': '0.15'}
Episode time 46.20
Saved _metrics_

=== Episode 24 ===
Training on [7000/28000] data points
> Train epoch 20 [ensemble -30.10 | reward 0.24]
> Train epoch 40 [ensemble -34.43 | reward 0.14]
> Train epoch 60 [ensemble -36.73 | reward 0.10]
> Train epoch 80 [ensemble -38.29 | reward 0.07]
> Train epoch 100 [ensemble -39.42 | reward 0.06]
Ensemble loss -39.42 / Reward Loss 0.06

=== Collecting data [24] ===
> Step 25 [reward 92.00]
> Step 50 [reward 192.00]
> Step 75 [reward 292.00]
> Step 100 [reward 392.00]
> Step 125 [reward 492.00]
> Step 150 [reward 592.00]
> Step 175 [reward 692.00]
> Step 200 [reward 792.00]
> Step 225 [reward 892.00]
> Step 250 [reward 992.00]
Rewards 992.00 / Steps 250.00
Reward stats:
 {'max': '32.10', 'mean': '8.15', 'min': '-1.55', 'std': '5.15'}
Information gain stats:
 {'max': '1.58', 'mean': '0.93', 'min': '0.36', 'std': '0.15'}
Episode time 47.29
Saved _metrics_

=== Episode 25 ===
Training on [7250/29000] data points
> Train epoch 20 [ensemble -30.53 | reward 0.24]
> Train epoch 40 [ensemble -34.78 | reward 0.14]
> Train epoch 60 [ensemble -37.04 | reward 0.09]
> Train epoch 80 [ensemble -38.55 | reward 0.07]
> Train epoch 100 [ensemble -39.65 | reward 0.06]
Ensemble loss -39.65 / Reward Loss 0.06

=== Collecting data [25] ===
> Step 25 [reward 0.00]
> Step 50 [reward 76.00]
> Step 75 [reward 176.00]
> Step 100 [reward 276.00]
> Step 125 [reward 376.00]
> Step 150 [reward 476.00]
> Step 175 [reward 576.00]
> Step 200 [reward 676.00]
> Step 225 [reward 776.00]
> Step 250 [reward 876.00]
Rewards 876.00 / Steps 250.00
Reward stats:
 {'max': '33.03', 'mean': '7.98', 'min': '-2.58', 'std': '5.67'}
Information gain stats:
 {'max': '1.68', 'mean': '0.96', 'min': '0.39', 'std': '0.17'}
Episode time 48.28
Saved _metrics_

=== Episode 26 ===
Training on [7500/30000] data points
> Train epoch 20 [ensemble -30.95 | reward 0.23]
> Train epoch 40 [ensemble -35.08 | reward 0.13]
> Train epoch 60 [ensemble -37.28 | reward 0.09]
> Train epoch 80 [ensemble -38.77 | reward 0.07]
> Train epoch 100 [ensemble -39.85 | reward 0.06]
Ensemble loss -39.85 / Reward Loss 0.06

=== Collecting data [26] ===
> Step 25 [reward 58.00]
> Step 50 [reward 158.00]
> Step 75 [reward 258.00]
> Step 100 [reward 358.00]
> Step 125 [reward 458.00]
> Step 150 [reward 558.00]
> Step 175 [reward 658.00]
> Step 200 [reward 758.00]
> Step 225 [reward 858.00]
> Step 250 [reward 958.00]
Rewards 958.00 / Steps 250.00
Reward stats:
 {'max': '32.44', 'mean': '9.48', 'min': '-2.02', 'std': '5.54'}
Information gain stats:
 {'max': '1.56', 'mean': '0.94', 'min': '0.38', 'std': '0.16'}
Episode time 49.38
Saved _metrics_

=== Episode 27 ===
Training on [7750/31000] data points
> Train epoch 20 [ensemble -31.25 | reward 0.24]
> Train epoch 40 [ensemble -35.33 | reward 0.14]
> Train epoch 60 [ensemble -37.51 | reward 0.10]
> Train epoch 80 [ensemble -38.96 | reward 0.07]
> Train epoch 100 [ensemble -40.01 | reward 0.06]
Ensemble loss -40.01 / Reward Loss 0.06

=== Collecting data [27] ===
> Step 25 [reward 0.00]
> Step 50 [reward 25.00]
> Step 75 [reward 125.00]
> Step 100 [reward 225.00]
> Step 125 [reward 325.00]
> Step 150 [reward 425.00]
> Step 175 [reward 525.00]
> Step 200 [reward 625.00]
> Step 225 [reward 725.00]
> Step 250 [reward 825.00]
Rewards 825.00 / Steps 250.00
Reward stats:
 {'max': '25.94', 'mean': '4.73', 'min': '-3.82', 'std': '3.87'}
Information gain stats:
 {'max': '1.70', 'mean': '0.98', 'min': '0.41', 'std': '0.14'}
Episode time 50.46
Saved _metrics_

=== Episode 28 ===
Training on [8000/32000] data points
> Train epoch 20 [ensemble -31.57 | reward 0.24]
> Train epoch 40 [ensemble -35.52 | reward 0.14]
> Train epoch 60 [ensemble -37.64 | reward 0.10]
> Train epoch 80 [ensemble -39.06 | reward 0.08]
> Train epoch 100 [ensemble -40.10 | reward 0.06]
Ensemble loss -40.10 / Reward Loss 0.06

=== Collecting data [28] ===
> Step 25 [reward 58.00]
> Step 50 [reward 158.00]
> Step 75 [reward 258.00]
> Step 100 [reward 358.00]
> Step 125 [reward 458.00]
> Step 150 [reward 558.00]
> Step 175 [reward 658.00]
> Step 200 [reward 758.00]
> Step 225 [reward 858.00]
> Step 250 [reward 958.00]
Rewards 958.00 / Steps 250.00
Reward stats:
 {'max': '32.85', 'mean': '8.56', 'min': '-1.97', 'std': '5.43'}
Information gain stats:
 {'max': '1.62', 'mean': '0.95', 'min': '0.38', 'std': '0.15'}
Episode time 51.52
Saved _metrics_

=== Episode 29 ===
Training on [8250/33000] data points
> Train epoch 20 [ensemble -31.81 | reward 0.22]
> Train epoch 40 [ensemble -35.74 | reward 0.12]
> Train epoch 60 [ensemble -37.85 | reward 0.09]
> Train epoch 80 [ensemble -39.26 | reward 0.07]
> Train epoch 100 [ensemble -40.28 | reward 0.05]
Ensemble loss -40.28 / Reward Loss 0.05

=== Collecting data [29] ===
> Step 25 [reward 45.00]
> Step 50 [reward 145.00]
> Step 75 [reward 245.00]
> Step 100 [reward 345.00]
> Step 125 [reward 445.00]
> Step 150 [reward 545.00]
> Step 175 [reward 645.00]
> Step 200 [reward 745.00]
> Step 225 [reward 845.00]
> Step 250 [reward 945.00]
Rewards 945.00 / Steps 250.00
Reward stats:
 {'max': '29.81', 'mean': '6.46', 'min': '-1.71', 'std': '4.43'}
Information gain stats:
 {'max': '1.57', 'mean': '0.97', 'min': '0.40', 'std': '0.15'}
Episode time 52.63
Saved _metrics_

=== Episode 30 ===
Training on [8500/34000] data points
> Train epoch 20 [ensemble -32.18 | reward 0.22]
> Train epoch 40 [ensemble -36.06 | reward 0.13]
> Train epoch 60 [ensemble -38.12 | reward 0.09]
> Train epoch 80 [ensemble -39.47 | reward 0.07]
> Train epoch 100 [ensemble -40.45 | reward 0.05]
Ensemble loss -40.45 / Reward Loss 0.05

=== Collecting data [30] ===
> Step 25 [reward 48.00]
> Step 50 [reward 148.00]
> Step 75 [reward 248.00]
> Step 100 [reward 348.00]
> Step 125 [reward 448.00]
> Step 150 [reward 548.00]
> Step 175 [reward 648.00]
> Step 200 [reward 748.00]
> Step 225 [reward 848.00]
> Step 250 [reward 948.00]
Rewards 948.00 / Steps 250.00
Reward stats:
 {'max': '33.92', 'mean': '8.73', 'min': '-2.78', 'std': '6.17'}
Information gain stats:
 {'max': '1.61', 'mean': '0.94', 'min': '0.38', 'std': '0.16'}
Episode time 53.68
Saved _metrics_

=== Episode 31 ===
Training on [8750/35000] data points
> Train epoch 20 [ensemble -32.47 | reward 0.22]
> Train epoch 40 [ensemble -36.27 | reward 0.13]
> Train epoch 60 [ensemble -38.31 | reward 0.09]
> Train epoch 80 [ensemble -39.65 | reward 0.07]
> Train epoch 100 [ensemble -40.62 | reward 0.05]
Ensemble loss -40.62 / Reward Loss 0.05

=== Collecting data [31] ===
> Step 25 [reward 59.00]
> Step 50 [reward 159.00]
> Step 75 [reward 259.00]
> Step 100 [reward 359.00]
> Step 125 [reward 459.00]
> Step 150 [reward 559.00]
> Step 175 [reward 659.00]
> Step 200 [reward 759.00]
> Step 225 [reward 859.00]
> Step 250 [reward 959.00]
Rewards 959.00 / Steps 250.00
Reward stats:
 {'max': '32.02', 'mean': '7.77', 'min': '-2.65', 'std': '5.30'}
Information gain stats:
 {'max': '1.63', 'mean': '0.96', 'min': '0.40', 'std': '0.16'}
Episode time 54.76
Saved _metrics_

=== Episode 32 ===
Training on [9000/36000] data points
> Train epoch 20 [ensemble -32.73 | reward 0.22]
> Train epoch 40 [ensemble -36.45 | reward 0.13]
> Train epoch 60 [ensemble -38.42 | reward 0.09]
> Train epoch 80 [ensemble -39.73 | reward 0.07]
> Train epoch 100 [ensemble -40.68 | reward 0.06]
Ensemble loss -40.68 / Reward Loss 0.06

=== Collecting data [32] ===
> Step 25 [reward 46.00]
> Step 50 [reward 146.00]
> Step 75 [reward 246.00]
> Step 100 [reward 346.00]
> Step 125 [reward 446.00]
> Step 150 [reward 546.00]
> Step 175 [reward 646.00]
> Step 200 [reward 746.00]
> Step 225 [reward 846.00]
> Step 250 [reward 946.00]
Rewards 946.00 / Steps 250.00
Reward stats:
 {'max': '28.49', 'mean': '6.04', 'min': '-2.28', 'std': '4.62'}
Information gain stats:
 {'max': '1.58', 'mean': '0.98', 'min': '0.43', 'std': '0.15'}
Episode time 55.97
Saved _metrics_

=== Episode 33 ===
Training on [9250/37000] data points
> Train epoch 20 [ensemble -33.08 | reward 0.21]
> Train epoch 40 [ensemble -36.73 | reward 0.12]
> Train epoch 60 [ensemble -38.67 | reward 0.08]
> Train epoch 80 [ensemble -39.94 | reward 0.06]
> Train epoch 100 [ensemble -40.86 | reward 0.05]
Ensemble loss -40.86 / Reward Loss 0.05

=== Collecting data [33] ===
> Step 25 [reward 58.00]
> Step 50 [reward 158.00]
> Step 75 [reward 258.00]
> Step 100 [reward 358.00]
> Step 125 [reward 458.00]
> Step 150 [reward 558.00]
> Step 175 [reward 658.00]
> Step 200 [reward 758.00]
> Step 225 [reward 858.00]
> Step 250 [reward 958.00]
Rewards 958.00 / Steps 250.00
Reward stats:
 {'max': '35.23', 'mean': '9.47', 'min': '-2.24', 'std': '6.23'}
Information gain stats:
 {'max': '1.64', 'mean': '0.96', 'min': '0.40', 'std': '0.16'}
Episode time 56.97
Saved _metrics_

=== Episode 34 ===
Training on [9500/38000] data points
> Train epoch 20 [ensemble -33.39 | reward 0.19]
> Train epoch 40 [ensemble -36.95 | reward 0.11]
> Train epoch 60 [ensemble -38.84 | reward 0.08]
> Train epoch 80 [ensemble -40.10 | reward 0.06]
> Train epoch 100 [ensemble -41.02 | reward 0.05]
Ensemble loss -41.02 / Reward Loss 0.05

=== Collecting data [34] ===
> Step 25 [reward 39.00]
> Step 50 [reward 139.00]
> Step 75 [reward 239.00]
> Step 100 [reward 339.00]
> Step 125 [reward 439.00]
> Step 150 [reward 539.00]
> Step 175 [reward 639.00]
> Step 200 [reward 739.00]
> Step 225 [reward 839.00]
> Step 250 [reward 939.00]
Rewards 939.00 / Steps 250.00
Reward stats:
 {'max': '29.36', 'mean': '6.91', 'min': '-2.67', 'std': '5.02'}
Information gain stats:
 {'max': '1.59', 'mean': '1.00', 'min': '0.35', 'std': '0.16'}
Episode time 57.91
Saved _metrics_

=== Episode 35 ===
Training on [9750/39000] data points
> Train epoch 20 [ensemble -33.62 | reward 0.21]
> Train epoch 40 [ensemble -37.12 | reward 0.12]
> Train epoch 60 [ensemble -38.99 | reward 0.08]
> Train epoch 80 [ensemble -40.22 | reward 0.06]
> Train epoch 100 [ensemble -41.11 | reward 0.05]
Ensemble loss -41.11 / Reward Loss 0.05

=== Collecting data [35] ===
> Step 25 [reward 54.00]
> Step 50 [reward 154.00]
> Step 75 [reward 254.00]
> Step 100 [reward 354.00]
> Step 125 [reward 454.00]
> Step 150 [reward 554.00]
> Step 175 [reward 654.00]
> Step 200 [reward 754.00]
> Step 225 [reward 854.00]
> Step 250 [reward 954.00]
Rewards 954.00 / Steps 250.00
Reward stats:
 {'max': '33.32', 'mean': '7.61', 'min': '-3.45', 'std': '5.49'}
Information gain stats:
 {'max': '1.61', 'mean': '0.98', 'min': '0.30', 'std': '0.16'}
Episode time 59.04
Saved _metrics_

=== Episode 36 ===
Training on [10000/40000] data points
> Train epoch 20 [ensemble -33.93 | reward 0.19]
> Train epoch 40 [ensemble -37.36 | reward 0.11]
> Train epoch 60 [ensemble -39.19 | reward 0.08]
> Train epoch 80 [ensemble -40.38 | reward 0.06]
> Train epoch 100 [ensemble -41.25 | reward 0.05]
Ensemble loss -41.25 / Reward Loss 0.05

=== Collecting data [36] ===
> Step 25 [reward 90.00]
> Step 50 [reward 190.00]
> Step 75 [reward 290.00]
> Step 100 [reward 390.00]
> Step 125 [reward 490.00]
> Step 150 [reward 590.00]
> Step 175 [reward 690.00]
> Step 200 [reward 790.00]
> Step 225 [reward 890.00]
> Step 250 [reward 990.00]
Rewards 990.00 / Steps 250.00
Reward stats:
 {'max': '33.31', 'mean': '8.87', 'min': '-2.13', 'std': '5.47'}
Information gain stats:
 {'max': '1.62', 'mean': '0.97', 'min': '0.34', 'std': '0.17'}
Episode time 60.26
Saved _metrics_

=== Episode 37 ===
Training on [10250/41000] data points
> Train epoch 20 [ensemble -34.01 | reward 0.19]
> Train epoch 40 [ensemble -37.42 | reward 0.11]
> Train epoch 60 [ensemble -39.24 | reward 0.08]
> Train epoch 80 [ensemble -40.44 | reward 0.06]
> Train epoch 100 [ensemble -41.32 | reward 0.05]
Ensemble loss -41.32 / Reward Loss 0.05

=== Collecting data [37] ===
> Step 25 [reward 96.00]
> Step 50 [reward 196.00]
> Step 75 [reward 296.00]
> Step 100 [reward 396.00]
> Step 125 [reward 496.00]
> Step 150 [reward 596.00]
> Step 175 [reward 696.00]
> Step 200 [reward 796.00]
> Step 225 [reward 896.00]
> Step 250 [reward 996.00]
Rewards 996.00 / Steps 250.00
Reward stats:
 {'max': '30.50', 'mean': '8.29', 'min': '-3.75', 'std': '5.01'}
Information gain stats:
 {'max': '1.64', 'mean': '0.98', 'min': '0.38', 'std': '0.17'}
Episode time 61.28
Saved _metrics_

=== Episode 38 ===
Training on [10500/42000] data points
> Train epoch 20 [ensemble -34.24 | reward 0.18]
> Train epoch 40 [ensemble -37.61 | reward 0.11]
> Train epoch 60 [ensemble -39.38 | reward 0.07]
> Train epoch 80 [ensemble -40.55 | reward 0.06]
> Train epoch 100 [ensemble -41.40 | reward 0.05]
Ensemble loss -41.40 / Reward Loss 0.05

=== Collecting data [38] ===
> Step 25 [reward 96.00]
> Step 50 [reward 196.00]
> Step 75 [reward 296.00]
> Step 100 [reward 396.00]
> Step 125 [reward 496.00]
> Step 150 [reward 596.00]
> Step 175 [reward 696.00]
> Step 200 [reward 796.00]
> Step 225 [reward 896.00]
> Step 250 [reward 996.00]
Rewards 996.00 / Steps 250.00
Reward stats:
 {'max': '38.37', 'mean': '9.81', 'min': '-0.36', 'std': '5.96'}
Information gain stats:
 {'max': '1.67', 'mean': '0.96', 'min': '0.36', 'std': '0.17'}
Episode time 62.28
Saved _metrics_

=== Episode 39 ===
Training on [10750/43000] data points
> Train epoch 20 [ensemble -34.56 | reward 0.18]
> Train epoch 40 [ensemble -37.85 | reward 0.10]
> Train epoch 60 [ensemble -39.60 | reward 0.07]
> Train epoch 80 [ensemble -40.74 | reward 0.06]
> Train epoch 100 [ensemble -41.58 | reward 0.05]
Ensemble loss -41.58 / Reward Loss 0.05

=== Collecting data [39] ===
> Step 25 [reward 57.00]
> Step 50 [reward 157.00]
> Step 75 [reward 257.00]
> Step 100 [reward 357.00]
> Step 125 [reward 457.00]
> Step 150 [reward 557.00]
> Step 175 [reward 657.00]
> Step 200 [reward 757.00]
> Step 225 [reward 857.00]
> Step 250 [reward 957.00]
Rewards 957.00 / Steps 250.00
Reward stats:
 {'max': '35.30', 'mean': '9.60', 'min': '-4.75', 'std': '6.65'}
Information gain stats:
 {'max': '1.66', 'mean': '0.97', 'min': '0.34', 'std': '0.18'}
Episode time 63.42
Saved _metrics_

=== Episode 40 ===
Training on [11000/44000] data points
> Train epoch 20 [ensemble -34.75 | reward 0.18]
> Train epoch 40 [ensemble -37.98 | reward 0.10]
> Train epoch 60 [ensemble -39.70 | reward 0.07]
> Train epoch 80 [ensemble -40.84 | reward 0.05]
> Train epoch 100 [ensemble -41.67 | reward 0.04]
Ensemble loss -41.67 / Reward Loss 0.04

=== Collecting data [40] ===
> Step 25 [reward 97.00]
> Step 50 [reward 197.00]
> Step 75 [reward 297.00]
> Step 100 [reward 397.00]
> Step 125 [reward 497.00]
> Step 150 [reward 597.00]
> Step 175 [reward 697.00]
> Step 200 [reward 797.00]
> Step 225 [reward 897.00]
> Step 250 [reward 997.00]
Rewards 997.00 / Steps 250.00
Reward stats:
 {'max': '33.28', 'mean': '9.26', 'min': '-1.65', 'std': '5.39'}
Information gain stats:
 {'max': '1.65', 'mean': '0.98', 'min': '0.38', 'std': '0.17'}
Episode time 64.54
Saved _metrics_

=== Episode 41 ===
Training on [11250/45000] data points
> Train epoch 20 [ensemble -35.04 | reward 0.17]
> Train epoch 40 [ensemble -38.23 | reward 0.09]
> Train epoch 60 [ensemble -39.91 | reward 0.07]
> Train epoch 80 [ensemble -41.01 | reward 0.05]
> Train epoch 100 [ensemble -41.82 | reward 0.04]
Ensemble loss -41.82 / Reward Loss 0.04

=== Collecting data [41] ===
> Step 25 [reward 56.00]
> Step 50 [reward 156.00]
> Step 75 [reward 256.00]
> Step 100 [reward 356.00]
> Step 125 [reward 456.00]
> Step 150 [reward 556.00]
> Step 175 [reward 656.00]
> Step 200 [reward 756.00]
> Step 225 [reward 856.00]
> Step 250 [reward 956.00]
Rewards 956.00 / Steps 250.00
Reward stats:
 {'max': '35.65', 'mean': '8.85', 'min': '-1.20', 'std': '5.89'}
Information gain stats:
 {'max': '1.69', 'mean': '1.00', 'min': '0.38', 'std': '0.17'}
Episode time 65.64
Saved _metrics_

=== Episode 42 ===
Training on [11500/46000] data points
> Train epoch 20 [ensemble -35.32 | reward 0.15]
> Train epoch 40 [ensemble -38.42 | reward 0.08]
> Train epoch 60 [ensemble -40.06 | reward 0.06]
> Train epoch 80 [ensemble -41.14 | reward 0.05]
> Train epoch 100 [ensemble -41.93 | reward 0.04]
Ensemble loss -41.93 / Reward Loss 0.04

=== Collecting data [42] ===
> Step 25 [reward 58.00]
> Step 50 [reward 158.00]
> Step 75 [reward 258.00]
> Step 100 [reward 358.00]
> Step 125 [reward 458.00]
> Step 150 [reward 558.00]
> Step 175 [reward 658.00]
> Step 200 [reward 758.00]
> Step 225 [reward 858.00]
> Step 250 [reward 958.00]
Rewards 958.00 / Steps 250.00
Reward stats:
 {'max': '30.20', 'mean': '8.37', 'min': '-2.10', 'std': '5.17'}
Information gain stats:
 {'max': '1.66', 'mean': '0.99', 'min': '0.36', 'std': '0.17'}
Episode time 66.64
Saved _metrics_

=== Episode 43 ===
Training on [11750/47000] data points
> Train epoch 20 [ensemble -35.49 | reward 0.17]
> Train epoch 40 [ensemble -38.58 | reward 0.09]
> Train epoch 60 [ensemble -40.19 | reward 0.06]
> Train epoch 80 [ensemble -41.25 | reward 0.05]
> Train epoch 100 [ensemble -42.03 | reward 0.04]
Ensemble loss -42.03 / Reward Loss 0.04

=== Collecting data [43] ===
> Step 25 [reward 20.00]
> Step 50 [reward 120.00]
> Step 75 [reward 220.00]
> Step 100 [reward 320.00]
> Step 125 [reward 420.00]
> Step 150 [reward 520.00]
> Step 175 [reward 620.00]
> Step 200 [reward 720.00]
> Step 225 [reward 820.00]
> Step 250 [reward 920.00]
Rewards 920.00 / Steps 250.00
Reward stats:
 {'max': '36.76', 'mean': '8.64', 'min': '-2.74', 'std': '6.16'}
Information gain stats:
 {'max': '1.66', 'mean': '0.98', 'min': '0.34', 'std': '0.17'}
Episode time 67.65
Saved _metrics_

=== Episode 44 ===
Training on [12000/48000] data points
> Train epoch 20 [ensemble -35.63 | reward 0.17]
> Train epoch 40 [ensemble -38.67 | reward 0.09]
> Train epoch 60 [ensemble -40.27 | reward 0.06]
> Train epoch 80 [ensemble -41.32 | reward 0.05]
> Train epoch 100 [ensemble -42.08 | reward 0.04]
Ensemble loss -42.08 / Reward Loss 0.04

=== Collecting data [44] ===
> Step 25 [reward 91.00]
> Step 50 [reward 191.00]
> Step 75 [reward 291.00]
> Step 100 [reward 391.00]
> Step 125 [reward 491.00]
> Step 150 [reward 591.00]
> Step 175 [reward 691.00]
> Step 200 [reward 791.00]
> Step 225 [reward 891.00]
> Step 250 [reward 991.00]
Rewards 991.00 / Steps 250.00
Reward stats:
 {'max': '40.09', 'mean': '10.18', 'min': '-1.27', 'std': '6.58'}
Information gain stats:
 {'max': '1.62', 'mean': '1.00', 'min': '0.33', 'std': '0.18'}
Episode time 68.60
Saved _metrics_

=== Episode 45 ===
Training on [12250/49000] data points
> Train epoch 20 [ensemble -35.87 | reward 0.15]
> Train epoch 40 [ensemble -38.86 | reward 0.08]
> Train epoch 60 [ensemble -40.42 | reward 0.06]
> Train epoch 80 [ensemble -41.45 | reward 0.04]
> Train epoch 100 [ensemble -42.21 | reward 0.04]
Ensemble loss -42.21 / Reward Loss 0.04

=== Collecting data [45] ===
> Step 25 [reward 96.00]
> Step 50 [reward 196.00]
> Step 75 [reward 296.00]
> Step 100 [reward 396.00]
> Step 125 [reward 496.00]
> Step 150 [reward 596.00]
> Step 175 [reward 696.00]
> Step 200 [reward 796.00]
> Step 225 [reward 896.00]
> Step 250 [reward 996.00]
Rewards 996.00 / Steps 250.00
Reward stats:
 {'max': '39.31', 'mean': '11.15', 'min': '-0.49', 'std': '6.52'}
Information gain stats:
 {'max': '1.67', 'mean': '0.99', 'min': '0.35', 'std': '0.18'}
Episode time 69.82
Saved _metrics_

=== Episode 46 ===
Training on [12500/50000] data points
> Train epoch 20 [ensemble -36.03 | reward 0.15]
> Train epoch 40 [ensemble -38.99 | reward 0.08]
> Train epoch 60 [ensemble -40.53 | reward 0.06]
> Train epoch 80 [ensemble -41.54 | reward 0.04]
> Train epoch 100 [ensemble -42.28 | reward 0.04]
Ensemble loss -42.28 / Reward Loss 0.04

=== Collecting data [46] ===
> Step 25 [reward 60.00]
> Step 50 [reward 160.00]
> Step 75 [reward 260.00]
> Step 100 [reward 360.00]
> Step 125 [reward 460.00]
> Step 150 [reward 560.00]
> Step 175 [reward 660.00]
> Step 200 [reward 760.00]
> Step 225 [reward 860.00]
> Step 250 [reward 960.00]
Rewards 960.00 / Steps 250.00
Reward stats:
 {'max': '38.45', 'mean': '10.60', 'min': '-1.72', 'std': '6.48'}
Information gain stats:
 {'max': '1.71', 'mean': '0.99', 'min': '0.32', 'std': '0.18'}
Episode time 70.80
Saved _metrics_

=== Episode 47 ===
Training on [12750/51000] data points
> Train epoch 20 [ensemble -36.21 | reward 0.14]
> Train epoch 40 [ensemble -39.11 | reward 0.08]
> Train epoch 60 [ensemble -40.62 | reward 0.05]
> Train epoch 80 [ensemble -41.62 | reward 0.04]
> Train epoch 100 [ensemble -42.35 | reward 0.03]
Ensemble loss -42.35 / Reward Loss 0.03

=== Collecting data [47] ===
> Step 25 [reward 0.00]
> Step 50 [reward 0.00]
> Step 75 [reward 35.00]
> Step 100 [reward 135.00]
> Step 125 [reward 235.00]
> Step 150 [reward 335.00]
> Step 175 [reward 435.00]
> Step 200 [reward 535.00]
> Step 225 [reward 635.00]
> Step 250 [reward 735.00]
Rewards 735.00 / Steps 250.00
Reward stats:
 {'max': '41.38', 'mean': '7.58', 'min': '-4.54', 'std': '7.05'}
Information gain stats:
 {'max': '1.75', 'mean': '1.01', 'min': '0.34', 'std': '0.18'}
Episode time 71.93
Saved _metrics_

=== Episode 48 ===
Training on [13000/52000] data points
> Train epoch 20 [ensemble -36.26 | reward 0.16]
> Train epoch 40 [ensemble -39.16 | reward 0.09]
> Train epoch 60 [ensemble -40.68 | reward 0.06]
> Train epoch 80 [ensemble -41.67 | reward 0.05]
> Train epoch 100 [ensemble -42.40 | reward 0.04]
Ensemble loss -42.40 / Reward Loss 0.04

=== Collecting data [48] ===
> Step 25 [reward 90.00]
> Step 50 [reward 190.00]
> Step 75 [reward 290.00]
> Step 100 [reward 390.00]
> Step 125 [reward 490.00]
> Step 150 [reward 590.00]
> Step 175 [reward 690.00]
> Step 200 [reward 790.00]
> Step 225 [reward 890.00]
> Step 250 [reward 990.00]
Rewards 990.00 / Steps 250.00
Reward stats:
 {'max': '33.70', 'mean': '8.89', 'min': '-1.09', 'std': '5.64'}
Information gain stats:
 {'max': '1.74', 'mean': '1.01', 'min': '0.35', 'std': '0.18'}
Episode time 72.98
Saved _metrics_

=== Episode 49 ===
Training on [13250/53000] data points
> Train epoch 20 [ensemble -36.48 | reward 0.15]
> Train epoch 40 [ensemble -39.31 | reward 0.08]
> Train epoch 60 [ensemble -40.79 | reward 0.06]
> Train epoch 80 [ensemble -41.76 | reward 0.04]
> Train epoch 100 [ensemble -42.47 | reward 0.03]
Ensemble loss -42.47 / Reward Loss 0.03

=== Collecting data [49] ===
> Step 25 [reward 89.00]
> Step 50 [reward 189.00]
> Step 75 [reward 289.00]
> Step 100 [reward 389.00]
> Step 125 [reward 489.00]
> Step 150 [reward 589.00]
> Step 175 [reward 689.00]
> Step 200 [reward 789.00]
> Step 225 [reward 889.00]
> Step 250 [reward 989.00]
Rewards 989.00 / Steps 250.00
Reward stats:
 {'max': '39.37', 'mean': '10.06', 'min': '-1.67', 'std': '6.43'}
Information gain stats:
 {'max': '1.67', 'mean': '0.99', 'min': '0.32', 'std': '0.19'}
Episode time 74.37
Saved _metrics_